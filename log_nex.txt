2021-04-13 00:18:40,595 maskrcnn_benchmark INFO: Using 8 GPUs
2021-04-13 00:18:40,596 maskrcnn_benchmark INFO: Namespace(config_file='configs/mmss_v07.yaml', distributed=True, local_rank=0, opts=['OUTPUT_DIR', '/mnt/lustre/lixiangtai/runs/vltrain_02'], skip_test=False)
2021-04-13 00:18:40,596 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2021-04-13 00:19:21,025 maskrcnn_benchmark INFO: 
PyTorch version: 1.4.0
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: CentOS Linux 7 (Core)
GCC version: (GCC) 5.4.0
CMake version: version 3.14.0

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: Tesla V100-SXM2-32GB
GPU 1: Tesla V100-SXM2-32GB
GPU 2: Tesla V100-SXM2-32GB
GPU 3: Tesla V100-SXM2-32GB
GPU 4: Tesla V100-SXM2-32GB
GPU 5: Tesla V100-SXM2-32GB
GPU 6: Tesla V100-SXM2-32GB
GPU 7: Tesla V100-SXM2-32GB

Nvidia driver version: 418.67
cuDNN version: /usr/local/cuda-9.0/lib64/libcudnn.so.7.0.4

Versions of relevant libraries:
[pip] numpy==1.17.5
[pip] torch==1.4.0
[pip] torchvision==0.5.0
[conda] magma-cuda101             2.5.2                         1    <unknown>
[conda] mkl                       2020.1                      217  
[conda] mkl-include               2020.1                      217  
[conda] torch                     1.4.0                    pypi_0    pypi
[conda] torchvision               0.5.0                    pypi_0    pypi
        Pillow (7.1.2)
2021-04-13 00:19:21,076 maskrcnn_benchmark INFO: Loaded configuration file configs/mmss_v07.yaml
2021-04-13 00:19:21,076 maskrcnn_benchmark INFO: 
MODEL:
  # This is what indicates we want image-caption training not object detection
  META_ARCHITECTURE: "MMSS-GCNN"
  # URL to the initial weights, trained for imagenet classification
  WEIGHT: "/mnt/lustre/lixiangtai/pretrained/R-50.pkl"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
  BACKBONE:
    # a full resnet, including stem and 4 blocks
    CONV_BODY: "R-50-C5"
    # don't freeze any layer, train everything
    FREEZE_CONV_BODY_AT: 0
  LANGUAGE_BACKBONE:
    # make a BERT model to process captions
    TYPE: "BERT-Base"
    # and freeze it (loaded from original pretrained bert of huggingface)
    FREEZE: True
  MMSS_HEAD:
    # We want both a grounding head and a transformer head on top of image and caption,
    # each of which defines its own objective functions.
    TYPES: ("GroundingHead", "TransformerHead")
    DEFAULT_HEAD: "GroundingHead"
    # Share the weights of the vision to language projection between the two heads. 
    # Use the one on the grounding head because that is the default (see above)
    TIE_VL_PROJECTION_WEIGHTS: True
    # Randomly keep up to 100 visual regions from each image. This is to save memory.
    SPATIAL_DROPOUT: 100
    GROUNDING:
      # Use dot product for grounding. This could be cosine or euclidean too.
      LOCAL_METRIC: "dot"
      # After aligning words to regions, sum the local distances to compute global distance.
      GLOBAL_METRIC: "aligned_local"
      # Use softmax to softly align each word to regions, and vice versa. 
      # This could be for instance hardmax, which aligns to the most similar
      ALIGNMENT: "softmax"
      # Typical good values are 100.0 for euclidean, 10.0 for dot, 0.01 for cosine
      ALIGNMENT_TEMPERATURE: 10.0
      # This loss is to choose the right caption out of all captions in the batch, 
      # And similarly choose the right image. Could be triplet loss instead.
      LOSS: "cross_entropy"
      # Whether to find a region for each word
      ALIGN_WORDS_TO_REGIONS: True
      # Whether to find a word for a region
      # At least one of these two should be True
      ALIGN_REGIONS_TO_WORDS: True
    TRANSFORMER:
      # Whether to perform masked language modeling (randomly mask words from captions
      # and have the model reconstruct them)
      MASKED_LANGUAGE_MODELING: True
      # Whether to do that during validation as well. That is not good if you want to
      # measure image-caption matching scores.
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      # For now this is not implemented, so keep it False and ''
      MASKED_VISUAL_MODELING: False
      MVM_LOSS: ''
      # For Multimedia Matching loss, cross-entropy works just like in the grounding head
      MMM_LOSS: 'cross_entropy'
      # Typical BERT configs as in Huggingface
      BERT_CONFIG:
        num_hidden_layers: 6
        num_attention_heads: 8
        intermediate_size: 768
DATASETS:
  TRAIN: ("coco_captions_train",)
  TEST: ("coco_captions_val",)
  DATASET_CLASS: "COCOCaptionsDataset"
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS: (20000, 35000)
  MAX_ITER: 40000
  IMS_PER_BATCH: 64
  TEST_PERIOD: 1000
  CHECKPOINT_PERIOD: 1000
  LOG_PERIOD: 100
  CLIP_GRAD_NORM_AT: 5.0
  # A value of more than one means accumulate gradients for several batches before updating
  GRADIENT_ACCUMULATION_STEPS: 1
  # If true, it calls model.train() before computing validation loss. Needed for some models.
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
TEST:
  DO_EVAL: False
  IMS_PER_BATCH: 64
  
2021-04-13 00:19:21,092 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DROP_LAST: False
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 0
DATASETS:
  DATASET_ARGS:
    EMB_DIM: 300
    EMB_KEY: GloVE
    LOAD_EMBEDDINGS: False
    MULTI_LABEL_MODE: False
  DATASET_CLASS: COCOCaptionsDataset
  TEST: ('coco_captions_val',)
  TRAIN: ('coco_captions_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-50-C5
    FREEZE_CONV_BODY_AT: 0
  BACKBONE_PREFIX: 
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    ADD_POSITION_EMBEDDING: False
    EMBEDDING_PATH: 
    FREEZE: True
    TYPE: BERT-Base
  LOAD_CLASSIFIER: True
  LOAD_EMB_PRED_FROM_MMSS_HEAD: False
  LOAD_TRAINER_STATE: True
  MASK_ON: False
  META_ARCHITECTURE: MMSS-GCNN
  MMSS_HEAD:
    DEFAULT_HEAD: GroundingHead
    GROUNDING:
      ALIGNMENT: softmax
      ALIGNMENT_TEMPERATURE: 10.0
      ALIGN_REGIONS_TO_WORDS: True
      ALIGN_WORDS_TO_REGIONS: True
      GLOBAL_METRIC: aligned_local
      LOCAL_METRIC: dot
      LOSS: cross_entropy
      NEGATIVE_MINING: random
      TRIPLET_MARGIN: 1.0
    SPATIAL_DROPOUT: 100
    TIE_VL_PROJECTION_WEIGHTS: True
    TRANSFORMER:
      BERT_CONFIG:
        attention_probs_dropout_prob: 0.1
        gradient_checkpointing: False
        hidden_act: gelu
        hidden_dropout_prob: 0.1
        hidden_size: 768
        initializer_range: 0.02
        intermediate_size: 768
        layer_norm_eps: 1e-12
        max_position_embeddings: 512
        num_attention_heads: 8
        num_hidden_layers: 6
        pad_token_id: 0
        type_vocab_size: 2
        vocab_size: 30522
      MASKED_LANGUAGE_MODELING: True
      MASKED_LANGUAGE_MODELING_PROB: 0.15
      MASKED_LANGUAGE_MODELING_PROB_MASK: 0.9
      MASKED_LANGUAGE_MODELING_PROB_NOISE: 0.0
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      MASKED_VISUAL_MODELING: False
      MMM_LOSS: cross_entropy
      MVM_LOSS: 
      MVM_LOSS_NUM_NEGATIVE: 128
    TYPES: ('GroundingHead', 'TransformerHead')
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    EMBEDDING_BASED: False
    EMB_DIM: 300
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    FREEZE_EMB_PRED: False
    FREEZE_FEATURE_EXTRACTOR: False
    LOSS_WEIGHT_BACKGROUND: 1.0
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
    WSDDN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    DONT_TRAIN: False
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  WEIGHT: /mnt/lustre/lixiangtai/pretrained/R-50.pkl
OUTPUT_DIR: /mnt/lustre/lixiangtai/runs/vltrain_02
PATHS_CATALOG: /mnt/lustre/lixiangtai/project/ovr-cnn/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 1000
  CLIP_GRAD_NORM_AT: 5.0
  GAMMA: 0.1
  GRADIENT_ACCUMULATION_STEPS: 1
  IMS_PER_BATCH: 64
  LOG_PERIOD: 100
  MAX_ITER: 40000
  MOMENTUM: 0.9
  SKIP_VAL_LOSS: False
  STEPS: (20000, 35000)
  TEST_PERIOD: 1000
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  DO_EVAL: False
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 64
2021-04-13 00:19:21,093 maskrcnn_benchmark INFO: Saving config into: /mnt/lustre/lixiangtai/runs/vltrain_02/config.yml
2021-04-13 00:19:32,476 maskrcnn_benchmark.make_optimizer INFO: The following parameters will be trained: 
2021-04-13 00:19:32,476 maskrcnn_benchmark.make_optimizer INFO: backbone.body.stem.conv1.weight
2021-04-13 00:19:32,476 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.downsample.0.weight
2021-04-13 00:19:32,477 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv1.weight
2021-04-13 00:19:32,477 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv2.weight
2021-04-13 00:19:32,477 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv3.weight
2021-04-13 00:19:32,477 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv1.weight
2021-04-13 00:19:32,477 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv2.weight
2021-04-13 00:19:32,477 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv3.weight
2021-04-13 00:19:32,478 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv1.weight
2021-04-13 00:19:32,478 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv2.weight
2021-04-13 00:19:32,478 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv3.weight
2021-04-13 00:19:32,478 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.downsample.0.weight
2021-04-13 00:19:32,478 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv1.weight
2021-04-13 00:19:32,478 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv2.weight
2021-04-13 00:19:32,478 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv3.weight
2021-04-13 00:19:32,479 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv1.weight
2021-04-13 00:19:32,479 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv2.weight
2021-04-13 00:19:32,479 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv3.weight
2021-04-13 00:19:32,479 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv1.weight
2021-04-13 00:19:32,479 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv2.weight
2021-04-13 00:19:32,479 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv3.weight
2021-04-13 00:19:32,479 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv1.weight
2021-04-13 00:19:32,480 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv2.weight
2021-04-13 00:19:32,480 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv3.weight
2021-04-13 00:19:32,480 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.downsample.0.weight
2021-04-13 00:19:32,480 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv1.weight
2021-04-13 00:19:32,480 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv2.weight
2021-04-13 00:19:32,480 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv3.weight
2021-04-13 00:19:32,480 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv1.weight
2021-04-13 00:19:32,481 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv2.weight
2021-04-13 00:19:32,481 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv3.weight
2021-04-13 00:19:32,481 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv1.weight
2021-04-13 00:19:32,481 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv2.weight
2021-04-13 00:19:32,481 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv3.weight
2021-04-13 00:19:32,481 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv1.weight
2021-04-13 00:19:32,482 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv2.weight
2021-04-13 00:19:32,482 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv3.weight
2021-04-13 00:19:32,482 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv1.weight
2021-04-13 00:19:32,482 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv2.weight
2021-04-13 00:19:32,482 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv3.weight
2021-04-13 00:19:32,482 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv1.weight
2021-04-13 00:19:32,483 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv2.weight
2021-04-13 00:19:32,483 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv3.weight
2021-04-13 00:19:32,483 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.downsample.0.weight
2021-04-13 00:19:32,483 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv1.weight
2021-04-13 00:19:32,483 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv2.weight
2021-04-13 00:19:32,483 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv3.weight
2021-04-13 00:19:32,483 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv1.weight
2021-04-13 00:19:32,483 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv2.weight
2021-04-13 00:19:32,483 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv3.weight
2021-04-13 00:19:32,484 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv1.weight
2021-04-13 00:19:32,484 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv2.weight
2021-04-13 00:19:32,484 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv3.weight
2021-04-13 00:19:32,485 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.GroundingHead.v2l_projection.weight
2021-04-13 00:19:32,485 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.GroundingHead.v2l_projection.bias
2021-04-13 00:19:32,485 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_embeddings.weight
2021-04-13 00:19:32,485 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_embeddings.bias
2021-04-13 00:19:32,485 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_location_embeddings.weight
2021-04-13 00:19:32,485 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_location_embeddings.bias
2021-04-13 00:19:32,486 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.LayerNorm.weight
2021-04-13 00:19:32,486 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.LayerNorm.bias
2021-04-13 00:19:32,486 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.weight
2021-04-13 00:19:32,486 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.bias
2021-04-13 00:19:32,486 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.weight
2021-04-13 00:19:32,486 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.bias
2021-04-13 00:19:32,486 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.weight
2021-04-13 00:19:32,486 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.bias
2021-04-13 00:19:32,487 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.weight
2021-04-13 00:19:32,487 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.bias
2021-04-13 00:19:32,487 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.weight
2021-04-13 00:19:32,487 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.bias
2021-04-13 00:19:32,487 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.weight
2021-04-13 00:19:32,487 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.bias
2021-04-13 00:19:32,487 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.dense.weight
2021-04-13 00:19:32,487 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.dense.bias
2021-04-13 00:19:32,487 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.weight
2021-04-13 00:19:32,488 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.bias
2021-04-13 00:19:32,488 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.weight
2021-04-13 00:19:32,488 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.bias
2021-04-13 00:19:32,488 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.weight
2021-04-13 00:19:32,488 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.bias
2021-04-13 00:19:32,488 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.weight
2021-04-13 00:19:32,488 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.bias
2021-04-13 00:19:32,488 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.weight
2021-04-13 00:19:32,489 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.bias
2021-04-13 00:19:32,489 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.weight
2021-04-13 00:19:32,489 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.bias
2021-04-13 00:19:32,489 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.weight
2021-04-13 00:19:32,489 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.bias
2021-04-13 00:19:32,489 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.dense.weight
2021-04-13 00:19:32,489 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.dense.bias
2021-04-13 00:19:32,489 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.weight
2021-04-13 00:19:32,489 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.bias
2021-04-13 00:19:32,490 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.weight
2021-04-13 00:19:32,490 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.bias
2021-04-13 00:19:32,490 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.weight
2021-04-13 00:19:32,490 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.bias
2021-04-13 00:19:32,490 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.weight
2021-04-13 00:19:32,490 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.bias
2021-04-13 00:19:32,490 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.weight
2021-04-13 00:19:32,490 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.bias
2021-04-13 00:19:32,490 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.weight
2021-04-13 00:19:32,491 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.bias
2021-04-13 00:19:32,491 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.weight
2021-04-13 00:19:32,491 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.bias
2021-04-13 00:19:32,491 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.dense.weight
2021-04-13 00:19:32,491 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.dense.bias
2021-04-13 00:19:32,491 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.weight
2021-04-13 00:19:32,491 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.bias
2021-04-13 00:19:32,491 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.weight
2021-04-13 00:19:32,491 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.bias
2021-04-13 00:19:32,492 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.weight
2021-04-13 00:19:32,492 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.bias
2021-04-13 00:19:32,492 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.weight
2021-04-13 00:19:32,492 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.bias
2021-04-13 00:19:32,492 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.weight
2021-04-13 00:19:32,492 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.bias
2021-04-13 00:19:32,492 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.weight
2021-04-13 00:19:32,492 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.bias
2021-04-13 00:19:32,492 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.weight
2021-04-13 00:19:32,493 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.bias
2021-04-13 00:19:32,493 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.dense.weight
2021-04-13 00:19:32,493 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.dense.bias
2021-04-13 00:19:32,493 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.weight
2021-04-13 00:19:32,493 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.bias
2021-04-13 00:19:32,493 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.weight
2021-04-13 00:19:32,493 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.bias
2021-04-13 00:19:32,494 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.weight
2021-04-13 00:19:32,494 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.bias
2021-04-13 00:19:32,494 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.weight
2021-04-13 00:19:32,494 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.bias
2021-04-13 00:19:32,494 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.weight
2021-04-13 00:19:32,494 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.bias
2021-04-13 00:19:32,494 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.weight
2021-04-13 00:19:32,494 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.bias
2021-04-13 00:19:32,494 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.weight
2021-04-13 00:19:32,495 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.bias
2021-04-13 00:19:32,495 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.dense.weight
2021-04-13 00:19:32,495 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.dense.bias
2021-04-13 00:19:32,495 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.weight
2021-04-13 00:19:32,495 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.bias
2021-04-13 00:19:32,495 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.weight
2021-04-13 00:19:32,495 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.bias
2021-04-13 00:19:32,495 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.weight
2021-04-13 00:19:32,495 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.bias
2021-04-13 00:19:32,495 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.weight
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.bias
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.weight
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.bias
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.weight
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.bias
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.weight
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.bias
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.dense.weight
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.dense.bias
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.weight
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.bias
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.pooler.dense.weight
2021-04-13 00:19:32,496 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.pooler.dense.bias
2021-04-13 00:19:32,497 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.bias
2021-04-13 00:19:32,497 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.dense.weight
2021-04-13 00:19:32,497 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.dense.bias
2021-04-13 00:19:32,497 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.weight
2021-04-13 00:19:32,497 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.bias
2021-04-13 00:19:32,497 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.bi_seq_relationship.weight
2021-04-13 00:19:32,497 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.bi_seq_relationship.bias
2021-04-13 00:19:33,954 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /mnt/lustre/lixiangtai/pretrained/R-50.pkl
2021-04-13 00:19:34,283 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping C2 weights
2021-04-13 00:19:34,294 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_b                         mapped name: conv1.bias
2021-04-13 00:19:34,294 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_w                         mapped name: conv1.weight
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_b                        mapped name: fc1000.bias
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_w                        mapped name: fc1000.weight
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_beta          mapped name: layer1.0.downsample.1.biaseta
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_gamma         mapped name: layer1.0.downsample.1.gamma
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_running_mean  mapped name: layer1.0.downsample.1.running.mean
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_running_var   mapped name: layer1.0.downsample.1.running.var
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w                mapped name: layer1.0.downsample.0.weight
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_beta         mapped name: layer1.0.bn1.biaseta
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_gamma        mapped name: layer1.0.bn1.gamma
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_running_mean mapped name: layer1.0.bn1.running.mean
2021-04-13 00:19:34,295 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_running_var  mapped name: layer1.0.bn1.running.var
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w               mapped name: layer1.0.conv1.weight
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_beta         mapped name: layer1.0.bn2.biaseta
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_gamma        mapped name: layer1.0.bn2.gamma
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_running_mean mapped name: layer1.0.bn2.running.mean
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_running_var  mapped name: layer1.0.bn2.running.var
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w               mapped name: layer1.0.conv2.weight
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_beta         mapped name: layer1.0.bn3.biaseta
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_gamma        mapped name: layer1.0.bn3.gamma
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_running_mean mapped name: layer1.0.bn3.running.mean
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_running_var  mapped name: layer1.0.bn3.running.var
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w               mapped name: layer1.0.conv3.weight
2021-04-13 00:19:34,296 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_beta         mapped name: layer1.1.bn1.biaseta
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_gamma        mapped name: layer1.1.bn1.gamma
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_running_mean mapped name: layer1.1.bn1.running.mean
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_running_var  mapped name: layer1.1.bn1.running.var
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w               mapped name: layer1.1.conv1.weight
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_beta         mapped name: layer1.1.bn2.biaseta
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_gamma        mapped name: layer1.1.bn2.gamma
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_running_mean mapped name: layer1.1.bn2.running.mean
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_running_var  mapped name: layer1.1.bn2.running.var
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w               mapped name: layer1.1.conv2.weight
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_beta         mapped name: layer1.1.bn3.biaseta
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_gamma        mapped name: layer1.1.bn3.gamma
2021-04-13 00:19:34,297 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_running_mean mapped name: layer1.1.bn3.running.mean
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_running_var  mapped name: layer1.1.bn3.running.var
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w               mapped name: layer1.1.conv3.weight
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_beta         mapped name: layer1.2.bn1.biaseta
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_gamma        mapped name: layer1.2.bn1.gamma
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_running_mean mapped name: layer1.2.bn1.running.mean
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_running_var  mapped name: layer1.2.bn1.running.var
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w               mapped name: layer1.2.conv1.weight
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_beta         mapped name: layer1.2.bn2.biaseta
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_gamma        mapped name: layer1.2.bn2.gamma
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_running_mean mapped name: layer1.2.bn2.running.mean
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_running_var  mapped name: layer1.2.bn2.running.var
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w               mapped name: layer1.2.conv2.weight
2021-04-13 00:19:34,298 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_beta         mapped name: layer1.2.bn3.biaseta
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_gamma        mapped name: layer1.2.bn3.gamma
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_running_mean mapped name: layer1.2.bn3.running.mean
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_running_var  mapped name: layer1.2.bn3.running.var
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w               mapped name: layer1.2.conv3.weight
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_beta          mapped name: layer2.0.downsample.1.biaseta
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_gamma         mapped name: layer2.0.downsample.1.gamma
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_running_mean  mapped name: layer2.0.downsample.1.running.mean
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_running_var   mapped name: layer2.0.downsample.1.running.var
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w                mapped name: layer2.0.downsample.0.weight
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_beta         mapped name: layer2.0.bn1.biaseta
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_gamma        mapped name: layer2.0.bn1.gamma
2021-04-13 00:19:34,299 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_running_mean mapped name: layer2.0.bn1.running.mean
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_running_var  mapped name: layer2.0.bn1.running.var
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w               mapped name: layer2.0.conv1.weight
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_beta         mapped name: layer2.0.bn2.biaseta
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_gamma        mapped name: layer2.0.bn2.gamma
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_running_mean mapped name: layer2.0.bn2.running.mean
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_running_var  mapped name: layer2.0.bn2.running.var
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w               mapped name: layer2.0.conv2.weight
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_beta         mapped name: layer2.0.bn3.biaseta
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_gamma        mapped name: layer2.0.bn3.gamma
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_running_mean mapped name: layer2.0.bn3.running.mean
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_running_var  mapped name: layer2.0.bn3.running.var
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w               mapped name: layer2.0.conv3.weight
2021-04-13 00:19:34,300 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_beta         mapped name: layer2.1.bn1.biaseta
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_gamma        mapped name: layer2.1.bn1.gamma
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_running_mean mapped name: layer2.1.bn1.running.mean
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_running_var  mapped name: layer2.1.bn1.running.var
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w               mapped name: layer2.1.conv1.weight
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_beta         mapped name: layer2.1.bn2.biaseta
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_gamma        mapped name: layer2.1.bn2.gamma
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_running_mean mapped name: layer2.1.bn2.running.mean
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_running_var  mapped name: layer2.1.bn2.running.var
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w               mapped name: layer2.1.conv2.weight
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_beta         mapped name: layer2.1.bn3.biaseta
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_gamma        mapped name: layer2.1.bn3.gamma
2021-04-13 00:19:34,301 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_running_mean mapped name: layer2.1.bn3.running.mean
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_running_var  mapped name: layer2.1.bn3.running.var
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w               mapped name: layer2.1.conv3.weight
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_beta         mapped name: layer2.2.bn1.biaseta
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_gamma        mapped name: layer2.2.bn1.gamma
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_running_mean mapped name: layer2.2.bn1.running.mean
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_running_var  mapped name: layer2.2.bn1.running.var
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w               mapped name: layer2.2.conv1.weight
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_beta         mapped name: layer2.2.bn2.biaseta
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_gamma        mapped name: layer2.2.bn2.gamma
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_running_mean mapped name: layer2.2.bn2.running.mean
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_running_var  mapped name: layer2.2.bn2.running.var
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w               mapped name: layer2.2.conv2.weight
2021-04-13 00:19:34,302 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_beta         mapped name: layer2.2.bn3.biaseta
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_gamma        mapped name: layer2.2.bn3.gamma
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_running_mean mapped name: layer2.2.bn3.running.mean
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_running_var  mapped name: layer2.2.bn3.running.var
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w               mapped name: layer2.2.conv3.weight
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_beta         mapped name: layer2.3.bn1.biaseta
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_gamma        mapped name: layer2.3.bn1.gamma
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_running_mean mapped name: layer2.3.bn1.running.mean
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_running_var  mapped name: layer2.3.bn1.running.var
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w               mapped name: layer2.3.conv1.weight
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_beta         mapped name: layer2.3.bn2.biaseta
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_gamma        mapped name: layer2.3.bn2.gamma
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_running_mean mapped name: layer2.3.bn2.running.mean
2021-04-13 00:19:34,303 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_running_var  mapped name: layer2.3.bn2.running.var
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w               mapped name: layer2.3.conv2.weight
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_beta         mapped name: layer2.3.bn3.biaseta
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_gamma        mapped name: layer2.3.bn3.gamma
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_running_mean mapped name: layer2.3.bn3.running.mean
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_running_var  mapped name: layer2.3.bn3.running.var
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w               mapped name: layer2.3.conv3.weight
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_beta          mapped name: layer3.0.downsample.1.biaseta
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_gamma         mapped name: layer3.0.downsample.1.gamma
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_running_mean  mapped name: layer3.0.downsample.1.running.mean
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_running_var   mapped name: layer3.0.downsample.1.running.var
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w                mapped name: layer3.0.downsample.0.weight
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_beta         mapped name: layer3.0.bn1.biaseta
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_gamma        mapped name: layer3.0.bn1.gamma
2021-04-13 00:19:34,304 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_running_mean mapped name: layer3.0.bn1.running.mean
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_running_var  mapped name: layer3.0.bn1.running.var
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w               mapped name: layer3.0.conv1.weight
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_beta         mapped name: layer3.0.bn2.biaseta
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_gamma        mapped name: layer3.0.bn2.gamma
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_running_mean mapped name: layer3.0.bn2.running.mean
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_running_var  mapped name: layer3.0.bn2.running.var
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w               mapped name: layer3.0.conv2.weight
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_beta         mapped name: layer3.0.bn3.biaseta
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_gamma        mapped name: layer3.0.bn3.gamma
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_running_mean mapped name: layer3.0.bn3.running.mean
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_running_var  mapped name: layer3.0.bn3.running.var
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w               mapped name: layer3.0.conv3.weight
2021-04-13 00:19:34,305 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_beta         mapped name: layer3.1.bn1.biaseta
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_gamma        mapped name: layer3.1.bn1.gamma
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_running_mean mapped name: layer3.1.bn1.running.mean
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_running_var  mapped name: layer3.1.bn1.running.var
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w               mapped name: layer3.1.conv1.weight
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_beta         mapped name: layer3.1.bn2.biaseta
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_gamma        mapped name: layer3.1.bn2.gamma
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_running_mean mapped name: layer3.1.bn2.running.mean
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_running_var  mapped name: layer3.1.bn2.running.var
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w               mapped name: layer3.1.conv2.weight
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_beta         mapped name: layer3.1.bn3.biaseta
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_gamma        mapped name: layer3.1.bn3.gamma
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_running_mean mapped name: layer3.1.bn3.running.mean
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_running_var  mapped name: layer3.1.bn3.running.var
2021-04-13 00:19:34,306 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w               mapped name: layer3.1.conv3.weight
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_beta         mapped name: layer3.2.bn1.biaseta
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_gamma        mapped name: layer3.2.bn1.gamma
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_running_mean mapped name: layer3.2.bn1.running.mean
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_running_var  mapped name: layer3.2.bn1.running.var
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w               mapped name: layer3.2.conv1.weight
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_beta         mapped name: layer3.2.bn2.biaseta
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_gamma        mapped name: layer3.2.bn2.gamma
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_running_mean mapped name: layer3.2.bn2.running.mean
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_running_var  mapped name: layer3.2.bn2.running.var
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w               mapped name: layer3.2.conv2.weight
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_beta         mapped name: layer3.2.bn3.biaseta
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_gamma        mapped name: layer3.2.bn3.gamma
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_running_mean mapped name: layer3.2.bn3.running.mean
2021-04-13 00:19:34,307 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_running_var  mapped name: layer3.2.bn3.running.var
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w               mapped name: layer3.2.conv3.weight
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_beta         mapped name: layer3.3.bn1.biaseta
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_gamma        mapped name: layer3.3.bn1.gamma
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_running_mean mapped name: layer3.3.bn1.running.mean
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_running_var  mapped name: layer3.3.bn1.running.var
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w               mapped name: layer3.3.conv1.weight
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_beta         mapped name: layer3.3.bn2.biaseta
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_gamma        mapped name: layer3.3.bn2.gamma
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_running_mean mapped name: layer3.3.bn2.running.mean
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_running_var  mapped name: layer3.3.bn2.running.var
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w               mapped name: layer3.3.conv2.weight
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_beta         mapped name: layer3.3.bn3.biaseta
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_gamma        mapped name: layer3.3.bn3.gamma
2021-04-13 00:19:34,308 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_running_mean mapped name: layer3.3.bn3.running.mean
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_running_var  mapped name: layer3.3.bn3.running.var
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w               mapped name: layer3.3.conv3.weight
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_beta         mapped name: layer3.4.bn1.biaseta
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_gamma        mapped name: layer3.4.bn1.gamma
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_running_mean mapped name: layer3.4.bn1.running.mean
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_running_var  mapped name: layer3.4.bn1.running.var
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w               mapped name: layer3.4.conv1.weight
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_beta         mapped name: layer3.4.bn2.biaseta
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_gamma        mapped name: layer3.4.bn2.gamma
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_running_mean mapped name: layer3.4.bn2.running.mean
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_running_var  mapped name: layer3.4.bn2.running.var
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w               mapped name: layer3.4.conv2.weight
2021-04-13 00:19:34,309 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_beta         mapped name: layer3.4.bn3.biaseta
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_gamma        mapped name: layer3.4.bn3.gamma
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_running_mean mapped name: layer3.4.bn3.running.mean
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_running_var  mapped name: layer3.4.bn3.running.var
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w               mapped name: layer3.4.conv3.weight
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_beta         mapped name: layer3.5.bn1.biaseta
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_gamma        mapped name: layer3.5.bn1.gamma
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_running_mean mapped name: layer3.5.bn1.running.mean
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_running_var  mapped name: layer3.5.bn1.running.var
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w               mapped name: layer3.5.conv1.weight
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_beta         mapped name: layer3.5.bn2.biaseta
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_gamma        mapped name: layer3.5.bn2.gamma
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_running_mean mapped name: layer3.5.bn2.running.mean
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_running_var  mapped name: layer3.5.bn2.running.var
2021-04-13 00:19:34,310 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w               mapped name: layer3.5.conv2.weight
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_beta         mapped name: layer3.5.bn3.biaseta
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_gamma        mapped name: layer3.5.bn3.gamma
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_running_mean mapped name: layer3.5.bn3.running.mean
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_running_var  mapped name: layer3.5.bn3.running.var
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w               mapped name: layer3.5.conv3.weight
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_beta          mapped name: layer4.0.downsample.1.biaseta
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_gamma         mapped name: layer4.0.downsample.1.gamma
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_running_mean  mapped name: layer4.0.downsample.1.running.mean
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_running_var   mapped name: layer4.0.downsample.1.running.var
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w                mapped name: layer4.0.downsample.0.weight
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_beta         mapped name: layer4.0.bn1.biaseta
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_gamma        mapped name: layer4.0.bn1.gamma
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_running_mean mapped name: layer4.0.bn1.running.mean
2021-04-13 00:19:34,311 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_running_var  mapped name: layer4.0.bn1.running.var
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w               mapped name: layer4.0.conv1.weight
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_beta         mapped name: layer4.0.bn2.biaseta
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_gamma        mapped name: layer4.0.bn2.gamma
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_running_mean mapped name: layer4.0.bn2.running.mean
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_running_var  mapped name: layer4.0.bn2.running.var
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w               mapped name: layer4.0.conv2.weight
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_beta         mapped name: layer4.0.bn3.biaseta
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_gamma        mapped name: layer4.0.bn3.gamma
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_running_mean mapped name: layer4.0.bn3.running.mean
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_running_var  mapped name: layer4.0.bn3.running.var
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w               mapped name: layer4.0.conv3.weight
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_beta         mapped name: layer4.1.bn1.biaseta
2021-04-13 00:19:34,312 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_gamma        mapped name: layer4.1.bn1.gamma
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_running_mean mapped name: layer4.1.bn1.running.mean
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_running_var  mapped name: layer4.1.bn1.running.var
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w               mapped name: layer4.1.conv1.weight
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_beta         mapped name: layer4.1.bn2.biaseta
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_gamma        mapped name: layer4.1.bn2.gamma
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_running_mean mapped name: layer4.1.bn2.running.mean
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_running_var  mapped name: layer4.1.bn2.running.var
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w               mapped name: layer4.1.conv2.weight
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_beta         mapped name: layer4.1.bn3.biaseta
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_gamma        mapped name: layer4.1.bn3.gamma
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_running_mean mapped name: layer4.1.bn3.running.mean
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_running_var  mapped name: layer4.1.bn3.running.var
2021-04-13 00:19:34,313 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w               mapped name: layer4.1.conv3.weight
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_beta         mapped name: layer4.2.bn1.biaseta
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_gamma        mapped name: layer4.2.bn1.gamma
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_running_mean mapped name: layer4.2.bn1.running.mean
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_running_var  mapped name: layer4.2.bn1.running.var
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w               mapped name: layer4.2.conv1.weight
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_beta         mapped name: layer4.2.bn2.biaseta
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_gamma        mapped name: layer4.2.bn2.gamma
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_running_mean mapped name: layer4.2.bn2.running.mean
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_running_var  mapped name: layer4.2.bn2.running.var
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w               mapped name: layer4.2.conv2.weight
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_beta         mapped name: layer4.2.bn3.biaseta
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_gamma        mapped name: layer4.2.bn3.gamma
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_running_mean mapped name: layer4.2.bn3.running.mean
2021-04-13 00:19:34,314 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_running_var  mapped name: layer4.2.bn3.running.var
2021-04-13 00:19:34,315 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w               mapped name: layer4.2.conv3.weight
2021-04-13 00:19:34,315 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_beta               mapped name: bn1.biaseta
2021-04-13 00:19:34,315 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_gamma              mapped name: bn1.gamma
2021-04-13 00:19:34,315 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_running_mean       mapped name: bn1.running.mean
2021-04-13 00:19:34,315 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_running_var        mapped name: bn1.running.var
2021-04-13 00:19:34,315 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping conv weights for deformable conv weights
2021-04-13 00:19:35,279 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv1.weight                                                               loaded from layer1.0.conv1.weight              of shape (64, 64, 1, 1)
2021-04-13 00:19:35,279 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv2.weight                                                               loaded from layer1.0.conv2.weight              of shape (64, 64, 3, 3)
2021-04-13 00:19:35,279 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv3.weight                                                               loaded from layer1.0.conv3.weight              of shape (256, 64, 1, 1)
2021-04-13 00:19:35,280 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.0.weight                                                        loaded from layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
2021-04-13 00:19:35,280 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv1.weight                                                               loaded from layer1.1.conv1.weight              of shape (64, 256, 1, 1)
2021-04-13 00:19:35,280 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv2.weight                                                               loaded from layer1.1.conv2.weight              of shape (64, 64, 3, 3)
2021-04-13 00:19:35,280 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv3.weight                                                               loaded from layer1.1.conv3.weight              of shape (256, 64, 1, 1)
2021-04-13 00:19:35,280 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv1.weight                                                               loaded from layer1.2.conv1.weight              of shape (64, 256, 1, 1)
2021-04-13 00:19:35,280 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv2.weight                                                               loaded from layer1.2.conv2.weight              of shape (64, 64, 3, 3)
2021-04-13 00:19:35,280 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv3.weight                                                               loaded from layer1.2.conv3.weight              of shape (256, 64, 1, 1)
2021-04-13 00:19:35,280 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv1.weight                                                               loaded from layer2.0.conv1.weight              of shape (128, 256, 1, 1)
2021-04-13 00:19:35,280 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv2.weight                                                               loaded from layer2.0.conv2.weight              of shape (128, 128, 3, 3)
2021-04-13 00:19:35,281 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv3.weight                                                               loaded from layer2.0.conv3.weight              of shape (512, 128, 1, 1)
2021-04-13 00:19:35,281 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.0.weight                                                        loaded from layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
2021-04-13 00:19:35,281 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv1.weight                                                               loaded from layer2.1.conv1.weight              of shape (128, 512, 1, 1)
2021-04-13 00:19:35,281 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv2.weight                                                               loaded from layer2.1.conv2.weight              of shape (128, 128, 3, 3)
2021-04-13 00:19:35,281 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv3.weight                                                               loaded from layer2.1.conv3.weight              of shape (512, 128, 1, 1)
2021-04-13 00:19:35,281 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv1.weight                                                               loaded from layer2.2.conv1.weight              of shape (128, 512, 1, 1)
2021-04-13 00:19:35,281 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv2.weight                                                               loaded from layer2.2.conv2.weight              of shape (128, 128, 3, 3)
2021-04-13 00:19:35,281 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv3.weight                                                               loaded from layer2.2.conv3.weight              of shape (512, 128, 1, 1)
2021-04-13 00:19:35,281 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv1.weight                                                               loaded from layer2.3.conv1.weight              of shape (128, 512, 1, 1)
2021-04-13 00:19:35,281 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv2.weight                                                               loaded from layer2.3.conv2.weight              of shape (128, 128, 3, 3)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv3.weight                                                               loaded from layer2.3.conv3.weight              of shape (512, 128, 1, 1)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv1.weight                                                               loaded from layer3.0.conv1.weight              of shape (256, 512, 1, 1)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv2.weight                                                               loaded from layer3.0.conv2.weight              of shape (256, 256, 3, 3)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv3.weight                                                               loaded from layer3.0.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.0.weight                                                        loaded from layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv1.weight                                                               loaded from layer3.1.conv1.weight              of shape (256, 1024, 1, 1)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv2.weight                                                               loaded from layer3.1.conv2.weight              of shape (256, 256, 3, 3)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv3.weight                                                               loaded from layer3.1.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv1.weight                                                               loaded from layer3.2.conv1.weight              of shape (256, 1024, 1, 1)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv2.weight                                                               loaded from layer3.2.conv2.weight              of shape (256, 256, 3, 3)
2021-04-13 00:19:35,282 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv3.weight                                                               loaded from layer3.2.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-13 00:19:35,283 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv1.weight                                                               loaded from layer3.3.conv1.weight              of shape (256, 1024, 1, 1)
2021-04-13 00:19:35,283 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv2.weight                                                               loaded from layer3.3.conv2.weight              of shape (256, 256, 3, 3)
2021-04-13 00:19:35,283 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv3.weight                                                               loaded from layer3.3.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-13 00:19:35,283 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv1.weight                                                               loaded from layer3.4.conv1.weight              of shape (256, 1024, 1, 1)
2021-04-13 00:19:35,283 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv2.weight                                                               loaded from layer3.4.conv2.weight              of shape (256, 256, 3, 3)
2021-04-13 00:19:35,283 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv3.weight                                                               loaded from layer3.4.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-13 00:19:35,283 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv1.weight                                                               loaded from layer3.5.conv1.weight              of shape (256, 1024, 1, 1)
2021-04-13 00:19:35,283 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv2.weight                                                               loaded from layer3.5.conv2.weight              of shape (256, 256, 3, 3)
2021-04-13 00:19:35,283 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv3.weight                                                               loaded from layer3.5.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-13 00:19:35,283 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv1.weight                                                               loaded from layer4.0.conv1.weight              of shape (512, 1024, 1, 1)
2021-04-13 00:19:35,284 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv2.weight                                                               loaded from layer4.0.conv2.weight              of shape (512, 512, 3, 3)
2021-04-13 00:19:35,284 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv3.weight                                                               loaded from layer4.0.conv3.weight              of shape (2048, 512, 1, 1)
2021-04-13 00:19:35,284 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.0.weight                                                        loaded from layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
2021-04-13 00:19:35,284 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv1.weight                                                               loaded from layer4.1.conv1.weight              of shape (512, 2048, 1, 1)
2021-04-13 00:19:35,284 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv2.weight                                                               loaded from layer4.1.conv2.weight              of shape (512, 512, 3, 3)
2021-04-13 00:19:35,284 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv3.weight                                                               loaded from layer4.1.conv3.weight              of shape (2048, 512, 1, 1)
2021-04-13 00:19:35,284 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv1.weight                                                               loaded from layer4.2.conv1.weight              of shape (512, 2048, 1, 1)
2021-04-13 00:19:35,284 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv2.weight                                                               loaded from layer4.2.conv2.weight              of shape (512, 512, 3, 3)
2021-04-13 00:19:35,284 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv3.weight                                                               loaded from layer4.2.conv3.weight              of shape (2048, 512, 1, 1)
2021-04-13 00:19:35,285 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.conv1.weight                                                                   loaded from conv1.weight                       of shape (64, 3, 7, 7)
2021-04-13 00:19:35,472 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2021-04-13 00:19:46,390 maskrcnn_benchmark.utils.miscellaneous WARNING: Dataset [COCOCaptionsDataset] has no categories attribute, labels.json file won't be created
2021-04-13 00:19:46,735 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2021-04-13 00:19:46,909 maskrcnn_benchmark.trainer INFO: Start training
2021-04-13 00:21:39,594 maskrcnn_benchmark.trainer INFO: eta: 12:28:03  iter: 100  Cross-Entropy Loss (Align Regions, Choose Caption): 1.9297 (2.0155)  Cross-Entropy Loss (Align Regions, Choose Image): 1.9266 (2.0100)  Cross-Entropy Loss (Align Words, Choose Caption): 1.9945 (2.0407)  Cross-Entropy Loss (Align Words, Choose Image): 1.9834 (2.0342)  Image Caption Matching Loss: 4.1546 (4.1602)  Masked Language Modeling Loss: 4.7291 (5.5197)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 16.6729 (17.7802)  Batch Accuracy (Align Regions, Choose Caption): 0.2500 (0.1841)  Batch Accuracy (Align Regions, Choose Image): 0.2500 (0.2095)  Batch Accuracy (Align Words, Choose Caption): 0.2188 (0.1805)  Batch Accuracy (Align Words, Choose Image): 0.2031 (0.1923)  Batch Accuracy (Choose Caption): 0.1250 (0.1248)  Batch Accuracy (Choose Image): 0.1250 (0.1311)  Masked Language Modeling Accuracy: 0.3343 (0.2489)  time: 0.9591 (1.1249)  data: 0.0483 (0.0991)  lr: 0.004667  max mem: 10407
2021-04-13 00:23:20,662 maskrcnn_benchmark.trainer INFO: eta: 11:48:40  iter: 200  Cross-Entropy Loss (Align Regions, Choose Caption): 1.8183 (1.9272)  Cross-Entropy Loss (Align Regions, Choose Image): 1.8282 (1.9257)  Cross-Entropy Loss (Align Words, Choose Caption): 1.9339 (1.9902)  Cross-Entropy Loss (Align Words, Choose Image): 1.9251 (1.9797)  Image Caption Matching Loss: 4.1065 (4.1484)  Masked Language Modeling Loss: 3.8352 (4.7723)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 15.4836 (16.7435)  Batch Accuracy (Align Regions, Choose Caption): 0.3125 (0.2365)  Batch Accuracy (Align Regions, Choose Image): 0.3125 (0.2609)  Batch Accuracy (Align Words, Choose Caption): 0.2656 (0.2187)  Batch Accuracy (Align Words, Choose Image): 0.2500 (0.2263)  Batch Accuracy (Choose Caption): 0.1719 (0.1388)  Batch Accuracy (Choose Image): 0.1719 (0.1437)  Masked Language Modeling Accuracy: 0.3932 (0.3213)  time: 0.9854 (1.0683)  data: 0.0503 (0.0767)  lr: 0.006000  max mem: 10407
2021-04-13 00:25:01,820 maskrcnn_benchmark.trainer INFO: eta: 11:34:21  iter: 300  Cross-Entropy Loss (Align Regions, Choose Caption): 1.7670 (1.8722)  Cross-Entropy Loss (Align Regions, Choose Image): 1.7681 (1.8707)  Cross-Entropy Loss (Align Words, Choose Caption): 1.8772 (1.9502)  Cross-Entropy Loss (Align Words, Choose Image): 1.8277 (1.9338)  Image Caption Matching Loss: 3.8689 (4.0814)  Masked Language Modeling Loss: 3.3785 (4.3654)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 14.5233 (16.0738)  Batch Accuracy (Align Regions, Choose Caption): 0.3281 (0.2721)  Batch Accuracy (Align Regions, Choose Image): 0.3438 (0.2883)  Batch Accuracy (Align Words, Choose Caption): 0.2812 (0.2443)  Batch Accuracy (Align Words, Choose Image): 0.3125 (0.2544)  Batch Accuracy (Choose Caption): 0.2031 (0.1600)  Batch Accuracy (Choose Image): 0.2188 (0.1627)  Masked Language Modeling Accuracy: 0.4642 (0.3614)  time: 0.9727 (1.0494)  data: 0.0439 (0.0693)  lr: 0.007333  max mem: 10422
2021-04-13 00:26:44,834 maskrcnn_benchmark.trainer INFO: eta: 11:29:24  iter: 400  Cross-Entropy Loss (Align Regions, Choose Caption): 1.5916 (1.8197)  Cross-Entropy Loss (Align Regions, Choose Image): 1.5927 (1.8170)  Cross-Entropy Loss (Align Words, Choose Caption): 1.7550 (1.9166)  Cross-Entropy Loss (Align Words, Choose Image): 1.6910 (1.8908)  Image Caption Matching Loss: 3.6482 (3.9829)  Masked Language Modeling Loss: 2.9767 (4.0731)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 13.2675 (15.5000)  Batch Accuracy (Align Regions, Choose Caption): 0.4062 (0.3005)  Batch Accuracy (Align Regions, Choose Image): 0.4062 (0.3151)  Batch Accuracy (Align Words, Choose Caption): 0.3594 (0.2643)  Batch Accuracy (Align Words, Choose Image): 0.3906 (0.2787)  Batch Accuracy (Choose Caption): 0.2656 (0.1841)  Batch Accuracy (Choose Image): 0.2969 (0.1871)  Masked Language Modeling Accuracy: 0.5068 (0.3892)  time: 0.9621 (1.0446)  data: 0.0531 (0.0661)  lr: 0.008667  max mem: 10538
2021-04-13 00:28:26,318 maskrcnn_benchmark.trainer INFO: eta: 11:23:44  iter: 500  Cross-Entropy Loss (Align Regions, Choose Caption): 1.5773 (1.7801)  Cross-Entropy Loss (Align Regions, Choose Image): 1.5722 (1.7738)  Cross-Entropy Loss (Align Words, Choose Caption): 1.7236 (1.8899)  Cross-Entropy Loss (Align Words, Choose Image): 1.6496 (1.8546)  Image Caption Matching Loss: 3.3557 (3.8817)  Masked Language Modeling Loss: 3.1142 (3.8691)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 13.0789 (15.0493)  Batch Accuracy (Align Regions, Choose Caption): 0.3906 (0.3211)  Batch Accuracy (Align Regions, Choose Image): 0.4219 (0.3356)  Batch Accuracy (Align Words, Choose Caption): 0.3438 (0.2795)  Batch Accuracy (Align Words, Choose Image): 0.3594 (0.2977)  Batch Accuracy (Choose Caption): 0.3438 (0.2112)  Batch Accuracy (Choose Image): 0.3438 (0.2143)  Masked Language Modeling Accuracy: 0.4633 (0.4093)  time: 0.9813 (1.0386)  data: 0.0427 (0.0639)  lr: 0.010000  max mem: 10539
2021-04-13 00:30:07,526 maskrcnn_benchmark.trainer INFO: eta: 11:19:05  iter: 600  Cross-Entropy Loss (Align Regions, Choose Caption): 1.4767 (1.7409)  Cross-Entropy Loss (Align Regions, Choose Image): 1.5053 (1.7357)  Cross-Entropy Loss (Align Words, Choose Caption): 1.7268 (1.8608)  Cross-Entropy Loss (Align Words, Choose Image): 1.6163 (1.8184)  Image Caption Matching Loss: 3.1079 (3.7661)  Masked Language Modeling Loss: 2.8539 (3.7052)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 12.2306 (14.6271)  Batch Accuracy (Align Regions, Choose Caption): 0.4688 (0.3410)  Batch Accuracy (Align Regions, Choose Image): 0.4375 (0.3548)  Batch Accuracy (Align Words, Choose Caption): 0.3906 (0.2936)  Batch Accuracy (Align Words, Choose Image): 0.4219 (0.3160)  Batch Accuracy (Choose Caption): 0.3750 (0.2377)  Batch Accuracy (Choose Image): 0.3906 (0.2421)  Masked Language Modeling Accuracy: 0.5145 (0.4254)  time: 0.9711 (1.0342)  data: 0.0488 (0.0622)  lr: 0.010000  max mem: 10539
2021-04-13 00:31:48,902 maskrcnn_benchmark.trainer INFO: eta: 11:15:27  iter: 700  Cross-Entropy Loss (Align Regions, Choose Caption): 1.4240 (1.7021)  Cross-Entropy Loss (Align Regions, Choose Image): 1.4358 (1.6971)  Cross-Entropy Loss (Align Words, Choose Caption): 1.6754 (1.8329)  Cross-Entropy Loss (Align Words, Choose Image): 1.5766 (1.7837)  Image Caption Matching Loss: 2.8409 (3.6480)  Masked Language Modeling Loss: 2.7290 (3.5730)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 11.7746 (14.2369)  Batch Accuracy (Align Regions, Choose Caption): 0.4688 (0.3590)  Batch Accuracy (Align Regions, Choose Image): 0.4844 (0.3714)  Batch Accuracy (Align Words, Choose Caption): 0.3906 (0.3076)  Batch Accuracy (Align Words, Choose Image): 0.4062 (0.3328)  Batch Accuracy (Choose Caption): 0.4375 (0.2657)  Batch Accuracy (Choose Image): 0.4375 (0.2701)  Masked Language Modeling Accuracy: 0.5202 (0.4395)  time: 0.9594 (1.0312)  data: 0.0595 (0.0615)  lr: 0.010000  max mem: 10709
2021-04-13 00:33:32,680 maskrcnn_benchmark.trainer INFO: eta: 11:14:17  iter: 800  Cross-Entropy Loss (Align Regions, Choose Caption): 1.3741 (1.6662)  Cross-Entropy Loss (Align Regions, Choose Image): 1.3896 (1.6642)  Cross-Entropy Loss (Align Words, Choose Caption): 1.5828 (1.8047)  Cross-Entropy Loss (Align Words, Choose Image): 1.4847 (1.7501)  Image Caption Matching Loss: 2.4892 (3.5339)  Masked Language Modeling Loss: 2.6666 (3.4714)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 11.2656 (13.8904)  Batch Accuracy (Align Regions, Choose Caption): 0.4844 (0.3757)  Batch Accuracy (Align Regions, Choose Image): 0.5000 (0.3874)  Batch Accuracy (Align Words, Choose Caption): 0.4375 (0.3209)  Batch Accuracy (Align Words, Choose Image): 0.4688 (0.3476)  Batch Accuracy (Choose Caption): 0.4844 (0.2909)  Batch Accuracy (Choose Image): 0.5312 (0.2968)  Masked Language Modeling Accuracy: 0.5180 (0.4504)  time: 0.9758 (1.0321)  data: 0.0536 (0.0609)  lr: 0.010000  max mem: 10709
2021-04-13 00:35:14,139 maskrcnn_benchmark.trainer INFO: eta: 11:11:17  iter: 900  Cross-Entropy Loss (Align Regions, Choose Caption): 1.3226 (1.6345)  Cross-Entropy Loss (Align Regions, Choose Image): 1.3491 (1.6328)  Cross-Entropy Loss (Align Words, Choose Caption): 1.5098 (1.7800)  Cross-Entropy Loss (Align Words, Choose Image): 1.4400 (1.7193)  Image Caption Matching Loss: 2.6365 (3.4342)  Masked Language Modeling Loss: 2.6420 (3.3814)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 10.9417 (13.5823)  Batch Accuracy (Align Regions, Choose Caption): 0.5000 (0.3896)  Batch Accuracy (Align Regions, Choose Image): 0.5156 (0.4007)  Batch Accuracy (Align Words, Choose Caption): 0.4375 (0.3322)  Batch Accuracy (Align Words, Choose Image): 0.4688 (0.3607)  Batch Accuracy (Choose Caption): 0.4531 (0.3124)  Batch Accuracy (Choose Image): 0.5000 (0.3192)  Masked Language Modeling Accuracy: 0.5448 (0.4603)  time: 0.9873 (1.0301)  data: 0.0481 (0.0609)  lr: 0.010000  max mem: 10947
2021-04-13 00:36:55,940 maskrcnn_benchmark.trainer INFO: eta: 11:08:46  iter: 1000  Cross-Entropy Loss (Align Regions, Choose Caption): 1.3539 (1.6066)  Cross-Entropy Loss (Align Regions, Choose Image): 1.3479 (1.6040)  Cross-Entropy Loss (Align Words, Choose Caption): 1.4890 (1.7553)  Cross-Entropy Loss (Align Words, Choose Image): 1.3957 (1.6898)  Image Caption Matching Loss: 2.5804 (3.3456)  Masked Language Modeling Loss: 2.5133 (3.3064)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 10.8315 (13.3077)  Batch Accuracy (Align Regions, Choose Caption): 0.5000 (0.4025)  Batch Accuracy (Align Regions, Choose Image): 0.5000 (0.4130)  Batch Accuracy (Align Words, Choose Caption): 0.4531 (0.3431)  Batch Accuracy (Align Words, Choose Image): 0.4844 (0.3734)  Batch Accuracy (Choose Caption): 0.4688 (0.3310)  Batch Accuracy (Choose Image): 0.5000 (0.3389)  Masked Language Modeling Accuracy: 0.5506 (0.4674)  time: 0.9868 (1.0289)  data: 0.0479 (0.0605)  lr: 0.010000  max mem: 10947
2021-04-13 00:36:56,979 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0001000.pth
2021-04-13 00:38:23,678 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 11:08:46  iter: 1000  loss: 7.8608 (7.9239)  Cross-Entropy Loss (Align Regions, Choose Caption): 1.2534 (1.2601)  Cross-Entropy Loss (Align Regions, Choose Image): 1.2376 (1.2300)  Cross-Entropy Loss (Align Words, Choose Caption): 1.4813 (1.5073)  Cross-Entropy Loss (Align Words, Choose Image): 1.3334 (1.3679)  Image Caption Matching Loss: 2.5231 (2.5586)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.5312 (0.5482)  Batch Accuracy (Align Regions, Choose Image): 0.5781 (0.5739)  Batch Accuracy (Align Words, Choose Caption): 0.4688 (0.4462)  Batch Accuracy (Align Words, Choose Image): 0.5000 (0.4964)  Batch Accuracy (Choose Caption): 0.5417 (0.5112)  Batch Accuracy (Choose Image): 0.5000 (0.5066)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 10947
2021-04-13 00:40:05,818 maskrcnn_benchmark.trainer INFO: eta: 11:58:20  iter: 1100  Cross-Entropy Loss (Align Regions, Choose Caption): 1.2822 (1.5787)  Cross-Entropy Loss (Align Regions, Choose Image): 1.2344 (1.5770)  Cross-Entropy Loss (Align Words, Choose Caption): 1.4214 (1.7299)  Cross-Entropy Loss (Align Words, Choose Image): 1.3596 (1.6611)  Image Caption Matching Loss: 2.3228 (3.2591)  Masked Language Modeling Loss: 2.4006 (3.2340)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 10.1608 (13.0399)  Batch Accuracy (Align Regions, Choose Caption): 0.5312 (0.4155)  Batch Accuracy (Align Regions, Choose Image): 0.5312 (0.4257)  Batch Accuracy (Align Words, Choose Caption): 0.4844 (0.3554)  Batch Accuracy (Align Words, Choose Image): 0.5156 (0.3851)  Batch Accuracy (Choose Caption): 0.5000 (0.3486)  Batch Accuracy (Choose Image): 0.5469 (0.3573)  Masked Language Modeling Accuracy: 0.5760 (0.4753)  time: 0.9875 (1.1080)  data: 0.0635 (0.1406)  lr: 0.010000  max mem: 10947
2021-04-13 00:41:47,115 maskrcnn_benchmark.trainer INFO: eta: 11:51:22  iter: 1200  Cross-Entropy Loss (Align Regions, Choose Caption): 1.2117 (1.5544)  Cross-Entropy Loss (Align Regions, Choose Image): 1.2506 (1.5532)  Cross-Entropy Loss (Align Words, Choose Caption): 1.3907 (1.7075)  Cross-Entropy Loss (Align Words, Choose Image): 1.3107 (1.6346)  Image Caption Matching Loss: 2.1407 (3.1809)  Masked Language Modeling Loss: 2.4311 (3.1749)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 9.8293 (12.8054)  Batch Accuracy (Align Regions, Choose Caption): 0.5625 (0.4265)  Batch Accuracy (Align Regions, Choose Image): 0.5625 (0.4355)  Batch Accuracy (Align Words, Choose Caption): 0.4844 (0.3651)  Batch Accuracy (Align Words, Choose Image): 0.5312 (0.3962)  Batch Accuracy (Choose Caption): 0.5781 (0.3650)  Batch Accuracy (Choose Image): 0.6094 (0.3746)  Masked Language Modeling Accuracy: 0.5496 (0.4811)  time: 0.9755 (1.1001)  data: 0.0545 (0.1335)  lr: 0.010000  max mem: 10947
2021-04-13 00:43:27,931 maskrcnn_benchmark.trainer INFO: eta: 11:44:58  iter: 1300  Cross-Entropy Loss (Align Regions, Choose Caption): 1.2181 (1.5321)  Cross-Entropy Loss (Align Regions, Choose Image): 1.1832 (1.5294)  Cross-Entropy Loss (Align Words, Choose Caption): 1.4481 (1.6872)  Cross-Entropy Loss (Align Words, Choose Image): 1.3342 (1.6101)  Image Caption Matching Loss: 2.2185 (3.1101)  Masked Language Modeling Loss: 2.5483 (3.1221)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 9.8621 (12.5910)  Batch Accuracy (Align Regions, Choose Caption): 0.5469 (0.4361)  Batch Accuracy (Align Regions, Choose Image): 0.5781 (0.4451)  Batch Accuracy (Align Words, Choose Caption): 0.4844 (0.3741)  Batch Accuracy (Align Words, Choose Image): 0.5156 (0.4062)  Batch Accuracy (Choose Caption): 0.5469 (0.3793)  Batch Accuracy (Choose Image): 0.5625 (0.3901)  Masked Language Modeling Accuracy: 0.5232 (0.4862)  time: 0.9814 (1.0930)  data: 0.0568 (0.1276)  lr: 0.010000  max mem: 10947
2021-04-13 00:45:10,575 maskrcnn_benchmark.trainer INFO: eta: 11:40:05  iter: 1400  Cross-Entropy Loss (Align Regions, Choose Caption): 1.1060 (1.5096)  Cross-Entropy Loss (Align Regions, Choose Image): 1.1400 (1.5069)  Cross-Entropy Loss (Align Words, Choose Caption): 1.3448 (1.6673)  Cross-Entropy Loss (Align Words, Choose Image): 1.2087 (1.5863)  Image Caption Matching Loss: 1.9715 (3.0380)  Masked Language Modeling Loss: 2.4571 (3.0762)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 9.2263 (12.3843)  Batch Accuracy (Align Regions, Choose Caption): 0.5938 (0.4459)  Batch Accuracy (Align Regions, Choose Image): 0.5625 (0.4542)  Batch Accuracy (Align Words, Choose Caption): 0.5312 (0.3832)  Batch Accuracy (Align Words, Choose Image): 0.5625 (0.4160)  Batch Accuracy (Choose Caption): 0.5938 (0.3942)  Batch Accuracy (Choose Image): 0.6406 (0.4053)  Masked Language Modeling Accuracy: 0.5522 (0.4914)  time: 0.9701 (1.0882)  data: 0.0504 (0.1225)  lr: 0.010000  max mem: 10947
2021-04-13 00:46:55,029 maskrcnn_benchmark.trainer INFO: eta: 11:36:24  iter: 1500  Cross-Entropy Loss (Align Regions, Choose Caption): 1.1424 (1.4878)  Cross-Entropy Loss (Align Regions, Choose Image): 1.1327 (1.4842)  Cross-Entropy Loss (Align Words, Choose Caption): 1.2862 (1.6456)  Cross-Entropy Loss (Align Words, Choose Image): 1.1815 (1.5620)  Image Caption Matching Loss: 1.9171 (2.9692)  Masked Language Modeling Loss: 2.4164 (3.0352)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 9.1438 (12.1840)  Batch Accuracy (Align Regions, Choose Caption): 0.5938 (0.4547)  Batch Accuracy (Align Regions, Choose Image): 0.5781 (0.4632)  Batch Accuracy (Align Words, Choose Caption): 0.5312 (0.3925)  Batch Accuracy (Align Words, Choose Image): 0.5625 (0.4262)  Batch Accuracy (Choose Caption): 0.5938 (0.4086)  Batch Accuracy (Choose Image): 0.6250 (0.4199)  Masked Language Modeling Accuracy: 0.5554 (0.4961)  time: 1.0053 (1.0853)  data: 0.0566 (0.1184)  lr: 0.010000  max mem: 10947
2021-04-13 00:48:36,475 maskrcnn_benchmark.trainer INFO: eta: 11:31:45  iter: 1600  Cross-Entropy Loss (Align Regions, Choose Caption): 1.1577 (1.4661)  Cross-Entropy Loss (Align Regions, Choose Image): 1.1183 (1.4604)  Cross-Entropy Loss (Align Words, Choose Caption): 1.3345 (1.6261)  Cross-Entropy Loss (Align Words, Choose Image): 1.1837 (1.5388)  Image Caption Matching Loss: 1.9139 (2.9036)  Masked Language Modeling Loss: 2.4159 (2.9974)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 9.1427 (11.9924)  Batch Accuracy (Align Regions, Choose Caption): 0.5938 (0.4641)  Batch Accuracy (Align Regions, Choose Image): 0.6094 (0.4722)  Batch Accuracy (Align Words, Choose Caption): 0.5312 (0.4007)  Batch Accuracy (Align Words, Choose Image): 0.5938 (0.4356)  Batch Accuracy (Choose Caption): 0.6094 (0.4222)  Batch Accuracy (Choose Image): 0.6250 (0.4339)  Masked Language Modeling Accuracy: 0.5820 (0.5002)  time: 0.9933 (1.0809)  data: 0.0621 (0.1150)  lr: 0.010000  max mem: 10947
2021-04-13 00:50:17,401 maskrcnn_benchmark.trainer INFO: eta: 11:27:16  iter: 1700  Cross-Entropy Loss (Align Regions, Choose Caption): 1.1440 (1.4477)  Cross-Entropy Loss (Align Regions, Choose Image): 1.0969 (1.4412)  Cross-Entropy Loss (Align Words, Choose Caption): 1.2821 (1.6081)  Cross-Entropy Loss (Align Words, Choose Image): 1.1870 (1.5184)  Image Caption Matching Loss: 1.8832 (2.8482)  Masked Language Modeling Loss: 2.3130 (2.9602)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.7453 (11.8238)  Batch Accuracy (Align Regions, Choose Caption): 0.5781 (0.4716)  Batch Accuracy (Align Regions, Choose Image): 0.6094 (0.4798)  Batch Accuracy (Align Words, Choose Caption): 0.5312 (0.4084)  Batch Accuracy (Align Words, Choose Image): 0.5781 (0.4446)  Batch Accuracy (Choose Caption): 0.6094 (0.4335)  Batch Accuracy (Choose Image): 0.6250 (0.4450)  Masked Language Modeling Accuracy: 0.5810 (0.5044)  time: 0.9647 (1.0767)  data: 0.0506 (0.1116)  lr: 0.010000  max mem: 10947
2021-04-13 00:51:58,735 maskrcnn_benchmark.trainer INFO: eta: 11:23:14  iter: 1800  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0486 (1.4297)  Cross-Entropy Loss (Align Regions, Choose Image): 1.0913 (1.4236)  Cross-Entropy Loss (Align Words, Choose Caption): 1.2921 (1.5910)  Cross-Entropy Loss (Align Words, Choose Image): 1.1910 (1.5000)  Image Caption Matching Loss: 1.8168 (2.7944)  Masked Language Modeling Loss: 2.2919 (2.9283)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.9038 (11.6670)  Batch Accuracy (Align Regions, Choose Caption): 0.6094 (0.4790)  Batch Accuracy (Align Regions, Choose Image): 0.6250 (0.4873)  Batch Accuracy (Align Words, Choose Caption): 0.5312 (0.4154)  Batch Accuracy (Align Words, Choose Image): 0.5781 (0.4520)  Batch Accuracy (Choose Caption): 0.6094 (0.4442)  Batch Accuracy (Choose Image): 0.6406 (0.4562)  Masked Language Modeling Accuracy: 0.5668 (0.5080)  time: 0.9887 (1.0732)  data: 0.0516 (0.1087)  lr: 0.010000  max mem: 10947
2021-04-13 00:53:39,339 maskrcnn_benchmark.trainer INFO: eta: 11:19:12  iter: 1900  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0777 (1.4112)  Cross-Entropy Loss (Align Regions, Choose Image): 1.0984 (1.4044)  Cross-Entropy Loss (Align Words, Choose Caption): 1.2145 (1.5729)  Cross-Entropy Loss (Align Words, Choose Image): 1.1210 (1.4799)  Image Caption Matching Loss: 1.7595 (2.7413)  Masked Language Modeling Loss: 2.3584 (2.8992)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.5937 (11.5088)  Batch Accuracy (Align Regions, Choose Caption): 0.5938 (0.4864)  Batch Accuracy (Align Regions, Choose Image): 0.6094 (0.4949)  Batch Accuracy (Align Words, Choose Caption): 0.5625 (0.4229)  Batch Accuracy (Align Words, Choose Image): 0.6094 (0.4603)  Batch Accuracy (Choose Caption): 0.6562 (0.4549)  Batch Accuracy (Choose Image): 0.6719 (0.4675)  Masked Language Modeling Accuracy: 0.5367 (0.5111)  time: 0.9979 (1.0696)  data: 0.0482 (0.1060)  lr: 0.010000  max mem: 10947
2021-04-13 00:55:21,328 maskrcnn_benchmark.trainer INFO: eta: 11:15:51  iter: 2000  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0095 (1.3926)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9579 (1.3846)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1824 (1.5545)  Cross-Entropy Loss (Align Words, Choose Image): 1.0454 (1.4596)  Image Caption Matching Loss: 1.6106 (2.6878)  Masked Language Modeling Loss: 2.2759 (2.8702)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.2001 (11.3493)  Batch Accuracy (Align Regions, Choose Caption): 0.6250 (0.4939)  Batch Accuracy (Align Regions, Choose Image): 0.6406 (0.5024)  Batch Accuracy (Align Words, Choose Caption): 0.5781 (0.4306)  Batch Accuracy (Align Words, Choose Image): 0.5938 (0.4681)  Batch Accuracy (Choose Caption): 0.6875 (0.4657)  Batch Accuracy (Choose Image): 0.6875 (0.4786)  Masked Language Modeling Accuracy: 0.5753 (0.5141)  time: 0.9755 (1.0671)  data: 0.0496 (0.1037)  lr: 0.010000  max mem: 10947
2021-04-13 00:55:22,288 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0002000.pth
2021-04-13 00:56:48,012 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 11:15:51  iter: 2000  loss: 5.7834 (5.8759)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9609 (0.9542)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9669 (0.9241)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1672 (1.1898)  Cross-Entropy Loss (Align Words, Choose Image): 1.0011 (1.0193)  Image Caption Matching Loss: 1.7912 (1.7886)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.6250 (0.6564)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.6796)  Batch Accuracy (Align Words, Choose Caption): 0.5625 (0.5694)  Batch Accuracy (Align Words, Choose Image): 0.6250 (0.6493)  Batch Accuracy (Choose Caption): 0.6406 (0.6607)  Batch Accuracy (Choose Image): 0.6406 (0.6463)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 10947
2021-04-13 00:58:28,737 maskrcnn_benchmark.trainer INFO: eta: 11:38:20  iter: 2100  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0279 (1.3766)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9987 (1.3671)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1640 (1.5390)  Cross-Entropy Loss (Align Words, Choose Image): 1.0260 (1.4413)  Image Caption Matching Loss: 1.6479 (2.6433)  Masked Language Modeling Loss: 2.2710 (2.8418)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.1081 (11.2090)  Batch Accuracy (Align Regions, Choose Caption): 0.6250 (0.5006)  Batch Accuracy (Align Regions, Choose Image): 0.6406 (0.5089)  Batch Accuracy (Align Words, Choose Caption): 0.5781 (0.4370)  Batch Accuracy (Align Words, Choose Image): 0.6250 (0.4753)  Batch Accuracy (Choose Caption): 0.6719 (0.4746)  Batch Accuracy (Choose Image): 0.6875 (0.4879)  Masked Language Modeling Accuracy: 0.5792 (0.5174)  time: 0.9715 (1.1056)  data: 0.0533 (0.1429)  lr: 0.010000  max mem: 10947
2021-04-13 01:00:11,774 maskrcnn_benchmark.trainer INFO: eta: 11:34:20  iter: 2200  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0256 (1.3599)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9926 (1.3500)  Cross-Entropy Loss (Align Words, Choose Caption): 1.2166 (1.5229)  Cross-Entropy Loss (Align Words, Choose Image): 1.0539 (1.4234)  Image Caption Matching Loss: 1.4705 (2.5960)  Masked Language Modeling Loss: 2.1648 (2.8165)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.9957 (11.0687)  Batch Accuracy (Align Regions, Choose Caption): 0.6406 (0.5078)  Batch Accuracy (Align Regions, Choose Image): 0.6406 (0.5151)  Batch Accuracy (Align Words, Choose Caption): 0.5781 (0.4437)  Batch Accuracy (Align Words, Choose Image): 0.6250 (0.4823)  Batch Accuracy (Choose Caption): 0.6875 (0.4842)  Batch Accuracy (Choose Image): 0.7188 (0.4974)  Masked Language Modeling Accuracy: 0.5720 (0.5201)  time: 0.9780 (1.1021)  data: 0.0458 (0.1391)  lr: 0.010000  max mem: 10947
2021-04-13 01:01:53,221 maskrcnn_benchmark.trainer INFO: eta: 11:30:07  iter: 2300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9944 (1.3447)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9151 (1.3340)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1287 (1.5079)  Cross-Entropy Loss (Align Words, Choose Image): 0.9812 (1.4068)  Image Caption Matching Loss: 1.4875 (2.5536)  Masked Language Modeling Loss: 2.3218 (2.7934)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.0684 (10.9405)  Batch Accuracy (Align Regions, Choose Caption): 0.6719 (0.5138)  Batch Accuracy (Align Regions, Choose Image): 0.6406 (0.5210)  Batch Accuracy (Align Words, Choose Caption): 0.6094 (0.4499)  Batch Accuracy (Align Words, Choose Image): 0.6719 (0.4892)  Batch Accuracy (Choose Caption): 0.6562 (0.4926)  Batch Accuracy (Choose Image): 0.6875 (0.5064)  Masked Language Modeling Accuracy: 0.5639 (0.5227)  time: 0.9836 (1.0983)  data: 0.0604 (0.1357)  lr: 0.010000  max mem: 10947
2021-04-13 01:03:37,799 maskrcnn_benchmark.trainer INFO: eta: 11:26:54  iter: 2400  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0282 (1.3303)  Cross-Entropy Loss (Align Regions, Choose Image): 1.0354 (1.3190)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1983 (1.4928)  Cross-Entropy Loss (Align Words, Choose Image): 1.0738 (1.3905)  Image Caption Matching Loss: 1.5900 (2.5127)  Masked Language Modeling Loss: 2.2568 (2.7720)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.1519 (10.8174)  Batch Accuracy (Align Regions, Choose Caption): 0.6406 (0.5193)  Batch Accuracy (Align Regions, Choose Image): 0.6406 (0.5268)  Batch Accuracy (Align Words, Choose Caption): 0.5781 (0.4559)  Batch Accuracy (Align Words, Choose Image): 0.6094 (0.4954)  Batch Accuracy (Choose Caption): 0.6875 (0.5009)  Batch Accuracy (Choose Image): 0.7188 (0.5150)  Masked Language Modeling Accuracy: 0.5676 (0.5252)  time: 1.0029 (1.0961)  data: 0.0666 (0.1325)  lr: 0.010000  max mem: 10947
2021-04-13 01:05:19,643 maskrcnn_benchmark.trainer INFO: eta: 11:23:09  iter: 2500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9292 (1.3155)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9533 (1.3042)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1110 (1.4773)  Cross-Entropy Loss (Align Words, Choose Image): 0.9721 (1.3738)  Image Caption Matching Loss: 1.4854 (2.4725)  Masked Language Modeling Loss: 2.3169 (2.7521)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.8285 (10.6954)  Batch Accuracy (Align Regions, Choose Caption): 0.6719 (0.5252)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.5325)  Batch Accuracy (Align Words, Choose Caption): 0.5625 (0.4619)  Batch Accuracy (Align Words, Choose Image): 0.6562 (0.5019)  Batch Accuracy (Choose Caption): 0.6719 (0.5088)  Batch Accuracy (Choose Image): 0.7031 (0.5235)  Masked Language Modeling Accuracy: 0.5692 (0.5273)  time: 0.9708 (1.0930)  data: 0.0678 (0.1298)  lr: 0.010000  max mem: 10947
2021-04-13 01:07:02,720 maskrcnn_benchmark.trainer INFO: eta: 11:19:49  iter: 2600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9492 (1.3022)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9005 (1.2903)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0703 (1.4637)  Cross-Entropy Loss (Align Words, Choose Image): 0.9463 (1.3580)  Image Caption Matching Loss: 1.4736 (2.4354)  Masked Language Modeling Loss: 2.1909 (2.7306)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.5718 (10.5802)  Batch Accuracy (Align Regions, Choose Caption): 0.6406 (0.5306)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.5376)  Batch Accuracy (Align Words, Choose Caption): 0.5938 (0.4677)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.5083)  Batch Accuracy (Choose Caption): 0.7344 (0.5164)  Batch Accuracy (Choose Image): 0.7188 (0.5309)  Masked Language Modeling Accuracy: 0.5853 (0.5298)  time: 0.9939 (1.0906)  data: 0.0594 (0.1273)  lr: 0.010000  max mem: 10947
2021-04-13 01:08:45,102 maskrcnn_benchmark.trainer INFO: eta: 11:16:28  iter: 2700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9556 (1.2886)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9239 (1.2770)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0748 (1.4494)  Cross-Entropy Loss (Align Words, Choose Image): 0.9521 (1.3423)  Image Caption Matching Loss: 1.4526 (2.3990)  Masked Language Modeling Loss: 2.2006 (2.7118)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.4241 (10.4683)  Batch Accuracy (Align Regions, Choose Caption): 0.6562 (0.5356)  Batch Accuracy (Align Regions, Choose Image): 0.6562 (0.5427)  Batch Accuracy (Align Words, Choose Caption): 0.6250 (0.4736)  Batch Accuracy (Align Words, Choose Image): 0.6719 (0.5145)  Batch Accuracy (Choose Caption): 0.7031 (0.5237)  Batch Accuracy (Choose Image): 0.7656 (0.5385)  Masked Language Modeling Accuracy: 0.5858 (0.5316)  time: 0.9951 (1.0882)  data: 0.0553 (0.1248)  lr: 0.010000  max mem: 10947
2021-04-13 01:10:26,822 maskrcnn_benchmark.trainer INFO: eta: 11:13:05  iter: 2800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9590 (1.2767)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9043 (1.2647)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0392 (1.4366)  Cross-Entropy Loss (Align Words, Choose Image): 0.9674 (1.3282)  Image Caption Matching Loss: 1.5316 (2.3671)  Masked Language Modeling Loss: 2.1686 (2.6944)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.4857 (10.3677)  Batch Accuracy (Align Regions, Choose Caption): 0.6719 (0.5404)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.5475)  Batch Accuracy (Align Words, Choose Caption): 0.5938 (0.4787)  Batch Accuracy (Align Words, Choose Image): 0.6719 (0.5203)  Batch Accuracy (Choose Caption): 0.6719 (0.5302)  Batch Accuracy (Choose Image): 0.7188 (0.5451)  Masked Language Modeling Accuracy: 0.5760 (0.5337)  time: 0.9900 (1.0856)  data: 0.0493 (0.1224)  lr: 0.010000  max mem: 10947
2021-04-13 01:12:08,381 maskrcnn_benchmark.trainer INFO: eta: 11:09:47  iter: 2900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8960 (1.2643)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8276 (1.2516)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0351 (1.4234)  Cross-Entropy Loss (Align Words, Choose Image): 0.8635 (1.3136)  Image Caption Matching Loss: 1.3172 (2.3339)  Masked Language Modeling Loss: 2.2415 (2.6772)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.0770 (10.2640)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5454)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5523)  Batch Accuracy (Align Words, Choose Caption): 0.6406 (0.4842)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.5259)  Batch Accuracy (Choose Caption): 0.7344 (0.5369)  Batch Accuracy (Choose Image): 0.7656 (0.5518)  Masked Language Modeling Accuracy: 0.5648 (0.5354)  time: 0.9935 (1.0832)  data: 0.0609 (0.1202)  lr: 0.010000  max mem: 10947
2021-04-13 01:13:48,756 maskrcnn_benchmark.trainer INFO: eta: 11:06:21  iter: 3000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9199 (1.2524)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8370 (1.2385)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0227 (1.4107)  Cross-Entropy Loss (Align Words, Choose Image): 0.8680 (1.2998)  Image Caption Matching Loss: 1.4320 (2.3020)  Masked Language Modeling Loss: 2.2637 (2.6613)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.4574 (10.1647)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5503)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.5573)  Batch Accuracy (Align Words, Choose Caption): 0.6406 (0.4892)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.5314)  Batch Accuracy (Choose Caption): 0.7188 (0.5433)  Batch Accuracy (Choose Image): 0.7500 (0.5583)  Masked Language Modeling Accuracy: 0.5949 (0.5374)  time: 0.9727 (1.0806)  data: 0.0477 (0.1181)  lr: 0.010000  max mem: 10947
2021-04-13 01:13:49,901 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0003000.pth
2021-04-13 01:15:15,872 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 11:06:21  iter: 3000  loss: 5.2761 (5.1693)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8096 (0.7963)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8193 (0.8004)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0946 (1.0126)  Cross-Entropy Loss (Align Words, Choose Image): 0.8356 (0.7840)  Image Caption Matching Loss: 1.7818 (1.7760)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.7248)  Batch Accuracy (Align Regions, Choose Image): 0.6875 (0.7282)  Batch Accuracy (Align Words, Choose Caption): 0.6198 (0.6400)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.7257)  Batch Accuracy (Choose Caption): 0.6562 (0.6626)  Batch Accuracy (Choose Image): 0.6094 (0.6468)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 10947
2021-04-13 01:17:00,332 maskrcnn_benchmark.trainer INFO: eta: 11:21:07  iter: 3100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9258 (1.2420)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8938 (1.2276)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0248 (1.3987)  Cross-Entropy Loss (Align Words, Choose Image): 0.8676 (1.2867)  Image Caption Matching Loss: 1.3448 (2.2728)  Masked Language Modeling Loss: 2.1687 (2.6463)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.2569 (10.0740)  Batch Accuracy (Align Regions, Choose Caption): 0.6719 (0.5543)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.5614)  Batch Accuracy (Align Words, Choose Caption): 0.6250 (0.4940)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.5366)  Batch Accuracy (Choose Caption): 0.7188 (0.5494)  Batch Accuracy (Choose Image): 0.7500 (0.5641)  Masked Language Modeling Accuracy: 0.5943 (0.5389)  time: 0.9688 (1.1075)  data: 0.0484 (0.1443)  lr: 0.010000  max mem: 11046
2021-04-13 01:18:41,773 maskrcnn_benchmark.trainer INFO: eta: 11:17:29  iter: 3200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9101 (1.2317)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9110 (1.2172)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0451 (1.3876)  Cross-Entropy Loss (Align Words, Choose Image): 0.9152 (1.2744)  Image Caption Matching Loss: 1.4195 (2.2451)  Masked Language Modeling Loss: 2.1715 (2.6317)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.3559 (9.9877)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5585)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.5655)  Batch Accuracy (Align Words, Choose Caption): 0.5938 (0.4985)  Batch Accuracy (Align Words, Choose Image): 0.6719 (0.5413)  Batch Accuracy (Choose Caption): 0.7188 (0.5547)  Batch Accuracy (Choose Image): 0.7344 (0.5698)  Masked Language Modeling Accuracy: 0.5793 (0.5403)  time: 0.9783 (1.1046)  data: 0.0569 (0.1417)  lr: 0.010000  max mem: 11046
2021-04-13 01:20:23,121 maskrcnn_benchmark.trainer INFO: eta: 11:13:57  iter: 3300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8728 (1.2212)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8265 (1.2059)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9798 (1.3761)  Cross-Entropy Loss (Align Words, Choose Image): 0.8351 (1.2618)  Image Caption Matching Loss: 1.2982 (2.2178)  Masked Language Modeling Loss: 1.9012 (2.6159)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.8211 (9.8988)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5624)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5696)  Batch Accuracy (Align Words, Choose Caption): 0.6562 (0.5030)  Batch Accuracy (Align Words, Choose Image): 0.7031 (0.5461)  Batch Accuracy (Choose Caption): 0.7344 (0.5603)  Batch Accuracy (Choose Image): 0.7500 (0.5752)  Masked Language Modeling Accuracy: 0.6241 (0.5422)  time: 0.9836 (1.1018)  data: 0.0534 (0.1391)  lr: 0.010000  max mem: 11046
2021-04-13 01:22:04,766 maskrcnn_benchmark.trainer INFO: eta: 11:10:35  iter: 3400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8582 (1.2112)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7775 (1.1954)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0006 (1.3649)  Cross-Entropy Loss (Align Words, Choose Image): 0.8175 (1.2496)  Image Caption Matching Loss: 1.2268 (2.1911)  Masked Language Modeling Loss: 2.0675 (2.6019)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.7048 (9.8141)  Batch Accuracy (Align Regions, Choose Caption): 0.7031 (0.5662)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5733)  Batch Accuracy (Align Words, Choose Caption): 0.6562 (0.5075)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.5507)  Batch Accuracy (Choose Caption): 0.7344 (0.5653)  Batch Accuracy (Choose Image): 0.7812 (0.5805)  Masked Language Modeling Accuracy: 0.6093 (0.5438)  time: 0.9902 (1.0993)  data: 0.0613 (0.1369)  lr: 0.010000  max mem: 11046
2021-04-13 01:23:46,392 maskrcnn_benchmark.trainer INFO: eta: 11:07:18  iter: 3500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8710 (1.2016)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8309 (1.1856)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9797 (1.3540)  Cross-Entropy Loss (Align Words, Choose Image): 0.8438 (1.2385)  Image Caption Matching Loss: 1.3411 (2.1647)  Masked Language Modeling Loss: 2.1017 (2.5885)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.9964 (9.7330)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5699)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5771)  Batch Accuracy (Align Words, Choose Caption): 0.6562 (0.5117)  Batch Accuracy (Align Words, Choose Image): 0.7031 (0.5548)  Batch Accuracy (Choose Caption): 0.7656 (0.5706)  Batch Accuracy (Choose Image): 0.7500 (0.5858)  Masked Language Modeling Accuracy: 0.5875 (0.5455)  time: 0.9759 (1.0970)  data: 0.0534 (0.1347)  lr: 0.010000  max mem: 11046
2021-04-13 01:25:27,415 maskrcnn_benchmark.trainer INFO: eta: 11:04:01  iter: 3600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8663 (1.1919)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8501 (1.1757)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9477 (1.3432)  Cross-Entropy Loss (Align Words, Choose Image): 0.8397 (1.2271)  Image Caption Matching Loss: 1.2722 (2.1388)  Masked Language Modeling Loss: 2.1378 (2.5749)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.7059 (9.6515)  Batch Accuracy (Align Regions, Choose Caption): 0.7031 (0.5738)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5809)  Batch Accuracy (Align Words, Choose Caption): 0.6562 (0.5160)  Batch Accuracy (Align Words, Choose Image): 0.7031 (0.5592)  Batch Accuracy (Choose Caption): 0.7656 (0.5759)  Batch Accuracy (Choose Image): 0.7812 (0.5911)  Masked Language Modeling Accuracy: 0.6063 (0.5471)  time: 0.9725 (1.0945)  data: 0.0648 (0.1325)  lr: 0.010000  max mem: 11046
2021-04-13 01:27:08,837 maskrcnn_benchmark.trainer INFO: eta: 11:00:53  iter: 3700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8222 (1.1827)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7900 (1.1659)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8980 (1.3329)  Cross-Entropy Loss (Align Words, Choose Image): 0.7887 (1.2162)  Image Caption Matching Loss: 1.1411 (2.1149)  Masked Language Modeling Loss: 2.1014 (2.5630)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.4508 (9.5756)  Batch Accuracy (Align Regions, Choose Caption): 0.7031 (0.5775)  Batch Accuracy (Align Regions, Choose Image): 0.7188 (0.5846)  Batch Accuracy (Align Words, Choose Caption): 0.6875 (0.5202)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.5633)  Batch Accuracy (Choose Caption): 0.7812 (0.5807)  Batch Accuracy (Choose Image): 0.7865 (0.5959)  Masked Language Modeling Accuracy: 0.5955 (0.5486)  time: 0.9821 (1.0924)  data: 0.0534 (0.1305)  lr: 0.010000  max mem: 11046
2021-04-13 01:28:50,305 maskrcnn_benchmark.trainer INFO: eta: 10:57:49  iter: 3800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8419 (1.1744)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8206 (1.1571)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9332 (1.3233)  Cross-Entropy Loss (Align Words, Choose Image): 0.7869 (1.2059)  Image Caption Matching Loss: 1.2262 (2.0930)  Masked Language Modeling Loss: 2.1784 (2.5520)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.7030 (9.5058)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5807)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5880)  Batch Accuracy (Align Words, Choose Caption): 0.6562 (0.5240)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.5672)  Batch Accuracy (Choose Caption): 0.7656 (0.5852)  Batch Accuracy (Choose Image): 0.7656 (0.6000)  Masked Language Modeling Accuracy: 0.5732 (0.5498)  time: 0.9998 (1.0903)  data: 0.0602 (0.1286)  lr: 0.010000  max mem: 11046
2021-04-13 01:30:31,517 maskrcnn_benchmark.trainer INFO: eta: 10:54:48  iter: 3900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8144 (1.1652)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7581 (1.1481)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9136 (1.3130)  Cross-Entropy Loss (Align Words, Choose Image): 0.7493 (1.1954)  Image Caption Matching Loss: 1.1480 (2.0697)  Masked Language Modeling Loss: 2.2660 (2.5411)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.6863 (9.4324)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.5843)  Batch Accuracy (Align Regions, Choose Image): 0.7188 (0.5914)  Batch Accuracy (Align Words, Choose Caption): 0.6719 (0.5281)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.5712)  Batch Accuracy (Choose Caption): 0.7656 (0.5899)  Batch Accuracy (Choose Image): 0.7812 (0.6046)  Masked Language Modeling Accuracy: 0.5922 (0.5510)  time: 1.0035 (1.0883)  data: 0.0567 (0.1269)  lr: 0.010000  max mem: 11046
2021-04-13 01:32:12,945 maskrcnn_benchmark.trainer INFO: eta: 10:51:53  iter: 4000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8204 (1.1566)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8611 (1.1396)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9547 (1.3031)  Cross-Entropy Loss (Align Words, Choose Image): 0.7707 (1.1853)  Image Caption Matching Loss: 1.2163 (2.0481)  Masked Language Modeling Loss: 2.1230 (2.5306)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.8251 (9.3632)  Batch Accuracy (Align Regions, Choose Caption): 0.7031 (0.5876)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5946)  Batch Accuracy (Align Words, Choose Caption): 0.6719 (0.5319)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.5750)  Batch Accuracy (Choose Caption): 0.7500 (0.5942)  Batch Accuracy (Choose Image): 0.7656 (0.6089)  Masked Language Modeling Accuracy: 0.5658 (0.5521)  time: 0.9732 (1.0865)  data: 0.0552 (0.1252)  lr: 0.010000  max mem: 11046
2021-04-13 01:32:13,889 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0004000.pth
2021-04-13 01:33:39,040 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 10:51:53  iter: 4000  loss: 3.9996 (3.8830)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6464 (0.6464)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6274 (0.6374)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8449 (0.8298)  Cross-Entropy Loss (Align Words, Choose Image): 0.6950 (0.6959)  Image Caption Matching Loss: 1.0810 (1.0735)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.7708 (0.7718)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.7763)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.7039)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.7537)  Batch Accuracy (Choose Caption): 0.7969 (0.8095)  Batch Accuracy (Choose Image): 0.7946 (0.7957)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11046
2021-04-13 01:35:21,230 maskrcnn_benchmark.trainer INFO: eta: 11:01:41  iter: 4100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7984 (1.1483)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8360 (1.1315)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8989 (1.2934)  Cross-Entropy Loss (Align Words, Choose Image): 0.8009 (1.1756)  Image Caption Matching Loss: 1.2905 (2.0266)  Masked Language Modeling Loss: 2.0511 (2.5190)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.7550 (9.2944)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.5908)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5976)  Batch Accuracy (Align Words, Choose Caption): 0.6719 (0.5357)  Batch Accuracy (Align Words, Choose Image): 0.7188 (0.5786)  Batch Accuracy (Choose Caption): 0.7656 (0.5984)  Batch Accuracy (Choose Image): 0.7656 (0.6132)  Masked Language Modeling Accuracy: 0.5849 (0.5534)  time: 0.9879 (1.1059)  data: 0.0532 (0.1446)  lr: 0.010000  max mem: 11046
2021-04-13 01:37:02,666 maskrcnn_benchmark.trainer INFO: eta: 10:58:33  iter: 4200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8018 (1.1397)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7456 (1.1227)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9440 (1.2831)  Cross-Entropy Loss (Align Words, Choose Image): 0.7924 (1.1652)  Image Caption Matching Loss: 1.1039 (2.0044)  Masked Language Modeling Loss: 2.0980 (2.5092)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.5782 (9.2243)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.5942)  Batch Accuracy (Align Regions, Choose Image): 0.7188 (0.6009)  Batch Accuracy (Align Words, Choose Caption): 0.6562 (0.5396)  Batch Accuracy (Align Words, Choose Image): 0.7031 (0.5824)  Batch Accuracy (Choose Caption): 0.7812 (0.6030)  Batch Accuracy (Choose Image): 0.7500 (0.6175)  Masked Language Modeling Accuracy: 0.5938 (0.5545)  time: 0.9814 (1.1037)  data: 0.0504 (0.1426)  lr: 0.010000  max mem: 11046
2021-04-13 01:38:44,595 maskrcnn_benchmark.trainer INFO: eta: 10:55:32  iter: 4300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6828 (1.1317)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7409 (1.1147)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8148 (1.2738)  Cross-Entropy Loss (Align Words, Choose Image): 0.7546 (1.1559)  Image Caption Matching Loss: 1.1063 (1.9845)  Masked Language Modeling Loss: 2.0136 (2.4997)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.3014 (9.1603)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.5974)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6040)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.5433)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.5859)  Batch Accuracy (Choose Caption): 0.7812 (0.6069)  Batch Accuracy (Choose Image): 0.7969 (0.6214)  Masked Language Modeling Accuracy: 0.6086 (0.5556)  time: 0.9946 (1.1017)  data: 0.0526 (0.1407)  lr: 0.010000  max mem: 11046
2021-04-13 01:40:26,233 maskrcnn_benchmark.trainer INFO: eta: 10:52:33  iter: 4400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7266 (1.1236)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7175 (1.1062)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7992 (1.2646)  Cross-Entropy Loss (Align Words, Choose Image): 0.6805 (1.1467)  Image Caption Matching Loss: 0.9863 (1.9643)  Masked Language Modeling Loss: 2.1681 (2.4907)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.0468 (9.0961)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.6004)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6072)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5468)  Batch Accuracy (Align Words, Choose Image): 0.7656 (0.5895)  Batch Accuracy (Choose Caption): 0.7656 (0.6109)  Batch Accuracy (Choose Image): 0.8125 (0.6254)  Masked Language Modeling Accuracy: 0.5890 (0.5566)  time: 0.9746 (1.0998)  data: 0.0581 (0.1388)  lr: 0.010000  max mem: 11046
2021-04-13 01:42:08,315 maskrcnn_benchmark.trainer INFO: eta: 10:49:41  iter: 4500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7755 (1.1159)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7546 (1.0985)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8545 (1.2558)  Cross-Entropy Loss (Align Words, Choose Image): 0.7247 (1.1378)  Image Caption Matching Loss: 1.0290 (1.9458)  Masked Language Modeling Loss: 2.1900 (2.4819)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.3436 (9.0357)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.6035)  Batch Accuracy (Align Regions, Choose Image): 0.7344 (0.6102)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5502)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.5929)  Batch Accuracy (Choose Caption): 0.7969 (0.6147)  Batch Accuracy (Choose Image): 0.7969 (0.6291)  Masked Language Modeling Accuracy: 0.6070 (0.5578)  time: 0.9803 (1.0981)  data: 0.0574 (0.1371)  lr: 0.010000  max mem: 11046
2021-04-13 01:43:50,413 maskrcnn_benchmark.trainer INFO: eta: 10:46:51  iter: 4600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8538 (1.1087)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8077 (1.0912)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8921 (1.2476)  Cross-Entropy Loss (Align Words, Choose Image): 0.6916 (1.1290)  Image Caption Matching Loss: 1.0901 (1.9276)  Masked Language Modeling Loss: 2.0606 (2.4729)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.5085 (8.9769)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.6061)  Batch Accuracy (Align Regions, Choose Image): 0.7188 (0.6130)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.5534)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.5962)  Batch Accuracy (Choose Caption): 0.7656 (0.6183)  Batch Accuracy (Choose Image): 0.7969 (0.6328)  Masked Language Modeling Accuracy: 0.6078 (0.5589)  time: 0.9785 (1.0964)  data: 0.0607 (0.1354)  lr: 0.010000  max mem: 11046
2021-04-13 01:45:34,244 maskrcnn_benchmark.trainer INFO: eta: 10:44:18  iter: 4700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7922 (1.1016)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8059 (1.0839)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8193 (1.2392)  Cross-Entropy Loss (Align Words, Choose Image): 0.7245 (1.1205)  Image Caption Matching Loss: 1.0728 (1.9098)  Masked Language Modeling Loss: 2.0245 (2.4657)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.5633 (8.9207)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6090)  Batch Accuracy (Align Regions, Choose Image): 0.7344 (0.6158)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.5567)  Batch Accuracy (Align Words, Choose Image): 0.7656 (0.5995)  Batch Accuracy (Choose Caption): 0.7656 (0.6219)  Batch Accuracy (Choose Image): 0.8281 (0.6365)  Masked Language Modeling Accuracy: 0.5881 (0.5595)  time: 0.9835 (1.0951)  data: 0.0573 (0.1339)  lr: 0.010000  max mem: 11046
2021-04-13 01:47:15,699 maskrcnn_benchmark.trainer INFO: eta: 10:41:30  iter: 4800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6903 (1.0944)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7142 (1.0768)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7702 (1.2305)  Cross-Entropy Loss (Align Words, Choose Image): 0.6733 (1.1119)  Image Caption Matching Loss: 0.9411 (1.8919)  Masked Language Modeling Loss: 2.0080 (2.4583)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.9544 (8.8638)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6117)  Batch Accuracy (Align Regions, Choose Image): 0.7344 (0.6186)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.5600)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.6028)  Batch Accuracy (Choose Caption): 0.8125 (0.6255)  Batch Accuracy (Choose Image): 0.8125 (0.6401)  Masked Language Modeling Accuracy: 0.6221 (0.5603)  time: 0.9897 (1.0935)  data: 0.0551 (0.1323)  lr: 0.010000  max mem: 11046
2021-04-13 01:48:57,332 maskrcnn_benchmark.trainer INFO: eta: 10:38:45  iter: 4900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6891 (1.0875)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6949 (1.0696)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8469 (1.2227)  Cross-Entropy Loss (Align Words, Choose Image): 0.7357 (1.1041)  Image Caption Matching Loss: 0.9812 (1.8749)  Masked Language Modeling Loss: 2.1248 (2.4501)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.0178 (8.8088)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6143)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6212)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5629)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.6057)  Batch Accuracy (Choose Caption): 0.8125 (0.6289)  Batch Accuracy (Choose Image): 0.7969 (0.6434)  Masked Language Modeling Accuracy: 0.5834 (0.5611)  time: 0.9890 (1.0919)  data: 0.0616 (0.1309)  lr: 0.010000  max mem: 11046
2021-04-13 01:50:39,873 maskrcnn_benchmark.trainer INFO: eta: 10:36:09  iter: 5000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7781 (1.0810)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7468 (1.0628)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8927 (1.2150)  Cross-Entropy Loss (Align Words, Choose Image): 0.6991 (1.0962)  Image Caption Matching Loss: 1.1209 (1.8585)  Masked Language Modeling Loss: 2.0439 (2.4414)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.2325 (8.7549)  Batch Accuracy (Align Regions, Choose Caption): 0.7031 (0.6169)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6236)  Batch Accuracy (Align Words, Choose Caption): 0.6875 (0.5659)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.6086)  Batch Accuracy (Choose Caption): 0.7812 (0.6323)  Batch Accuracy (Choose Image): 0.7656 (0.6466)  Masked Language Modeling Accuracy: 0.6069 (0.5622)  time: 0.9607 (1.0906)  data: 0.0651 (0.1295)  lr: 0.010000  max mem: 11046
2021-04-13 01:50:40,986 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0005000.pth
2021-04-13 01:52:07,211 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 10:36:09  iter: 5000  loss: 3.3605 (3.5280)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5886 (0.6056)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6116 (0.6096)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6918 (0.7039)  Cross-Entropy Loss (Align Words, Choose Image): 0.6304 (0.5999)  Image Caption Matching Loss: 0.9205 (1.0090)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.7884)  Batch Accuracy (Align Regions, Choose Image): 0.7902 (0.7952)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.7565)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7974)  Batch Accuracy (Choose Caption): 0.8281 (0.8185)  Batch Accuracy (Choose Image): 0.8281 (0.8168)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11046
2021-04-13 01:53:50,384 maskrcnn_benchmark.trainer INFO: eta: 10:43:38  iter: 5100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6903 (1.0740)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7091 (1.0560)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8080 (1.2066)  Cross-Entropy Loss (Align Words, Choose Image): 0.6939 (1.0881)  Image Caption Matching Loss: 0.9569 (1.8417)  Masked Language Modeling Loss: 2.0002 (2.4327)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.7705 (8.6990)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6195)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6261)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5690)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6116)  Batch Accuracy (Choose Caption): 0.7969 (0.6356)  Batch Accuracy (Choose Image): 0.8125 (0.6498)  Masked Language Modeling Accuracy: 0.6298 (0.5633)  time: 0.9935 (1.1065)  data: 0.0479 (0.1453)  lr: 0.010000  max mem: 11046
2021-04-13 01:55:34,572 maskrcnn_benchmark.trainer INFO: eta: 10:41:04  iter: 5200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7100 (1.0680)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7434 (1.0503)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7759 (1.1991)  Cross-Entropy Loss (Align Words, Choose Image): 0.7029 (1.0808)  Image Caption Matching Loss: 1.0151 (1.8268)  Masked Language Modeling Loss: 1.9482 (2.4256)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.9046 (8.6506)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6218)  Batch Accuracy (Align Regions, Choose Image): 0.7344 (0.6284)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.5718)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6143)  Batch Accuracy (Choose Caption): 0.7969 (0.6387)  Batch Accuracy (Choose Image): 0.7812 (0.6527)  Masked Language Modeling Accuracy: 0.6160 (0.5642)  time: 0.9752 (1.1053)  data: 0.0467 (0.1436)  lr: 0.010000  max mem: 11046
2021-04-13 01:57:15,466 maskrcnn_benchmark.trainer INFO: eta: 10:38:10  iter: 5300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7226 (1.0617)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7258 (1.0440)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7850 (1.1916)  Cross-Entropy Loss (Align Words, Choose Image): 0.7276 (1.0734)  Image Caption Matching Loss: 1.0054 (1.8111)  Masked Language Modeling Loss: 2.0343 (2.4185)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.0642 (8.6002)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6243)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6307)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5747)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6171)  Batch Accuracy (Choose Caption): 0.7969 (0.6418)  Batch Accuracy (Choose Image): 0.8125 (0.6558)  Masked Language Modeling Accuracy: 0.5898 (0.5650)  time: 0.9857 (1.1035)  data: 0.0496 (0.1419)  lr: 0.010000  max mem: 11046
2021-04-13 01:58:55,902 maskrcnn_benchmark.trainer INFO: eta: 10:35:16  iter: 5400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7126 (1.0556)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7101 (1.0377)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7316 (1.1843)  Cross-Entropy Loss (Align Words, Choose Image): 0.6816 (1.0659)  Image Caption Matching Loss: 1.0713 (1.7959)  Masked Language Modeling Loss: 2.0715 (2.4117)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.0087 (8.5510)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6266)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6331)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.5774)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6199)  Batch Accuracy (Choose Caption): 0.8125 (0.6448)  Batch Accuracy (Choose Image): 0.8125 (0.6589)  Masked Language Modeling Accuracy: 0.6096 (0.5657)  time: 0.9786 (1.1016)  data: 0.0554 (0.1404)  lr: 0.010000  max mem: 11046
2021-04-13 02:00:37,684 maskrcnn_benchmark.trainer INFO: eta: 10:32:33  iter: 5500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7314 (1.0497)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7121 (1.0322)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7327 (1.1775)  Cross-Entropy Loss (Align Words, Choose Image): 0.6631 (1.0591)  Image Caption Matching Loss: 1.0510 (1.7814)  Masked Language Modeling Loss: 2.0319 (2.4041)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.7050 (8.5040)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6288)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6352)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.5798)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6226)  Batch Accuracy (Choose Caption): 0.8125 (0.6478)  Batch Accuracy (Choose Image): 0.8125 (0.6616)  Masked Language Modeling Accuracy: 0.6187 (0.5667)  time: 0.9793 (1.1001)  data: 0.0650 (0.1389)  lr: 0.010000  max mem: 11046
2021-04-13 02:02:20,932 maskrcnn_benchmark.trainer INFO: eta: 10:30:02  iter: 5600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7091 (1.0437)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6502 (1.0259)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7884 (1.1708)  Cross-Entropy Loss (Align Words, Choose Image): 0.6649 (1.0521)  Image Caption Matching Loss: 0.9551 (1.7668)  Masked Language Modeling Loss: 1.8504 (2.3971)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.6702 (8.4565)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6311)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6375)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.5823)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6251)  Batch Accuracy (Choose Caption): 0.7969 (0.6507)  Batch Accuracy (Choose Image): 0.8438 (0.6645)  Masked Language Modeling Accuracy: 0.6369 (0.5675)  time: 0.9557 (1.0989)  data: 0.0489 (0.1376)  lr: 0.010000  max mem: 11046
2021-04-13 02:04:02,840 maskrcnn_benchmark.trainer INFO: eta: 10:27:24  iter: 5700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6651 (1.0377)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6863 (1.0200)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6981 (1.1639)  Cross-Entropy Loss (Align Words, Choose Image): 0.6293 (1.0453)  Image Caption Matching Loss: 0.8946 (1.7524)  Masked Language Modeling Loss: 1.9411 (2.3905)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.7700 (8.4099)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6335)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6397)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.5850)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6276)  Batch Accuracy (Choose Caption): 0.8125 (0.6536)  Batch Accuracy (Choose Image): 0.8438 (0.6674)  Masked Language Modeling Accuracy: 0.5935 (0.5682)  time: 0.9961 (1.0975)  data: 0.0501 (0.1362)  lr: 0.010000  max mem: 11046
2021-04-13 02:05:43,748 maskrcnn_benchmark.trainer INFO: eta: 10:24:42  iter: 5800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6508 (1.0320)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6473 (1.0145)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7155 (1.1568)  Cross-Entropy Loss (Align Words, Choose Image): 0.6521 (1.0386)  Image Caption Matching Loss: 0.9327 (1.7380)  Masked Language Modeling Loss: 2.0434 (2.3841)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.7942 (8.3640)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6356)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6418)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5876)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6301)  Batch Accuracy (Choose Caption): 0.8281 (0.6565)  Batch Accuracy (Choose Image): 0.8281 (0.6701)  Masked Language Modeling Accuracy: 0.6148 (0.5688)  time: 0.9816 (1.0960)  data: 0.0562 (0.1349)  lr: 0.010000  max mem: 11046
2021-04-13 02:07:25,544 maskrcnn_benchmark.trainer INFO: eta: 10:22:07  iter: 5900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7425 (1.0267)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7255 (1.0092)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7944 (1.1503)  Cross-Entropy Loss (Align Words, Choose Image): 0.6549 (1.0321)  Image Caption Matching Loss: 0.9079 (1.7243)  Masked Language Modeling Loss: 1.8753 (2.3777)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.9043 (8.3203)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6375)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6438)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.5900)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6325)  Batch Accuracy (Choose Caption): 0.8281 (0.6592)  Batch Accuracy (Choose Image): 0.7969 (0.6727)  Masked Language Modeling Accuracy: 0.6232 (0.5695)  time: 0.9880 (1.0947)  data: 0.0603 (0.1337)  lr: 0.010000  max mem: 11046
2021-04-13 02:09:06,783 maskrcnn_benchmark.trainer INFO: eta: 10:19:31  iter: 6000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6257 (1.0210)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6535 (1.0036)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7523 (1.1438)  Cross-Entropy Loss (Align Words, Choose Image): 0.6168 (1.0257)  Image Caption Matching Loss: 0.9340 (1.7116)  Masked Language Modeling Loss: 1.9861 (2.3710)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.7802 (8.2767)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6396)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6459)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.5925)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6350)  Batch Accuracy (Choose Caption): 0.8125 (0.6617)  Batch Accuracy (Choose Image): 0.8438 (0.6753)  Masked Language Modeling Accuracy: 0.6004 (0.5704)  time: 0.9786 (1.0933)  data: 0.0559 (0.1324)  lr: 0.010000  max mem: 11046
2021-04-13 02:09:07,571 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0006000.pth
2021-04-13 02:10:33,345 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 10:19:31  iter: 6000  loss: 3.2725 (3.2466)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5129 (0.5327)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5410 (0.5350)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6775 (0.6545)  Cross-Entropy Loss (Align Words, Choose Image): 0.5792 (0.5585)  Image Caption Matching Loss: 0.9553 (0.9659)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8118)  Batch Accuracy (Align Regions, Choose Image): 0.8058 (0.8166)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.7702)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.8031)  Batch Accuracy (Choose Caption): 0.8229 (0.8306)  Batch Accuracy (Choose Image): 0.8125 (0.8313)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11046
2021-04-13 02:12:14,080 maskrcnn_benchmark.trainer INFO: eta: 10:24:55  iter: 6100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6777 (1.0158)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6795 (0.9984)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7291 (1.1378)  Cross-Entropy Loss (Align Words, Choose Image): 0.6427 (1.0197)  Image Caption Matching Loss: 0.8907 (1.6989)  Masked Language Modeling Loss: 1.9865 (2.3647)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.7499 (8.2354)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6417)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6478)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.5948)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6372)  Batch Accuracy (Choose Caption): 0.8281 (0.6643)  Batch Accuracy (Choose Image): 0.8281 (0.6778)  Masked Language Modeling Accuracy: 0.6038 (0.5711)  time: 0.9809 (1.1061)  data: 0.0682 (0.1454)  lr: 0.010000  max mem: 11046
2021-04-13 02:13:56,852 maskrcnn_benchmark.trainer INFO: eta: 10:22:22  iter: 6200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6544 (1.0108)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6594 (0.9935)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6977 (1.1316)  Cross-Entropy Loss (Align Words, Choose Image): 0.6057 (1.0137)  Image Caption Matching Loss: 0.9443 (1.6864)  Masked Language Modeling Loss: 1.9854 (2.3588)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.4992 (8.1949)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6436)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6498)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.5972)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6394)  Batch Accuracy (Choose Caption): 0.8125 (0.6669)  Batch Accuracy (Choose Image): 0.8125 (0.6803)  Masked Language Modeling Accuracy: 0.6193 (0.5718)  time: 0.9855 (1.1048)  data: 0.0507 (0.1440)  lr: 0.010000  max mem: 11046
2021-04-13 02:15:40,223 maskrcnn_benchmark.trainer INFO: eta: 10:19:53  iter: 6300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7061 (1.0059)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6989 (0.9885)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7259 (1.1255)  Cross-Entropy Loss (Align Words, Choose Image): 0.6277 (1.0077)  Image Caption Matching Loss: 0.9033 (1.6743)  Masked Language Modeling Loss: 1.8993 (2.3524)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.7085 (8.1544)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6454)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6516)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.5995)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6417)  Batch Accuracy (Choose Caption): 0.7969 (0.6693)  Batch Accuracy (Choose Image): 0.7969 (0.6826)  Masked Language Modeling Accuracy: 0.6201 (0.5725)  time: 0.9765 (1.1037)  data: 0.0587 (0.1427)  lr: 0.010000  max mem: 11046
2021-04-13 02:17:21,217 maskrcnn_benchmark.trainer INFO: eta: 10:17:14  iter: 6400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5966 (1.0007)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6558 (0.9836)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6650 (1.1194)  Cross-Entropy Loss (Align Words, Choose Image): 0.5883 (1.0019)  Image Caption Matching Loss: 0.8305 (1.6620)  Masked Language Modeling Loss: 1.9152 (2.3467)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.3488 (8.1143)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6473)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6534)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.6018)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6439)  Batch Accuracy (Choose Caption): 0.8281 (0.6718)  Batch Accuracy (Choose Image): 0.8438 (0.6851)  Masked Language Modeling Accuracy: 0.6170 (0.5732)  time: 0.9945 (1.1022)  data: 0.0568 (0.1415)  lr: 0.010000  max mem: 11046
2021-04-13 02:19:02,766 maskrcnn_benchmark.trainer INFO: eta: 10:14:39  iter: 6500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6481 (0.9956)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7137 (0.9786)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7314 (1.1134)  Cross-Entropy Loss (Align Words, Choose Image): 0.6201 (0.9959)  Image Caption Matching Loss: 0.9046 (1.6502)  Masked Language Modeling Loss: 1.9282 (2.3411)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.6603 (8.0748)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6492)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6553)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.6040)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6461)  Batch Accuracy (Choose Caption): 0.8281 (0.6741)  Batch Accuracy (Choose Image): 0.8281 (0.6873)  Masked Language Modeling Accuracy: 0.6009 (0.5738)  time: 0.9819 (1.1009)  data: 0.0554 (0.1402)  lr: 0.010000  max mem: 11046
2021-04-13 02:20:43,946 maskrcnn_benchmark.trainer INFO: eta: 10:12:04  iter: 6600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6442 (0.9906)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6229 (0.9734)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6927 (1.1079)  Cross-Entropy Loss (Align Words, Choose Image): 0.6092 (0.9904)  Image Caption Matching Loss: 0.7718 (1.6388)  Masked Language Modeling Loss: 1.8228 (2.3346)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1718 (8.0356)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6510)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6572)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.6061)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6481)  Batch Accuracy (Choose Caption): 0.8125 (0.6764)  Batch Accuracy (Choose Image): 0.8281 (0.6896)  Masked Language Modeling Accuracy: 0.6479 (0.5747)  time: 0.9997 (1.0995)  data: 0.0549 (0.1390)  lr: 0.010000  max mem: 11046
2021-04-13 02:22:25,914 maskrcnn_benchmark.trainer INFO: eta: 10:09:34  iter: 6700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6555 (0.9861)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6652 (0.9689)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6670 (1.1023)  Cross-Entropy Loss (Align Words, Choose Image): 0.5787 (0.9850)  Image Caption Matching Loss: 0.9035 (1.6280)  Masked Language Modeling Loss: 1.9482 (2.3291)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.4608 (7.9994)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6527)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6589)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6082)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6502)  Batch Accuracy (Choose Caption): 0.8281 (0.6786)  Batch Accuracy (Choose Image): 0.8281 (0.6917)  Masked Language Modeling Accuracy: 0.5974 (0.5753)  time: 0.9793 (1.0983)  data: 0.0591 (0.1378)  lr: 0.010000  max mem: 11185
2021-04-13 02:24:08,609 maskrcnn_benchmark.trainer INFO: eta: 10:07:10  iter: 6800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7355 (0.9818)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6465 (0.9645)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7661 (1.0967)  Cross-Entropy Loss (Align Words, Choose Image): 0.6127 (0.9795)  Image Caption Matching Loss: 0.8908 (1.6172)  Masked Language Modeling Loss: 1.9961 (2.3239)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.7422 (7.9636)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6543)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6605)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.6103)  Batch Accuracy (Align Words, Choose Image): 0.7656 (0.6523)  Batch Accuracy (Choose Caption): 0.8281 (0.6808)  Batch Accuracy (Choose Image): 0.8438 (0.6938)  Masked Language Modeling Accuracy: 0.6287 (0.5759)  time: 0.9771 (1.0973)  data: 0.0552 (0.1367)  lr: 0.010000  max mem: 11185
2021-04-13 02:25:50,872 maskrcnn_benchmark.trainer INFO: eta: 10:04:44  iter: 6900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6201 (0.9773)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6310 (0.9600)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6152 (1.0910)  Cross-Entropy Loss (Align Words, Choose Image): 0.5888 (0.9740)  Image Caption Matching Loss: 0.8236 (1.6064)  Masked Language Modeling Loss: 1.9453 (2.3189)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1797 (7.9276)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6560)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6623)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6124)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6543)  Batch Accuracy (Choose Caption): 0.8281 (0.6829)  Batch Accuracy (Choose Image): 0.8125 (0.6960)  Masked Language Modeling Accuracy: 0.6119 (0.5764)  time: 0.9744 (1.0962)  data: 0.0488 (0.1355)  lr: 0.010000  max mem: 11185
2021-04-13 02:27:32,815 maskrcnn_benchmark.trainer INFO: eta: 10:02:18  iter: 7000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6315 (0.9729)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5994 (0.9555)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5993 (1.0859)  Cross-Entropy Loss (Align Words, Choose Image): 0.5526 (0.9689)  Image Caption Matching Loss: 0.8539 (1.5960)  Masked Language Modeling Loss: 1.9779 (2.3135)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1656 (7.8928)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6577)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6639)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6144)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6562)  Batch Accuracy (Choose Caption): 0.7969 (0.6850)  Batch Accuracy (Choose Image): 0.8438 (0.6981)  Masked Language Modeling Accuracy: 0.6005 (0.5770)  time: 0.9833 (1.0951)  data: 0.0542 (0.1344)  lr: 0.010000  max mem: 11185
2021-04-13 02:27:33,387 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0007000.pth
2021-04-13 02:28:59,461 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 10:02:18  iter: 7000  loss: 3.2308 (3.2238)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5547 (0.5713)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5694 (0.5572)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5773 (0.6152)  Cross-Entropy Loss (Align Words, Choose Image): 0.5025 (0.5267)  Image Caption Matching Loss: 0.9715 (0.9534)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.8136)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8104)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.7825)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.8178)  Batch Accuracy (Choose Caption): 0.8415 (0.8272)  Batch Accuracy (Choose Image): 0.8259 (0.8263)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 02:30:41,307 maskrcnn_benchmark.trainer INFO: eta: 10:06:35  iter: 7100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6776 (0.9688)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6824 (0.9514)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6745 (1.0806)  Cross-Entropy Loss (Align Words, Choose Image): 0.6155 (0.9640)  Image Caption Matching Loss: 0.8911 (1.5861)  Masked Language Modeling Loss: 2.0308 (2.3081)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.5808 (7.8589)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6592)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6654)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6162)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6580)  Batch Accuracy (Choose Caption): 0.8281 (0.6870)  Batch Accuracy (Choose Image): 0.8281 (0.7000)  Masked Language Modeling Accuracy: 0.6209 (0.5777)  time: 0.9931 (1.1062)  data: 0.0588 (0.1455)  lr: 0.010000  max mem: 11185
2021-04-13 02:32:23,730 maskrcnn_benchmark.trainer INFO: eta: 10:04:07  iter: 7200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6588 (0.9644)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6089 (0.9468)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6986 (1.0751)  Cross-Entropy Loss (Align Words, Choose Image): 0.6099 (0.9587)  Image Caption Matching Loss: 0.8485 (1.5755)  Masked Language Modeling Loss: 1.9786 (2.3034)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.3440 (7.8239)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6609)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6671)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6183)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6601)  Batch Accuracy (Choose Caption): 0.8281 (0.6891)  Batch Accuracy (Choose Image): 0.8281 (0.7021)  Masked Language Modeling Accuracy: 0.6043 (0.5782)  time: 0.9934 (1.1051)  data: 0.0593 (0.1443)  lr: 0.010000  max mem: 11185
2021-04-13 02:34:05,853 maskrcnn_benchmark.trainer INFO: eta: 10:01:38  iter: 7300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6466 (0.9601)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6477 (0.9426)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7072 (1.0700)  Cross-Entropy Loss (Align Words, Choose Image): 0.6122 (0.9540)  Image Caption Matching Loss: 0.7501 (1.5651)  Masked Language Modeling Loss: 1.8309 (2.2980)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1624 (7.7898)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6625)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6687)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6202)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6618)  Batch Accuracy (Choose Caption): 0.8438 (0.6912)  Batch Accuracy (Choose Image): 0.8594 (0.7041)  Masked Language Modeling Accuracy: 0.6431 (0.5789)  time: 0.9939 (1.1039)  data: 0.0620 (0.1432)  lr: 0.010000  max mem: 11185
2021-04-13 02:35:47,801 maskrcnn_benchmark.trainer INFO: eta: 9:59:11  iter: 7400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6125 (0.9561)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5573 (0.9386)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6231 (1.0649)  Cross-Entropy Loss (Align Words, Choose Image): 0.6010 (0.9492)  Image Caption Matching Loss: 0.7918 (1.5552)  Masked Language Modeling Loss: 1.9475 (2.2930)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0094 (7.7571)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6641)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6702)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6220)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6636)  Batch Accuracy (Choose Caption): 0.8594 (0.6931)  Batch Accuracy (Choose Image): 0.8438 (0.7060)  Masked Language Modeling Accuracy: 0.6258 (0.5795)  time: 0.9669 (1.1028)  data: 0.0561 (0.1421)  lr: 0.010000  max mem: 11185
2021-04-13 02:37:29,536 maskrcnn_benchmark.trainer INFO: eta: 9:56:44  iter: 7500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5874 (0.9522)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6038 (0.9347)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6116 (1.0597)  Cross-Entropy Loss (Align Words, Choose Image): 0.5691 (0.9443)  Image Caption Matching Loss: 0.8473 (1.5458)  Masked Language Modeling Loss: 1.8671 (2.2880)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1923 (7.7246)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6656)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6716)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6240)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6654)  Batch Accuracy (Choose Caption): 0.8281 (0.6950)  Batch Accuracy (Choose Image): 0.8438 (0.7079)  Masked Language Modeling Accuracy: 0.6337 (0.5801)  time: 1.0042 (1.1017)  data: 0.0559 (0.1410)  lr: 0.010000  max mem: 11185
2021-04-13 02:39:14,072 maskrcnn_benchmark.trainer INFO: eta: 9:54:29  iter: 7600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6735 (0.9483)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6833 (0.9308)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7273 (1.0548)  Cross-Entropy Loss (Align Words, Choose Image): 0.5623 (0.9394)  Image Caption Matching Loss: 0.8665 (1.5367)  Masked Language Modeling Loss: 1.9008 (2.2832)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.3837 (7.6932)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6670)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6730)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.6258)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6672)  Batch Accuracy (Choose Caption): 0.8438 (0.6968)  Batch Accuracy (Choose Image): 0.8125 (0.7096)  Masked Language Modeling Accuracy: 0.6117 (0.5806)  time: 0.9786 (1.1009)  data: 0.0567 (0.1400)  lr: 0.010000  max mem: 11185
2021-04-13 02:40:57,265 maskrcnn_benchmark.trainer INFO: eta: 9:52:10  iter: 7700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6220 (0.9445)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6250 (0.9272)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6420 (1.0501)  Cross-Entropy Loss (Align Words, Choose Image): 0.5828 (0.9349)  Image Caption Matching Loss: 0.7560 (1.5274)  Masked Language Modeling Loss: 1.9229 (2.2788)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.3279 (7.6629)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6684)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6743)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6276)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6689)  Batch Accuracy (Choose Caption): 0.8594 (0.6986)  Batch Accuracy (Choose Image): 0.8438 (0.7114)  Masked Language Modeling Accuracy: 0.6177 (0.5811)  time: 0.9922 (1.1000)  data: 0.0482 (0.1389)  lr: 0.010000  max mem: 11185
2021-04-13 02:42:39,377 maskrcnn_benchmark.trainer INFO: eta: 9:49:48  iter: 7800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6042 (0.9407)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5841 (0.9236)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7220 (1.0452)  Cross-Entropy Loss (Align Words, Choose Image): 0.5643 (0.9304)  Image Caption Matching Loss: 0.8125 (1.5184)  Masked Language Modeling Loss: 1.9712 (2.2748)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1971 (7.6332)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6698)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6757)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6293)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6706)  Batch Accuracy (Choose Caption): 0.8281 (0.7005)  Batch Accuracy (Choose Image): 0.8438 (0.7132)  Masked Language Modeling Accuracy: 0.6072 (0.5816)  time: 1.0031 (1.0990)  data: 0.0585 (0.1379)  lr: 0.010000  max mem: 11185
2021-04-13 02:44:22,304 maskrcnn_benchmark.trainer INFO: eta: 9:47:30  iter: 7900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6082 (0.9370)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5872 (0.9196)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6547 (1.0405)  Cross-Entropy Loss (Align Words, Choose Image): 0.5827 (0.9259)  Image Caption Matching Loss: 0.7246 (1.5094)  Masked Language Modeling Loss: 1.9005 (2.2703)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.9817 (7.6027)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6712)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6771)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6310)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6723)  Batch Accuracy (Choose Caption): 0.8594 (0.7023)  Batch Accuracy (Choose Image): 0.8594 (0.7150)  Masked Language Modeling Accuracy: 0.6341 (0.5821)  time: 0.9921 (1.0981)  data: 0.0563 (0.1369)  lr: 0.010000  max mem: 11185
2021-04-13 02:46:03,778 maskrcnn_benchmark.trainer INFO: eta: 9:45:06  iter: 8000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6966 (0.9332)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6441 (0.9159)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7374 (1.0358)  Cross-Entropy Loss (Align Words, Choose Image): 0.5764 (0.9213)  Image Caption Matching Loss: 0.7970 (1.5006)  Masked Language Modeling Loss: 1.9896 (2.2662)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.5315 (7.5730)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6727)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6785)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6328)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6740)  Batch Accuracy (Choose Caption): 0.8281 (0.7040)  Batch Accuracy (Choose Image): 0.8281 (0.7166)  Masked Language Modeling Accuracy: 0.5982 (0.5825)  time: 0.9791 (1.0971)  data: 0.0554 (0.1360)  lr: 0.010000  max mem: 11185
2021-04-13 02:46:04,526 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0008000.pth
2021-04-13 02:47:30,852 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 9:45:06  iter: 8000  loss: 3.0414 (2.8997)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4883 (0.4932)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5081 (0.4936)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6071 (0.5877)  Cross-Entropy Loss (Align Words, Choose Image): 0.4981 (0.5070)  Image Caption Matching Loss: 0.8455 (0.8182)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8277)  Batch Accuracy (Align Regions, Choose Image): 0.8080 (0.8261)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.7936)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8204)  Batch Accuracy (Choose Caption): 0.8281 (0.8452)  Batch Accuracy (Choose Image): 0.8237 (0.8413)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 02:49:13,722 maskrcnn_benchmark.trainer INFO: eta: 9:48:33  iter: 8100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6491 (0.9296)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6076 (0.9121)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6439 (1.0313)  Cross-Entropy Loss (Align Words, Choose Image): 0.5614 (0.9169)  Image Caption Matching Loss: 0.7528 (1.4920)  Masked Language Modeling Loss: 1.9370 (2.2615)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.2252 (7.5434)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6741)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6798)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6345)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6757)  Batch Accuracy (Choose Caption): 0.8281 (0.7058)  Batch Accuracy (Choose Image): 0.8281 (0.7182)  Masked Language Modeling Accuracy: 0.6168 (0.5831)  time: 0.9898 (1.1070)  data: 0.0642 (0.1458)  lr: 0.010000  max mem: 11185
2021-04-13 02:50:55,220 maskrcnn_benchmark.trainer INFO: eta: 9:46:06  iter: 8200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5929 (0.9261)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5810 (0.9087)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6238 (1.0272)  Cross-Entropy Loss (Align Words, Choose Image): 0.5466 (0.9129)  Image Caption Matching Loss: 0.7439 (1.4836)  Masked Language Modeling Loss: 1.9761 (2.2575)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0416 (7.5160)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6753)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6811)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6361)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6771)  Batch Accuracy (Choose Caption): 0.8438 (0.7073)  Batch Accuracy (Choose Image): 0.8594 (0.7198)  Masked Language Modeling Accuracy: 0.6165 (0.5835)  time: 0.9753 (1.1059)  data: 0.0522 (0.1448)  lr: 0.010000  max mem: 11185
2021-04-13 02:52:36,970 maskrcnn_benchmark.trainer INFO: eta: 9:43:42  iter: 8300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6369 (0.9226)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6550 (0.9052)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6377 (1.0229)  Cross-Entropy Loss (Align Words, Choose Image): 0.5784 (0.9088)  Image Caption Matching Loss: 0.7408 (1.4753)  Masked Language Modeling Loss: 2.0103 (2.2538)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.2460 (7.4887)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6766)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6824)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6376)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6787)  Batch Accuracy (Choose Caption): 0.8594 (0.7090)  Batch Accuracy (Choose Image): 0.8438 (0.7215)  Masked Language Modeling Accuracy: 0.6025 (0.5839)  time: 0.9970 (1.1048)  data: 0.0610 (0.1438)  lr: 0.010000  max mem: 11185
2021-04-13 02:54:18,213 maskrcnn_benchmark.trainer INFO: eta: 9:41:17  iter: 8400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5778 (0.9190)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5967 (0.9016)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6318 (1.0185)  Cross-Entropy Loss (Align Words, Choose Image): 0.5758 (0.9046)  Image Caption Matching Loss: 0.7770 (1.4670)  Masked Language Modeling Loss: 1.9043 (2.2495)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1715 (7.4602)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6779)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6837)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6392)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6802)  Batch Accuracy (Choose Caption): 0.8594 (0.7107)  Batch Accuracy (Choose Image): 0.8594 (0.7230)  Masked Language Modeling Accuracy: 0.6102 (0.5844)  time: 0.9867 (1.1037)  data: 0.0571 (0.1428)  lr: 0.010000  max mem: 11185
2021-04-13 02:55:59,953 maskrcnn_benchmark.trainer INFO: eta: 9:38:54  iter: 8500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6278 (0.9156)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5700 (0.8982)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6581 (1.0142)  Cross-Entropy Loss (Align Words, Choose Image): 0.5357 (0.9005)  Image Caption Matching Loss: 0.8461 (1.4594)  Masked Language Modeling Loss: 1.8711 (2.2453)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0742 (7.4333)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6791)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6850)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6408)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6817)  Batch Accuracy (Choose Caption): 0.8281 (0.7123)  Batch Accuracy (Choose Image): 0.8438 (0.7245)  Masked Language Modeling Accuracy: 0.6251 (0.5848)  time: 0.9666 (1.1027)  data: 0.0516 (0.1418)  lr: 0.010000  max mem: 11185
2021-04-13 02:57:41,448 maskrcnn_benchmark.trainer INFO: eta: 9:36:32  iter: 8600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6492 (0.9126)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5780 (0.8949)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6157 (1.0102)  Cross-Entropy Loss (Align Words, Choose Image): 0.5308 (0.8968)  Image Caption Matching Loss: 0.7552 (1.4519)  Masked Language Modeling Loss: 1.8905 (2.2417)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1066 (7.4080)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6803)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6862)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6423)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6831)  Batch Accuracy (Choose Caption): 0.8594 (0.7138)  Batch Accuracy (Choose Image): 0.8438 (0.7259)  Masked Language Modeling Accuracy: 0.5955 (0.5852)  time: 0.9791 (1.1017)  data: 0.0539 (0.1408)  lr: 0.010000  max mem: 11185
2021-04-13 02:59:23,175 maskrcnn_benchmark.trainer INFO: eta: 9:34:12  iter: 8700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5494 (0.9089)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5488 (0.8915)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6073 (1.0059)  Cross-Entropy Loss (Align Words, Choose Image): 0.5498 (0.8928)  Image Caption Matching Loss: 0.7146 (1.4436)  Masked Language Modeling Loss: 1.8543 (2.2378)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7794 (7.3806)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6816)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.6874)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6439)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6846)  Batch Accuracy (Choose Caption): 0.8594 (0.7155)  Batch Accuracy (Choose Image): 0.8594 (0.7275)  Masked Language Modeling Accuracy: 0.6337 (0.5856)  time: 0.9773 (1.1007)  data: 0.0558 (0.1399)  lr: 0.010000  max mem: 11185
2021-04-13 03:01:04,976 maskrcnn_benchmark.trainer INFO: eta: 9:31:52  iter: 8800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6566 (0.9058)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5842 (0.8882)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6800 (1.0018)  Cross-Entropy Loss (Align Words, Choose Image): 0.5402 (0.8891)  Image Caption Matching Loss: 0.7581 (1.4361)  Masked Language Modeling Loss: 1.9196 (2.2343)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1272 (7.3553)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6827)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6886)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6454)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6860)  Batch Accuracy (Choose Caption): 0.8750 (0.7170)  Batch Accuracy (Choose Image): 0.8438 (0.7290)  Masked Language Modeling Accuracy: 0.6184 (0.5860)  time: 0.9717 (1.0998)  data: 0.0592 (0.1390)  lr: 0.010000  max mem: 11185
2021-04-13 03:02:46,905 maskrcnn_benchmark.trainer INFO: eta: 9:29:34  iter: 8900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6157 (0.9025)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6109 (0.8850)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6909 (0.9982)  Cross-Entropy Loss (Align Words, Choose Image): 0.6121 (0.8855)  Image Caption Matching Loss: 0.7622 (1.4288)  Masked Language Modeling Loss: 1.8353 (2.2308)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1323 (7.3308)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6840)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6898)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6468)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6873)  Batch Accuracy (Choose Caption): 0.8438 (0.7184)  Batch Accuracy (Choose Image): 0.8594 (0.7304)  Masked Language Modeling Accuracy: 0.6250 (0.5864)  time: 0.9944 (1.0989)  data: 0.0463 (0.1381)  lr: 0.010000  max mem: 11185
2021-04-13 03:04:28,219 maskrcnn_benchmark.trainer INFO: eta: 9:27:15  iter: 9000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5723 (0.8993)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5660 (0.8817)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6172 (0.9940)  Cross-Entropy Loss (Align Words, Choose Image): 0.5255 (0.8817)  Image Caption Matching Loss: 0.7096 (1.4212)  Masked Language Modeling Loss: 2.0204 (2.2278)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.9365 (7.3057)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6851)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6910)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6484)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6887)  Batch Accuracy (Choose Caption): 0.8438 (0.7200)  Batch Accuracy (Choose Image): 0.8906 (0.7319)  Masked Language Modeling Accuracy: 0.5839 (0.5866)  time: 0.9823 (1.0979)  data: 0.0522 (0.1372)  lr: 0.010000  max mem: 11185
2021-04-13 03:04:29,079 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0009000.pth
2021-04-13 03:05:54,803 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 9:27:15  iter: 9000  loss: 3.1009 (2.9991)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5573 (0.5389)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5481 (0.5507)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6305 (0.5973)  Cross-Entropy Loss (Align Words, Choose Image): 0.5331 (0.5065)  Image Caption Matching Loss: 0.8109 (0.8056)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8177 (0.8188)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.8175)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.7866)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.8247)  Batch Accuracy (Choose Caption): 0.8125 (0.8433)  Batch Accuracy (Choose Image): 0.8438 (0.8488)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 03:07:38,199 maskrcnn_benchmark.trainer INFO: eta: 9:29:57  iter: 9100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5808 (0.8961)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5822 (0.8786)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6198 (0.9901)  Cross-Entropy Loss (Align Words, Choose Image): 0.5512 (0.8780)  Image Caption Matching Loss: 0.6760 (1.4138)  Masked Language Modeling Loss: 1.9188 (2.2243)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.9690 (7.2809)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.6863)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6922)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6498)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6901)  Batch Accuracy (Choose Caption): 0.8750 (0.7215)  Batch Accuracy (Choose Image): 0.8750 (0.7333)  Masked Language Modeling Accuracy: 0.6106 (0.5870)  time: 0.9788 (1.1067)  data: 0.0629 (0.1458)  lr: 0.010000  max mem: 11185
2021-04-13 03:09:21,411 maskrcnn_benchmark.trainer INFO: eta: 9:27:41  iter: 9200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5970 (0.8929)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5862 (0.8755)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5838 (0.9861)  Cross-Entropy Loss (Align Words, Choose Image): 0.5541 (0.8745)  Image Caption Matching Loss: 0.7180 (1.4064)  Masked Language Modeling Loss: 1.9228 (2.2210)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.8552 (7.2564)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6875)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6934)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6512)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6914)  Batch Accuracy (Choose Caption): 0.8594 (0.7229)  Batch Accuracy (Choose Image): 0.8594 (0.7347)  Masked Language Modeling Accuracy: 0.6330 (0.5874)  time: 1.0015 (1.1059)  data: 0.0685 (0.1449)  lr: 0.010000  max mem: 11185
2021-04-13 03:11:01,846 maskrcnn_benchmark.trainer INFO: eta: 9:25:17  iter: 9300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5633 (0.8896)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5824 (0.8723)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6136 (0.9823)  Cross-Entropy Loss (Align Words, Choose Image): 0.5256 (0.8706)  Image Caption Matching Loss: 0.6944 (1.3991)  Masked Language Modeling Loss: 1.8709 (2.2172)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7477 (7.2310)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6887)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.6946)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6527)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6928)  Batch Accuracy (Choose Caption): 0.8750 (0.7244)  Batch Accuracy (Choose Image): 0.8594 (0.7361)  Masked Language Modeling Accuracy: 0.6291 (0.5879)  time: 0.9714 (1.1048)  data: 0.0570 (0.1440)  lr: 0.010000  max mem: 11185
2021-04-13 03:12:42,832 maskrcnn_benchmark.trainer INFO: eta: 9:22:56  iter: 9400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5465 (0.8865)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5079 (0.8692)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5704 (0.9784)  Cross-Entropy Loss (Align Words, Choose Image): 0.4861 (0.8670)  Image Caption Matching Loss: 0.6170 (1.3918)  Masked Language Modeling Loss: 1.9487 (2.2137)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.8226 (7.2066)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.6899)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.6957)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6541)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6942)  Batch Accuracy (Choose Caption): 0.8906 (0.7259)  Batch Accuracy (Choose Image): 0.8750 (0.7375)  Masked Language Modeling Accuracy: 0.6177 (0.5883)  time: 1.0026 (1.1038)  data: 0.0667 (0.1431)  lr: 0.010000  max mem: 11185
2021-04-13 03:14:25,062 maskrcnn_benchmark.trainer INFO: eta: 9:20:39  iter: 9500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5806 (0.8833)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5709 (0.8663)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5517 (0.9745)  Cross-Entropy Loss (Align Words, Choose Image): 0.4883 (0.8633)  Image Caption Matching Loss: 0.6744 (1.3848)  Masked Language Modeling Loss: 1.7672 (2.2101)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6570 (7.1822)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6911)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.6968)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6557)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.6955)  Batch Accuracy (Choose Caption): 0.8594 (0.7273)  Batch Accuracy (Choose Image): 0.8750 (0.7389)  Masked Language Modeling Accuracy: 0.6023 (0.5887)  time: 0.9754 (1.1029)  data: 0.0521 (0.1423)  lr: 0.010000  max mem: 11185
2021-04-13 03:16:06,535 maskrcnn_benchmark.trainer INFO: eta: 9:18:21  iter: 9600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5625 (0.8804)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6042 (0.8635)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6430 (0.9710)  Cross-Entropy Loss (Align Words, Choose Image): 0.5183 (0.8599)  Image Caption Matching Loss: 0.6856 (1.3780)  Masked Language Modeling Loss: 1.9704 (2.2067)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.8388 (7.1595)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6922)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6978)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6570)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6968)  Batch Accuracy (Choose Caption): 0.8594 (0.7286)  Batch Accuracy (Choose Image): 0.8750 (0.7402)  Masked Language Modeling Accuracy: 0.5973 (0.5891)  time: 0.9940 (1.1020)  data: 0.0560 (0.1415)  lr: 0.010000  max mem: 11185
2021-04-13 03:17:49,350 maskrcnn_benchmark.trainer INFO: eta: 9:16:08  iter: 9700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5854 (0.8777)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5526 (0.8605)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6259 (0.9675)  Cross-Entropy Loss (Align Words, Choose Image): 0.5119 (0.8566)  Image Caption Matching Loss: 0.7383 (1.3711)  Masked Language Modeling Loss: 1.8359 (2.2031)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7969 (7.1365)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6933)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6988)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6583)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6980)  Batch Accuracy (Choose Caption): 0.8594 (0.7300)  Batch Accuracy (Choose Image): 0.8594 (0.7415)  Masked Language Modeling Accuracy: 0.6115 (0.5895)  time: 0.9685 (1.1013)  data: 0.0578 (0.1407)  lr: 0.010000  max mem: 11185
2021-04-13 03:19:31,282 maskrcnn_benchmark.trainer INFO: eta: 9:13:52  iter: 9800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5857 (0.8747)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5496 (0.8575)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6372 (0.9641)  Cross-Entropy Loss (Align Words, Choose Image): 0.5337 (0.8531)  Image Caption Matching Loss: 0.7316 (1.3641)  Masked Language Modeling Loss: 1.8225 (2.2003)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0715 (7.1138)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6944)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.6999)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6596)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6992)  Batch Accuracy (Choose Caption): 0.8438 (0.7314)  Batch Accuracy (Choose Image): 0.8906 (0.7428)  Masked Language Modeling Accuracy: 0.5950 (0.5898)  time: 0.9849 (1.1004)  data: 0.0514 (0.1398)  lr: 0.010000  max mem: 11185
2021-04-13 03:21:11,941 maskrcnn_benchmark.trainer INFO: eta: 9:11:34  iter: 9900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5940 (0.8718)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5280 (0.8546)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5989 (0.9608)  Cross-Entropy Loss (Align Words, Choose Image): 0.4707 (0.8500)  Image Caption Matching Loss: 0.6607 (1.3576)  Masked Language Modeling Loss: 1.7782 (2.1968)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7986 (7.0916)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6955)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7010)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6608)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7004)  Batch Accuracy (Choose Caption): 0.8750 (0.7327)  Batch Accuracy (Choose Image): 0.8750 (0.7441)  Masked Language Modeling Accuracy: 0.6309 (0.5902)  time: 0.9737 (1.0995)  data: 0.0532 (0.1390)  lr: 0.010000  max mem: 11185
2021-04-13 03:22:54,965 maskrcnn_benchmark.trainer INFO: eta: 9:09:23  iter: 10000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5622 (0.8691)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5795 (0.8520)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5843 (0.9574)  Cross-Entropy Loss (Align Words, Choose Image): 0.4989 (0.8469)  Image Caption Matching Loss: 0.6688 (1.3512)  Masked Language Modeling Loss: 1.7979 (2.1936)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.8321 (7.0701)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6965)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7020)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6620)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7015)  Batch Accuracy (Choose Caption): 0.8594 (0.7340)  Batch Accuracy (Choose Image): 0.8594 (0.7453)  Masked Language Modeling Accuracy: 0.6301 (0.5906)  time: 0.9782 (1.0988)  data: 0.0604 (0.1382)  lr: 0.010000  max mem: 11185
2021-04-13 03:22:55,524 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0010000.pth
2021-04-13 03:24:20,558 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 9:09:23  iter: 10000  loss: 2.6758 (2.6041)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4554 (0.4570)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4793 (0.4596)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5253 (0.5218)  Cross-Entropy Loss (Align Words, Choose Image): 0.4617 (0.4447)  Image Caption Matching Loss: 0.7483 (0.7209)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8546)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8474)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.8125)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.8464)  Batch Accuracy (Choose Caption): 0.8594 (0.8713)  Batch Accuracy (Choose Image): 0.8438 (0.8607)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 03:26:02,022 maskrcnn_benchmark.trainer INFO: eta: 9:11:22  iter: 10100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5665 (0.8664)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5561 (0.8493)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6606 (0.9542)  Cross-Entropy Loss (Align Words, Choose Image): 0.5509 (0.8438)  Image Caption Matching Loss: 0.7508 (1.3449)  Masked Language Modeling Loss: 1.6955 (2.1903)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7695 (7.0489)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6976)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7029)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6632)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7026)  Batch Accuracy (Choose Caption): 0.8594 (0.7352)  Batch Accuracy (Choose Image): 0.8594 (0.7465)  Masked Language Modeling Accuracy: 0.6457 (0.5909)  time: 0.9627 (1.1064)  data: 0.0646 (0.1460)  lr: 0.010000  max mem: 11185
2021-04-13 03:27:44,514 maskrcnn_benchmark.trainer INFO: eta: 9:09:07  iter: 10200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6382 (0.8640)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6259 (0.8468)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6799 (0.9511)  Cross-Entropy Loss (Align Words, Choose Image): 0.5628 (0.8410)  Image Caption Matching Loss: 0.8175 (1.3392)  Masked Language Modeling Loss: 1.8323 (2.1875)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.3601 (7.0296)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6984)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.7038)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6644)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.7036)  Batch Accuracy (Choose Caption): 0.8281 (0.7363)  Batch Accuracy (Choose Image): 0.8281 (0.7476)  Masked Language Modeling Accuracy: 0.6023 (0.5912)  time: 1.0105 (1.1056)  data: 0.0554 (0.1451)  lr: 0.010000  max mem: 11185
2021-04-13 03:29:26,840 maskrcnn_benchmark.trainer INFO: eta: 9:06:53  iter: 10300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5534 (0.8614)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5537 (0.8442)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5704 (0.9477)  Cross-Entropy Loss (Align Words, Choose Image): 0.4905 (0.8378)  Image Caption Matching Loss: 0.7163 (1.3327)  Masked Language Modeling Loss: 1.8655 (2.1838)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0141 (7.0076)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6994)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7048)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6656)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7048)  Batch Accuracy (Choose Caption): 0.8594 (0.7376)  Batch Accuracy (Choose Image): 0.8750 (0.7488)  Masked Language Modeling Accuracy: 0.6307 (0.5917)  time: 0.9769 (1.1048)  data: 0.0638 (0.1444)  lr: 0.010000  max mem: 11185
2021-04-13 03:31:09,111 maskrcnn_benchmark.trainer INFO: eta: 9:04:39  iter: 10400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5602 (0.8589)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5736 (0.8416)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5617 (0.9447)  Cross-Entropy Loss (Align Words, Choose Image): 0.5117 (0.8348)  Image Caption Matching Loss: 0.6436 (1.3268)  Masked Language Modeling Loss: 1.8217 (2.1809)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7936 (6.9876)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7003)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7058)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6668)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.7059)  Batch Accuracy (Choose Caption): 0.8594 (0.7388)  Batch Accuracy (Choose Image): 0.8750 (0.7500)  Masked Language Modeling Accuracy: 0.6340 (0.5920)  time: 0.9693 (1.1040)  data: 0.0514 (0.1436)  lr: 0.010000  max mem: 11185
2021-04-13 03:32:51,940 maskrcnn_benchmark.trainer INFO: eta: 9:02:27  iter: 10500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5470 (0.8563)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5393 (0.8389)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6160 (0.9415)  Cross-Entropy Loss (Align Words, Choose Image): 0.5429 (0.8316)  Image Caption Matching Loss: 0.6933 (1.3209)  Masked Language Modeling Loss: 1.9714 (2.1777)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7785 (6.9669)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7013)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7068)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6680)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7071)  Batch Accuracy (Choose Caption): 0.8438 (0.7399)  Batch Accuracy (Choose Image): 0.8750 (0.7512)  Masked Language Modeling Accuracy: 0.6278 (0.5924)  time: 1.0088 (1.1033)  data: 0.0576 (0.1428)  lr: 0.010000  max mem: 11185
2021-04-13 03:34:33,214 maskrcnn_benchmark.trainer INFO: eta: 9:00:12  iter: 10600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5659 (0.8536)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5590 (0.8363)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5932 (0.9381)  Cross-Entropy Loss (Align Words, Choose Image): 0.4896 (0.8284)  Image Caption Matching Loss: 0.5680 (1.3148)  Masked Language Modeling Loss: 1.9182 (2.1751)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6581 (6.9464)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7023)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7078)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6692)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7082)  Batch Accuracy (Choose Caption): 0.8906 (0.7412)  Batch Accuracy (Choose Image): 0.8906 (0.7523)  Masked Language Modeling Accuracy: 0.6167 (0.5927)  time: 0.9777 (1.1025)  data: 0.0581 (0.1420)  lr: 0.010000  max mem: 11185
2021-04-13 03:36:18,755 maskrcnn_benchmark.trainer INFO: eta: 8:58:09  iter: 10700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6191 (0.8511)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5685 (0.8337)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5959 (0.9351)  Cross-Entropy Loss (Align Words, Choose Image): 0.5169 (0.8255)  Image Caption Matching Loss: 0.7000 (1.3089)  Masked Language Modeling Loss: 1.7979 (2.1720)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0215 (6.9263)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.7032)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7087)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6704)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7093)  Batch Accuracy (Choose Caption): 0.8438 (0.7423)  Batch Accuracy (Choose Image): 0.8906 (0.7535)  Masked Language Modeling Accuracy: 0.6246 (0.5931)  time: 0.9827 (1.1020)  data: 0.0481 (0.1413)  lr: 0.010000  max mem: 11185
2021-04-13 03:38:00,825 maskrcnn_benchmark.trainer INFO: eta: 8:55:57  iter: 10800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5616 (0.8486)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5584 (0.8311)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6066 (0.9321)  Cross-Entropy Loss (Align Words, Choose Image): 0.4672 (0.8224)  Image Caption Matching Loss: 0.6512 (1.3033)  Masked Language Modeling Loss: 1.8216 (2.1687)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6823 (6.9062)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7042)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7096)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6716)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7105)  Batch Accuracy (Choose Caption): 0.8594 (0.7434)  Batch Accuracy (Choose Image): 0.8750 (0.7545)  Masked Language Modeling Accuracy: 0.6205 (0.5934)  time: 0.9761 (1.1013)  data: 0.0589 (0.1405)  lr: 0.010000  max mem: 11185
2021-04-13 03:39:43,078 maskrcnn_benchmark.trainer INFO: eta: 8:53:46  iter: 10900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5732 (0.8461)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5679 (0.8287)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5279 (0.9288)  Cross-Entropy Loss (Align Words, Choose Image): 0.4394 (0.8194)  Image Caption Matching Loss: 0.6774 (1.2973)  Masked Language Modeling Loss: 1.8248 (2.1656)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6850 (6.8860)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7052)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7105)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6728)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7115)  Batch Accuracy (Choose Caption): 0.8750 (0.7446)  Batch Accuracy (Choose Image): 0.8594 (0.7556)  Masked Language Modeling Accuracy: 0.6173 (0.5938)  time: 0.9641 (1.1006)  data: 0.0526 (0.1398)  lr: 0.010000  max mem: 11185
2021-04-13 03:41:24,472 maskrcnn_benchmark.trainer INFO: eta: 8:51:33  iter: 11000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5613 (0.8437)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5631 (0.8264)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5800 (0.9260)  Cross-Entropy Loss (Align Words, Choose Image): 0.5082 (0.8167)  Image Caption Matching Loss: 0.6529 (1.2920)  Masked Language Modeling Loss: 1.6644 (2.1626)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4598 (6.8675)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7060)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7113)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6738)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7125)  Batch Accuracy (Choose Caption): 0.8594 (0.7457)  Batch Accuracy (Choose Image): 0.8594 (0.7567)  Masked Language Modeling Accuracy: 0.6657 (0.5942)  time: 0.9671 (1.0998)  data: 0.0611 (0.1391)  lr: 0.010000  max mem: 11185
2021-04-13 03:41:24,840 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0011000.pth
2021-04-13 03:42:49,389 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 8:51:33  iter: 11000  loss: 2.4212 (2.3619)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3912 (0.4002)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3993 (0.4093)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5035 (0.5069)  Cross-Entropy Loss (Align Words, Choose Image): 0.3948 (0.4000)  Image Caption Matching Loss: 0.6345 (0.6455)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8603)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8620)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8222)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8595)  Batch Accuracy (Choose Caption): 0.8750 (0.8838)  Batch Accuracy (Choose Image): 0.8906 (0.8744)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 03:44:30,851 maskrcnn_benchmark.trainer INFO: eta: 8:53:02  iter: 11100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5198 (0.8413)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5480 (0.8240)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5201 (0.9229)  Cross-Entropy Loss (Align Words, Choose Image): 0.4727 (0.8138)  Image Caption Matching Loss: 0.5827 (1.2865)  Masked Language Modeling Loss: 1.7529 (2.1597)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4885 (6.8482)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7069)  Batch Accuracy (Align Regions, Choose Image): 0.8073 (0.7123)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6750)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7136)  Batch Accuracy (Choose Caption): 0.8750 (0.7467)  Batch Accuracy (Choose Image): 0.8750 (0.7577)  Masked Language Modeling Accuracy: 0.6406 (0.5946)  time: 0.9801 (1.1066)  data: 0.0541 (0.1460)  lr: 0.010000  max mem: 11185
2021-04-13 03:46:11,983 maskrcnn_benchmark.trainer INFO: eta: 8:50:46  iter: 11200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5198 (0.8389)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5240 (0.8217)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5409 (0.9199)  Cross-Entropy Loss (Align Words, Choose Image): 0.4608 (0.8109)  Image Caption Matching Loss: 0.5813 (1.2809)  Masked Language Modeling Loss: 1.7644 (2.1568)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5020 (6.8292)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7078)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7131)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6761)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7147)  Batch Accuracy (Choose Caption): 0.8750 (0.7479)  Batch Accuracy (Choose Image): 0.8750 (0.7588)  Masked Language Modeling Accuracy: 0.6368 (0.5949)  time: 0.9866 (1.1058)  data: 0.0584 (0.1452)  lr: 0.010000  max mem: 11185
2021-04-13 03:47:53,543 maskrcnn_benchmark.trainer INFO: eta: 8:48:33  iter: 11300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5899 (0.8366)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5483 (0.8193)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5789 (0.9170)  Cross-Entropy Loss (Align Words, Choose Image): 0.5223 (0.8083)  Image Caption Matching Loss: 0.6402 (1.2757)  Masked Language Modeling Loss: 1.6874 (2.1540)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6022 (6.8108)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7087)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7140)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6772)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7157)  Batch Accuracy (Choose Caption): 0.8750 (0.7490)  Batch Accuracy (Choose Image): 0.8750 (0.7598)  Masked Language Modeling Accuracy: 0.6519 (0.5952)  time: 0.9783 (1.1050)  data: 0.0434 (0.1445)  lr: 0.010000  max mem: 11185
2021-04-13 03:49:35,193 maskrcnn_benchmark.trainer INFO: eta: 8:46:20  iter: 11400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5425 (0.8343)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5643 (0.8171)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5690 (0.9142)  Cross-Entropy Loss (Align Words, Choose Image): 0.4881 (0.8056)  Image Caption Matching Loss: 0.5834 (1.2703)  Masked Language Modeling Loss: 1.8564 (2.1512)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6957 (6.7927)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7096)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7148)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6783)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7166)  Batch Accuracy (Choose Caption): 0.8906 (0.7501)  Batch Accuracy (Choose Image): 0.8906 (0.7608)  Masked Language Modeling Accuracy: 0.6136 (0.5956)  time: 0.9755 (1.1042)  data: 0.0669 (0.1437)  lr: 0.010000  max mem: 11185
2021-04-13 03:51:16,747 maskrcnn_benchmark.trainer INFO: eta: 8:44:08  iter: 11500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5507 (0.8318)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5562 (0.8147)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5547 (0.9111)  Cross-Entropy Loss (Align Words, Choose Image): 0.5161 (0.8027)  Image Caption Matching Loss: 0.6530 (1.2648)  Masked Language Modeling Loss: 1.7737 (2.1485)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6332 (6.7736)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7105)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7156)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6794)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7177)  Batch Accuracy (Choose Caption): 0.8906 (0.7511)  Batch Accuracy (Choose Image): 0.8750 (0.7619)  Masked Language Modeling Accuracy: 0.6197 (0.5959)  time: 0.9912 (1.1034)  data: 0.0602 (0.1430)  lr: 0.010000  max mem: 11185
2021-04-13 03:52:58,420 maskrcnn_benchmark.trainer INFO: eta: 8:41:56  iter: 11600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4794 (0.8293)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5124 (0.8123)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5421 (0.9082)  Cross-Entropy Loss (Align Words, Choose Image): 0.4857 (0.8001)  Image Caption Matching Loss: 0.6213 (1.2595)  Masked Language Modeling Loss: 1.7320 (2.1460)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4751 (6.7553)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7114)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7165)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6805)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7186)  Batch Accuracy (Choose Caption): 0.8750 (0.7522)  Batch Accuracy (Choose Image): 0.8750 (0.7629)  Masked Language Modeling Accuracy: 0.6373 (0.5962)  time: 0.9807 (1.1027)  data: 0.0554 (0.1423)  lr: 0.010000  max mem: 11185
2021-04-13 03:54:39,568 maskrcnn_benchmark.trainer INFO: eta: 8:39:44  iter: 11700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5202 (0.8270)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4990 (0.8100)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5390 (0.9052)  Cross-Entropy Loss (Align Words, Choose Image): 0.4265 (0.7974)  Image Caption Matching Loss: 0.6059 (1.2544)  Masked Language Modeling Loss: 1.8552 (2.1437)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6011 (6.7376)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7123)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7173)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6816)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7196)  Batch Accuracy (Choose Caption): 0.8438 (0.7532)  Batch Accuracy (Choose Image): 0.8750 (0.7638)  Masked Language Modeling Accuracy: 0.6052 (0.5965)  time: 0.9851 (1.1019)  data: 0.0583 (0.1416)  lr: 0.010000  max mem: 11185
2021-04-13 03:56:22,390 maskrcnn_benchmark.trainer INFO: eta: 8:37:36  iter: 11800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5216 (0.8247)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5579 (0.8078)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5439 (0.9025)  Cross-Entropy Loss (Align Words, Choose Image): 0.4620 (0.7948)  Image Caption Matching Loss: 0.6592 (1.2493)  Masked Language Modeling Loss: 1.7731 (2.1412)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4899 (6.7203)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7131)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7181)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6825)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7205)  Batch Accuracy (Choose Caption): 0.8906 (0.7542)  Batch Accuracy (Choose Image): 0.8750 (0.7648)  Masked Language Modeling Accuracy: 0.6442 (0.5968)  time: 0.9782 (1.1013)  data: 0.0626 (0.1409)  lr: 0.010000  max mem: 11185
2021-04-13 03:58:03,293 maskrcnn_benchmark.trainer INFO: eta: 8:35:24  iter: 11900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4987 (0.8225)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4982 (0.8056)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5431 (0.8997)  Cross-Entropy Loss (Align Words, Choose Image): 0.4819 (0.7922)  Image Caption Matching Loss: 0.6387 (1.2443)  Masked Language Modeling Loss: 1.8283 (2.1386)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2850 (6.7030)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7140)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7189)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6836)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7214)  Batch Accuracy (Choose Caption): 0.8906 (0.7552)  Batch Accuracy (Choose Image): 0.8750 (0.7657)  Masked Language Modeling Accuracy: 0.6481 (0.5971)  time: 0.9964 (1.1005)  data: 0.0531 (0.1402)  lr: 0.010000  max mem: 11185
2021-04-13 03:59:44,226 maskrcnn_benchmark.trainer INFO: eta: 8:33:13  iter: 12000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5245 (0.8203)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5131 (0.8034)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5545 (0.8971)  Cross-Entropy Loss (Align Words, Choose Image): 0.4835 (0.7898)  Image Caption Matching Loss: 0.5961 (1.2394)  Masked Language Modeling Loss: 1.8501 (2.1362)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4852 (6.6861)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7147)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7197)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6845)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.7223)  Batch Accuracy (Choose Caption): 0.8750 (0.7561)  Batch Accuracy (Choose Image): 0.8750 (0.7667)  Masked Language Modeling Accuracy: 0.6482 (0.5974)  time: 0.9759 (1.0998)  data: 0.0513 (0.1396)  lr: 0.010000  max mem: 11185
2021-04-13 03:59:45,063 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0012000.pth
2021-04-13 04:01:11,859 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 8:33:13  iter: 12000  loss: 2.2437 (2.3050)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3582 (0.3894)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4076 (0.4227)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4564 (0.4925)  Cross-Entropy Loss (Align Words, Choose Image): 0.3599 (0.3773)  Image Caption Matching Loss: 0.5646 (0.6231)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8602)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8549)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8356)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8743)  Batch Accuracy (Choose Caption): 0.8802 (0.8838)  Batch Accuracy (Choose Image): 0.8906 (0.8773)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 04:02:52,371 maskrcnn_benchmark.trainer INFO: eta: 8:34:23  iter: 12100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5416 (0.8181)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5571 (0.8014)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5282 (0.8945)  Cross-Entropy Loss (Align Words, Choose Image): 0.4812 (0.7873)  Image Caption Matching Loss: 0.6439 (1.2346)  Masked Language Modeling Loss: 1.7813 (2.1338)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6323 (6.6697)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7155)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7204)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6855)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7232)  Batch Accuracy (Choose Caption): 0.8438 (0.7571)  Batch Accuracy (Choose Image): 0.8750 (0.7676)  Masked Language Modeling Accuracy: 0.6381 (0.5977)  time: 0.9671 (1.1062)  data: 0.0492 (0.1462)  lr: 0.010000  max mem: 11185
2021-04-13 04:04:33,711 maskrcnn_benchmark.trainer INFO: eta: 8:32:11  iter: 12200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5489 (0.8160)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5191 (0.7992)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5186 (0.8917)  Cross-Entropy Loss (Align Words, Choose Image): 0.4518 (0.7847)  Image Caption Matching Loss: 0.5997 (1.2297)  Masked Language Modeling Loss: 1.8800 (2.1315)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5039 (6.6529)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7163)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7212)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6865)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7241)  Batch Accuracy (Choose Caption): 0.8750 (0.7581)  Batch Accuracy (Choose Image): 0.8906 (0.7685)  Masked Language Modeling Accuracy: 0.6232 (0.5979)  time: 0.9859 (1.1055)  data: 0.0533 (0.1455)  lr: 0.010000  max mem: 11185
2021-04-13 04:06:15,610 maskrcnn_benchmark.trainer INFO: eta: 8:30:01  iter: 12300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5128 (0.8138)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4877 (0.7971)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5472 (0.8890)  Cross-Entropy Loss (Align Words, Choose Image): 0.4816 (0.7823)  Image Caption Matching Loss: 0.6375 (1.2249)  Masked Language Modeling Loss: 1.7723 (2.1294)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5371 (6.6364)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7171)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7220)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6875)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7250)  Batch Accuracy (Choose Caption): 0.8750 (0.7590)  Batch Accuracy (Choose Image): 0.8750 (0.7694)  Masked Language Modeling Accuracy: 0.6353 (0.5981)  time: 0.9771 (1.1048)  data: 0.0673 (0.1449)  lr: 0.010000  max mem: 11185
2021-04-13 04:08:00,582 maskrcnn_benchmark.trainer INFO: eta: 8:27:59  iter: 12400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5600 (0.8118)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5068 (0.7950)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5369 (0.8864)  Cross-Entropy Loss (Align Words, Choose Image): 0.4489 (0.7799)  Image Caption Matching Loss: 0.6579 (1.2201)  Masked Language Modeling Loss: 1.7713 (2.1271)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3977 (6.6202)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7178)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7228)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6885)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7259)  Batch Accuracy (Choose Caption): 0.8750 (0.7600)  Batch Accuracy (Choose Image): 0.8906 (0.7704)  Masked Language Modeling Accuracy: 0.6403 (0.5984)  time: 0.9879 (1.1043)  data: 0.0580 (0.1442)  lr: 0.010000  max mem: 11185
2021-04-13 04:09:41,062 maskrcnn_benchmark.trainer INFO: eta: 8:25:46  iter: 12500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5239 (0.8097)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5444 (0.7930)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5636 (0.8839)  Cross-Entropy Loss (Align Words, Choose Image): 0.4626 (0.7774)  Image Caption Matching Loss: 0.5390 (1.2151)  Masked Language Modeling Loss: 1.7662 (2.1245)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4293 (6.6037)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7186)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7235)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6893)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7268)  Batch Accuracy (Choose Caption): 0.8750 (0.7610)  Batch Accuracy (Choose Image): 0.8906 (0.7713)  Masked Language Modeling Accuracy: 0.6253 (0.5987)  time: 0.9854 (1.1035)  data: 0.0532 (0.1435)  lr: 0.010000  max mem: 11185
2021-04-13 04:11:24,153 maskrcnn_benchmark.trainer INFO: eta: 8:23:40  iter: 12600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4603 (0.8076)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4758 (0.7910)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5143 (0.8814)  Cross-Entropy Loss (Align Words, Choose Image): 0.4651 (0.7751)  Image Caption Matching Loss: 0.5675 (1.2106)  Masked Language Modeling Loss: 1.8447 (2.1222)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4633 (6.5879)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7194)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7243)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6903)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7276)  Batch Accuracy (Choose Caption): 0.8750 (0.7619)  Batch Accuracy (Choose Image): 0.8906 (0.7722)  Masked Language Modeling Accuracy: 0.6513 (0.5990)  time: 0.9786 (1.1029)  data: 0.0484 (0.1429)  lr: 0.010000  max mem: 11185
2021-04-13 04:13:05,312 maskrcnn_benchmark.trainer INFO: eta: 8:21:30  iter: 12700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5535 (0.8056)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5235 (0.7890)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5474 (0.8791)  Cross-Entropy Loss (Align Words, Choose Image): 0.4491 (0.7729)  Image Caption Matching Loss: 0.6533 (1.2060)  Masked Language Modeling Loss: 1.7522 (2.1198)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4584 (6.5725)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7201)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7250)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6912)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7285)  Batch Accuracy (Choose Caption): 0.8906 (0.7628)  Batch Accuracy (Choose Image): 0.8906 (0.7731)  Masked Language Modeling Accuracy: 0.6261 (0.5993)  time: 0.9724 (1.1022)  data: 0.0524 (0.1422)  lr: 0.010000  max mem: 11185
2021-04-13 04:14:47,052 maskrcnn_benchmark.trainer INFO: eta: 8:19:22  iter: 12800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5542 (0.8036)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5584 (0.7871)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6003 (0.8767)  Cross-Entropy Loss (Align Words, Choose Image): 0.5153 (0.7706)  Image Caption Matching Loss: 0.6925 (1.2016)  Masked Language Modeling Loss: 1.7698 (2.1174)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6810 (6.5571)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7208)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7257)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6920)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7293)  Batch Accuracy (Choose Caption): 0.8594 (0.7637)  Batch Accuracy (Choose Image): 0.8750 (0.7740)  Masked Language Modeling Accuracy: 0.6492 (0.5997)  time: 0.9962 (1.1016)  data: 0.0552 (0.1416)  lr: 0.010000  max mem: 11185
2021-04-13 04:16:26,733 maskrcnn_benchmark.trainer INFO: eta: 8:17:10  iter: 12900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5471 (0.8016)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5350 (0.7851)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5251 (0.8742)  Cross-Entropy Loss (Align Words, Choose Image): 0.4611 (0.7683)  Image Caption Matching Loss: 0.6166 (1.1972)  Masked Language Modeling Loss: 1.8088 (2.1153)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5580 (6.5418)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7216)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7264)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6929)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7301)  Batch Accuracy (Choose Caption): 0.8594 (0.7646)  Batch Accuracy (Choose Image): 0.8750 (0.7748)  Masked Language Modeling Accuracy: 0.6256 (0.5999)  time: 0.9714 (1.1007)  data: 0.0469 (0.1410)  lr: 0.010000  max mem: 11185
2021-04-13 04:18:07,632 maskrcnn_benchmark.trainer INFO: eta: 8:15:01  iter: 13000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5585 (0.7998)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5713 (0.7832)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5388 (0.8716)  Cross-Entropy Loss (Align Words, Choose Image): 0.4942 (0.7659)  Image Caption Matching Loss: 0.5611 (1.1929)  Masked Language Modeling Loss: 1.7681 (2.1128)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5429 (6.5261)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7224)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7272)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6939)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7310)  Batch Accuracy (Choose Caption): 0.8906 (0.7655)  Batch Accuracy (Choose Image): 0.8906 (0.7757)  Masked Language Modeling Accuracy: 0.6371 (0.6002)  time: 0.9911 (1.1000)  data: 0.0624 (0.1404)  lr: 0.010000  max mem: 11185
2021-04-13 04:18:08,276 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0013000.pth
2021-04-13 04:19:34,249 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 8:15:01  iter: 13000  loss: 2.3389 (2.4054)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4230 (0.4001)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4087 (0.4284)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4518 (0.4956)  Cross-Entropy Loss (Align Words, Choose Image): 0.3818 (0.4069)  Image Caption Matching Loss: 0.6731 (0.6743)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8562)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8522)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8317)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8619)  Batch Accuracy (Choose Caption): 0.8594 (0.8776)  Batch Accuracy (Choose Image): 0.8728 (0.8612)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 04:21:15,089 maskrcnn_benchmark.trainer INFO: eta: 8:15:50  iter: 13100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5620 (0.7979)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5330 (0.7814)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5730 (0.8693)  Cross-Entropy Loss (Align Words, Choose Image): 0.4827 (0.7637)  Image Caption Matching Loss: 0.5981 (1.1886)  Masked Language Modeling Loss: 1.7858 (2.1104)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6655 (6.5113)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7230)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7279)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6947)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7317)  Batch Accuracy (Choose Caption): 0.8750 (0.7663)  Batch Accuracy (Choose Image): 0.8906 (0.7765)  Masked Language Modeling Accuracy: 0.6307 (0.6006)  time: 0.9504 (1.1060)  data: 0.0596 (0.1465)  lr: 0.010000  max mem: 11185
2021-04-13 04:22:56,983 maskrcnn_benchmark.trainer INFO: eta: 8:13:41  iter: 13200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5563 (0.7959)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5172 (0.7794)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5130 (0.8668)  Cross-Entropy Loss (Align Words, Choose Image): 0.4641 (0.7614)  Image Caption Matching Loss: 0.6469 (1.1842)  Masked Language Modeling Loss: 1.7560 (2.1081)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7765 (6.4959)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7237)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7286)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6956)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7326)  Batch Accuracy (Choose Caption): 0.8594 (0.7672)  Batch Accuracy (Choose Image): 0.8750 (0.7773)  Masked Language Modeling Accuracy: 0.6407 (0.6009)  time: 0.9813 (1.1053)  data: 0.0483 (0.1458)  lr: 0.010000  max mem: 11185
2021-04-13 04:24:37,814 maskrcnn_benchmark.trainer INFO: eta: 8:11:31  iter: 13300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5088 (0.7940)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5275 (0.7774)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5158 (0.8645)  Cross-Entropy Loss (Align Words, Choose Image): 0.4661 (0.7592)  Image Caption Matching Loss: 0.6105 (1.1799)  Masked Language Modeling Loss: 1.7184 (2.1057)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4176 (6.4807)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7244)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7293)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.6964)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7334)  Batch Accuracy (Choose Caption): 0.8594 (0.7680)  Batch Accuracy (Choose Image): 0.8906 (0.7782)  Masked Language Modeling Accuracy: 0.6616 (0.6011)  time: 0.9847 (1.1046)  data: 0.0731 (0.1452)  lr: 0.010000  max mem: 11185
2021-04-13 04:26:19,625 maskrcnn_benchmark.trainer INFO: eta: 8:09:24  iter: 13400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5261 (0.7921)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5264 (0.7756)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5677 (0.8622)  Cross-Entropy Loss (Align Words, Choose Image): 0.4693 (0.7571)  Image Caption Matching Loss: 0.5903 (1.1758)  Masked Language Modeling Loss: 1.7476 (2.1036)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5124 (6.4663)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7251)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7300)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6973)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7341)  Batch Accuracy (Choose Caption): 0.8750 (0.7688)  Batch Accuracy (Choose Image): 0.8750 (0.7789)  Masked Language Modeling Accuracy: 0.6352 (0.6013)  time: 0.9804 (1.1039)  data: 0.0565 (0.1445)  lr: 0.010000  max mem: 11185
2021-04-13 04:28:04,404 maskrcnn_benchmark.trainer INFO: eta: 8:07:22  iter: 13500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5148 (0.7902)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4781 (0.7737)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4999 (0.8599)  Cross-Entropy Loss (Align Words, Choose Image): 0.4615 (0.7549)  Image Caption Matching Loss: 0.5152 (1.1716)  Masked Language Modeling Loss: 1.7835 (2.1016)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1057 (6.4518)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7258)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7306)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6981)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7349)  Batch Accuracy (Choose Caption): 0.8906 (0.7697)  Batch Accuracy (Choose Image): 0.8906 (0.7797)  Masked Language Modeling Accuracy: 0.6408 (0.6016)  time: 0.9564 (1.1035)  data: 0.0574 (0.1439)  lr: 0.010000  max mem: 11185
2021-04-13 04:29:47,596 maskrcnn_benchmark.trainer INFO: eta: 8:05:18  iter: 13600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5530 (0.7884)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5178 (0.7719)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6151 (0.8576)  Cross-Entropy Loss (Align Words, Choose Image): 0.4684 (0.7528)  Image Caption Matching Loss: 0.6639 (1.1674)  Masked Language Modeling Loss: 1.8270 (2.0994)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6236 (6.4376)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7265)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7313)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6990)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7356)  Batch Accuracy (Choose Caption): 0.8750 (0.7705)  Batch Accuracy (Choose Image): 0.8750 (0.7805)  Masked Language Modeling Accuracy: 0.6155 (0.6018)  time: 0.9768 (1.1030)  data: 0.0563 (0.1433)  lr: 0.010000  max mem: 11185
2021-04-13 04:31:31,226 maskrcnn_benchmark.trainer INFO: eta: 8:03:15  iter: 13700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5333 (0.7866)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5181 (0.7701)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5856 (0.8555)  Cross-Entropy Loss (Align Words, Choose Image): 0.4555 (0.7508)  Image Caption Matching Loss: 0.5959 (1.1633)  Masked Language Modeling Loss: 1.8266 (2.0974)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7006 (6.4238)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7271)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7319)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6998)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7363)  Batch Accuracy (Choose Caption): 0.8750 (0.7713)  Batch Accuracy (Choose Image): 0.8906 (0.7813)  Masked Language Modeling Accuracy: 0.6128 (0.6021)  time: 1.0178 (1.1025)  data: 0.0510 (0.1427)  lr: 0.010000  max mem: 11185
2021-04-13 04:33:14,991 maskrcnn_benchmark.trainer INFO: eta: 8:01:12  iter: 13800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5609 (0.7848)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5646 (0.7684)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4949 (0.8532)  Cross-Entropy Loss (Align Words, Choose Image): 0.4590 (0.7486)  Image Caption Matching Loss: 0.5774 (1.1592)  Masked Language Modeling Loss: 1.7853 (2.0952)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5144 (6.4093)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7279)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7325)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7007)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7372)  Batch Accuracy (Choose Caption): 0.8906 (0.7721)  Batch Accuracy (Choose Image): 0.9062 (0.7821)  Masked Language Modeling Accuracy: 0.6191 (0.6023)  time: 0.9999 (1.1020)  data: 0.0534 (0.1421)  lr: 0.010000  max mem: 11185
2021-04-13 04:34:56,840 maskrcnn_benchmark.trainer INFO: eta: 7:59:07  iter: 13900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5312 (0.7831)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4859 (0.7665)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4823 (0.8509)  Cross-Entropy Loss (Align Words, Choose Image): 0.4424 (0.7464)  Image Caption Matching Loss: 0.5562 (1.1551)  Masked Language Modeling Loss: 1.7231 (2.0932)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2437 (6.3952)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7285)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7332)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7015)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7379)  Batch Accuracy (Choose Caption): 0.8750 (0.7729)  Batch Accuracy (Choose Image): 0.8750 (0.7829)  Masked Language Modeling Accuracy: 0.6433 (0.6025)  time: 0.9767 (1.1014)  data: 0.0432 (0.1415)  lr: 0.010000  max mem: 11185
2021-04-13 04:36:38,170 maskrcnn_benchmark.trainer INFO: eta: 7:57:00  iter: 14000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4948 (0.7813)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4679 (0.7647)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5302 (0.8486)  Cross-Entropy Loss (Align Words, Choose Image): 0.4147 (0.7444)  Image Caption Matching Loss: 0.5634 (1.1512)  Masked Language Modeling Loss: 1.8562 (2.0912)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2440 (6.3814)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7292)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7339)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7023)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7386)  Batch Accuracy (Choose Caption): 0.8906 (0.7737)  Batch Accuracy (Choose Image): 0.8906 (0.7836)  Masked Language Modeling Accuracy: 0.6313 (0.6028)  time: 0.9968 (1.1008)  data: 0.0594 (0.1410)  lr: 0.010000  max mem: 11185
2021-04-13 04:36:39,111 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0014000.pth
2021-04-13 04:38:05,904 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:57:00  iter: 14000  loss: 2.5341 (2.4087)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4334 (0.4266)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4248 (0.4384)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5168 (0.5011)  Cross-Entropy Loss (Align Words, Choose Image): 0.4114 (0.3906)  Image Caption Matching Loss: 0.6129 (0.6521)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8549 (0.8483)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8529)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8257)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8654)  Batch Accuracy (Choose Caption): 0.8906 (0.8836)  Batch Accuracy (Choose Image): 0.8750 (0.8747)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 04:39:48,101 maskrcnn_benchmark.trainer INFO: eta: 7:57:37  iter: 14100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5623 (0.7796)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5567 (0.7631)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5123 (0.8464)  Cross-Entropy Loss (Align Words, Choose Image): 0.4485 (0.7424)  Image Caption Matching Loss: 0.6102 (1.1474)  Masked Language Modeling Loss: 1.6718 (2.0892)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3758 (6.3680)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7298)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7345)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7031)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7394)  Batch Accuracy (Choose Caption): 0.8750 (0.7745)  Batch Accuracy (Choose Image): 0.8750 (0.7843)  Masked Language Modeling Accuracy: 0.6512 (0.6030)  time: 0.9870 (1.1065)  data: 0.0440 (0.1466)  lr: 0.010000  max mem: 11185
2021-04-13 04:41:28,479 maskrcnn_benchmark.trainer INFO: eta: 7:55:27  iter: 14200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5632 (0.7779)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5360 (0.7613)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5170 (0.8445)  Cross-Entropy Loss (Align Words, Choose Image): 0.4121 (0.7404)  Image Caption Matching Loss: 0.6083 (1.1437)  Masked Language Modeling Loss: 1.8717 (2.0870)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5008 (6.3548)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7304)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7351)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7039)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7401)  Batch Accuracy (Choose Caption): 0.8594 (0.7752)  Batch Accuracy (Choose Image): 0.8906 (0.7850)  Masked Language Modeling Accuracy: 0.6243 (0.6033)  time: 0.9732 (1.1057)  data: 0.0504 (0.1460)  lr: 0.010000  max mem: 11185
2021-04-13 04:43:09,079 maskrcnn_benchmark.trainer INFO: eta: 7:53:19  iter: 14300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4786 (0.7761)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5280 (0.7596)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4856 (0.8422)  Cross-Entropy Loss (Align Words, Choose Image): 0.4690 (0.7385)  Image Caption Matching Loss: 0.5796 (1.1400)  Masked Language Modeling Loss: 1.8429 (2.0850)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6126 (6.3414)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7311)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7358)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7047)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7408)  Batch Accuracy (Choose Caption): 0.9062 (0.7760)  Batch Accuracy (Choose Image): 0.8906 (0.7858)  Masked Language Modeling Accuracy: 0.6224 (0.6035)  time: 0.9945 (1.1050)  data: 0.0507 (0.1454)  lr: 0.010000  max mem: 11185
2021-04-13 04:44:51,438 maskrcnn_benchmark.trainer INFO: eta: 7:51:14  iter: 14400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5020 (0.7745)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5392 (0.7580)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5361 (0.8402)  Cross-Entropy Loss (Align Words, Choose Image): 0.4423 (0.7366)  Image Caption Matching Loss: 0.5639 (1.1362)  Masked Language Modeling Loss: 1.7974 (2.0832)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4387 (6.3288)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7317)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7364)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.7054)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7415)  Batch Accuracy (Choose Caption): 0.8906 (0.7767)  Batch Accuracy (Choose Image): 0.8750 (0.7865)  Masked Language Modeling Accuracy: 0.6236 (0.6037)  time: 0.9700 (1.1045)  data: 0.0578 (0.1449)  lr: 0.010000  max mem: 11185
2021-04-13 04:46:34,090 maskrcnn_benchmark.trainer INFO: eta: 7:49:10  iter: 14500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5389 (0.7728)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5162 (0.7563)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5380 (0.8382)  Cross-Entropy Loss (Align Words, Choose Image): 0.4828 (0.7347)  Image Caption Matching Loss: 0.6115 (1.1325)  Masked Language Modeling Loss: 1.8575 (2.0810)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5867 (6.3155)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7323)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7370)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7061)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7422)  Batch Accuracy (Choose Caption): 0.8594 (0.7774)  Batch Accuracy (Choose Image): 0.8906 (0.7872)  Masked Language Modeling Accuracy: 0.6320 (0.6039)  time: 0.9772 (1.1039)  data: 0.0484 (0.1443)  lr: 0.010000  max mem: 11185
2021-04-13 04:48:17,043 maskrcnn_benchmark.trainer INFO: eta: 7:47:06  iter: 14600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5357 (0.7712)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4899 (0.7546)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5465 (0.8362)  Cross-Entropy Loss (Align Words, Choose Image): 0.4153 (0.7327)  Image Caption Matching Loss: 0.6401 (1.1290)  Masked Language Modeling Loss: 1.6963 (2.0788)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3100 (6.3026)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7329)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7376)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7068)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7429)  Batch Accuracy (Choose Caption): 0.8750 (0.7781)  Batch Accuracy (Choose Image): 0.8750 (0.7878)  Masked Language Modeling Accuracy: 0.6567 (0.6042)  time: 0.9648 (1.1034)  data: 0.0572 (0.1437)  lr: 0.010000  max mem: 11185
2021-04-13 04:49:58,623 maskrcnn_benchmark.trainer INFO: eta: 7:45:01  iter: 14700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5439 (0.7696)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5584 (0.7531)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5532 (0.8342)  Cross-Entropy Loss (Align Words, Choose Image): 0.4957 (0.7309)  Image Caption Matching Loss: 0.6105 (1.1256)  Masked Language Modeling Loss: 1.8114 (2.0771)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4814 (6.2905)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7334)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7382)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.7075)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7436)  Batch Accuracy (Choose Caption): 0.8750 (0.7788)  Batch Accuracy (Choose Image): 0.8906 (0.7885)  Masked Language Modeling Accuracy: 0.6421 (0.6045)  time: 0.9830 (1.1028)  data: 0.0604 (0.1431)  lr: 0.010000  max mem: 11185
2021-04-13 04:51:40,437 maskrcnn_benchmark.trainer INFO: eta: 7:42:56  iter: 14800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4920 (0.7680)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4922 (0.7516)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4618 (0.8321)  Cross-Entropy Loss (Align Words, Choose Image): 0.4361 (0.7291)  Image Caption Matching Loss: 0.6058 (1.1220)  Masked Language Modeling Loss: 1.8433 (2.0750)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3720 (6.2778)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7340)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7387)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7083)  Batch Accuracy (Align Words, Choose Image): 0.8452 (0.7442)  Batch Accuracy (Choose Caption): 0.9062 (0.7795)  Batch Accuracy (Choose Image): 0.8906 (0.7892)  Masked Language Modeling Accuracy: 0.6223 (0.6047)  time: 0.9852 (1.1023)  data: 0.0480 (0.1425)  lr: 0.010000  max mem: 11185
2021-04-13 04:53:24,060 maskrcnn_benchmark.trainer INFO: eta: 7:40:55  iter: 14900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5258 (0.7664)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5638 (0.7501)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4864 (0.8301)  Cross-Entropy Loss (Align Words, Choose Image): 0.4003 (0.7273)  Image Caption Matching Loss: 0.5748 (1.1186)  Masked Language Modeling Loss: 1.8481 (2.0732)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4341 (6.2656)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7346)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7393)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7091)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7449)  Batch Accuracy (Choose Caption): 0.8906 (0.7802)  Batch Accuracy (Choose Image): 0.9062 (0.7898)  Masked Language Modeling Accuracy: 0.6341 (0.6049)  time: 1.0085 (1.1018)  data: 0.0540 (0.1420)  lr: 0.010000  max mem: 11185
2021-04-13 04:55:05,781 maskrcnn_benchmark.trainer INFO: eta: 7:38:51  iter: 15000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5066 (0.7649)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4657 (0.7486)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5323 (0.8282)  Cross-Entropy Loss (Align Words, Choose Image): 0.4418 (0.7254)  Image Caption Matching Loss: 0.5695 (1.1150)  Masked Language Modeling Loss: 1.8079 (2.0711)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2779 (6.2532)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7352)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7398)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7097)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7456)  Batch Accuracy (Choose Caption): 0.8906 (0.7809)  Batch Accuracy (Choose Image): 0.8906 (0.7905)  Masked Language Modeling Accuracy: 0.6421 (0.6051)  time: 0.9984 (1.1012)  data: 0.0508 (0.1414)  lr: 0.010000  max mem: 11185
2021-04-13 04:55:06,659 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0015000.pth
2021-04-13 04:56:31,767 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:38:51  iter: 15000  loss: 2.2949 (2.1514)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3844 (0.3874)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4354 (0.3951)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4933 (0.4626)  Cross-Entropy Loss (Align Words, Choose Image): 0.3689 (0.3620)  Image Caption Matching Loss: 0.5627 (0.5443)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8663)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8626)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8467)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8712)  Batch Accuracy (Choose Caption): 0.8906 (0.8976)  Batch Accuracy (Choose Image): 0.8906 (0.8967)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 04:58:14,684 maskrcnn_benchmark.trainer INFO: eta: 7:39:10  iter: 15100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5263 (0.7633)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5357 (0.7470)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5034 (0.8262)  Cross-Entropy Loss (Align Words, Choose Image): 0.4480 (0.7235)  Image Caption Matching Loss: 0.5584 (1.1115)  Masked Language Modeling Loss: 1.7921 (2.0692)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2019 (6.2406)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7358)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7404)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7105)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7463)  Batch Accuracy (Choose Caption): 0.8750 (0.7816)  Batch Accuracy (Choose Image): 0.9062 (0.7912)  Masked Language Modeling Accuracy: 0.6248 (0.6053)  time: 0.9725 (1.1065)  data: 0.0481 (0.1465)  lr: 0.010000  max mem: 11185
2021-04-13 04:59:58,019 maskrcnn_benchmark.trainer INFO: eta: 7:37:08  iter: 15200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4625 (0.7616)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4494 (0.7454)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4722 (0.8243)  Cross-Entropy Loss (Align Words, Choose Image): 0.4090 (0.7217)  Image Caption Matching Loss: 0.4984 (1.1080)  Masked Language Modeling Loss: 1.7180 (2.0675)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1299 (6.2285)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7364)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7410)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7112)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7469)  Batch Accuracy (Choose Caption): 0.9062 (0.7823)  Batch Accuracy (Choose Image): 0.8906 (0.7918)  Masked Language Modeling Accuracy: 0.6398 (0.6055)  time: 1.0050 (1.1060)  data: 0.0503 (0.1459)  lr: 0.010000  max mem: 11185
2021-04-13 05:01:41,764 maskrcnn_benchmark.trainer INFO: eta: 7:35:06  iter: 15300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4967 (0.7599)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5137 (0.7437)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4929 (0.8221)  Cross-Entropy Loss (Align Words, Choose Image): 0.4861 (0.7199)  Image Caption Matching Loss: 0.5367 (1.1045)  Masked Language Modeling Loss: 1.8026 (2.0657)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3085 (6.2158)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7370)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7416)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7119)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7476)  Batch Accuracy (Choose Caption): 0.8906 (0.7830)  Batch Accuracy (Choose Image): 0.8906 (0.7925)  Masked Language Modeling Accuracy: 0.6331 (0.6057)  time: 0.9750 (1.1055)  data: 0.0525 (0.1454)  lr: 0.010000  max mem: 11185
2021-04-13 05:03:26,149 maskrcnn_benchmark.trainer INFO: eta: 7:33:06  iter: 15400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4507 (0.7582)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4459 (0.7420)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4865 (0.8200)  Cross-Entropy Loss (Align Words, Choose Image): 0.3923 (0.7179)  Image Caption Matching Loss: 0.4821 (1.1008)  Masked Language Modeling Loss: 1.8274 (2.0640)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0009 (6.2029)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7377)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7423)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7127)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7483)  Batch Accuracy (Choose Caption): 0.9219 (0.7837)  Batch Accuracy (Choose Image): 0.9062 (0.7932)  Masked Language Modeling Accuracy: 0.6426 (0.6059)  time: 1.0110 (1.1051)  data: 0.0591 (0.1448)  lr: 0.010000  max mem: 11185
2021-04-13 05:05:07,736 maskrcnn_benchmark.trainer INFO: eta: 7:31:01  iter: 15500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5241 (0.7565)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4764 (0.7404)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4970 (0.8180)  Cross-Entropy Loss (Align Words, Choose Image): 0.4535 (0.7161)  Image Caption Matching Loss: 0.5271 (1.0972)  Masked Language Modeling Loss: 1.7411 (2.0619)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2641 (6.1901)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7383)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7429)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7135)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7490)  Batch Accuracy (Choose Caption): 0.8750 (0.7844)  Batch Accuracy (Choose Image): 0.9062 (0.7939)  Masked Language Modeling Accuracy: 0.6391 (0.6062)  time: 1.0097 (1.1046)  data: 0.0534 (0.1443)  lr: 0.010000  max mem: 11185
2021-04-13 05:06:50,578 maskrcnn_benchmark.trainer INFO: eta: 7:28:59  iter: 15600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4578 (0.7549)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4453 (0.7388)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4445 (0.8161)  Cross-Entropy Loss (Align Words, Choose Image): 0.3570 (0.7142)  Image Caption Matching Loss: 0.4922 (1.0937)  Masked Language Modeling Loss: 1.7524 (2.0602)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.9219 (6.1778)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7389)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7435)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7142)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7497)  Batch Accuracy (Choose Caption): 0.8906 (0.7851)  Batch Accuracy (Choose Image): 0.9062 (0.7945)  Masked Language Modeling Accuracy: 0.6440 (0.6063)  time: 0.9797 (1.1041)  data: 0.0534 (0.1437)  lr: 0.010000  max mem: 11185
2021-04-13 05:08:33,213 maskrcnn_benchmark.trainer INFO: eta: 7:26:56  iter: 15700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5127 (0.7534)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5154 (0.7374)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4978 (0.8141)  Cross-Entropy Loss (Align Words, Choose Image): 0.4377 (0.7125)  Image Caption Matching Loss: 0.5639 (1.0903)  Masked Language Modeling Loss: 1.7999 (2.0583)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2911 (6.1660)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7394)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7440)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7148)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7503)  Batch Accuracy (Choose Caption): 0.8906 (0.7858)  Batch Accuracy (Choose Image): 0.8906 (0.7951)  Masked Language Modeling Accuracy: 0.6450 (0.6066)  time: 0.9894 (1.1036)  data: 0.0359 (0.1431)  lr: 0.010000  max mem: 11185
2021-04-13 05:10:17,052 maskrcnn_benchmark.trainer INFO: eta: 7:24:56  iter: 15800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4941 (0.7520)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5304 (0.7359)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4917 (0.8122)  Cross-Entropy Loss (Align Words, Choose Image): 0.4566 (0.7108)  Image Caption Matching Loss: 0.6135 (1.0870)  Masked Language Modeling Loss: 1.8100 (2.0564)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2325 (6.1543)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7400)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7445)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7155)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7509)  Batch Accuracy (Choose Caption): 0.8906 (0.7864)  Batch Accuracy (Choose Image): 0.8906 (0.7958)  Masked Language Modeling Accuracy: 0.6315 (0.6068)  time: 0.9753 (1.1032)  data: 0.0720 (0.1426)  lr: 0.010000  max mem: 11185
2021-04-13 05:11:58,549 maskrcnn_benchmark.trainer INFO: eta: 7:22:52  iter: 15900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5079 (0.7505)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5152 (0.7344)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5237 (0.8105)  Cross-Entropy Loss (Align Words, Choose Image): 0.4550 (0.7091)  Image Caption Matching Loss: 0.5486 (1.0838)  Masked Language Modeling Loss: 1.7207 (2.0547)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2086 (6.1431)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7405)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7450)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7161)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7515)  Batch Accuracy (Choose Caption): 0.8906 (0.7871)  Batch Accuracy (Choose Image): 0.8906 (0.7964)  Masked Language Modeling Accuracy: 0.6524 (0.6070)  time: 1.0061 (1.1026)  data: 0.0526 (0.1421)  lr: 0.010000  max mem: 11185
2021-04-13 05:13:39,550 maskrcnn_benchmark.trainer INFO: eta: 7:20:48  iter: 16000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4851 (0.7489)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4727 (0.7329)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5308 (0.8086)  Cross-Entropy Loss (Align Words, Choose Image): 0.4361 (0.7074)  Image Caption Matching Loss: 0.5699 (1.0806)  Masked Language Modeling Loss: 1.7328 (2.0528)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2725 (6.1312)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7411)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7456)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7168)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7521)  Batch Accuracy (Choose Caption): 0.8906 (0.7878)  Batch Accuracy (Choose Image): 0.8906 (0.7970)  Masked Language Modeling Accuracy: 0.6276 (0.6072)  time: 0.9668 (1.1020)  data: 0.0615 (0.1416)  lr: 0.010000  max mem: 11185
2021-04-13 05:13:40,533 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0016000.pth
2021-04-13 05:15:06,219 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:20:48  iter: 16000  loss: 1.9873 (1.9613)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3436 (0.3410)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3514 (0.3610)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4415 (0.4188)  Cross-Entropy Loss (Align Words, Choose Image): 0.3986 (0.3557)  Image Caption Matching Loss: 0.4591 (0.4847)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8866)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8809)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8570)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8762)  Batch Accuracy (Choose Caption): 0.9062 (0.9096)  Batch Accuracy (Choose Image): 0.9219 (0.9062)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 05:16:49,020 maskrcnn_benchmark.trainer INFO: eta: 7:20:56  iter: 16100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5219 (0.7476)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5180 (0.7316)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5405 (0.8069)  Cross-Entropy Loss (Align Words, Choose Image): 0.4773 (0.7059)  Image Caption Matching Loss: 0.5768 (1.0776)  Masked Language Modeling Loss: 1.7010 (2.0510)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4999 (6.1205)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7416)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7461)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7175)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7526)  Batch Accuracy (Choose Caption): 0.8906 (0.7884)  Batch Accuracy (Choose Image): 0.9062 (0.7976)  Masked Language Modeling Accuracy: 0.6284 (0.6074)  time: 0.9760 (1.1070)  data: 0.0602 (0.1465)  lr: 0.010000  max mem: 11185
2021-04-13 05:18:31,877 maskrcnn_benchmark.trainer INFO: eta: 7:18:53  iter: 16200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5351 (0.7463)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4561 (0.7303)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4837 (0.8050)  Cross-Entropy Loss (Align Words, Choose Image): 0.4051 (0.7042)  Image Caption Matching Loss: 0.5986 (1.0744)  Masked Language Modeling Loss: 1.8126 (2.0492)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2098 (6.1094)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7421)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7465)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7181)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7532)  Batch Accuracy (Choose Caption): 0.8750 (0.7890)  Batch Accuracy (Choose Image): 0.8906 (0.7982)  Masked Language Modeling Accuracy: 0.6304 (0.6076)  time: 0.9737 (1.1065)  data: 0.0493 (0.1460)  lr: 0.010000  max mem: 11185
2021-04-13 05:20:13,455 maskrcnn_benchmark.trainer INFO: eta: 7:16:50  iter: 16300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4553 (0.7448)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4548 (0.7289)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5418 (0.8032)  Cross-Entropy Loss (Align Words, Choose Image): 0.3957 (0.7025)  Image Caption Matching Loss: 0.5160 (1.0713)  Masked Language Modeling Loss: 1.8452 (2.0476)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3162 (6.0983)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7426)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7471)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7188)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7538)  Batch Accuracy (Choose Caption): 0.8906 (0.7896)  Batch Accuracy (Choose Image): 0.8906 (0.7988)  Masked Language Modeling Accuracy: 0.6148 (0.6077)  time: 1.0007 (1.1059)  data: 0.0595 (0.1455)  lr: 0.010000  max mem: 11185
2021-04-13 05:21:54,665 maskrcnn_benchmark.trainer INFO: eta: 7:14:46  iter: 16400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4360 (0.7433)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4405 (0.7274)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4781 (0.8013)  Cross-Entropy Loss (Align Words, Choose Image): 0.4147 (0.7008)  Image Caption Matching Loss: 0.4748 (1.0679)  Masked Language Modeling Loss: 1.6845 (2.0456)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.8715 (6.0863)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7432)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7476)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7195)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7545)  Batch Accuracy (Choose Caption): 0.9062 (0.7903)  Batch Accuracy (Choose Image): 0.9062 (0.7994)  Masked Language Modeling Accuracy: 0.6628 (0.6080)  time: 0.9745 (1.1053)  data: 0.0679 (0.1450)  lr: 0.010000  max mem: 11185
2021-04-13 05:23:38,012 maskrcnn_benchmark.trainer INFO: eta: 7:12:45  iter: 16500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4689 (0.7419)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4766 (0.7260)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4850 (0.7995)  Cross-Entropy Loss (Align Words, Choose Image): 0.3764 (0.6992)  Image Caption Matching Loss: 0.4856 (1.0647)  Masked Language Modeling Loss: 1.7615 (2.0436)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0449 (6.0749)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7437)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7481)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7201)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7551)  Batch Accuracy (Choose Caption): 0.9219 (0.7909)  Batch Accuracy (Choose Image): 0.9062 (0.8000)  Masked Language Modeling Accuracy: 0.6331 (0.6083)  time: 0.9954 (1.1049)  data: 0.0425 (0.1444)  lr: 0.010000  max mem: 11185
2021-04-13 05:25:20,222 maskrcnn_benchmark.trainer INFO: eta: 7:10:43  iter: 16600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4633 (0.7404)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4706 (0.7246)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4761 (0.7977)  Cross-Entropy Loss (Align Words, Choose Image): 0.4049 (0.6975)  Image Caption Matching Loss: 0.5743 (1.0616)  Masked Language Modeling Loss: 1.8540 (2.0418)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2498 (6.0636)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7442)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7486)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7208)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7556)  Batch Accuracy (Choose Caption): 0.8906 (0.7915)  Batch Accuracy (Choose Image): 0.8906 (0.8006)  Masked Language Modeling Accuracy: 0.6420 (0.6085)  time: 0.9844 (1.1044)  data: 0.0538 (0.1439)  lr: 0.010000  max mem: 11185
2021-04-13 05:27:02,625 maskrcnn_benchmark.trainer INFO: eta: 7:08:41  iter: 16700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4268 (0.7388)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4511 (0.7231)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4944 (0.7958)  Cross-Entropy Loss (Align Words, Choose Image): 0.4292 (0.6958)  Image Caption Matching Loss: 0.4671 (1.0583)  Masked Language Modeling Loss: 1.6906 (2.0400)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.9677 (6.0518)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7448)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7491)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7215)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7562)  Batch Accuracy (Choose Caption): 0.9062 (0.7922)  Batch Accuracy (Choose Image): 0.8906 (0.8012)  Masked Language Modeling Accuracy: 0.6514 (0.6087)  time: 0.9581 (1.1039)  data: 0.0654 (0.1434)  lr: 0.010000  max mem: 11185
2021-04-13 05:28:44,704 maskrcnn_benchmark.trainer INFO: eta: 7:06:39  iter: 16800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4932 (0.7375)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4987 (0.7217)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4708 (0.7940)  Cross-Entropy Loss (Align Words, Choose Image): 0.4065 (0.6942)  Image Caption Matching Loss: 0.5130 (1.0554)  Masked Language Modeling Loss: 1.6271 (2.0381)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1100 (6.0409)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7453)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7496)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7221)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7568)  Batch Accuracy (Choose Caption): 0.8906 (0.7928)  Batch Accuracy (Choose Image): 0.8906 (0.8018)  Masked Language Modeling Accuracy: 0.6394 (0.6089)  time: 1.0040 (1.1034)  data: 0.0520 (0.1429)  lr: 0.010000  max mem: 11185
2021-04-13 05:30:27,572 maskrcnn_benchmark.trainer INFO: eta: 7:04:39  iter: 16900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4535 (0.7361)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4768 (0.7203)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4031 (0.7922)  Cross-Entropy Loss (Align Words, Choose Image): 0.3658 (0.6927)  Image Caption Matching Loss: 0.4775 (1.0522)  Masked Language Modeling Loss: 1.6995 (2.0363)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0727 (6.0298)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7458)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7501)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7228)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7574)  Batch Accuracy (Choose Caption): 0.8906 (0.7934)  Batch Accuracy (Choose Image): 0.8906 (0.8024)  Masked Language Modeling Accuracy: 0.6613 (0.6092)  time: 1.0062 (1.1030)  data: 0.0506 (0.1424)  lr: 0.010000  max mem: 11185
2021-04-13 05:32:10,705 maskrcnn_benchmark.trainer INFO: eta: 7:02:39  iter: 17000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4982 (0.7347)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4729 (0.7190)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4551 (0.7906)  Cross-Entropy Loss (Align Words, Choose Image): 0.3951 (0.6912)  Image Caption Matching Loss: 0.4792 (1.0493)  Masked Language Modeling Loss: 1.6682 (2.0345)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0144 (6.0193)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7463)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7506)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7234)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7579)  Batch Accuracy (Choose Caption): 0.9062 (0.7940)  Batch Accuracy (Choose Image): 0.8906 (0.8029)  Masked Language Modeling Accuracy: 0.6498 (0.6094)  time: 0.9695 (1.1026)  data: 0.0494 (0.1419)  lr: 0.010000  max mem: 11185
2021-04-13 05:32:11,305 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0017000.pth
2021-04-13 05:33:36,694 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:02:39  iter: 17000  loss: 2.1159 (2.0851)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3605 (0.3623)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3772 (0.3906)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4570 (0.4521)  Cross-Entropy Loss (Align Words, Choose Image): 0.3373 (0.3565)  Image Caption Matching Loss: 0.5569 (0.5237)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8775)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8714)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8440)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8792)  Batch Accuracy (Choose Caption): 0.9040 (0.9014)  Batch Accuracy (Choose Image): 0.8906 (0.9016)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 05:35:18,455 maskrcnn_benchmark.trainer INFO: eta: 7:02:32  iter: 17100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4771 (0.7334)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4837 (0.7177)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5099 (0.7889)  Cross-Entropy Loss (Align Words, Choose Image): 0.4134 (0.6896)  Image Caption Matching Loss: 0.5811 (1.0463)  Masked Language Modeling Loss: 1.7301 (2.0329)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2022 (6.0088)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7468)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7511)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7240)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7585)  Batch Accuracy (Choose Caption): 0.8906 (0.7946)  Batch Accuracy (Choose Image): 0.9062 (0.8035)  Masked Language Modeling Accuracy: 0.6406 (0.6096)  time: 0.9716 (1.1071)  data: 0.0499 (0.1464)  lr: 0.010000  max mem: 11185
2021-04-13 05:37:00,153 maskrcnn_benchmark.trainer INFO: eta: 7:00:29  iter: 17200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4786 (0.7320)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4414 (0.7164)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4471 (0.7872)  Cross-Entropy Loss (Align Words, Choose Image): 0.3888 (0.6882)  Image Caption Matching Loss: 0.4738 (1.0433)  Masked Language Modeling Loss: 1.9227 (2.0315)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1188 (5.9986)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7473)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7515)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7246)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7590)  Batch Accuracy (Choose Caption): 0.9062 (0.7953)  Batch Accuracy (Choose Image): 0.9062 (0.8040)  Masked Language Modeling Accuracy: 0.6117 (0.6098)  time: 0.9871 (1.1066)  data: 0.0483 (0.1459)  lr: 0.010000  max mem: 11185
2021-04-13 05:38:43,732 maskrcnn_benchmark.trainer INFO: eta: 6:58:29  iter: 17300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4139 (0.7306)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4814 (0.7151)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4296 (0.7855)  Cross-Entropy Loss (Align Words, Choose Image): 0.3676 (0.6866)  Image Caption Matching Loss: 0.5491 (1.0404)  Masked Language Modeling Loss: 1.6067 (2.0299)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.8494 (5.9882)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7478)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7520)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7252)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7596)  Batch Accuracy (Choose Caption): 0.9062 (0.7958)  Batch Accuracy (Choose Image): 0.9062 (0.8046)  Masked Language Modeling Accuracy: 0.6607 (0.6100)  time: 0.9952 (1.1062)  data: 0.0614 (0.1454)  lr: 0.010000  max mem: 11185
2021-04-13 05:40:25,316 maskrcnn_benchmark.trainer INFO: eta: 6:56:27  iter: 17400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4839 (0.7293)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5172 (0.7138)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5080 (0.7838)  Cross-Entropy Loss (Align Words, Choose Image): 0.4515 (0.6852)  Image Caption Matching Loss: 0.5593 (1.0375)  Masked Language Modeling Loss: 1.7296 (2.0281)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2309 (5.9776)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7483)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7525)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7258)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7601)  Batch Accuracy (Choose Caption): 0.8906 (0.7964)  Batch Accuracy (Choose Image): 0.8906 (0.8052)  Masked Language Modeling Accuracy: 0.6322 (0.6101)  time: 0.9781 (1.1056)  data: 0.0558 (0.1449)  lr: 0.010000  max mem: 11185
2021-04-13 05:42:07,168 maskrcnn_benchmark.trainer INFO: eta: 6:54:25  iter: 17500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4832 (0.7279)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4146 (0.7124)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4586 (0.7822)  Cross-Entropy Loss (Align Words, Choose Image): 0.3890 (0.6837)  Image Caption Matching Loss: 0.5543 (1.0347)  Masked Language Modeling Loss: 1.5861 (2.0264)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.7816 (5.9673)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7488)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7530)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7264)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7606)  Batch Accuracy (Choose Caption): 0.8906 (0.7970)  Batch Accuracy (Choose Image): 0.9062 (0.8057)  Masked Language Modeling Accuracy: 0.6585 (0.6103)  time: 1.0029 (1.1051)  data: 0.0681 (0.1445)  lr: 0.010000  max mem: 11185
2021-04-13 05:43:48,855 maskrcnn_benchmark.trainer INFO: eta: 6:52:24  iter: 17600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4519 (0.7266)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4496 (0.7110)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4888 (0.7806)  Cross-Entropy Loss (Align Words, Choose Image): 0.3917 (0.6821)  Image Caption Matching Loss: 0.4869 (1.0318)  Masked Language Modeling Loss: 1.7549 (2.0248)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1312 (5.9569)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7493)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7535)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7270)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7612)  Batch Accuracy (Choose Caption): 0.8906 (0.7976)  Batch Accuracy (Choose Image): 0.9062 (0.8062)  Masked Language Modeling Accuracy: 0.6493 (0.6105)  time: 0.9838 (1.1046)  data: 0.0523 (0.1440)  lr: 0.010000  max mem: 11185
2021-04-13 05:45:31,924 maskrcnn_benchmark.trainer INFO: eta: 6:50:24  iter: 17700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5032 (0.7252)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4387 (0.7097)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4793 (0.7790)  Cross-Entropy Loss (Align Words, Choose Image): 0.3938 (0.6806)  Image Caption Matching Loss: 0.4884 (1.0289)  Masked Language Modeling Loss: 1.6722 (2.0232)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1914 (5.9465)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7498)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7540)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7276)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7617)  Batch Accuracy (Choose Caption): 0.8906 (0.7981)  Batch Accuracy (Choose Image): 0.9062 (0.8068)  Masked Language Modeling Accuracy: 0.6601 (0.6107)  time: 0.9971 (1.1042)  data: 0.0445 (0.1435)  lr: 0.010000  max mem: 11185
2021-04-13 05:47:13,982 maskrcnn_benchmark.trainer INFO: eta: 6:48:23  iter: 17800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4801 (0.7238)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4559 (0.7084)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4440 (0.7774)  Cross-Entropy Loss (Align Words, Choose Image): 0.4405 (0.6792)  Image Caption Matching Loss: 0.5341 (1.0262)  Masked Language Modeling Loss: 1.6413 (2.0215)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0162 (5.9365)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7503)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7545)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7282)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7622)  Batch Accuracy (Choose Caption): 0.8906 (0.7987)  Batch Accuracy (Choose Image): 0.8906 (0.8073)  Masked Language Modeling Accuracy: 0.6498 (0.6109)  time: 0.9922 (1.1038)  data: 0.0577 (0.1430)  lr: 0.010000  max mem: 11185
2021-04-13 05:48:55,659 maskrcnn_benchmark.trainer INFO: eta: 6:46:22  iter: 17900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4390 (0.7225)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4468 (0.7071)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4468 (0.7758)  Cross-Entropy Loss (Align Words, Choose Image): 0.3794 (0.6778)  Image Caption Matching Loss: 0.4690 (1.0234)  Masked Language Modeling Loss: 1.7074 (2.0200)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.9011 (5.9266)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7508)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7550)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7287)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7627)  Batch Accuracy (Choose Caption): 0.9219 (0.7992)  Batch Accuracy (Choose Image): 0.9062 (0.8079)  Masked Language Modeling Accuracy: 0.6525 (0.6111)  time: 0.9682 (1.1033)  data: 0.0589 (0.1425)  lr: 0.010000  max mem: 11185
2021-04-13 05:50:36,755 maskrcnn_benchmark.trainer INFO: eta: 6:44:20  iter: 18000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4390 (0.7212)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4771 (0.7058)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4877 (0.7742)  Cross-Entropy Loss (Align Words, Choose Image): 0.4024 (0.6763)  Image Caption Matching Loss: 0.5215 (1.0206)  Masked Language Modeling Loss: 1.7349 (2.0182)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0594 (5.9163)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7512)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7554)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7293)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7632)  Batch Accuracy (Choose Caption): 0.9062 (0.7998)  Batch Accuracy (Choose Image): 0.8906 (0.8084)  Masked Language Modeling Accuracy: 0.6493 (0.6113)  time: 0.9887 (1.1028)  data: 0.0491 (0.1420)  lr: 0.010000  max mem: 11185
2021-04-13 05:50:37,174 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0018000.pth
2021-04-13 05:52:02,497 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 6:44:20  iter: 18000  loss: 2.0206 (1.9856)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3427 (0.3500)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3705 (0.3636)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4326 (0.4522)  Cross-Entropy Loss (Align Words, Choose Image): 0.3856 (0.3655)  Image Caption Matching Loss: 0.4305 (0.4542)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8737)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8779)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8482)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8718)  Batch Accuracy (Choose Caption): 0.9062 (0.9103)  Batch Accuracy (Choose Image): 0.9062 (0.9153)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 05:53:44,355 maskrcnn_benchmark.trainer INFO: eta: 6:44:04  iter: 18100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4995 (0.7201)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4936 (0.7046)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5282 (0.7728)  Cross-Entropy Loss (Align Words, Choose Image): 0.4365 (0.6750)  Image Caption Matching Loss: 0.4647 (1.0179)  Masked Language Modeling Loss: 1.7074 (2.0164)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3363 (5.9069)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7517)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7558)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7298)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7637)  Batch Accuracy (Choose Caption): 0.9062 (0.8003)  Batch Accuracy (Choose Image): 0.9062 (0.8089)  Masked Language Modeling Accuracy: 0.6452 (0.6115)  time: 0.9870 (1.1070)  data: 0.0484 (0.1463)  lr: 0.010000  max mem: 11185
2021-04-13 05:55:26,968 maskrcnn_benchmark.trainer INFO: eta: 6:42:03  iter: 18200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4394 (0.7189)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5295 (0.7036)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4612 (0.7714)  Cross-Entropy Loss (Align Words, Choose Image): 0.4188 (0.6737)  Image Caption Matching Loss: 0.5526 (1.0152)  Masked Language Modeling Loss: 1.6418 (2.0149)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0773 (5.8977)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7521)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7562)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7304)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7641)  Batch Accuracy (Choose Caption): 0.9062 (0.8009)  Batch Accuracy (Choose Image): 0.8906 (0.8094)  Masked Language Modeling Accuracy: 0.6664 (0.6117)  time: 0.9788 (1.1066)  data: 0.0567 (0.1458)  lr: 0.010000  max mem: 11185
2021-04-13 05:57:09,724 maskrcnn_benchmark.trainer INFO: eta: 6:40:03  iter: 18300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5190 (0.7178)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5282 (0.7025)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5400 (0.7700)  Cross-Entropy Loss (Align Words, Choose Image): 0.4292 (0.6724)  Image Caption Matching Loss: 0.5518 (1.0126)  Masked Language Modeling Loss: 1.6964 (2.0131)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2358 (5.8883)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7525)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7567)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7309)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7646)  Batch Accuracy (Choose Caption): 0.9062 (0.8014)  Batch Accuracy (Choose Image): 0.9062 (0.8099)  Masked Language Modeling Accuracy: 0.6300 (0.6119)  time: 0.9892 (1.1062)  data: 0.0569 (0.1453)  lr: 0.010000  max mem: 11185
2021-04-13 05:58:52,076 maskrcnn_benchmark.trainer INFO: eta: 6:38:03  iter: 18400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4340 (0.7165)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4374 (0.7014)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3706 (0.7685)  Cross-Entropy Loss (Align Words, Choose Image): 0.3649 (0.6710)  Image Caption Matching Loss: 0.4871 (1.0101)  Masked Language Modeling Loss: 1.8025 (2.0116)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.7685 (5.8791)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7530)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7571)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7314)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7651)  Batch Accuracy (Choose Caption): 0.9062 (0.8019)  Batch Accuracy (Choose Image): 0.9062 (0.8104)  Masked Language Modeling Accuracy: 0.6353 (0.6121)  time: 0.9911 (1.1057)  data: 0.0527 (0.1448)  lr: 0.010000  max mem: 11185
2021-04-13 06:00:36,920 maskrcnn_benchmark.trainer INFO: eta: 6:36:06  iter: 18500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4391 (0.7152)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3642 (0.7001)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4411 (0.7669)  Cross-Entropy Loss (Align Words, Choose Image): 0.3210 (0.6696)  Image Caption Matching Loss: 0.4952 (1.0075)  Masked Language Modeling Loss: 1.7425 (2.0101)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.6804 (5.8695)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7535)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7575)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7320)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7656)  Batch Accuracy (Choose Caption): 0.9062 (0.8024)  Batch Accuracy (Choose Image): 0.9219 (0.8109)  Masked Language Modeling Accuracy: 0.6490 (0.6123)  time: 0.9813 (1.1054)  data: 0.0524 (0.1444)  lr: 0.010000  max mem: 11185
2021-04-13 06:02:19,081 maskrcnn_benchmark.trainer INFO: eta: 6:34:05  iter: 18600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4528 (0.7140)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4605 (0.6990)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4605 (0.7655)  Cross-Entropy Loss (Align Words, Choose Image): 0.4230 (0.6683)  Image Caption Matching Loss: 0.5494 (1.0050)  Masked Language Modeling Loss: 1.7010 (2.0086)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2799 (5.8604)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7539)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7580)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7326)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7661)  Batch Accuracy (Choose Caption): 0.9062 (0.8029)  Batch Accuracy (Choose Image): 0.9062 (0.8113)  Masked Language Modeling Accuracy: 0.6389 (0.6125)  time: 0.9792 (1.1049)  data: 0.0541 (0.1439)  lr: 0.010000  max mem: 11185
2021-04-13 06:04:02,527 maskrcnn_benchmark.trainer INFO: eta: 6:32:07  iter: 18700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4161 (0.7128)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4163 (0.6978)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3928 (0.7639)  Cross-Entropy Loss (Align Words, Choose Image): 0.3298 (0.6670)  Image Caption Matching Loss: 0.3968 (1.0024)  Masked Language Modeling Loss: 1.6838 (2.0070)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.6775 (5.8509)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7543)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7584)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7331)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7665)  Batch Accuracy (Choose Caption): 0.9062 (0.8034)  Batch Accuracy (Choose Image): 0.9062 (0.8118)  Masked Language Modeling Accuracy: 0.6534 (0.6127)  time: 0.9894 (1.1046)  data: 0.0543 (0.1434)  lr: 0.010000  max mem: 11185
2021-04-13 06:05:45,520 maskrcnn_benchmark.trainer INFO: eta: 6:30:08  iter: 18800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4488 (0.7116)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4475 (0.6967)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4689 (0.7625)  Cross-Entropy Loss (Align Words, Choose Image): 0.3891 (0.6656)  Image Caption Matching Loss: 0.4825 (0.9998)  Masked Language Modeling Loss: 1.6916 (2.0057)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.8948 (5.8419)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7548)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7588)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7336)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7670)  Batch Accuracy (Choose Caption): 0.9062 (0.8039)  Batch Accuracy (Choose Image): 0.9219 (0.8123)  Masked Language Modeling Accuracy: 0.6621 (0.6128)  time: 0.9949 (1.1042)  data: 0.0440 (0.1429)  lr: 0.010000  max mem: 11185
2021-04-13 06:07:27,947 maskrcnn_benchmark.trainer INFO: eta: 6:28:09  iter: 18900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4223 (0.7104)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4303 (0.6955)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4022 (0.7611)  Cross-Entropy Loss (Align Words, Choose Image): 0.3737 (0.6643)  Image Caption Matching Loss: 0.4054 (0.9971)  Masked Language Modeling Loss: 1.6680 (2.0044)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.8158 (5.8329)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7552)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7592)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7341)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7675)  Batch Accuracy (Choose Caption): 0.9219 (0.8044)  Batch Accuracy (Choose Image): 0.8906 (0.8128)  Masked Language Modeling Accuracy: 0.6571 (0.6130)  time: 0.9713 (1.1038)  data: 0.0430 (0.1425)  lr: 0.010000  max mem: 11185
2021-04-13 06:09:10,397 maskrcnn_benchmark.trainer INFO: eta: 6:26:09  iter: 19000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4682 (0.7093)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5008 (0.6943)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4966 (0.7597)  Cross-Entropy Loss (Align Words, Choose Image): 0.4075 (0.6629)  Image Caption Matching Loss: 0.4443 (0.9946)  Masked Language Modeling Loss: 1.6987 (2.0031)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0834 (5.8240)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7556)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7596)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7346)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7680)  Batch Accuracy (Choose Caption): 0.8906 (0.8049)  Batch Accuracy (Choose Image): 0.9219 (0.8133)  Masked Language Modeling Accuracy: 0.6370 (0.6131)  time: 0.9743 (1.1033)  data: 0.0598 (0.1420)  lr: 0.010000  max mem: 11185
2021-04-13 06:09:11,316 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0019000.pth
2021-04-13 06:10:37,766 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 6:26:09  iter: 19000  loss: 2.0239 (2.0864)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4072 (0.3973)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4014 (0.4008)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4076 (0.4295)  Cross-Entropy Loss (Align Words, Choose Image): 0.3552 (0.3551)  Image Caption Matching Loss: 0.5342 (0.5038)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8698)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8620)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8511)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8782)  Batch Accuracy (Choose Caption): 0.8906 (0.9002)  Batch Accuracy (Choose Image): 0.9062 (0.9134)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11185
2021-04-13 06:12:23,812 maskrcnn_benchmark.trainer INFO: eta: 6:25:50  iter: 19100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4582 (0.7081)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4774 (0.6932)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4432 (0.7583)  Cross-Entropy Loss (Align Words, Choose Image): 0.3847 (0.6616)  Image Caption Matching Loss: 0.4901 (0.9921)  Masked Language Modeling Loss: 1.7060 (2.0017)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0135 (5.8150)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7561)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7600)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7352)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7684)  Batch Accuracy (Choose Caption): 0.9219 (0.8054)  Batch Accuracy (Choose Image): 0.9062 (0.8138)  Masked Language Modeling Accuracy: 0.6423 (0.6133)  time: 1.0013 (1.1077)  data: 0.0600 (0.1462)  lr: 0.010000  max mem: 11185
2021-04-13 06:14:06,828 maskrcnn_benchmark.trainer INFO: eta: 6:23:51  iter: 19200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4337 (0.7069)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4229 (0.6920)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4360 (0.7568)  Cross-Entropy Loss (Align Words, Choose Image): 0.4001 (0.6603)  Image Caption Matching Loss: 0.4396 (0.9896)  Masked Language Modeling Loss: 1.7478 (2.0004)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0329 (5.8060)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7565)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7604)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7357)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7689)  Batch Accuracy (Choose Caption): 0.9062 (0.8059)  Batch Accuracy (Choose Image): 0.9062 (0.8143)  Masked Language Modeling Accuracy: 0.6258 (0.6135)  time: 0.9875 (1.1073)  data: 0.0470 (0.1457)  lr: 0.010000  max mem: 11185
2021-04-13 06:15:47,087 maskrcnn_benchmark.trainer INFO: eta: 6:21:49  iter: 19300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4984 (0.7057)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4696 (0.6908)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4803 (0.7553)  Cross-Entropy Loss (Align Words, Choose Image): 0.4207 (0.6590)  Image Caption Matching Loss: 0.5387 (0.9871)  Masked Language Modeling Loss: 1.7466 (1.9990)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1986 (5.7969)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7569)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7609)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7363)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7694)  Batch Accuracy (Choose Caption): 0.8906 (0.8064)  Batch Accuracy (Choose Image): 0.8906 (0.8148)  Masked Language Modeling Accuracy: 0.6370 (0.6136)  time: 0.9533 (1.1067)  data: 0.0588 (0.1453)  lr: 0.010000  max mem: 11185
2021-04-13 06:17:27,916 maskrcnn_benchmark.trainer INFO: eta: 6:19:48  iter: 19400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5073 (0.7047)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4527 (0.6897)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5139 (0.7540)  Cross-Entropy Loss (Align Words, Choose Image): 0.4166 (0.6577)  Image Caption Matching Loss: 0.5105 (0.9846)  Masked Language Modeling Loss: 1.6239 (1.9975)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1062 (5.7881)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7573)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7613)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7368)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7698)  Batch Accuracy (Choose Caption): 0.8906 (0.8069)  Batch Accuracy (Choose Image): 0.9219 (0.8152)  Masked Language Modeling Accuracy: 0.6414 (0.6138)  time: 1.0038 (1.1062)  data: 0.0461 (0.1449)  lr: 0.010000  max mem: 11185
2021-04-13 06:19:10,045 maskrcnn_benchmark.trainer INFO: eta: 6:17:48  iter: 19500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5358 (0.7036)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5113 (0.6886)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4706 (0.7527)  Cross-Entropy Loss (Align Words, Choose Image): 0.4088 (0.6565)  Image Caption Matching Loss: 0.5466 (0.9821)  Masked Language Modeling Loss: 1.7831 (1.9962)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3195 (5.7796)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7578)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7616)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7373)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7703)  Batch Accuracy (Choose Caption): 0.8906 (0.8074)  Batch Accuracy (Choose Image): 0.8906 (0.8157)  Masked Language Modeling Accuracy: 0.6170 (0.6140)  time: 0.9956 (1.1058)  data: 0.0530 (0.1444)  lr: 0.010000  max mem: 11185
2021-04-13 06:20:52,339 maskrcnn_benchmark.trainer INFO: eta: 6:15:49  iter: 19600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4667 (0.7024)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4467 (0.6875)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4688 (0.7513)  Cross-Entropy Loss (Align Words, Choose Image): 0.4091 (0.6552)  Image Caption Matching Loss: 0.5269 (0.9798)  Masked Language Modeling Loss: 1.7389 (1.9948)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0929 (5.7709)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7582)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7621)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7378)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7707)  Batch Accuracy (Choose Caption): 0.8906 (0.8079)  Batch Accuracy (Choose Image): 0.9062 (0.8161)  Masked Language Modeling Accuracy: 0.6333 (0.6142)  time: 1.0089 (1.1054)  data: 0.0488 (0.1440)  lr: 0.010000  max mem: 11185
2021-04-13 06:22:34,024 maskrcnn_benchmark.trainer INFO: eta: 6:13:49  iter: 19700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5465 (0.7013)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4783 (0.6863)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4481 (0.7498)  Cross-Entropy Loss (Align Words, Choose Image): 0.3806 (0.6539)  Image Caption Matching Loss: 0.5038 (0.9773)  Masked Language Modeling Loss: 1.7783 (1.9935)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0850 (5.7621)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7586)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7625)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7383)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7712)  Batch Accuracy (Choose Caption): 0.9062 (0.8083)  Batch Accuracy (Choose Image): 0.8906 (0.8166)  Masked Language Modeling Accuracy: 0.6448 (0.6143)  time: 0.9868 (1.1049)  data: 0.0499 (0.1435)  lr: 0.010000  max mem: 11185
2021-04-13 06:24:16,813 maskrcnn_benchmark.trainer INFO: eta: 6:11:51  iter: 19800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4671 (0.7002)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4753 (0.6853)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4346 (0.7485)  Cross-Entropy Loss (Align Words, Choose Image): 0.4356 (0.6528)  Image Caption Matching Loss: 0.4341 (0.9749)  Masked Language Modeling Loss: 1.6696 (1.9921)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.8810 (5.7539)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7590)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7628)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7388)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7716)  Batch Accuracy (Choose Caption): 0.9062 (0.8088)  Batch Accuracy (Choose Image): 0.9219 (0.8171)  Masked Language Modeling Accuracy: 0.6595 (0.6145)  time: 0.9701 (1.1045)  data: 0.0452 (0.1431)  lr: 0.010000  max mem: 11185
2021-04-13 06:25:59,702 maskrcnn_benchmark.trainer INFO: eta: 6:09:53  iter: 19900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4281 (0.6991)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4183 (0.6843)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4588 (0.7472)  Cross-Entropy Loss (Align Words, Choose Image): 0.3871 (0.6515)  Image Caption Matching Loss: 0.5588 (0.9725)  Masked Language Modeling Loss: 1.6671 (1.9907)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.9982 (5.7453)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7594)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7632)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7392)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7721)  Batch Accuracy (Choose Caption): 0.9062 (0.8093)  Batch Accuracy (Choose Image): 0.9062 (0.8175)  Masked Language Modeling Accuracy: 0.6577 (0.6146)  time: 0.9948 (1.1042)  data: 0.0513 (0.1426)  lr: 0.010000  max mem: 11185
2021-04-13 06:27:45,904 maskrcnn_benchmark.trainer INFO: eta: 6:07:58  iter: 20000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4520 (0.6980)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4381 (0.6831)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4160 (0.7458)  Cross-Entropy Loss (Align Words, Choose Image): 0.3507 (0.6502)  Image Caption Matching Loss: 0.4473 (0.9701)  Masked Language Modeling Loss: 1.7147 (1.9893)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.8401 (5.7365)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7598)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7636)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.7398)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7725)  Batch Accuracy (Choose Caption): 0.9062 (0.8097)  Batch Accuracy (Choose Image): 0.9062 (0.8180)  Masked Language Modeling Accuracy: 0.6507 (0.6148)  time: 0.9841 (1.1039)  data: 0.0557 (0.1422)  lr: 0.001000  max mem: 11185
2021-04-13 06:27:46,753 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0020000.pth
2021-04-13 06:29:12,010 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 6:07:58  iter: 20000  loss: 1.9110 (1.9647)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3499 (0.3526)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3376 (0.3759)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4142 (0.4258)  Cross-Entropy Loss (Align Words, Choose Image): 0.3351 (0.3386)  Image Caption Matching Loss: 0.4683 (0.4720)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8733)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8752)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8562)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8808)  Batch Accuracy (Choose Caption): 0.8906 (0.9104)  Batch Accuracy (Choose Image): 0.9062 (0.9167)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11185
2021-04-13 06:30:54,056 maskrcnn_benchmark.trainer INFO: eta: 6:07:25  iter: 20100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4414 (0.6968)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4165 (0.6820)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3863 (0.7442)  Cross-Entropy Loss (Align Words, Choose Image): 0.3330 (0.6489)  Image Caption Matching Loss: 0.4328 (0.9676)  Masked Language Modeling Loss: 1.6318 (1.9879)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.6136 (5.7273)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7603)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7640)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7403)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7730)  Batch Accuracy (Choose Caption): 0.9219 (0.8103)  Batch Accuracy (Choose Image): 0.9062 (0.8184)  Masked Language Modeling Accuracy: 0.6626 (0.6149)  time: 0.9958 (1.1078)  data: 0.0571 (0.1461)  lr: 0.001000  max mem: 11185
2021-04-13 06:32:35,192 maskrcnn_benchmark.trainer INFO: eta: 6:05:25  iter: 20200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3722 (0.6954)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4169 (0.6806)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3855 (0.7425)  Cross-Entropy Loss (Align Words, Choose Image): 0.3652 (0.6475)  Image Caption Matching Loss: 0.4175 (0.9648)  Masked Language Modeling Loss: 1.7148 (1.9863)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.7149 (5.7171)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7608)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7645)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7409)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7735)  Batch Accuracy (Choose Caption): 0.9219 (0.8108)  Batch Accuracy (Choose Image): 0.9062 (0.8189)  Masked Language Modeling Accuracy: 0.6360 (0.6151)  time: 0.9794 (1.1073)  data: 0.0538 (0.1457)  lr: 0.001000  max mem: 11185
2021-04-13 06:34:20,213 maskrcnn_benchmark.trainer INFO: eta: 6:03:28  iter: 20300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4080 (0.6939)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3969 (0.6793)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3976 (0.7409)  Cross-Entropy Loss (Align Words, Choose Image): 0.3406 (0.6460)  Image Caption Matching Loss: 0.3884 (0.9621)  Masked Language Modeling Loss: 1.5281 (1.9848)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.6760 (5.7070)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7613)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7650)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7415)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7740)  Batch Accuracy (Choose Caption): 0.9375 (0.8114)  Batch Accuracy (Choose Image): 0.9219 (0.8194)  Masked Language Modeling Accuracy: 0.6580 (0.6153)  time: 0.9774 (1.1071)  data: 0.0632 (0.1453)  lr: 0.001000  max mem: 11185
2021-04-13 06:36:00,520 maskrcnn_benchmark.trainer INFO: eta: 6:01:28  iter: 20400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3868 (0.6924)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3710 (0.6779)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4000 (0.7392)  Cross-Entropy Loss (Align Words, Choose Image): 0.3534 (0.6445)  Image Caption Matching Loss: 0.4274 (0.9592)  Masked Language Modeling Loss: 1.7041 (1.9832)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.6946 (5.6964)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7618)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7655)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7421)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7745)  Batch Accuracy (Choose Caption): 0.9219 (0.8119)  Batch Accuracy (Choose Image): 0.9219 (0.8199)  Masked Language Modeling Accuracy: 0.6440 (0.6155)  time: 0.9930 (1.1065)  data: 0.0605 (0.1449)  lr: 0.001000  max mem: 11185
2021-04-13 06:37:43,886 maskrcnn_benchmark.trainer INFO: eta: 5:59:30  iter: 20500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4039 (0.6910)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3877 (0.6765)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3636 (0.7374)  Cross-Entropy Loss (Align Words, Choose Image): 0.3608 (0.6430)  Image Caption Matching Loss: 0.3539 (0.9565)  Masked Language Modeling Loss: 1.6941 (1.9815)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.6418 (5.6858)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7623)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7660)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7428)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7751)  Batch Accuracy (Choose Caption): 0.9219 (0.8125)  Batch Accuracy (Choose Image): 0.9375 (0.8204)  Masked Language Modeling Accuracy: 0.6527 (0.6157)  time: 0.9844 (1.1062)  data: 0.0433 (0.1444)  lr: 0.001000  max mem: 11185
2021-04-13 06:39:26,052 maskrcnn_benchmark.trainer INFO: eta: 5:57:32  iter: 20600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4243 (0.6894)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3705 (0.6750)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3650 (0.7356)  Cross-Entropy Loss (Align Words, Choose Image): 0.3274 (0.6414)  Image Caption Matching Loss: 0.3293 (0.9536)  Masked Language Modeling Loss: 1.6787 (1.9802)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3672 (5.6751)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7629)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7665)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7434)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7756)  Batch Accuracy (Choose Caption): 0.9375 (0.8131)  Batch Accuracy (Choose Image): 0.9219 (0.8209)  Masked Language Modeling Accuracy: 0.6324 (0.6159)  time: 0.9781 (1.1058)  data: 0.0655 (0.1440)  lr: 0.001000  max mem: 11185
2021-04-13 06:41:07,332 maskrcnn_benchmark.trainer INFO: eta: 5:55:32  iter: 20700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3603 (0.6880)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3420 (0.6736)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3434 (0.7339)  Cross-Entropy Loss (Align Words, Choose Image): 0.2741 (0.6399)  Image Caption Matching Loss: 0.3382 (0.9509)  Masked Language Modeling Loss: 1.7550 (1.9788)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3555 (5.6650)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7634)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7670)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7440)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7761)  Batch Accuracy (Choose Caption): 0.9375 (0.8136)  Batch Accuracy (Choose Image): 0.9219 (0.8214)  Masked Language Modeling Accuracy: 0.6359 (0.6161)  time: 0.9924 (1.1053)  data: 0.0488 (0.1436)  lr: 0.001000  max mem: 11185
2021-04-13 06:42:52,324 maskrcnn_benchmark.trainer INFO: eta: 5:53:37  iter: 20800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3264 (0.6866)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3508 (0.6722)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3685 (0.7321)  Cross-Entropy Loss (Align Words, Choose Image): 0.3101 (0.6384)  Image Caption Matching Loss: 0.3970 (0.9482)  Masked Language Modeling Loss: 1.6697 (1.9774)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4880 (5.6549)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7639)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7675)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7446)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7767)  Batch Accuracy (Choose Caption): 0.9062 (0.8141)  Batch Accuracy (Choose Image): 0.9375 (0.8219)  Masked Language Modeling Accuracy: 0.6646 (0.6163)  time: 0.9836 (1.1051)  data: 0.0577 (0.1432)  lr: 0.001000  max mem: 11185
2021-04-13 06:44:34,430 maskrcnn_benchmark.trainer INFO: eta: 5:51:38  iter: 20900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3183 (0.6851)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3431 (0.6708)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3844 (0.7304)  Cross-Entropy Loss (Align Words, Choose Image): 0.3039 (0.6369)  Image Caption Matching Loss: 0.3100 (0.9453)  Masked Language Modeling Loss: 1.6547 (1.9761)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2138 (5.6447)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7644)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7680)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7452)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7772)  Batch Accuracy (Choose Caption): 0.9375 (0.8147)  Batch Accuracy (Choose Image): 0.9219 (0.8224)  Masked Language Modeling Accuracy: 0.6654 (0.6164)  time: 0.9887 (1.1047)  data: 0.0499 (0.1428)  lr: 0.001000  max mem: 11185
2021-04-13 06:46:16,999 maskrcnn_benchmark.trainer INFO: eta: 5:49:41  iter: 21000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3684 (0.6837)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3451 (0.6693)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3579 (0.7287)  Cross-Entropy Loss (Align Words, Choose Image): 0.3049 (0.6353)  Image Caption Matching Loss: 0.3289 (0.9426)  Masked Language Modeling Loss: 1.5463 (1.9745)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3231 (5.6341)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7650)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7685)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7458)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7778)  Batch Accuracy (Choose Caption): 0.9219 (0.8152)  Batch Accuracy (Choose Image): 0.9219 (0.8229)  Masked Language Modeling Accuracy: 0.6631 (0.6167)  time: 0.9905 (1.1043)  data: 0.0528 (0.1424)  lr: 0.001000  max mem: 11185
2021-04-13 06:46:17,590 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0021000.pth
2021-04-13 06:47:43,479 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 5:49:41  iter: 21000  loss: 1.3276 (1.4109)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2418 (0.2607)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2680 (0.2872)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2830 (0.3000)  Cross-Entropy Loss (Align Words, Choose Image): 0.2409 (0.2498)  Image Caption Matching Loss: 0.3142 (0.3132)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9126)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9015)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8989)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9126)  Batch Accuracy (Choose Caption): 0.9531 (0.9398)  Batch Accuracy (Choose Image): 0.9375 (0.9416)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11185
2021-04-13 06:49:26,566 maskrcnn_benchmark.trainer INFO: eta: 5:49:01  iter: 21100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3885 (0.6823)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3940 (0.6679)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3518 (0.7270)  Cross-Entropy Loss (Align Words, Choose Image): 0.3340 (0.6338)  Image Caption Matching Loss: 0.3317 (0.9399)  Masked Language Modeling Loss: 1.7456 (1.9730)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4944 (5.6239)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7655)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7689)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7464)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7783)  Batch Accuracy (Choose Caption): 0.9219 (0.8158)  Batch Accuracy (Choose Image): 0.9219 (0.8234)  Masked Language Modeling Accuracy: 0.6395 (0.6168)  time: 0.9729 (1.1080)  data: 0.0550 (0.1461)  lr: 0.001000  max mem: 11185
2021-04-13 06:51:09,026 maskrcnn_benchmark.trainer INFO: eta: 5:47:03  iter: 21200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3559 (0.6809)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3320 (0.6666)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3605 (0.7253)  Cross-Entropy Loss (Align Words, Choose Image): 0.3102 (0.6324)  Image Caption Matching Loss: 0.3862 (0.9372)  Masked Language Modeling Loss: 1.7462 (1.9716)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.5201 (5.6139)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7660)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7694)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7470)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7788)  Batch Accuracy (Choose Caption): 0.9219 (0.8163)  Batch Accuracy (Choose Image): 0.9375 (0.8239)  Masked Language Modeling Accuracy: 0.6401 (0.6170)  time: 0.9902 (1.1076)  data: 0.0588 (0.1458)  lr: 0.001000  max mem: 11185
2021-04-13 06:52:50,407 maskrcnn_benchmark.trainer INFO: eta: 5:45:04  iter: 21300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3410 (0.6794)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3141 (0.6652)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3360 (0.7235)  Cross-Entropy Loss (Align Words, Choose Image): 0.3220 (0.6309)  Image Caption Matching Loss: 0.3069 (0.9344)  Masked Language Modeling Loss: 1.5496 (1.9700)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1482 (5.6034)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7665)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7699)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7476)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7793)  Batch Accuracy (Choose Caption): 0.9375 (0.8169)  Batch Accuracy (Choose Image): 0.9375 (0.8244)  Masked Language Modeling Accuracy: 0.6490 (0.6172)  time: 0.9897 (1.1072)  data: 0.0504 (0.1453)  lr: 0.001000  max mem: 11185
2021-04-13 06:54:32,461 maskrcnn_benchmark.trainer INFO: eta: 5:43:06  iter: 21400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3758 (0.6781)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3892 (0.6639)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3560 (0.7219)  Cross-Entropy Loss (Align Words, Choose Image): 0.3445 (0.6294)  Image Caption Matching Loss: 0.4004 (0.9318)  Masked Language Modeling Loss: 1.7104 (1.9684)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.6133 (5.5934)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7670)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7704)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7482)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7798)  Batch Accuracy (Choose Caption): 0.9375 (0.8174)  Batch Accuracy (Choose Image): 0.9062 (0.8249)  Masked Language Modeling Accuracy: 0.6686 (0.6175)  time: 0.9722 (1.1068)  data: 0.0591 (0.1450)  lr: 0.001000  max mem: 11185
2021-04-13 06:56:13,338 maskrcnn_benchmark.trainer INFO: eta: 5:41:07  iter: 21500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3531 (0.6767)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3515 (0.6626)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3229 (0.7202)  Cross-Entropy Loss (Align Words, Choose Image): 0.3151 (0.6280)  Image Caption Matching Loss: 0.3293 (0.9291)  Masked Language Modeling Loss: 1.6192 (1.9671)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4335 (5.5836)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7675)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7708)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7488)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7803)  Batch Accuracy (Choose Caption): 0.9375 (0.8179)  Batch Accuracy (Choose Image): 0.9375 (0.8254)  Masked Language Modeling Accuracy: 0.6402 (0.6176)  time: 0.9819 (1.1063)  data: 0.0569 (0.1446)  lr: 0.001000  max mem: 11185
2021-04-13 06:57:56,067 maskrcnn_benchmark.trainer INFO: eta: 5:39:09  iter: 21600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3551 (0.6753)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3339 (0.6612)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3139 (0.7185)  Cross-Entropy Loss (Align Words, Choose Image): 0.3082 (0.6265)  Image Caption Matching Loss: 0.3426 (0.9265)  Masked Language Modeling Loss: 1.6435 (1.9654)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2041 (5.5734)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7680)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7713)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7494)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7808)  Batch Accuracy (Choose Caption): 0.9219 (0.8185)  Batch Accuracy (Choose Image): 0.9219 (0.8258)  Masked Language Modeling Accuracy: 0.6559 (0.6179)  time: 0.9991 (1.1060)  data: 0.0523 (0.1442)  lr: 0.001000  max mem: 11185
2021-04-13 06:59:39,182 maskrcnn_benchmark.trainer INFO: eta: 5:37:12  iter: 21700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3779 (0.6739)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3103 (0.6599)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3675 (0.7169)  Cross-Entropy Loss (Align Words, Choose Image): 0.2993 (0.6251)  Image Caption Matching Loss: 0.2983 (0.9238)  Masked Language Modeling Loss: 1.6682 (1.9640)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2313 (5.5636)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7685)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7718)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7500)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7814)  Batch Accuracy (Choose Caption): 0.9375 (0.8190)  Batch Accuracy (Choose Image): 0.9375 (0.8263)  Masked Language Modeling Accuracy: 0.6394 (0.6180)  time: 0.9752 (1.1056)  data: 0.0548 (0.1438)  lr: 0.001000  max mem: 11185
2021-04-13 07:01:24,171 maskrcnn_benchmark.trainer INFO: eta: 5:35:17  iter: 21800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3861 (0.6725)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3628 (0.6585)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3301 (0.7153)  Cross-Entropy Loss (Align Words, Choose Image): 0.2761 (0.6236)  Image Caption Matching Loss: 0.3630 (0.9212)  Masked Language Modeling Loss: 1.6876 (1.9627)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4966 (5.5538)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7690)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7722)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7505)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7819)  Batch Accuracy (Choose Caption): 0.9219 (0.8195)  Batch Accuracy (Choose Image): 0.9219 (0.8268)  Masked Language Modeling Accuracy: 0.6277 (0.6182)  time: 0.9802 (1.1054)  data: 0.0669 (0.1434)  lr: 0.001000  max mem: 11185
2021-04-13 07:03:04,847 maskrcnn_benchmark.trainer INFO: eta: 5:33:19  iter: 21900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2944 (0.6711)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3366 (0.6572)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3230 (0.7136)  Cross-Entropy Loss (Align Words, Choose Image): 0.2468 (0.6222)  Image Caption Matching Loss: 0.3114 (0.9186)  Masked Language Modeling Loss: 1.6573 (1.9615)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2246 (5.5441)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7695)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7727)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7511)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7824)  Batch Accuracy (Choose Caption): 0.9375 (0.8200)  Batch Accuracy (Choose Image): 0.9219 (0.8273)  Masked Language Modeling Accuracy: 0.6536 (0.6184)  time: 0.9744 (1.1049)  data: 0.0497 (0.1430)  lr: 0.001000  max mem: 11185
2021-04-13 07:04:46,944 maskrcnn_benchmark.trainer INFO: eta: 5:31:21  iter: 22000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3588 (0.6697)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3326 (0.6558)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2935 (0.7119)  Cross-Entropy Loss (Align Words, Choose Image): 0.2828 (0.6207)  Image Caption Matching Loss: 0.2769 (0.9159)  Masked Language Modeling Loss: 1.6407 (1.9601)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1472 (5.5343)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7700)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7732)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7517)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7829)  Batch Accuracy (Choose Caption): 0.9375 (0.8206)  Batch Accuracy (Choose Image): 0.9375 (0.8278)  Masked Language Modeling Accuracy: 0.6641 (0.6186)  time: 0.9880 (1.1045)  data: 0.0540 (0.1427)  lr: 0.001000  max mem: 11185
2021-04-13 07:04:47,506 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0022000.pth
2021-04-13 07:06:11,485 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 5:31:21  iter: 22000  loss: 1.4359 (1.4032)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2620 (0.2646)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2540 (0.2739)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2803 (0.2959)  Cross-Entropy Loss (Align Words, Choose Image): 0.2297 (0.2546)  Image Caption Matching Loss: 0.3146 (0.3141)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9110)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9046)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8977)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.9056)  Batch Accuracy (Choose Caption): 0.9375 (0.9399)  Batch Accuracy (Choose Image): 0.9375 (0.9431)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11185
2021-04-13 07:07:53,096 maskrcnn_benchmark.trainer INFO: eta: 5:30:32  iter: 22100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3524 (0.6685)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3036 (0.6545)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3093 (0.7102)  Cross-Entropy Loss (Align Words, Choose Image): 0.2776 (0.6193)  Image Caption Matching Loss: 0.3223 (0.9134)  Masked Language Modeling Loss: 1.6981 (1.9588)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3826 (5.5247)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7705)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7737)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7523)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7834)  Batch Accuracy (Choose Caption): 0.9375 (0.8211)  Batch Accuracy (Choose Image): 0.9375 (0.8283)  Masked Language Modeling Accuracy: 0.6545 (0.6187)  time: 0.9910 (1.1080)  data: 0.0669 (0.1461)  lr: 0.001000  max mem: 11185
2021-04-13 07:09:34,121 maskrcnn_benchmark.trainer INFO: eta: 5:28:33  iter: 22200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3275 (0.6671)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3188 (0.6531)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2683 (0.7085)  Cross-Entropy Loss (Align Words, Choose Image): 0.2766 (0.6178)  Image Caption Matching Loss: 0.3376 (0.9109)  Masked Language Modeling Loss: 1.7196 (1.9573)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1018 (5.5147)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.7710)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7741)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7529)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7838)  Batch Accuracy (Choose Caption): 0.9375 (0.8216)  Batch Accuracy (Choose Image): 0.9375 (0.8287)  Masked Language Modeling Accuracy: 0.6536 (0.6189)  time: 0.9639 (1.1075)  data: 0.0568 (0.1457)  lr: 0.001000  max mem: 11185
2021-04-13 07:11:16,703 maskrcnn_benchmark.trainer INFO: eta: 5:26:36  iter: 22300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3312 (0.6658)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3423 (0.6519)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3281 (0.7070)  Cross-Entropy Loss (Align Words, Choose Image): 0.2998 (0.6165)  Image Caption Matching Loss: 0.2929 (0.9084)  Masked Language Modeling Loss: 1.6890 (1.9559)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4158 (5.5055)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7714)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7745)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7534)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7843)  Batch Accuracy (Choose Caption): 0.9375 (0.8221)  Batch Accuracy (Choose Image): 0.9375 (0.8292)  Masked Language Modeling Accuracy: 0.6487 (0.6191)  time: 0.9808 (1.1072)  data: 0.0553 (0.1454)  lr: 0.001000  max mem: 11185
2021-04-13 07:12:58,289 maskrcnn_benchmark.trainer INFO: eta: 5:24:38  iter: 22400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3236 (0.6645)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3200 (0.6506)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3132 (0.7053)  Cross-Entropy Loss (Align Words, Choose Image): 0.2685 (0.6150)  Image Caption Matching Loss: 0.3280 (0.9059)  Masked Language Modeling Loss: 1.5981 (1.9545)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2202 (5.4958)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7719)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7750)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7540)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7848)  Batch Accuracy (Choose Caption): 0.9375 (0.8226)  Batch Accuracy (Choose Image): 0.9219 (0.8296)  Masked Language Modeling Accuracy: 0.6562 (0.6193)  time: 0.9681 (1.1068)  data: 0.0479 (0.1450)  lr: 0.001000  max mem: 11185
2021-04-13 07:14:40,415 maskrcnn_benchmark.trainer INFO: eta: 5:22:41  iter: 22500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3428 (0.6631)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3652 (0.6493)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3467 (0.7037)  Cross-Entropy Loss (Align Words, Choose Image): 0.2538 (0.6136)  Image Caption Matching Loss: 0.3012 (0.9034)  Masked Language Modeling Loss: 1.6192 (1.9531)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1977 (5.4862)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7724)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7755)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7546)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7853)  Batch Accuracy (Choose Caption): 0.9375 (0.8231)  Batch Accuracy (Choose Image): 0.9375 (0.8301)  Masked Language Modeling Accuracy: 0.6379 (0.6195)  time: 0.9874 (1.1064)  data: 0.0569 (0.1446)  lr: 0.001000  max mem: 11185
2021-04-13 07:16:23,499 maskrcnn_benchmark.trainer INFO: eta: 5:20:45  iter: 22600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3709 (0.6619)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3754 (0.6481)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3505 (0.7020)  Cross-Entropy Loss (Align Words, Choose Image): 0.3122 (0.6122)  Image Caption Matching Loss: 0.3248 (0.9010)  Masked Language Modeling Loss: 1.5973 (1.9517)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3380 (5.4769)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7728)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7759)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7552)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7858)  Batch Accuracy (Choose Caption): 0.9219 (0.8236)  Batch Accuracy (Choose Image): 0.9219 (0.8305)  Masked Language Modeling Accuracy: 0.6770 (0.6197)  time: 1.0014 (1.1060)  data: 0.0537 (0.1442)  lr: 0.001000  max mem: 11185
2021-04-13 07:18:05,683 maskrcnn_benchmark.trainer INFO: eta: 5:18:48  iter: 22700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3948 (0.6606)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3682 (0.6468)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3651 (0.7005)  Cross-Entropy Loss (Align Words, Choose Image): 0.2701 (0.6109)  Image Caption Matching Loss: 0.3617 (0.8986)  Masked Language Modeling Loss: 1.5631 (1.9503)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3904 (5.4676)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7733)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7764)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7557)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7863)  Batch Accuracy (Choose Caption): 0.9219 (0.8241)  Batch Accuracy (Choose Image): 0.9375 (0.8310)  Masked Language Modeling Accuracy: 0.6682 (0.6199)  time: 0.9874 (1.1057)  data: 0.0538 (0.1439)  lr: 0.001000  max mem: 11185
2021-04-13 07:19:48,683 maskrcnn_benchmark.trainer INFO: eta: 5:16:51  iter: 22800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3096 (0.6593)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3339 (0.6455)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3371 (0.6989)  Cross-Entropy Loss (Align Words, Choose Image): 0.2860 (0.6095)  Image Caption Matching Loss: 0.3028 (0.8961)  Masked Language Modeling Loss: 1.6678 (1.9491)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2139 (5.4584)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7738)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7768)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7563)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7867)  Batch Accuracy (Choose Caption): 0.9375 (0.8246)  Batch Accuracy (Choose Image): 0.9531 (0.8315)  Masked Language Modeling Accuracy: 0.6505 (0.6200)  time: 0.9876 (1.1053)  data: 0.0396 (0.1435)  lr: 0.001000  max mem: 11185
2021-04-13 07:21:31,342 maskrcnn_benchmark.trainer INFO: eta: 5:14:55  iter: 22900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3150 (0.6580)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3557 (0.6442)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2926 (0.6974)  Cross-Entropy Loss (Align Words, Choose Image): 0.2606 (0.6081)  Image Caption Matching Loss: 0.3033 (0.8936)  Masked Language Modeling Loss: 1.6598 (1.9478)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0657 (5.4491)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7742)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7773)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7568)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7872)  Batch Accuracy (Choose Caption): 0.9375 (0.8251)  Batch Accuracy (Choose Image): 0.9375 (0.8319)  Masked Language Modeling Accuracy: 0.6579 (0.6202)  time: 0.9865 (1.1050)  data: 0.0560 (0.1431)  lr: 0.001000  max mem: 11185
2021-04-13 07:23:16,798 maskrcnn_benchmark.trainer INFO: eta: 5:13:01  iter: 23000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3717 (0.6568)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3819 (0.6430)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3652 (0.6959)  Cross-Entropy Loss (Align Words, Choose Image): 0.3132 (0.6068)  Image Caption Matching Loss: 0.3303 (0.8912)  Masked Language Modeling Loss: 1.6295 (1.9464)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4210 (5.4401)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7747)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7777)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7573)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7877)  Batch Accuracy (Choose Caption): 0.9219 (0.8256)  Batch Accuracy (Choose Image): 0.9219 (0.8323)  Masked Language Modeling Accuracy: 0.6540 (0.6204)  time: 0.9745 (1.1048)  data: 0.0409 (0.1427)  lr: 0.001000  max mem: 11185
2021-04-13 07:23:17,466 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0023000.pth
2021-04-13 07:24:42,975 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 5:13:01  iter: 23000  loss: 1.4392 (1.3776)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2684 (0.2540)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2443 (0.2602)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3073 (0.2910)  Cross-Entropy Loss (Align Words, Choose Image): 0.2468 (0.2566)  Image Caption Matching Loss: 0.3444 (0.3157)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9137)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9087)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8979)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9109)  Batch Accuracy (Choose Caption): 0.9219 (0.9410)  Batch Accuracy (Choose Image): 0.9375 (0.9349)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11185
2021-04-13 07:26:25,142 maskrcnn_benchmark.trainer INFO: eta: 5:12:07  iter: 23100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3496 (0.6555)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3450 (0.6418)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3258 (0.6943)  Cross-Entropy Loss (Align Words, Choose Image): 0.3063 (0.6054)  Image Caption Matching Loss: 0.3328 (0.8887)  Masked Language Modeling Loss: 1.6755 (1.9452)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.5030 (5.4309)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7751)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7782)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7579)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7881)  Batch Accuracy (Choose Caption): 0.9375 (0.8261)  Batch Accuracy (Choose Image): 0.9062 (0.8328)  Masked Language Modeling Accuracy: 0.6486 (0.6206)  time: 0.9717 (1.1081)  data: 0.0517 (0.1461)  lr: 0.001000  max mem: 11185
2021-04-13 07:28:06,559 maskrcnn_benchmark.trainer INFO: eta: 5:10:09  iter: 23200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3488 (0.6542)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3423 (0.6405)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3239 (0.6928)  Cross-Entropy Loss (Align Words, Choose Image): 0.2706 (0.6040)  Image Caption Matching Loss: 0.3178 (0.8863)  Masked Language Modeling Loss: 1.5319 (1.9436)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2394 (5.4215)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7756)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7786)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7584)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7886)  Batch Accuracy (Choose Caption): 0.9375 (0.8266)  Batch Accuracy (Choose Image): 0.9219 (0.8332)  Masked Language Modeling Accuracy: 0.6732 (0.6208)  time: 0.9767 (1.1077)  data: 0.0479 (0.1458)  lr: 0.001000  max mem: 11185
2021-04-13 07:29:49,491 maskrcnn_benchmark.trainer INFO: eta: 5:08:13  iter: 23300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3541 (0.6530)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3646 (0.6393)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3602 (0.6913)  Cross-Entropy Loss (Align Words, Choose Image): 0.3211 (0.6027)  Image Caption Matching Loss: 0.3134 (0.8839)  Masked Language Modeling Loss: 1.6041 (1.9422)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3679 (5.4125)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7760)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7790)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7590)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7891)  Batch Accuracy (Choose Caption): 0.9375 (0.8271)  Batch Accuracy (Choose Image): 0.9375 (0.8336)  Masked Language Modeling Accuracy: 0.6506 (0.6210)  time: 0.9879 (1.1074)  data: 0.0498 (0.1454)  lr: 0.001000  max mem: 11185
2021-04-13 07:31:32,319 maskrcnn_benchmark.trainer INFO: eta: 5:06:17  iter: 23400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3389 (0.6518)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3376 (0.6381)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2719 (0.6897)  Cross-Entropy Loss (Align Words, Choose Image): 0.2832 (0.6014)  Image Caption Matching Loss: 0.3609 (0.8816)  Masked Language Modeling Loss: 1.5314 (1.9408)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2256 (5.4034)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7765)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7795)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7595)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.7895)  Batch Accuracy (Choose Caption): 0.9375 (0.8275)  Batch Accuracy (Choose Image): 0.9219 (0.8341)  Masked Language Modeling Accuracy: 0.6879 (0.6212)  time: 1.0018 (1.1071)  data: 0.0459 (0.1450)  lr: 0.001000  max mem: 11185
2021-04-13 07:33:13,632 maskrcnn_benchmark.trainer INFO: eta: 5:04:19  iter: 23500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3271 (0.6505)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3521 (0.6369)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3237 (0.6882)  Cross-Entropy Loss (Align Words, Choose Image): 0.2764 (0.6001)  Image Caption Matching Loss: 0.3066 (0.8792)  Masked Language Modeling Loss: 1.5488 (1.9393)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1281 (5.3942)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7769)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7799)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7600)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7900)  Batch Accuracy (Choose Caption): 0.9375 (0.8280)  Batch Accuracy (Choose Image): 0.9219 (0.8345)  Masked Language Modeling Accuracy: 0.6584 (0.6214)  time: 1.0032 (1.1067)  data: 0.0485 (0.1446)  lr: 0.001000  max mem: 11185
2021-04-13 07:34:55,477 maskrcnn_benchmark.trainer INFO: eta: 5:02:23  iter: 23600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3332 (0.6492)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3731 (0.6357)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3249 (0.6866)  Cross-Entropy Loss (Align Words, Choose Image): 0.2713 (0.5987)  Image Caption Matching Loss: 0.2998 (0.8768)  Masked Language Modeling Loss: 1.6866 (1.9379)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2381 (5.3849)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7773)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7803)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7606)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7904)  Batch Accuracy (Choose Caption): 0.9375 (0.8285)  Batch Accuracy (Choose Image): 0.9375 (0.8349)  Masked Language Modeling Accuracy: 0.6562 (0.6216)  time: 0.9984 (1.1063)  data: 0.0479 (0.1442)  lr: 0.001000  max mem: 11185
2021-04-13 07:36:38,276 maskrcnn_benchmark.trainer INFO: eta: 5:00:27  iter: 23700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3579 (0.6481)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3133 (0.6345)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3088 (0.6853)  Cross-Entropy Loss (Align Words, Choose Image): 0.2979 (0.5975)  Image Caption Matching Loss: 0.3029 (0.8746)  Masked Language Modeling Loss: 1.5268 (1.9365)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3163 (5.3765)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7777)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7807)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7611)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7908)  Batch Accuracy (Choose Caption): 0.9219 (0.8289)  Batch Accuracy (Choose Image): 0.9375 (0.8353)  Masked Language Modeling Accuracy: 0.6826 (0.6218)  time: 1.0018 (1.1060)  data: 0.0575 (0.1439)  lr: 0.001000  max mem: 11185
2021-04-13 07:38:23,580 maskrcnn_benchmark.trainer INFO: eta: 4:58:32  iter: 23800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3179 (0.6469)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3219 (0.6334)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2907 (0.6837)  Cross-Entropy Loss (Align Words, Choose Image): 0.2896 (0.5963)  Image Caption Matching Loss: 0.2736 (0.8723)  Masked Language Modeling Loss: 1.5853 (1.9353)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0974 (5.3678)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7782)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7811)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7616)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7913)  Batch Accuracy (Choose Caption): 0.9531 (0.8294)  Batch Accuracy (Choose Image): 0.9531 (0.8358)  Masked Language Modeling Accuracy: 0.6762 (0.6220)  time: 0.9855 (1.1057)  data: 0.0553 (0.1435)  lr: 0.001000  max mem: 11185
2021-04-13 07:40:08,223 maskrcnn_benchmark.trainer INFO: eta: 4:56:38  iter: 23900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3777 (0.6457)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3711 (0.6322)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3607 (0.6823)  Cross-Entropy Loss (Align Words, Choose Image): 0.2968 (0.5950)  Image Caption Matching Loss: 0.3358 (0.8701)  Masked Language Modeling Loss: 1.5043 (1.9341)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1805 (5.3594)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7786)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7815)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7621)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7917)  Batch Accuracy (Choose Caption): 0.9375 (0.8298)  Batch Accuracy (Choose Image): 0.9219 (0.8362)  Masked Language Modeling Accuracy: 0.6614 (0.6222)  time: 1.0022 (1.1055)  data: 0.0496 (0.1432)  lr: 0.001000  max mem: 11185
2021-04-13 07:41:52,015 maskrcnn_benchmark.trainer INFO: eta: 4:54:43  iter: 24000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3567 (0.6445)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3459 (0.6311)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3130 (0.6809)  Cross-Entropy Loss (Align Words, Choose Image): 0.2644 (0.5937)  Image Caption Matching Loss: 0.3127 (0.8679)  Masked Language Modeling Loss: 1.6391 (1.9329)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2888 (5.3510)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7790)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7819)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7626)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7922)  Batch Accuracy (Choose Caption): 0.9375 (0.8303)  Batch Accuracy (Choose Image): 0.9375 (0.8366)  Masked Language Modeling Accuracy: 0.6535 (0.6223)  time: 0.9784 (1.1052)  data: 0.0601 (0.1428)  lr: 0.001000  max mem: 11185
2021-04-13 07:41:53,081 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0024000.pth
2021-04-13 07:43:18,006 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 4:54:43  iter: 24000  loss: 1.2968 (1.3233)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2270 (0.2406)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2242 (0.2558)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2619 (0.2796)  Cross-Entropy Loss (Align Words, Choose Image): 0.2121 (0.2393)  Image Caption Matching Loss: 0.3200 (0.3080)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9172)  Batch Accuracy (Align Regions, Choose Image): 0.9155 (0.9073)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8983)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9167)  Batch Accuracy (Choose Caption): 0.9375 (0.9413)  Batch Accuracy (Choose Image): 0.9375 (0.9414)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11185
2021-04-13 07:45:00,298 maskrcnn_benchmark.trainer INFO: eta: 4:53:44  iter: 24100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3855 (0.6434)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3718 (0.6299)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3496 (0.6794)  Cross-Entropy Loss (Align Words, Choose Image): 0.2985 (0.5924)  Image Caption Matching Loss: 0.3395 (0.8656)  Masked Language Modeling Loss: 1.5973 (1.9316)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4250 (5.3423)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7794)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7823)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7632)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7926)  Batch Accuracy (Choose Caption): 0.9375 (0.8307)  Batch Accuracy (Choose Image): 0.9375 (0.8370)  Masked Language Modeling Accuracy: 0.6594 (0.6225)  time: 1.0024 (1.1084)  data: 0.0561 (0.1461)  lr: 0.001000  max mem: 11185
2021-04-13 07:46:42,326 maskrcnn_benchmark.trainer INFO: eta: 4:51:47  iter: 24200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3529 (0.6422)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3400 (0.6287)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2800 (0.6780)  Cross-Entropy Loss (Align Words, Choose Image): 0.2816 (0.5912)  Image Caption Matching Loss: 0.3771 (0.8634)  Masked Language Modeling Loss: 1.5382 (1.9302)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1605 (5.3337)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7798)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7828)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7637)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7931)  Batch Accuracy (Choose Caption): 0.9375 (0.8311)  Batch Accuracy (Choose Image): 0.9375 (0.8374)  Masked Language Modeling Accuracy: 0.6938 (0.6227)  time: 0.9962 (1.1081)  data: 0.0640 (0.1457)  lr: 0.001000  max mem: 11185
2021-04-13 07:48:24,863 maskrcnn_benchmark.trainer INFO: eta: 4:49:51  iter: 24300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3739 (0.6410)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3383 (0.6275)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3378 (0.6765)  Cross-Entropy Loss (Align Words, Choose Image): 0.2413 (0.5899)  Image Caption Matching Loss: 0.3256 (0.8612)  Masked Language Modeling Loss: 1.5298 (1.9289)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3043 (5.3249)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7802)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7832)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7642)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7935)  Batch Accuracy (Choose Caption): 0.9375 (0.8316)  Batch Accuracy (Choose Image): 0.9219 (0.8378)  Masked Language Modeling Accuracy: 0.6774 (0.6229)  time: 0.9899 (1.1077)  data: 0.0502 (0.1454)  lr: 0.001000  max mem: 11185
2021-04-13 07:50:09,214 maskrcnn_benchmark.trainer INFO: eta: 4:47:56  iter: 24400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3936 (0.6398)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3540 (0.6264)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3438 (0.6751)  Cross-Entropy Loss (Align Words, Choose Image): 0.2906 (0.5887)  Image Caption Matching Loss: 0.3144 (0.8590)  Masked Language Modeling Loss: 1.5892 (1.9277)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4674 (5.3167)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7807)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7836)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7647)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7939)  Batch Accuracy (Choose Caption): 0.9531 (0.8320)  Batch Accuracy (Choose Image): 0.9375 (0.8382)  Masked Language Modeling Accuracy: 0.6611 (0.6230)  time: 0.9799 (1.1075)  data: 0.0421 (0.1450)  lr: 0.001000  max mem: 11185
2021-04-13 07:51:51,502 maskrcnn_benchmark.trainer INFO: eta: 4:46:00  iter: 24500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2775 (0.6386)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2688 (0.6252)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2325 (0.6736)  Cross-Entropy Loss (Align Words, Choose Image): 0.2218 (0.5874)  Image Caption Matching Loss: 0.2581 (0.8569)  Masked Language Modeling Loss: 1.6175 (1.9265)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9683 (5.3082)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7811)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7840)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7652)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7944)  Batch Accuracy (Choose Caption): 0.9531 (0.8325)  Batch Accuracy (Choose Image): 0.9531 (0.8386)  Masked Language Modeling Accuracy: 0.6635 (0.6232)  time: 0.9905 (1.1071)  data: 0.0510 (0.1446)  lr: 0.001000  max mem: 11185
2021-04-13 07:53:33,791 maskrcnn_benchmark.trainer INFO: eta: 4:44:04  iter: 24600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3285 (0.6375)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2976 (0.6241)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3068 (0.6722)  Cross-Entropy Loss (Align Words, Choose Image): 0.2765 (0.5862)  Image Caption Matching Loss: 0.2531 (0.8547)  Masked Language Modeling Loss: 1.6485 (1.9254)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1409 (5.3001)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7815)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7843)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7657)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7948)  Batch Accuracy (Choose Caption): 0.9531 (0.8329)  Batch Accuracy (Choose Image): 0.9531 (0.8390)  Masked Language Modeling Accuracy: 0.6402 (0.6234)  time: 0.9796 (1.1068)  data: 0.0671 (0.1443)  lr: 0.001000  max mem: 11185
2021-04-13 07:55:16,294 maskrcnn_benchmark.trainer INFO: eta: 4:42:08  iter: 24700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3454 (0.6363)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3307 (0.6229)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3275 (0.6708)  Cross-Entropy Loss (Align Words, Choose Image): 0.2840 (0.5850)  Image Caption Matching Loss: 0.3092 (0.8525)  Masked Language Modeling Loss: 1.5836 (1.9243)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1854 (5.2919)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7819)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7848)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7662)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7952)  Batch Accuracy (Choose Caption): 0.9375 (0.8333)  Batch Accuracy (Choose Image): 0.9531 (0.8394)  Masked Language Modeling Accuracy: 0.6748 (0.6235)  time: 0.9874 (1.1064)  data: 0.0504 (0.1439)  lr: 0.001000  max mem: 11185
2021-04-13 07:56:59,077 maskrcnn_benchmark.trainer INFO: eta: 4:40:13  iter: 24800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3469 (0.6352)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3533 (0.6218)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3064 (0.6694)  Cross-Entropy Loss (Align Words, Choose Image): 0.2829 (0.5838)  Image Caption Matching Loss: 0.3221 (0.8504)  Masked Language Modeling Loss: 1.5825 (1.9232)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2678 (5.2839)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7823)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7851)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7666)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7956)  Batch Accuracy (Choose Caption): 0.9219 (0.8338)  Batch Accuracy (Choose Image): 0.9219 (0.8398)  Masked Language Modeling Accuracy: 0.6389 (0.6237)  time: 0.9864 (1.1061)  data: 0.0453 (0.1436)  lr: 0.001000  max mem: 11185
2021-04-13 07:58:42,456 maskrcnn_benchmark.trainer INFO: eta: 4:38:18  iter: 24900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3334 (0.6341)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2852 (0.6206)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2928 (0.6680)  Cross-Entropy Loss (Align Words, Choose Image): 0.2603 (0.5826)  Image Caption Matching Loss: 0.2606 (0.8483)  Masked Language Modeling Loss: 1.4741 (1.9219)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8989 (5.2755)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7827)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7855)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7671)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.7960)  Batch Accuracy (Choose Caption): 0.9375 (0.8342)  Batch Accuracy (Choose Image): 0.9531 (0.8402)  Masked Language Modeling Accuracy: 0.6881 (0.6239)  time: 0.9804 (1.1058)  data: 0.0521 (0.1433)  lr: 0.001000  max mem: 11185
2021-04-13 08:00:25,999 maskrcnn_benchmark.trainer INFO: eta: 4:36:23  iter: 25000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3180 (0.6329)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3506 (0.6195)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3003 (0.6666)  Cross-Entropy Loss (Align Words, Choose Image): 0.2904 (0.5815)  Image Caption Matching Loss: 0.2929 (0.8462)  Masked Language Modeling Loss: 1.6027 (1.9206)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4632 (5.2674)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7831)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7859)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7676)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7964)  Batch Accuracy (Choose Caption): 0.9375 (0.8346)  Batch Accuracy (Choose Image): 0.9375 (0.8406)  Masked Language Modeling Accuracy: 0.6406 (0.6240)  time: 0.9887 (1.1056)  data: 0.0566 (0.1429)  lr: 0.001000  max mem: 11185
2021-04-13 08:00:26,772 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0025000.pth
2021-04-13 08:01:50,106 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 4:36:23  iter: 25000  loss: 1.2663 (1.3197)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2362 (0.2439)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2032 (0.2532)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2694 (0.2828)  Cross-Entropy Loss (Align Words, Choose Image): 0.2386 (0.2461)  Image Caption Matching Loss: 0.2654 (0.2936)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9174)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9125)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.9023)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9203)  Batch Accuracy (Choose Caption): 0.9531 (0.9492)  Batch Accuracy (Choose Image): 0.9375 (0.9403)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11185
2021-04-13 08:03:29,729 maskrcnn_benchmark.trainer INFO: eta: 4:35:16  iter: 25100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3519 (0.6319)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3477 (0.6185)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3039 (0.6653)  Cross-Entropy Loss (Align Words, Choose Image): 0.2813 (0.5803)  Image Caption Matching Loss: 0.3421 (0.8442)  Masked Language Modeling Loss: 1.6781 (1.9195)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3290 (5.2597)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7835)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7863)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7681)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7968)  Batch Accuracy (Choose Caption): 0.9375 (0.8350)  Batch Accuracy (Choose Image): 0.9375 (0.8409)  Masked Language Modeling Accuracy: 0.6574 (0.6242)  time: 0.9703 (1.1085)  data: 0.0497 (0.1459)  lr: 0.001000  max mem: 11185
2021-04-13 08:05:09,974 maskrcnn_benchmark.trainer INFO: eta: 4:33:19  iter: 25200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3509 (0.6308)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3414 (0.6175)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2963 (0.6639)  Cross-Entropy Loss (Align Words, Choose Image): 0.2636 (0.5792)  Image Caption Matching Loss: 0.2688 (0.8421)  Masked Language Modeling Loss: 1.7231 (1.9184)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2730 (5.2518)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7839)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7866)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7686)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7973)  Batch Accuracy (Choose Caption): 0.9531 (0.8354)  Batch Accuracy (Choose Image): 0.9531 (0.8413)  Masked Language Modeling Accuracy: 0.6457 (0.6243)  time: 1.0082 (1.1081)  data: 0.0564 (0.1455)  lr: 0.001000  max mem: 11185
2021-04-13 08:06:49,010 maskrcnn_benchmark.trainer INFO: eta: 4:31:21  iter: 25300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3477 (0.6297)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3127 (0.6164)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3082 (0.6626)  Cross-Entropy Loss (Align Words, Choose Image): 0.2619 (0.5780)  Image Caption Matching Loss: 0.3115 (0.8401)  Masked Language Modeling Loss: 1.5786 (1.9172)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1377 (5.2439)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7842)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7870)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7691)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.7977)  Batch Accuracy (Choose Caption): 0.9375 (0.8358)  Batch Accuracy (Choose Image): 0.9375 (0.8417)  Masked Language Modeling Accuracy: 0.6751 (0.6245)  time: 0.9948 (1.1076)  data: 0.0492 (0.1452)  lr: 0.001000  max mem: 11185
2021-04-13 08:08:28,915 maskrcnn_benchmark.trainer INFO: eta: 4:29:24  iter: 25400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3143 (0.6286)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2978 (0.6154)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3436 (0.6612)  Cross-Entropy Loss (Align Words, Choose Image): 0.2656 (0.5768)  Image Caption Matching Loss: 0.3129 (0.8381)  Masked Language Modeling Loss: 1.7415 (1.9161)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3377 (5.2362)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7846)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7874)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7696)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7981)  Batch Accuracy (Choose Caption): 0.9375 (0.8362)  Batch Accuracy (Choose Image): 0.9375 (0.8420)  Masked Language Modeling Accuracy: 0.6344 (0.6246)  time: 0.9933 (1.1072)  data: 0.0546 (0.1448)  lr: 0.001000  max mem: 11185
2021-04-13 08:10:08,671 maskrcnn_benchmark.trainer INFO: eta: 4:27:27  iter: 25500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3291 (0.6275)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3463 (0.6143)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2833 (0.6599)  Cross-Entropy Loss (Align Words, Choose Image): 0.2575 (0.5757)  Image Caption Matching Loss: 0.2861 (0.8361)  Masked Language Modeling Loss: 1.5722 (1.9150)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2634 (5.2286)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7850)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7877)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7700)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7984)  Batch Accuracy (Choose Caption): 0.9375 (0.8366)  Batch Accuracy (Choose Image): 0.9375 (0.8424)  Masked Language Modeling Accuracy: 0.6677 (0.6248)  time: 0.9834 (1.1067)  data: 0.0589 (0.1445)  lr: 0.001000  max mem: 11185
2021-04-13 08:11:48,297 maskrcnn_benchmark.trainer INFO: eta: 4:25:30  iter: 25600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3381 (0.6264)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3544 (0.6133)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3158 (0.6586)  Cross-Entropy Loss (Align Words, Choose Image): 0.2843 (0.5746)  Image Caption Matching Loss: 0.2871 (0.8340)  Masked Language Modeling Loss: 1.5232 (1.9138)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1314 (5.2208)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7854)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7881)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7705)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7989)  Batch Accuracy (Choose Caption): 0.9375 (0.8370)  Batch Accuracy (Choose Image): 0.9219 (0.8428)  Masked Language Modeling Accuracy: 0.6720 (0.6250)  time: 0.9831 (1.1063)  data: 0.0512 (0.1441)  lr: 0.001000  max mem: 11185
2021-04-13 08:13:28,029 maskrcnn_benchmark.trainer INFO: eta: 4:23:33  iter: 25700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3344 (0.6255)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3453 (0.6123)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2895 (0.6572)  Cross-Entropy Loss (Align Words, Choose Image): 0.2501 (0.5734)  Image Caption Matching Loss: 0.3546 (0.8321)  Masked Language Modeling Loss: 1.7582 (1.9128)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3857 (5.2132)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7858)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7885)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7710)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.7993)  Batch Accuracy (Choose Caption): 0.9219 (0.8374)  Batch Accuracy (Choose Image): 0.9219 (0.8431)  Masked Language Modeling Accuracy: 0.6595 (0.6251)  time: 0.9762 (1.1059)  data: 0.0521 (0.1438)  lr: 0.001000  max mem: 11185
2021-04-13 08:15:07,862 maskrcnn_benchmark.trainer INFO: eta: 4:21:37  iter: 25800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3450 (0.6244)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2805 (0.6112)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3285 (0.6559)  Cross-Entropy Loss (Align Words, Choose Image): 0.2730 (0.5723)  Image Caption Matching Loss: 0.2757 (0.8302)  Masked Language Modeling Loss: 1.4799 (1.9117)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0865 (5.2058)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7861)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7888)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7714)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.7996)  Batch Accuracy (Choose Caption): 0.9531 (0.8378)  Batch Accuracy (Choose Image): 0.9375 (0.8435)  Masked Language Modeling Accuracy: 0.6611 (0.6253)  time: 0.9861 (1.1055)  data: 0.0548 (0.1434)  lr: 0.001000  max mem: 11185
2021-04-13 08:16:47,612 maskrcnn_benchmark.trainer INFO: eta: 4:19:41  iter: 25900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3061 (0.6233)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3136 (0.6102)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2361 (0.6546)  Cross-Entropy Loss (Align Words, Choose Image): 0.2506 (0.5711)  Image Caption Matching Loss: 0.2718 (0.8282)  Masked Language Modeling Loss: 1.5834 (1.9106)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9288 (5.1980)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7865)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7892)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.7719)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8001)  Batch Accuracy (Choose Caption): 0.9531 (0.8382)  Batch Accuracy (Choose Image): 0.9375 (0.8438)  Masked Language Modeling Accuracy: 0.6747 (0.6254)  time: 0.9795 (1.1050)  data: 0.0568 (0.1431)  lr: 0.001000  max mem: 11185
2021-04-13 08:18:27,298 maskrcnn_benchmark.trainer INFO: eta: 4:17:44  iter: 26000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3160 (0.6223)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3502 (0.6093)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3417 (0.6534)  Cross-Entropy Loss (Align Words, Choose Image): 0.2929 (0.5700)  Image Caption Matching Loss: 0.3149 (0.8263)  Masked Language Modeling Loss: 1.5444 (1.9096)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2375 (5.1908)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7869)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7895)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7723)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8004)  Batch Accuracy (Choose Caption): 0.9219 (0.8386)  Batch Accuracy (Choose Image): 0.9375 (0.8442)  Masked Language Modeling Accuracy: 0.6510 (0.6255)  time: 0.9643 (1.1046)  data: 0.0561 (0.1427)  lr: 0.001000  max mem: 11185
2021-04-13 08:18:28,061 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0026000.pth
2021-04-13 08:19:51,000 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 4:17:44  iter: 26000  loss: 1.2375 (1.3542)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2079 (0.2489)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2493 (0.2693)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2390 (0.2842)  Cross-Entropy Loss (Align Words, Choose Image): 0.2483 (0.2433)  Image Caption Matching Loss: 0.2720 (0.3086)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9191)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9075)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9023)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9145)  Batch Accuracy (Choose Caption): 0.9531 (0.9381)  Batch Accuracy (Choose Image): 0.9531 (0.9416)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11185
2021-04-13 08:21:30,718 maskrcnn_benchmark.trainer INFO: eta: 4:16:33  iter: 26100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2881 (0.6213)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2812 (0.6082)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2570 (0.6521)  Cross-Entropy Loss (Align Words, Choose Image): 0.2910 (0.5689)  Image Caption Matching Loss: 0.2607 (0.8244)  Masked Language Modeling Loss: 1.6506 (1.9085)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1367 (5.1834)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7872)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.7899)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7728)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8008)  Batch Accuracy (Choose Caption): 0.9375 (0.8389)  Batch Accuracy (Choose Image): 0.9531 (0.8445)  Masked Language Modeling Accuracy: 0.6465 (0.6257)  time: 1.0083 (1.1074)  data: 0.0636 (0.1456)  lr: 0.001000  max mem: 11185
2021-04-13 08:23:10,214 maskrcnn_benchmark.trainer INFO: eta: 4:14:36  iter: 26200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3362 (0.6203)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3404 (0.6072)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3270 (0.6509)  Cross-Entropy Loss (Align Words, Choose Image): 0.3020 (0.5678)  Image Caption Matching Loss: 0.3078 (0.8225)  Masked Language Modeling Loss: 1.5973 (1.9075)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1979 (5.1762)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7876)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7902)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7732)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8012)  Batch Accuracy (Choose Caption): 0.9219 (0.8393)  Batch Accuracy (Choose Image): 0.9375 (0.8449)  Masked Language Modeling Accuracy: 0.6635 (0.6258)  time: 1.0002 (1.1070)  data: 0.0578 (0.1453)  lr: 0.001000  max mem: 11185
2021-04-13 08:24:49,790 maskrcnn_benchmark.trainer INFO: eta: 4:12:39  iter: 26300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3139 (0.6192)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2979 (0.6062)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3129 (0.6496)  Cross-Entropy Loss (Align Words, Choose Image): 0.2754 (0.5667)  Image Caption Matching Loss: 0.3027 (0.8206)  Masked Language Modeling Loss: 1.6034 (1.9063)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0030 (5.1687)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7880)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7905)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7736)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8016)  Batch Accuracy (Choose Caption): 0.9531 (0.8397)  Batch Accuracy (Choose Image): 0.9375 (0.8452)  Masked Language Modeling Accuracy: 0.6848 (0.6260)  time: 0.9904 (1.1066)  data: 0.0532 (0.1449)  lr: 0.001000  max mem: 11185
2021-04-13 08:26:29,954 maskrcnn_benchmark.trainer INFO: eta: 4:10:43  iter: 26400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2693 (0.6181)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2608 (0.6052)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2714 (0.6483)  Cross-Entropy Loss (Align Words, Choose Image): 0.2111 (0.5656)  Image Caption Matching Loss: 0.2229 (0.8186)  Masked Language Modeling Loss: 1.5659 (1.9052)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.7216 (5.1611)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.7883)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.7909)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7741)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8020)  Batch Accuracy (Choose Caption): 0.9531 (0.8401)  Batch Accuracy (Choose Image): 0.9531 (0.8456)  Masked Language Modeling Accuracy: 0.6659 (0.6261)  time: 0.9971 (1.1062)  data: 0.0452 (0.1446)  lr: 0.001000  max mem: 11185
2021-04-13 08:28:10,170 maskrcnn_benchmark.trainer INFO: eta: 4:08:47  iter: 26500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3113 (0.6172)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3487 (0.6043)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3139 (0.6470)  Cross-Entropy Loss (Align Words, Choose Image): 0.2920 (0.5645)  Image Caption Matching Loss: 0.2812 (0.8168)  Masked Language Modeling Loss: 1.6639 (1.9042)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1388 (5.1540)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7887)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7912)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7745)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8023)  Batch Accuracy (Choose Caption): 0.9375 (0.8405)  Batch Accuracy (Choose Image): 0.9375 (0.8459)  Masked Language Modeling Accuracy: 0.6666 (0.6262)  time: 0.9973 (1.1058)  data: 0.0538 (0.1442)  lr: 0.001000  max mem: 11185
2021-04-13 08:29:50,224 maskrcnn_benchmark.trainer INFO: eta: 4:06:52  iter: 26600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3560 (0.6161)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3310 (0.6032)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3064 (0.6458)  Cross-Entropy Loss (Align Words, Choose Image): 0.2973 (0.5634)  Image Caption Matching Loss: 0.2820 (0.8148)  Masked Language Modeling Loss: 1.6023 (1.9031)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3509 (5.1464)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7890)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7916)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7750)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8027)  Batch Accuracy (Choose Caption): 0.9531 (0.8409)  Batch Accuracy (Choose Image): 0.9375 (0.8462)  Masked Language Modeling Accuracy: 0.6831 (0.6264)  time: 0.9785 (1.1054)  data: 0.0620 (0.1439)  lr: 0.001000  max mem: 11185
2021-04-13 08:31:29,910 maskrcnn_benchmark.trainer INFO: eta: 4:04:56  iter: 26700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3847 (0.6152)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3355 (0.6023)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3293 (0.6446)  Cross-Entropy Loss (Align Words, Choose Image): 0.2612 (0.5625)  Image Caption Matching Loss: 0.2591 (0.8130)  Masked Language Modeling Loss: 1.7199 (1.9021)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2414 (5.1396)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7894)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7919)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7753)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8031)  Batch Accuracy (Choose Caption): 0.9531 (0.8412)  Batch Accuracy (Choose Image): 0.9531 (0.8466)  Masked Language Modeling Accuracy: 0.6531 (0.6265)  time: 0.9801 (1.1050)  data: 0.0436 (0.1436)  lr: 0.001000  max mem: 11185
2021-04-13 08:33:10,057 maskrcnn_benchmark.trainer INFO: eta: 4:03:00  iter: 26800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3497 (0.6142)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3064 (0.6013)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3013 (0.6434)  Cross-Entropy Loss (Align Words, Choose Image): 0.2449 (0.5614)  Image Caption Matching Loss: 0.3031 (0.8111)  Masked Language Modeling Loss: 1.7432 (1.9012)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2116 (5.1326)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7897)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7922)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7758)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8035)  Batch Accuracy (Choose Caption): 0.9531 (0.8416)  Batch Accuracy (Choose Image): 0.9375 (0.8469)  Masked Language Modeling Accuracy: 0.6409 (0.6267)  time: 0.9735 (1.1046)  data: 0.0484 (0.1433)  lr: 0.001000  max mem: 11185
2021-04-13 08:34:50,060 maskrcnn_benchmark.trainer INFO: eta: 4:01:05  iter: 26900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2802 (0.6132)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2969 (0.6003)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3038 (0.6422)  Cross-Entropy Loss (Align Words, Choose Image): 0.2789 (0.5604)  Image Caption Matching Loss: 0.2269 (0.8093)  Masked Language Modeling Loss: 1.5581 (1.9002)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0303 (5.1256)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7901)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.7926)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7762)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8038)  Batch Accuracy (Choose Caption): 0.9531 (0.8420)  Batch Accuracy (Choose Image): 0.9531 (0.8473)  Masked Language Modeling Accuracy: 0.6598 (0.6268)  time: 0.9788 (1.1042)  data: 0.0499 (0.1429)  lr: 0.001000  max mem: 11185
2021-04-13 08:36:30,206 maskrcnn_benchmark.trainer INFO: eta: 3:59:09  iter: 27000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3519 (0.6121)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3519 (0.5993)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3543 (0.6410)  Cross-Entropy Loss (Align Words, Choose Image): 0.2492 (0.5593)  Image Caption Matching Loss: 0.2797 (0.8074)  Masked Language Modeling Loss: 1.5714 (1.8992)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2143 (5.1183)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7904)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7929)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7766)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8042)  Batch Accuracy (Choose Caption): 0.9531 (0.8423)  Batch Accuracy (Choose Image): 0.9375 (0.8476)  Masked Language Modeling Accuracy: 0.6801 (0.6269)  time: 0.9757 (1.1038)  data: 0.0555 (0.1426)  lr: 0.001000  max mem: 11185
2021-04-13 08:36:30,968 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0027000.pth
2021-04-13 08:37:54,229 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 3:59:09  iter: 27000  loss: 1.3143 (1.2748)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2342 (0.2388)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2383 (0.2481)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2642 (0.2744)  Cross-Entropy Loss (Align Words, Choose Image): 0.2044 (0.2304)  Image Caption Matching Loss: 0.2926 (0.2831)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9177)  Batch Accuracy (Align Regions, Choose Image): 0.9155 (0.9112)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9031)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9168)  Batch Accuracy (Choose Caption): 0.9375 (0.9453)  Batch Accuracy (Choose Image): 0.9393 (0.9450)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11185
2021-04-13 08:39:32,820 maskrcnn_benchmark.trainer INFO: eta: 3:57:53  iter: 27100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2914 (0.6111)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3094 (0.5984)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2604 (0.6398)  Cross-Entropy Loss (Align Words, Choose Image): 0.2285 (0.5582)  Image Caption Matching Loss: 0.3020 (0.8056)  Masked Language Modeling Loss: 1.5260 (1.8980)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0309 (5.1111)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7908)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7933)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.7771)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8045)  Batch Accuracy (Choose Caption): 0.9375 (0.8427)  Batch Accuracy (Choose Image): 0.9375 (0.8479)  Masked Language Modeling Accuracy: 0.6657 (0.6271)  time: 0.9798 (1.1065)  data: 0.0570 (0.1454)  lr: 0.001000  max mem: 11185
2021-04-13 08:41:12,445 maskrcnn_benchmark.trainer INFO: eta: 3:55:57  iter: 27200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2838 (0.6102)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3328 (0.5975)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2738 (0.6386)  Cross-Entropy Loss (Align Words, Choose Image): 0.2705 (0.5572)  Image Caption Matching Loss: 0.2892 (0.8038)  Masked Language Modeling Loss: 1.5370 (1.8970)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0646 (5.1044)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7911)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.7936)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7775)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8049)  Batch Accuracy (Choose Caption): 0.9375 (0.8431)  Batch Accuracy (Choose Image): 0.9375 (0.8482)  Masked Language Modeling Accuracy: 0.6604 (0.6272)  time: 0.9877 (1.1061)  data: 0.0542 (0.1451)  lr: 0.001000  max mem: 11185
2021-04-13 08:42:51,796 maskrcnn_benchmark.trainer INFO: eta: 3:54:01  iter: 27300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3866 (0.6093)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3830 (0.5966)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3719 (0.6374)  Cross-Entropy Loss (Align Words, Choose Image): 0.3240 (0.5563)  Image Caption Matching Loss: 0.2837 (0.8021)  Masked Language Modeling Loss: 1.6604 (1.8961)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4781 (5.0978)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7914)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7939)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7779)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8052)  Batch Accuracy (Choose Caption): 0.9531 (0.8434)  Batch Accuracy (Choose Image): 0.9219 (0.8485)  Masked Language Modeling Accuracy: 0.6450 (0.6273)  time: 0.9654 (1.1057)  data: 0.0512 (0.1448)  lr: 0.001000  max mem: 11185
2021-04-13 08:44:31,471 maskrcnn_benchmark.trainer INFO: eta: 3:52:06  iter: 27400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2720 (0.6083)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2872 (0.5956)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2876 (0.6362)  Cross-Entropy Loss (Align Words, Choose Image): 0.2466 (0.5552)  Image Caption Matching Loss: 0.2789 (0.8003)  Masked Language Modeling Loss: 1.5879 (1.8951)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1009 (5.0906)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7918)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7942)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7783)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8056)  Batch Accuracy (Choose Caption): 0.9531 (0.8438)  Batch Accuracy (Choose Image): 0.9531 (0.8489)  Masked Language Modeling Accuracy: 0.6524 (0.6275)  time: 0.9602 (1.1053)  data: 0.0436 (0.1444)  lr: 0.001000  max mem: 11185
2021-04-13 08:46:11,134 maskrcnn_benchmark.trainer INFO: eta: 3:50:10  iter: 27500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3490 (0.6073)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3198 (0.5947)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2967 (0.6350)  Cross-Entropy Loss (Align Words, Choose Image): 0.2849 (0.5542)  Image Caption Matching Loss: 0.2958 (0.7985)  Masked Language Modeling Loss: 1.6500 (1.8940)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1768 (5.0836)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7921)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7945)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7787)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8060)  Batch Accuracy (Choose Caption): 0.9375 (0.8441)  Batch Accuracy (Choose Image): 0.9375 (0.8492)  Masked Language Modeling Accuracy: 0.6587 (0.6276)  time: 1.0095 (1.1049)  data: 0.0508 (0.1441)  lr: 0.001000  max mem: 11185
2021-04-13 08:47:50,864 maskrcnn_benchmark.trainer INFO: eta: 3:48:15  iter: 27600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3452 (0.6064)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3149 (0.5938)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3521 (0.6338)  Cross-Entropy Loss (Align Words, Choose Image): 0.2797 (0.5532)  Image Caption Matching Loss: 0.3334 (0.7968)  Masked Language Modeling Loss: 1.5360 (1.8930)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3210 (5.0769)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7925)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7949)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7791)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8063)  Batch Accuracy (Choose Caption): 0.9375 (0.8445)  Batch Accuracy (Choose Image): 0.9219 (0.8495)  Masked Language Modeling Accuracy: 0.6760 (0.6278)  time: 1.0103 (1.1045)  data: 0.0559 (0.1438)  lr: 0.001000  max mem: 11185
2021-04-13 08:49:30,398 maskrcnn_benchmark.trainer INFO: eta: 3:46:20  iter: 27700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3328 (0.6055)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2998 (0.5929)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3127 (0.6327)  Cross-Entropy Loss (Align Words, Choose Image): 0.2625 (0.5522)  Image Caption Matching Loss: 0.2764 (0.7951)  Masked Language Modeling Loss: 1.5366 (1.8921)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0174 (5.0704)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7928)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7952)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7795)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8066)  Batch Accuracy (Choose Caption): 0.9375 (0.8448)  Batch Accuracy (Choose Image): 0.9375 (0.8498)  Masked Language Modeling Accuracy: 0.6720 (0.6279)  time: 0.9952 (1.1041)  data: 0.0575 (0.1435)  lr: 0.001000  max mem: 11185
2021-04-13 08:51:09,682 maskrcnn_benchmark.trainer INFO: eta: 3:44:25  iter: 27800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3500 (0.6046)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3056 (0.5920)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3334 (0.6315)  Cross-Entropy Loss (Align Words, Choose Image): 0.2911 (0.5512)  Image Caption Matching Loss: 0.2793 (0.7933)  Masked Language Modeling Loss: 1.6493 (1.8912)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2781 (5.0639)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7931)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7955)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7799)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8070)  Batch Accuracy (Choose Caption): 0.9375 (0.8451)  Batch Accuracy (Choose Image): 0.9375 (0.8501)  Masked Language Modeling Accuracy: 0.6440 (0.6280)  time: 0.9919 (1.1037)  data: 0.0530 (0.1432)  lr: 0.001000  max mem: 11185
2021-04-13 08:52:48,918 maskrcnn_benchmark.trainer INFO: eta: 3:42:29  iter: 27900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3005 (0.6036)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2943 (0.5910)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2701 (0.6304)  Cross-Entropy Loss (Align Words, Choose Image): 0.2453 (0.5502)  Image Caption Matching Loss: 0.2483 (0.7916)  Masked Language Modeling Loss: 1.6025 (1.8902)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9704 (5.0570)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.7935)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7958)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7803)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8074)  Batch Accuracy (Choose Caption): 0.9531 (0.8455)  Batch Accuracy (Choose Image): 0.9531 (0.8504)  Masked Language Modeling Accuracy: 0.6591 (0.6281)  time: 0.9837 (1.1033)  data: 0.0570 (0.1429)  lr: 0.001000  max mem: 11185
2021-04-13 08:54:28,762 maskrcnn_benchmark.trainer INFO: eta: 3:40:35  iter: 28000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3054 (0.6027)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2837 (0.5901)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3108 (0.6293)  Cross-Entropy Loss (Align Words, Choose Image): 0.2339 (0.5493)  Image Caption Matching Loss: 0.3006 (0.7900)  Masked Language Modeling Loss: 1.4503 (1.8893)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8692 (5.0506)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7938)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7961)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7807)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8077)  Batch Accuracy (Choose Caption): 0.9375 (0.8458)  Batch Accuracy (Choose Image): 0.9375 (0.8507)  Masked Language Modeling Accuracy: 0.6824 (0.6283)  time: 0.9786 (1.1029)  data: 0.0529 (0.1426)  lr: 0.001000  max mem: 11185
2021-04-13 08:54:29,672 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0028000.pth
2021-04-13 08:55:53,316 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 3:40:35  iter: 28000  loss: 1.1597 (1.2691)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2074 (0.2274)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2206 (0.2521)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2604 (0.2761)  Cross-Entropy Loss (Align Words, Choose Image): 0.2087 (0.2316)  Image Caption Matching Loss: 0.2556 (0.2819)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9195)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9125)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9053)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9181)  Batch Accuracy (Choose Caption): 0.9531 (0.9490)  Batch Accuracy (Choose Image): 0.9393 (0.9448)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11185
2021-04-13 08:57:32,177 maskrcnn_benchmark.trainer INFO: eta: 3:39:15  iter: 28100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4053 (0.6018)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3601 (0.5893)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2680 (0.6281)  Cross-Entropy Loss (Align Words, Choose Image): 0.2535 (0.5483)  Image Caption Matching Loss: 0.2808 (0.7883)  Masked Language Modeling Loss: 1.5865 (1.8883)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1972 (5.0441)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7941)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7964)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7811)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8080)  Batch Accuracy (Choose Caption): 0.9531 (0.8461)  Batch Accuracy (Choose Image): 0.9375 (0.8511)  Masked Language Modeling Accuracy: 0.6725 (0.6284)  time: 0.9916 (1.1055)  data: 0.0639 (0.1453)  lr: 0.001000  max mem: 11185
2021-04-13 08:59:12,028 maskrcnn_benchmark.trainer INFO: eta: 3:37:20  iter: 28200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3272 (0.6009)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3526 (0.5884)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3062 (0.6270)  Cross-Entropy Loss (Align Words, Choose Image): 0.2976 (0.5474)  Image Caption Matching Loss: 0.2883 (0.7866)  Masked Language Modeling Loss: 1.7158 (1.8872)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1833 (5.0376)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7944)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7967)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7815)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8083)  Batch Accuracy (Choose Caption): 0.9531 (0.8465)  Batch Accuracy (Choose Image): 0.9375 (0.8513)  Masked Language Modeling Accuracy: 0.6426 (0.6285)  time: 0.9899 (1.1051)  data: 0.0581 (0.1450)  lr: 0.001000  max mem: 11185
2021-04-13 09:00:51,387 maskrcnn_benchmark.trainer INFO: eta: 3:35:25  iter: 28300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3436 (0.6000)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2945 (0.5875)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2875 (0.6259)  Cross-Entropy Loss (Align Words, Choose Image): 0.2950 (0.5464)  Image Caption Matching Loss: 0.2651 (0.7850)  Masked Language Modeling Loss: 1.5838 (1.8863)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2327 (5.0312)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.7947)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7970)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7819)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8086)  Batch Accuracy (Choose Caption): 0.9531 (0.8468)  Batch Accuracy (Choose Image): 0.9531 (0.8516)  Masked Language Modeling Accuracy: 0.6485 (0.6287)  time: 0.9863 (1.1047)  data: 0.0373 (0.1446)  lr: 0.001000  max mem: 11185
2021-04-13 09:02:31,217 maskrcnn_benchmark.trainer INFO: eta: 3:33:30  iter: 28400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3940 (0.5992)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3265 (0.5867)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3239 (0.6248)  Cross-Entropy Loss (Align Words, Choose Image): 0.2834 (0.5455)  Image Caption Matching Loss: 0.3229 (0.7833)  Masked Language Modeling Loss: 1.6168 (1.8853)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.5012 (5.0247)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7950)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7973)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7823)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8090)  Batch Accuracy (Choose Caption): 0.9219 (0.8471)  Batch Accuracy (Choose Image): 0.9375 (0.8519)  Masked Language Modeling Accuracy: 0.6555 (0.6288)  time: 0.9757 (1.1044)  data: 0.0600 (0.1443)  lr: 0.001000  max mem: 11185
2021-04-13 09:04:10,884 maskrcnn_benchmark.trainer INFO: eta: 3:31:35  iter: 28500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3046 (0.5982)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3142 (0.5858)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2730 (0.6237)  Cross-Entropy Loss (Align Words, Choose Image): 0.2416 (0.5445)  Image Caption Matching Loss: 0.2486 (0.7816)  Masked Language Modeling Loss: 1.5287 (1.8842)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8924 (5.0181)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7953)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7976)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7827)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8093)  Batch Accuracy (Choose Caption): 0.9531 (0.8475)  Batch Accuracy (Choose Image): 0.9531 (0.8523)  Masked Language Modeling Accuracy: 0.6566 (0.6289)  time: 0.9984 (1.1040)  data: 0.0607 (0.1440)  lr: 0.001000  max mem: 11185
2021-04-13 09:05:50,614 maskrcnn_benchmark.trainer INFO: eta: 3:29:41  iter: 28600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3255 (0.5973)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3126 (0.5849)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2423 (0.6227)  Cross-Entropy Loss (Align Words, Choose Image): 0.2229 (0.5436)  Image Caption Matching Loss: 0.2503 (0.7800)  Masked Language Modeling Loss: 1.5815 (1.8832)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0785 (5.0116)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7956)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7979)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.7830)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8096)  Batch Accuracy (Choose Caption): 0.9531 (0.8478)  Batch Accuracy (Choose Image): 0.9375 (0.8526)  Masked Language Modeling Accuracy: 0.6879 (0.6291)  time: 0.9892 (1.1036)  data: 0.0382 (0.1437)  lr: 0.001000  max mem: 11185
2021-04-13 09:07:30,144 maskrcnn_benchmark.trainer INFO: eta: 3:27:46  iter: 28700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3316 (0.5965)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3438 (0.5840)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3120 (0.6216)  Cross-Entropy Loss (Align Words, Choose Image): 0.2473 (0.5427)  Image Caption Matching Loss: 0.2858 (0.7783)  Masked Language Modeling Loss: 1.7194 (1.8824)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2062 (5.0055)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7959)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7982)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7834)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8099)  Batch Accuracy (Choose Caption): 0.9375 (0.8481)  Batch Accuracy (Choose Image): 0.9375 (0.8529)  Masked Language Modeling Accuracy: 0.6460 (0.6292)  time: 0.9864 (1.1032)  data: 0.0596 (0.1434)  lr: 0.001000  max mem: 11185
2021-04-13 09:09:09,958 maskrcnn_benchmark.trainer INFO: eta: 3:25:52  iter: 28800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2838 (0.5956)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3053 (0.5832)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2730 (0.6205)  Cross-Entropy Loss (Align Words, Choose Image): 0.2621 (0.5417)  Image Caption Matching Loss: 0.2807 (0.7767)  Masked Language Modeling Loss: 1.6267 (1.8813)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0792 (4.9990)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7962)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7985)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7838)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8102)  Batch Accuracy (Choose Caption): 0.9531 (0.8485)  Batch Accuracy (Choose Image): 0.9375 (0.8532)  Masked Language Modeling Accuracy: 0.6720 (0.6294)  time: 0.9897 (1.1029)  data: 0.0585 (0.1431)  lr: 0.001000  max mem: 11185
2021-04-13 09:10:49,273 maskrcnn_benchmark.trainer INFO: eta: 3:23:57  iter: 28900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3256 (0.5948)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3594 (0.5823)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2997 (0.6195)  Cross-Entropy Loss (Align Words, Choose Image): 0.2559 (0.5408)  Image Caption Matching Loss: 0.2912 (0.7751)  Masked Language Modeling Loss: 1.5224 (1.8806)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0159 (4.9931)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7966)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7988)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7842)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8105)  Batch Accuracy (Choose Caption): 0.9375 (0.8488)  Batch Accuracy (Choose Image): 0.9375 (0.8534)  Masked Language Modeling Accuracy: 0.6627 (0.6294)  time: 0.9953 (1.1025)  data: 0.0515 (0.1428)  lr: 0.001000  max mem: 11185
2021-04-13 09:12:29,254 maskrcnn_benchmark.trainer INFO: eta: 3:22:03  iter: 29000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3520 (0.5938)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3060 (0.5815)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3487 (0.6184)  Cross-Entropy Loss (Align Words, Choose Image): 0.3066 (0.5399)  Image Caption Matching Loss: 0.3243 (0.7735)  Masked Language Modeling Loss: 1.4920 (1.8795)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1586 (4.9865)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7969)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.7991)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7845)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8108)  Batch Accuracy (Choose Caption): 0.9219 (0.8491)  Batch Accuracy (Choose Image): 0.9219 (0.8537)  Masked Language Modeling Accuracy: 0.6667 (0.6296)  time: 0.9857 (1.1021)  data: 0.0489 (0.1425)  lr: 0.001000  max mem: 11185
2021-04-13 09:12:29,977 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0029000.pth
2021-04-13 09:13:53,006 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 3:22:03  iter: 29000  loss: 1.2902 (1.2871)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2713 (0.2393)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2537 (0.2533)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2337 (0.2672)  Cross-Entropy Loss (Align Words, Choose Image): 0.2034 (0.2329)  Image Caption Matching Loss: 0.2753 (0.2944)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.9131)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9121)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.9024)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9207)  Batch Accuracy (Choose Caption): 0.9531 (0.9454)  Batch Accuracy (Choose Image): 0.9531 (0.9385)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11185
2021-04-13 09:15:32,680 maskrcnn_benchmark.trainer INFO: eta: 3:20:40  iter: 29100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3669 (0.5930)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3720 (0.5806)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2863 (0.6173)  Cross-Entropy Loss (Align Words, Choose Image): 0.2436 (0.5390)  Image Caption Matching Loss: 0.2713 (0.7718)  Masked Language Modeling Loss: 1.6241 (1.8786)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1849 (4.9803)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7972)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.7994)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7849)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8111)  Batch Accuracy (Choose Caption): 0.9375 (0.8494)  Batch Accuracy (Choose Image): 0.9375 (0.8540)  Masked Language Modeling Accuracy: 0.6626 (0.6297)  time: 1.0131 (1.1047)  data: 0.0600 (0.1451)  lr: 0.001000  max mem: 11185
2021-04-13 09:17:11,497 maskrcnn_benchmark.trainer INFO: eta: 3:18:46  iter: 29200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3348 (0.5921)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3590 (0.5798)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2906 (0.6162)  Cross-Entropy Loss (Align Words, Choose Image): 0.2534 (0.5381)  Image Caption Matching Loss: 0.3231 (0.7703)  Masked Language Modeling Loss: 1.7633 (1.8777)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3081 (4.9742)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7975)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.7997)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7853)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8115)  Batch Accuracy (Choose Caption): 0.9375 (0.8497)  Batch Accuracy (Choose Image): 0.9375 (0.8543)  Masked Language Modeling Accuracy: 0.6556 (0.6298)  time: 0.9727 (1.1043)  data: 0.0474 (0.1448)  lr: 0.001000  max mem: 11185
2021-04-13 09:18:51,200 maskrcnn_benchmark.trainer INFO: eta: 3:16:51  iter: 29300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3602 (0.5913)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3456 (0.5789)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3554 (0.6152)  Cross-Entropy Loss (Align Words, Choose Image): 0.2774 (0.5372)  Image Caption Matching Loss: 0.3183 (0.7687)  Masked Language Modeling Loss: 1.7424 (1.8769)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4334 (4.9682)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.7978)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8000)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7857)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8118)  Batch Accuracy (Choose Caption): 0.9219 (0.8501)  Batch Accuracy (Choose Image): 0.9219 (0.8546)  Masked Language Modeling Accuracy: 0.6408 (0.6300)  time: 1.0012 (1.1039)  data: 0.0548 (0.1445)  lr: 0.001000  max mem: 11185
2021-04-13 09:20:30,637 maskrcnn_benchmark.trainer INFO: eta: 3:14:57  iter: 29400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2818 (0.5904)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3400 (0.5781)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2667 (0.6142)  Cross-Entropy Loss (Align Words, Choose Image): 0.2997 (0.5363)  Image Caption Matching Loss: 0.2370 (0.7671)  Masked Language Modeling Loss: 1.5493 (1.8758)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9572 (4.9619)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7981)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8003)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7860)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8121)  Batch Accuracy (Choose Caption): 0.9531 (0.8504)  Batch Accuracy (Choose Image): 0.9531 (0.8549)  Masked Language Modeling Accuracy: 0.6814 (0.6301)  time: 0.9690 (1.1035)  data: 0.0575 (0.1442)  lr: 0.001000  max mem: 11185
2021-04-13 09:22:10,555 maskrcnn_benchmark.trainer INFO: eta: 3:13:03  iter: 29500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4109 (0.5896)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3643 (0.5772)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3396 (0.6132)  Cross-Entropy Loss (Align Words, Choose Image): 0.2695 (0.5354)  Image Caption Matching Loss: 0.3525 (0.7656)  Masked Language Modeling Loss: 1.6247 (1.8750)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4868 (4.9560)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.7984)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8006)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7864)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8124)  Batch Accuracy (Choose Caption): 0.9375 (0.8507)  Batch Accuracy (Choose Image): 0.9219 (0.8552)  Masked Language Modeling Accuracy: 0.6591 (0.6302)  time: 1.0030 (1.1032)  data: 0.0532 (0.1439)  lr: 0.001000  max mem: 11185
2021-04-13 09:23:49,773 maskrcnn_benchmark.trainer INFO: eta: 3:11:09  iter: 29600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3174 (0.5888)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3091 (0.5764)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2381 (0.6121)  Cross-Entropy Loss (Align Words, Choose Image): 0.2197 (0.5345)  Image Caption Matching Loss: 0.2697 (0.7641)  Masked Language Modeling Loss: 1.5561 (1.8742)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0507 (4.9500)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.7987)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8009)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.7868)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8127)  Batch Accuracy (Choose Caption): 0.9531 (0.8510)  Batch Accuracy (Choose Image): 0.9531 (0.8555)  Masked Language Modeling Accuracy: 0.6683 (0.6303)  time: 0.9711 (1.1028)  data: 0.0374 (0.1436)  lr: 0.001000  max mem: 11185
2021-04-13 09:25:29,456 maskrcnn_benchmark.trainer INFO: eta: 3:09:15  iter: 29700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3439 (0.5880)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2802 (0.5755)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3254 (0.6111)  Cross-Entropy Loss (Align Words, Choose Image): 0.2428 (0.5336)  Image Caption Matching Loss: 0.2568 (0.7625)  Masked Language Modeling Loss: 1.5729 (1.8733)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0535 (4.9440)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7990)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8012)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7871)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8130)  Batch Accuracy (Choose Caption): 0.9375 (0.8513)  Batch Accuracy (Choose Image): 0.9531 (0.8558)  Masked Language Modeling Accuracy: 0.6848 (0.6305)  time: 0.9815 (1.1024)  data: 0.0619 (0.1433)  lr: 0.001000  max mem: 11185
2021-04-13 09:27:09,628 maskrcnn_benchmark.trainer INFO: eta: 3:07:21  iter: 29800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2922 (0.5872)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3355 (0.5748)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3058 (0.6101)  Cross-Entropy Loss (Align Words, Choose Image): 0.2693 (0.5327)  Image Caption Matching Loss: 0.2973 (0.7610)  Masked Language Modeling Loss: 1.4937 (1.8724)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1572 (4.9381)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7992)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8014)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7874)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8133)  Batch Accuracy (Choose Caption): 0.9375 (0.8516)  Batch Accuracy (Choose Image): 0.9219 (0.8560)  Masked Language Modeling Accuracy: 0.6468 (0.6306)  time: 0.9927 (1.1021)  data: 0.0400 (0.1430)  lr: 0.001000  max mem: 11185
2021-04-13 09:28:49,302 maskrcnn_benchmark.trainer INFO: eta: 3:05:27  iter: 29900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2710 (0.5864)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3249 (0.5740)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2825 (0.6091)  Cross-Entropy Loss (Align Words, Choose Image): 0.2513 (0.5318)  Image Caption Matching Loss: 0.2612 (0.7595)  Masked Language Modeling Loss: 1.5410 (1.8716)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1313 (4.9324)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.7995)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8017)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.7878)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8136)  Batch Accuracy (Choose Caption): 0.9375 (0.8519)  Batch Accuracy (Choose Image): 0.9375 (0.8563)  Masked Language Modeling Accuracy: 0.6671 (0.6307)  time: 0.9844 (1.1017)  data: 0.0532 (0.1427)  lr: 0.001000  max mem: 11185
2021-04-13 09:30:28,626 maskrcnn_benchmark.trainer INFO: eta: 3:03:33  iter: 30000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3046 (0.5855)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3397 (0.5732)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3123 (0.6081)  Cross-Entropy Loss (Align Words, Choose Image): 0.2569 (0.5310)  Image Caption Matching Loss: 0.3245 (0.7581)  Masked Language Modeling Loss: 1.6272 (1.8707)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1190 (4.9266)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.7998)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8020)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7881)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8139)  Batch Accuracy (Choose Caption): 0.9375 (0.8522)  Batch Accuracy (Choose Image): 0.9375 (0.8566)  Masked Language Modeling Accuracy: 0.6662 (0.6308)  time: 0.9929 (1.1014)  data: 0.0491 (0.1425)  lr: 0.001000  max mem: 11254
2021-04-13 09:30:29,387 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0030000.pth
2021-04-13 09:31:52,817 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 3:03:33  iter: 30000  loss: 1.2386 (1.2512)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2120 (0.2242)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2231 (0.2473)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2485 (0.2705)  Cross-Entropy Loss (Align Words, Choose Image): 0.2208 (0.2255)  Image Caption Matching Loss: 0.2950 (0.2837)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9221)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9159)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9097)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9229)  Batch Accuracy (Choose Caption): 0.9375 (0.9470)  Batch Accuracy (Choose Image): 0.9375 (0.9427)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11254
2021-04-13 09:33:31,461 maskrcnn_benchmark.trainer INFO: eta: 3:02:07  iter: 30100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2963 (0.5847)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3105 (0.5724)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2500 (0.6072)  Cross-Entropy Loss (Align Words, Choose Image): 0.2307 (0.5301)  Image Caption Matching Loss: 0.2245 (0.7567)  Masked Language Modeling Loss: 1.6404 (1.8700)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0207 (4.9210)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8001)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8023)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7885)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8142)  Batch Accuracy (Choose Caption): 0.9375 (0.8524)  Batch Accuracy (Choose Image): 0.9531 (0.8568)  Masked Language Modeling Accuracy: 0.6652 (0.6309)  time: 0.9735 (1.1038)  data: 0.0729 (0.1450)  lr: 0.001000  max mem: 11254
2021-04-13 09:35:10,288 maskrcnn_benchmark.trainer INFO: eta: 3:00:13  iter: 30200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3431 (0.5839)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3500 (0.5716)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3017 (0.6061)  Cross-Entropy Loss (Align Words, Choose Image): 0.2761 (0.5293)  Image Caption Matching Loss: 0.2698 (0.7551)  Masked Language Modeling Loss: 1.6237 (1.8691)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1859 (4.9151)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8004)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8025)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7888)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8145)  Batch Accuracy (Choose Caption): 0.9375 (0.8528)  Batch Accuracy (Choose Image): 0.9375 (0.8571)  Masked Language Modeling Accuracy: 0.6573 (0.6310)  time: 0.9837 (1.1034)  data: 0.0524 (0.1447)  lr: 0.001000  max mem: 11254
2021-04-13 09:36:49,815 maskrcnn_benchmark.trainer INFO: eta: 2:58:19  iter: 30300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3300 (0.5831)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3275 (0.5708)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3281 (0.6051)  Cross-Entropy Loss (Align Words, Choose Image): 0.3105 (0.5284)  Image Caption Matching Loss: 0.3457 (0.7536)  Masked Language Modeling Loss: 1.6595 (1.8683)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2680 (4.9094)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8007)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8028)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7892)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8148)  Batch Accuracy (Choose Caption): 0.9375 (0.8531)  Batch Accuracy (Choose Image): 0.9219 (0.8574)  Masked Language Modeling Accuracy: 0.6807 (0.6311)  time: 1.0053 (1.1031)  data: 0.0415 (0.1444)  lr: 0.001000  max mem: 11254
2021-04-13 09:38:29,077 maskrcnn_benchmark.trainer INFO: eta: 2:56:25  iter: 30400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3149 (0.5823)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3037 (0.5700)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2691 (0.6042)  Cross-Entropy Loss (Align Words, Choose Image): 0.2328 (0.5275)  Image Caption Matching Loss: 0.3055 (0.7522)  Masked Language Modeling Loss: 1.6481 (1.8675)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0500 (4.9037)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8010)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8031)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7895)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8152)  Batch Accuracy (Choose Caption): 0.9531 (0.8533)  Batch Accuracy (Choose Image): 0.9375 (0.8577)  Masked Language Modeling Accuracy: 0.6668 (0.6312)  time: 0.9959 (1.1027)  data: 0.0468 (0.1441)  lr: 0.001000  max mem: 11254
2021-04-13 09:40:08,947 maskrcnn_benchmark.trainer INFO: eta: 2:54:32  iter: 30500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3610 (0.5815)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3338 (0.5693)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3184 (0.6032)  Cross-Entropy Loss (Align Words, Choose Image): 0.2931 (0.5267)  Image Caption Matching Loss: 0.3398 (0.7507)  Masked Language Modeling Loss: 1.6175 (1.8667)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2958 (4.8982)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8012)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8033)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7899)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8155)  Batch Accuracy (Choose Caption): 0.9375 (0.8536)  Batch Accuracy (Choose Image): 0.9219 (0.8579)  Masked Language Modeling Accuracy: 0.6483 (0.6313)  time: 1.0014 (1.1024)  data: 0.0533 (0.1438)  lr: 0.001000  max mem: 11254
2021-04-13 09:41:48,700 maskrcnn_benchmark.trainer INFO: eta: 2:52:38  iter: 30600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3664 (0.5808)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3594 (0.5685)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3138 (0.6023)  Cross-Entropy Loss (Align Words, Choose Image): 0.2899 (0.5259)  Image Caption Matching Loss: 0.2983 (0.7493)  Masked Language Modeling Loss: 1.5813 (1.8659)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3751 (4.8928)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8015)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8036)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7902)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8157)  Batch Accuracy (Choose Caption): 0.9531 (0.8539)  Batch Accuracy (Choose Image): 0.9219 (0.8582)  Masked Language Modeling Accuracy: 0.6687 (0.6314)  time: 0.9959 (1.1020)  data: 0.0545 (0.1436)  lr: 0.001000  max mem: 11254
2021-04-13 09:43:28,302 maskrcnn_benchmark.trainer INFO: eta: 2:50:45  iter: 30700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3783 (0.5801)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3669 (0.5678)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2693 (0.6013)  Cross-Entropy Loss (Align Words, Choose Image): 0.2625 (0.5250)  Image Caption Matching Loss: 0.2819 (0.7479)  Masked Language Modeling Loss: 1.7520 (1.8652)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3564 (4.8871)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8017)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8039)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7905)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8160)  Batch Accuracy (Choose Caption): 0.9375 (0.8542)  Batch Accuracy (Choose Image): 0.9375 (0.8585)  Masked Language Modeling Accuracy: 0.6352 (0.6315)  time: 0.9938 (1.1017)  data: 0.0475 (0.1433)  lr: 0.001000  max mem: 11254
2021-04-13 09:45:08,126 maskrcnn_benchmark.trainer INFO: eta: 2:48:52  iter: 30800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2965 (0.5793)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3047 (0.5670)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2578 (0.6004)  Cross-Entropy Loss (Align Words, Choose Image): 0.2809 (0.5242)  Image Caption Matching Loss: 0.2551 (0.7464)  Masked Language Modeling Loss: 1.5855 (1.8643)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1122 (4.8816)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8020)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8041)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7908)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8163)  Batch Accuracy (Choose Caption): 0.9531 (0.8545)  Batch Accuracy (Choose Image): 0.9375 (0.8587)  Masked Language Modeling Accuracy: 0.6658 (0.6316)  time: 0.9931 (1.1013)  data: 0.0494 (0.1430)  lr: 0.001000  max mem: 11254
2021-04-13 09:46:47,937 maskrcnn_benchmark.trainer INFO: eta: 2:46:59  iter: 30900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2624 (0.5785)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2546 (0.5662)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2560 (0.5994)  Cross-Entropy Loss (Align Words, Choose Image): 0.2277 (0.5234)  Image Caption Matching Loss: 0.2273 (0.7449)  Masked Language Modeling Loss: 1.5996 (1.8635)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9221 (4.8761)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8023)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8044)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7912)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8166)  Batch Accuracy (Choose Caption): 0.9531 (0.8548)  Batch Accuracy (Choose Image): 0.9531 (0.8590)  Masked Language Modeling Accuracy: 0.6603 (0.6317)  time: 1.0048 (1.1010)  data: 0.0590 (0.1427)  lr: 0.001000  max mem: 11254
2021-04-13 09:48:27,960 maskrcnn_benchmark.trainer INFO: eta: 2:45:06  iter: 31000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3170 (0.5777)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3070 (0.5655)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2548 (0.5985)  Cross-Entropy Loss (Align Words, Choose Image): 0.2408 (0.5226)  Image Caption Matching Loss: 0.2713 (0.7435)  Masked Language Modeling Loss: 1.5218 (1.8627)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8493 (4.8704)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8026)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8047)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.7915)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8169)  Batch Accuracy (Choose Caption): 0.9375 (0.8551)  Batch Accuracy (Choose Image): 0.9375 (0.8592)  Masked Language Modeling Accuracy: 0.6915 (0.6318)  time: 0.9918 (1.1007)  data: 0.0585 (0.1424)  lr: 0.001000  max mem: 11254
2021-04-13 09:48:28,549 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0031000.pth
2021-04-13 09:49:51,629 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 2:45:06  iter: 31000  loss: 1.1718 (1.2474)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2031 (0.2333)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2258 (0.2539)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2797 (0.2658)  Cross-Entropy Loss (Align Words, Choose Image): 0.2169 (0.2259)  Image Caption Matching Loss: 0.2478 (0.2685)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9167 (0.9191)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9108)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.9061)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9171)  Batch Accuracy (Choose Caption): 0.9375 (0.9521)  Batch Accuracy (Choose Image): 0.9531 (0.9455)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11254
2021-04-13 09:51:30,841 maskrcnn_benchmark.trainer INFO: eta: 2:43:36  iter: 31100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3061 (0.5770)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2785 (0.5647)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2666 (0.5975)  Cross-Entropy Loss (Align Words, Choose Image): 0.2441 (0.5217)  Image Caption Matching Loss: 0.2654 (0.7421)  Masked Language Modeling Loss: 1.5398 (1.8619)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.7417 (4.8649)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8028)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8049)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7919)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8171)  Batch Accuracy (Choose Caption): 0.9531 (0.8554)  Batch Accuracy (Choose Image): 0.9531 (0.8595)  Masked Language Modeling Accuracy: 0.6693 (0.6320)  time: 1.0000 (1.1030)  data: 0.0531 (0.1449)  lr: 0.001000  max mem: 11254
2021-04-13 09:53:10,122 maskrcnn_benchmark.trainer INFO: eta: 2:41:43  iter: 31200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3307 (0.5762)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3310 (0.5640)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3049 (0.5966)  Cross-Entropy Loss (Align Words, Choose Image): 0.2670 (0.5209)  Image Caption Matching Loss: 0.3011 (0.7407)  Masked Language Modeling Loss: 1.5472 (1.8610)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0590 (4.8595)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8031)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8052)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7922)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8174)  Batch Accuracy (Choose Caption): 0.9375 (0.8556)  Batch Accuracy (Choose Image): 0.9375 (0.8597)  Masked Language Modeling Accuracy: 0.6783 (0.6321)  time: 0.9787 (1.1027)  data: 0.0508 (0.1446)  lr: 0.001000  max mem: 11254
2021-04-13 09:54:49,509 maskrcnn_benchmark.trainer INFO: eta: 2:39:50  iter: 31300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3373 (0.5754)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3197 (0.5633)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3013 (0.5956)  Cross-Entropy Loss (Align Words, Choose Image): 0.2893 (0.5201)  Image Caption Matching Loss: 0.3197 (0.7393)  Masked Language Modeling Loss: 1.4705 (1.8602)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1594 (4.8540)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8034)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8054)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7925)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8177)  Batch Accuracy (Choose Caption): 0.9375 (0.8559)  Batch Accuracy (Choose Image): 0.9219 (0.8600)  Masked Language Modeling Accuracy: 0.6733 (0.6322)  time: 0.9867 (1.1023)  data: 0.0536 (0.1443)  lr: 0.001000  max mem: 11254
2021-04-13 09:56:29,559 maskrcnn_benchmark.trainer INFO: eta: 2:37:57  iter: 31400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3435 (0.5747)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3209 (0.5626)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3351 (0.5947)  Cross-Entropy Loss (Align Words, Choose Image): 0.2389 (0.5193)  Image Caption Matching Loss: 0.2924 (0.7379)  Masked Language Modeling Loss: 1.5195 (1.8594)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1093 (4.8486)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8036)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8057)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7929)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8180)  Batch Accuracy (Choose Caption): 0.9375 (0.8562)  Batch Accuracy (Choose Image): 0.9375 (0.8602)  Masked Language Modeling Accuracy: 0.6677 (0.6323)  time: 0.9943 (1.1020)  data: 0.0498 (0.1440)  lr: 0.001000  max mem: 11254
2021-04-13 09:58:09,274 maskrcnn_benchmark.trainer INFO: eta: 2:36:04  iter: 31500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3312 (0.5739)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3474 (0.5618)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2851 (0.5937)  Cross-Entropy Loss (Align Words, Choose Image): 0.2591 (0.5185)  Image Caption Matching Loss: 0.3069 (0.7365)  Masked Language Modeling Loss: 1.5160 (1.8586)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1329 (4.8432)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8039)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8059)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7932)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8183)  Batch Accuracy (Choose Caption): 0.9375 (0.8565)  Batch Accuracy (Choose Image): 0.9375 (0.8605)  Masked Language Modeling Accuracy: 0.6700 (0.6324)  time: 0.9865 (1.1017)  data: 0.0592 (0.1437)  lr: 0.001000  max mem: 11254
2021-04-13 09:59:48,759 maskrcnn_benchmark.trainer INFO: eta: 2:34:11  iter: 31600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2939 (0.5732)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2840 (0.5611)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2728 (0.5928)  Cross-Entropy Loss (Align Words, Choose Image): 0.2404 (0.5177)  Image Caption Matching Loss: 0.2856 (0.7352)  Masked Language Modeling Loss: 1.6318 (1.8578)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9962 (4.8378)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8042)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8062)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7935)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8185)  Batch Accuracy (Choose Caption): 0.9531 (0.8567)  Batch Accuracy (Choose Image): 0.9531 (0.8607)  Masked Language Modeling Accuracy: 0.6649 (0.6325)  time: 0.9798 (1.1013)  data: 0.0566 (0.1435)  lr: 0.001000  max mem: 11254
2021-04-13 10:01:28,612 maskrcnn_benchmark.trainer INFO: eta: 2:32:18  iter: 31700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2667 (0.5724)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2868 (0.5604)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2545 (0.5919)  Cross-Entropy Loss (Align Words, Choose Image): 0.2126 (0.5170)  Image Caption Matching Loss: 0.2396 (0.7339)  Masked Language Modeling Loss: 1.5688 (1.8569)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.7776 (4.8324)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8044)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8064)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7938)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8188)  Batch Accuracy (Choose Caption): 0.9531 (0.8570)  Batch Accuracy (Choose Image): 0.9531 (0.8610)  Masked Language Modeling Accuracy: 0.6792 (0.6327)  time: 0.9985 (1.1010)  data: 0.0494 (0.1432)  lr: 0.001000  max mem: 11254
2021-04-13 10:03:08,870 maskrcnn_benchmark.trainer INFO: eta: 2:30:25  iter: 31800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3512 (0.5717)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3145 (0.5596)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2571 (0.5909)  Cross-Entropy Loss (Align Words, Choose Image): 0.2837 (0.5162)  Image Caption Matching Loss: 0.2699 (0.7325)  Masked Language Modeling Loss: 1.4888 (1.8560)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0296 (4.8269)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8047)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8067)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7942)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8191)  Batch Accuracy (Choose Caption): 0.9531 (0.8573)  Batch Accuracy (Choose Image): 0.9375 (0.8613)  Masked Language Modeling Accuracy: 0.6912 (0.6328)  time: 1.0021 (1.1007)  data: 0.0501 (0.1429)  lr: 0.001000  max mem: 11254
2021-04-13 10:04:49,013 maskrcnn_benchmark.trainer INFO: eta: 2:28:33  iter: 31900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3024 (0.5710)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2981 (0.5590)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2755 (0.5901)  Cross-Entropy Loss (Align Words, Choose Image): 0.2647 (0.5154)  Image Caption Matching Loss: 0.2510 (0.7312)  Masked Language Modeling Loss: 1.5450 (1.8551)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9974 (4.8217)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8049)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8069)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7944)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8194)  Batch Accuracy (Choose Caption): 0.9375 (0.8576)  Batch Accuracy (Choose Image): 0.9531 (0.8615)  Masked Language Modeling Accuracy: 0.6749 (0.6329)  time: 0.9975 (1.1004)  data: 0.0504 (0.1427)  lr: 0.001000  max mem: 11254
2021-04-13 10:06:29,125 maskrcnn_benchmark.trainer INFO: eta: 2:26:40  iter: 32000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3218 (0.5702)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3380 (0.5582)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2362 (0.5891)  Cross-Entropy Loss (Align Words, Choose Image): 0.2551 (0.5146)  Image Caption Matching Loss: 0.2774 (0.7298)  Masked Language Modeling Loss: 1.4953 (1.8543)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0460 (4.8163)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8052)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8072)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7948)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8196)  Batch Accuracy (Choose Caption): 0.9375 (0.8578)  Batch Accuracy (Choose Image): 0.9375 (0.8617)  Masked Language Modeling Accuracy: 0.6920 (0.6330)  time: 0.9825 (1.1001)  data: 0.0606 (0.1424)  lr: 0.001000  max mem: 11254
2021-04-13 10:06:29,543 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0032000.pth
2021-04-13 10:07:53,144 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 2:26:40  iter: 32000  loss: 1.2328 (1.2646)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2264 (0.2356)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2308 (0.2572)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2667 (0.2650)  Cross-Entropy Loss (Align Words, Choose Image): 0.2105 (0.2218)  Image Caption Matching Loss: 0.2799 (0.2850)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9160)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9087)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9038)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9170)  Batch Accuracy (Choose Caption): 0.9375 (0.9473)  Batch Accuracy (Choose Image): 0.9375 (0.9387)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11254
2021-04-13 10:09:32,184 maskrcnn_benchmark.trainer INFO: eta: 2:25:08  iter: 32100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3109 (0.5695)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3166 (0.5575)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3040 (0.5882)  Cross-Entropy Loss (Align Words, Choose Image): 0.2356 (0.5138)  Image Caption Matching Loss: 0.2947 (0.7285)  Masked Language Modeling Loss: 1.5369 (1.8535)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8701 (4.8111)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8055)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8074)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7951)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8199)  Batch Accuracy (Choose Caption): 0.9375 (0.8581)  Batch Accuracy (Choose Image): 0.9375 (0.8620)  Masked Language Modeling Accuracy: 0.6780 (0.6332)  time: 0.9967 (1.1023)  data: 0.0566 (0.1448)  lr: 0.001000  max mem: 11254
2021-04-13 10:11:11,272 maskrcnn_benchmark.trainer INFO: eta: 2:23:15  iter: 32200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2904 (0.5688)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2949 (0.5568)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2949 (0.5874)  Cross-Entropy Loss (Align Words, Choose Image): 0.2295 (0.5131)  Image Caption Matching Loss: 0.2825 (0.7272)  Masked Language Modeling Loss: 1.5804 (1.8528)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0913 (4.8061)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8057)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8077)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7954)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8202)  Batch Accuracy (Choose Caption): 0.9531 (0.8584)  Batch Accuracy (Choose Image): 0.9375 (0.8622)  Masked Language Modeling Accuracy: 0.6635 (0.6332)  time: 0.9914 (1.1020)  data: 0.0529 (0.1445)  lr: 0.001000  max mem: 11254
2021-04-13 10:12:50,960 maskrcnn_benchmark.trainer INFO: eta: 2:21:22  iter: 32300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3655 (0.5681)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3513 (0.5561)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3281 (0.5865)  Cross-Entropy Loss (Align Words, Choose Image): 0.2869 (0.5123)  Image Caption Matching Loss: 0.3218 (0.7258)  Masked Language Modeling Loss: 1.5371 (1.8521)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2234 (4.8010)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8060)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8079)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7957)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8204)  Batch Accuracy (Choose Caption): 0.9531 (0.8586)  Batch Accuracy (Choose Image): 0.9375 (0.8625)  Masked Language Modeling Accuracy: 0.6600 (0.6334)  time: 0.9800 (1.1017)  data: 0.0563 (0.1442)  lr: 0.001000  max mem: 11254
2021-04-13 10:14:29,968 maskrcnn_benchmark.trainer INFO: eta: 2:19:30  iter: 32400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2779 (0.5673)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3390 (0.5554)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2487 (0.5856)  Cross-Entropy Loss (Align Words, Choose Image): 0.2346 (0.5115)  Image Caption Matching Loss: 0.2607 (0.7245)  Masked Language Modeling Loss: 1.5826 (1.8514)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9080 (4.7956)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8062)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8082)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7960)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8207)  Batch Accuracy (Choose Caption): 0.9375 (0.8589)  Batch Accuracy (Choose Image): 0.9375 (0.8627)  Masked Language Modeling Accuracy: 0.6719 (0.6335)  time: 0.9700 (1.1013)  data: 0.0539 (0.1439)  lr: 0.001000  max mem: 11254
2021-04-13 10:16:10,298 maskrcnn_benchmark.trainer INFO: eta: 2:17:37  iter: 32500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3533 (0.5667)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3350 (0.5547)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3115 (0.5847)  Cross-Entropy Loss (Align Words, Choose Image): 0.2681 (0.5108)  Image Caption Matching Loss: 0.3196 (0.7232)  Masked Language Modeling Loss: 1.6771 (1.8506)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4202 (4.7907)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8065)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8084)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7963)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8210)  Batch Accuracy (Choose Caption): 0.9375 (0.8591)  Batch Accuracy (Choose Image): 0.9375 (0.8630)  Masked Language Modeling Accuracy: 0.6569 (0.6336)  time: 0.9897 (1.1010)  data: 0.0538 (0.1437)  lr: 0.001000  max mem: 11254
2021-04-13 10:17:49,932 maskrcnn_benchmark.trainer INFO: eta: 2:15:45  iter: 32600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3011 (0.5659)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2792 (0.5540)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3076 (0.5838)  Cross-Entropy Loss (Align Words, Choose Image): 0.2425 (0.5100)  Image Caption Matching Loss: 0.3033 (0.7219)  Masked Language Modeling Loss: 1.4937 (1.8498)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9206 (4.7854)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8067)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8087)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7966)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8212)  Batch Accuracy (Choose Caption): 0.9375 (0.8594)  Batch Accuracy (Choose Image): 0.9531 (0.8632)  Masked Language Modeling Accuracy: 0.6705 (0.6337)  time: 0.9828 (1.1007)  data: 0.0510 (0.1434)  lr: 0.001000  max mem: 11254
2021-04-13 10:19:30,305 maskrcnn_benchmark.trainer INFO: eta: 2:13:52  iter: 32700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2872 (0.5652)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2861 (0.5533)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2989 (0.5830)  Cross-Entropy Loss (Align Words, Choose Image): 0.2560 (0.5093)  Image Caption Matching Loss: 0.3086 (0.7207)  Masked Language Modeling Loss: 1.4163 (1.8490)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0131 (4.7805)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8070)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8089)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7969)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8215)  Batch Accuracy (Choose Caption): 0.9219 (0.8596)  Batch Accuracy (Choose Image): 0.9531 (0.8634)  Masked Language Modeling Accuracy: 0.6800 (0.6338)  time: 1.0004 (1.1004)  data: 0.0512 (0.1431)  lr: 0.001000  max mem: 11254
2021-04-13 10:21:10,727 maskrcnn_benchmark.trainer INFO: eta: 2:12:00  iter: 32800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3387 (0.5646)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3499 (0.5526)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3098 (0.5822)  Cross-Entropy Loss (Align Words, Choose Image): 0.2907 (0.5087)  Image Caption Matching Loss: 0.3256 (0.7195)  Masked Language Modeling Loss: 1.6791 (1.8482)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2686 (4.7758)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8072)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8092)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7972)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8217)  Batch Accuracy (Choose Caption): 0.9375 (0.8599)  Batch Accuracy (Choose Image): 0.9219 (0.8636)  Masked Language Modeling Accuracy: 0.6655 (0.6339)  time: 0.9796 (1.1001)  data: 0.0552 (0.1428)  lr: 0.001000  max mem: 11254
2021-04-13 10:22:50,773 maskrcnn_benchmark.trainer INFO: eta: 2:10:08  iter: 32900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3828 (0.5640)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3569 (0.5520)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3216 (0.5814)  Cross-Entropy Loss (Align Words, Choose Image): 0.3142 (0.5080)  Image Caption Matching Loss: 0.3048 (0.7182)  Masked Language Modeling Loss: 1.6678 (1.8476)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2831 (4.7712)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8074)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8094)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.7974)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8220)  Batch Accuracy (Choose Caption): 0.9375 (0.8601)  Batch Accuracy (Choose Image): 0.9375 (0.8639)  Masked Language Modeling Accuracy: 0.6713 (0.6340)  time: 0.9852 (1.0998)  data: 0.0535 (0.1426)  lr: 0.001000  max mem: 11254
2021-04-13 10:24:31,534 maskrcnn_benchmark.trainer INFO: eta: 2:08:16  iter: 33000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3216 (0.5633)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3596 (0.5513)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2707 (0.5806)  Cross-Entropy Loss (Align Words, Choose Image): 0.2760 (0.5072)  Image Caption Matching Loss: 0.3269 (0.7170)  Masked Language Modeling Loss: 1.5718 (1.8468)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0892 (4.7662)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8077)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8096)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7977)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8222)  Batch Accuracy (Choose Caption): 0.9375 (0.8604)  Batch Accuracy (Choose Image): 0.9219 (0.8641)  Masked Language Modeling Accuracy: 0.6634 (0.6341)  time: 0.9982 (1.0995)  data: 0.0521 (0.1423)  lr: 0.001000  max mem: 11254
2021-04-13 10:24:32,090 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0033000.pth
2021-04-13 10:25:55,376 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 2:08:16  iter: 33000  loss: 1.1890 (1.1936)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2086 (0.2231)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2128 (0.2423)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2474 (0.2505)  Cross-Entropy Loss (Align Words, Choose Image): 0.1982 (0.2166)  Image Caption Matching Loss: 0.2567 (0.2611)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9222)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9155)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9111)  Batch Accuracy (Align Words, Choose Image): 0.9375 (0.9238)  Batch Accuracy (Choose Caption): 0.9375 (0.9509)  Batch Accuracy (Choose Image): 0.9531 (0.9492)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11254
2021-04-13 10:27:34,564 maskrcnn_benchmark.trainer INFO: eta: 2:06:41  iter: 33100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2701 (0.5626)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2935 (0.5507)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2248 (0.5797)  Cross-Entropy Loss (Align Words, Choose Image): 0.2278 (0.5065)  Image Caption Matching Loss: 0.2757 (0.7157)  Masked Language Modeling Loss: 1.6969 (1.8461)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9996 (4.7612)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8079)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8098)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.7980)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8224)  Batch Accuracy (Choose Caption): 0.9531 (0.8606)  Batch Accuracy (Choose Image): 0.9375 (0.8643)  Masked Language Modeling Accuracy: 0.6288 (0.6341)  time: 0.9996 (1.1017)  data: 0.0473 (0.1446)  lr: 0.001000  max mem: 11254
2021-04-13 10:29:14,844 maskrcnn_benchmark.trainer INFO: eta: 2:04:49  iter: 33200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3319 (0.5619)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3304 (0.5500)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2873 (0.5788)  Cross-Entropy Loss (Align Words, Choose Image): 0.2368 (0.5057)  Image Caption Matching Loss: 0.3123 (0.7144)  Masked Language Modeling Loss: 1.6498 (1.8454)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1549 (4.7563)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8082)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8101)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7983)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8227)  Batch Accuracy (Choose Caption): 0.9375 (0.8609)  Batch Accuracy (Choose Image): 0.9375 (0.8645)  Masked Language Modeling Accuracy: 0.6494 (0.6343)  time: 1.0101 (1.1014)  data: 0.0617 (0.1443)  lr: 0.001000  max mem: 11254
2021-04-13 10:30:56,156 maskrcnn_benchmark.trainer INFO: eta: 2:02:57  iter: 33300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3292 (0.5613)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2980 (0.5494)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2544 (0.5780)  Cross-Entropy Loss (Align Words, Choose Image): 0.2081 (0.5050)  Image Caption Matching Loss: 0.2581 (0.7132)  Masked Language Modeling Loss: 1.5245 (1.8446)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0512 (4.7515)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8084)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8103)  Batch Accuracy (Align Words, Choose Caption): 0.9010 (0.7986)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8229)  Batch Accuracy (Choose Caption): 0.9531 (0.8611)  Batch Accuracy (Choose Image): 0.9219 (0.8648)  Masked Language Modeling Accuracy: 0.6592 (0.6344)  time: 0.9700 (1.1012)  data: 0.0644 (0.1441)  lr: 0.001000  max mem: 11254
2021-04-13 10:32:35,316 maskrcnn_benchmark.trainer INFO: eta: 2:01:05  iter: 33400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3377 (0.5606)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3374 (0.5487)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2756 (0.5771)  Cross-Entropy Loss (Align Words, Choose Image): 0.2341 (0.5043)  Image Caption Matching Loss: 0.3085 (0.7119)  Masked Language Modeling Loss: 1.4785 (1.8439)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9911 (4.7464)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8087)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8105)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.7989)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8232)  Batch Accuracy (Choose Caption): 0.9531 (0.8614)  Batch Accuracy (Choose Image): 0.9375 (0.8650)  Masked Language Modeling Accuracy: 0.6851 (0.6345)  time: 0.9963 (1.1008)  data: 0.0589 (0.1438)  lr: 0.001000  max mem: 11254
2021-04-13 10:34:15,073 maskrcnn_benchmark.trainer INFO: eta: 1:59:13  iter: 33500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3057 (0.5599)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3386 (0.5480)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2832 (0.5763)  Cross-Entropy Loss (Align Words, Choose Image): 0.2709 (0.5036)  Image Caption Matching Loss: 0.3057 (0.7108)  Masked Language Modeling Loss: 1.6470 (1.8431)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2116 (4.7416)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8089)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8108)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7992)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8234)  Batch Accuracy (Choose Caption): 0.9375 (0.8616)  Batch Accuracy (Choose Image): 0.9531 (0.8652)  Masked Language Modeling Accuracy: 0.6414 (0.6346)  time: 0.9961 (1.1005)  data: 0.0616 (0.1436)  lr: 0.001000  max mem: 11254
2021-04-13 10:35:54,737 maskrcnn_benchmark.trainer INFO: eta: 1:57:21  iter: 33600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3583 (0.5592)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3430 (0.5474)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2922 (0.5755)  Cross-Entropy Loss (Align Words, Choose Image): 0.3058 (0.5029)  Image Caption Matching Loss: 0.2666 (0.7096)  Masked Language Modeling Loss: 1.5128 (1.8424)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1802 (4.7370)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8091)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8110)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.7995)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8237)  Batch Accuracy (Choose Caption): 0.9375 (0.8618)  Batch Accuracy (Choose Image): 0.9531 (0.8654)  Masked Language Modeling Accuracy: 0.6676 (0.6347)  time: 0.9807 (1.1002)  data: 0.0559 (0.1433)  lr: 0.001000  max mem: 11254
2021-04-13 10:37:34,501 maskrcnn_benchmark.trainer INFO: eta: 1:55:29  iter: 33700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3405 (0.5586)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3242 (0.5467)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2592 (0.5746)  Cross-Entropy Loss (Align Words, Choose Image): 0.2458 (0.5021)  Image Caption Matching Loss: 0.3041 (0.7084)  Masked Language Modeling Loss: 1.7379 (1.8418)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4343 (4.7323)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8094)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8112)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.7998)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8239)  Batch Accuracy (Choose Caption): 0.9531 (0.8621)  Batch Accuracy (Choose Image): 0.9375 (0.8656)  Masked Language Modeling Accuracy: 0.6439 (0.6348)  time: 0.9931 (1.0999)  data: 0.0518 (0.1431)  lr: 0.001000  max mem: 11254
2021-04-13 10:39:14,886 maskrcnn_benchmark.trainer INFO: eta: 1:53:37  iter: 33800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3587 (0.5579)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3344 (0.5461)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3128 (0.5738)  Cross-Entropy Loss (Align Words, Choose Image): 0.2629 (0.5014)  Image Caption Matching Loss: 0.2722 (0.7072)  Masked Language Modeling Loss: 1.5599 (1.8412)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0905 (4.7276)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8096)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8115)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8001)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8242)  Batch Accuracy (Choose Caption): 0.9531 (0.8623)  Batch Accuracy (Choose Image): 0.9375 (0.8659)  Masked Language Modeling Accuracy: 0.6780 (0.6349)  time: 0.9823 (1.0996)  data: 0.0676 (0.1428)  lr: 0.001000  max mem: 11254
2021-04-13 10:40:54,799 maskrcnn_benchmark.trainer INFO: eta: 1:51:45  iter: 33900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3031 (0.5573)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3165 (0.5454)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2615 (0.5730)  Cross-Entropy Loss (Align Words, Choose Image): 0.2661 (0.5007)  Image Caption Matching Loss: 0.3400 (0.7060)  Masked Language Modeling Loss: 1.6517 (1.8405)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1292 (4.7229)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8099)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8117)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8004)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8244)  Batch Accuracy (Choose Caption): 0.9219 (0.8625)  Batch Accuracy (Choose Image): 0.9375 (0.8661)  Masked Language Modeling Accuracy: 0.6607 (0.6350)  time: 0.9709 (1.0993)  data: 0.0553 (0.1425)  lr: 0.001000  max mem: 11254
2021-04-13 10:42:34,049 maskrcnn_benchmark.trainer INFO: eta: 1:49:54  iter: 34000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3285 (0.5566)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2906 (0.5447)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2775 (0.5722)  Cross-Entropy Loss (Align Words, Choose Image): 0.2470 (0.5000)  Image Caption Matching Loss: 0.2983 (0.7048)  Masked Language Modeling Loss: 1.4559 (1.8397)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0473 (4.7180)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8101)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8119)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8006)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8247)  Batch Accuracy (Choose Caption): 0.9375 (0.8628)  Batch Accuracy (Choose Image): 0.9375 (0.8663)  Masked Language Modeling Accuracy: 0.6761 (0.6351)  time: 0.9774 (1.0990)  data: 0.0546 (0.1423)  lr: 0.001000  max mem: 11254
2021-04-13 10:42:34,608 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0034000.pth
2021-04-13 10:43:58,488 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 1:49:54  iter: 34000  loss: 1.0938 (1.2364)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.1996 (0.2249)  Cross-Entropy Loss (Align Regions, Choose Image): 0.1951 (0.2441)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2511 (0.2609)  Cross-Entropy Loss (Align Words, Choose Image): 0.2262 (0.2278)  Image Caption Matching Loss: 0.2771 (0.2787)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9185)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9154)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9039)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9235)  Batch Accuracy (Choose Caption): 0.9375 (0.9434)  Batch Accuracy (Choose Image): 0.9531 (0.9478)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11254
2021-04-13 10:45:37,655 maskrcnn_benchmark.trainer INFO: eta: 1:48:17  iter: 34100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3487 (0.5560)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3382 (0.5441)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3021 (0.5714)  Cross-Entropy Loss (Align Words, Choose Image): 0.2536 (0.4993)  Image Caption Matching Loss: 0.3140 (0.7036)  Masked Language Modeling Loss: 1.6343 (1.8390)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0660 (4.7133)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8103)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8121)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8009)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8249)  Batch Accuracy (Choose Caption): 0.9531 (0.8630)  Batch Accuracy (Choose Image): 0.9375 (0.8665)  Masked Language Modeling Accuracy: 0.6547 (0.6352)  time: 0.9802 (1.1012)  data: 0.0589 (0.1445)  lr: 0.001000  max mem: 11254
2021-04-13 10:47:17,215 maskrcnn_benchmark.trainer INFO: eta: 1:46:25  iter: 34200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3274 (0.5553)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3067 (0.5435)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3180 (0.5706)  Cross-Entropy Loss (Align Words, Choose Image): 0.2560 (0.4986)  Image Caption Matching Loss: 0.3081 (0.7024)  Masked Language Modeling Loss: 1.7060 (1.8384)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2026 (4.7087)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8105)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8124)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8012)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8252)  Batch Accuracy (Choose Caption): 0.9531 (0.8632)  Batch Accuracy (Choose Image): 0.9219 (0.8667)  Masked Language Modeling Accuracy: 0.6504 (0.6353)  time: 0.9936 (1.1009)  data: 0.0517 (0.1443)  lr: 0.001000  max mem: 11254
2021-04-13 10:48:56,628 maskrcnn_benchmark.trainer INFO: eta: 1:44:33  iter: 34300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3226 (0.5547)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3171 (0.5428)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2915 (0.5698)  Cross-Entropy Loss (Align Words, Choose Image): 0.2344 (0.4979)  Image Caption Matching Loss: 0.3077 (0.7012)  Masked Language Modeling Loss: 1.5152 (1.8378)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1160 (4.7043)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8108)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8126)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8015)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8254)  Batch Accuracy (Choose Caption): 0.9375 (0.8635)  Batch Accuracy (Choose Image): 0.9375 (0.8669)  Masked Language Modeling Accuracy: 0.6545 (0.6353)  time: 0.9953 (1.1006)  data: 0.0549 (0.1440)  lr: 0.001000  max mem: 11254
2021-04-13 10:50:36,685 maskrcnn_benchmark.trainer INFO: eta: 1:42:41  iter: 34400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3186 (0.5540)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3095 (0.5422)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3102 (0.5691)  Cross-Entropy Loss (Align Words, Choose Image): 0.2560 (0.4973)  Image Caption Matching Loss: 0.2863 (0.7001)  Masked Language Modeling Loss: 1.6029 (1.8371)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1251 (4.6998)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8110)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8128)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8017)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8256)  Batch Accuracy (Choose Caption): 0.9375 (0.8637)  Batch Accuracy (Choose Image): 0.9375 (0.8671)  Masked Language Modeling Accuracy: 0.6505 (0.6354)  time: 0.9881 (1.1003)  data: 0.0563 (0.1437)  lr: 0.001000  max mem: 11254
2021-04-13 10:52:16,478 maskrcnn_benchmark.trainer INFO: eta: 1:40:49  iter: 34500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3175 (0.5534)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2938 (0.5415)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2735 (0.5683)  Cross-Entropy Loss (Align Words, Choose Image): 0.2502 (0.4966)  Image Caption Matching Loss: 0.2647 (0.6990)  Masked Language Modeling Loss: 1.7382 (1.8364)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2230 (4.6952)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8112)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8130)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8020)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8259)  Batch Accuracy (Choose Caption): 0.9531 (0.8639)  Batch Accuracy (Choose Image): 0.9531 (0.8673)  Masked Language Modeling Accuracy: 0.6432 (0.6355)  time: 1.0015 (1.1000)  data: 0.0458 (0.1435)  lr: 0.001000  max mem: 11254
2021-04-13 10:53:56,237 maskrcnn_benchmark.trainer INFO: eta: 1:38:58  iter: 34600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3403 (0.5528)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3211 (0.5409)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2999 (0.5675)  Cross-Entropy Loss (Align Words, Choose Image): 0.2743 (0.4960)  Image Caption Matching Loss: 0.3619 (0.6979)  Masked Language Modeling Loss: 1.5488 (1.8357)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2591 (4.6908)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8114)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8132)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8023)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8261)  Batch Accuracy (Choose Caption): 0.9375 (0.8642)  Batch Accuracy (Choose Image): 0.9375 (0.8675)  Masked Language Modeling Accuracy: 0.6878 (0.6355)  time: 0.9831 (1.0997)  data: 0.0590 (0.1432)  lr: 0.001000  max mem: 11254
2021-04-13 10:55:35,927 maskrcnn_benchmark.trainer INFO: eta: 1:37:06  iter: 34700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3156 (0.5521)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2850 (0.5403)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2244 (0.5667)  Cross-Entropy Loss (Align Words, Choose Image): 0.2253 (0.4952)  Image Caption Matching Loss: 0.2529 (0.6966)  Masked Language Modeling Loss: 1.6704 (1.8351)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0664 (4.6860)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8117)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8135)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.8026)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8263)  Batch Accuracy (Choose Caption): 0.9375 (0.8644)  Batch Accuracy (Choose Image): 0.9375 (0.8678)  Masked Language Modeling Accuracy: 0.6387 (0.6356)  time: 0.9734 (1.0994)  data: 0.0508 (0.1430)  lr: 0.001000  max mem: 11254
2021-04-13 10:57:15,548 maskrcnn_benchmark.trainer INFO: eta: 1:35:15  iter: 34800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3409 (0.5514)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3265 (0.5396)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3113 (0.5659)  Cross-Entropy Loss (Align Words, Choose Image): 0.2708 (0.4946)  Image Caption Matching Loss: 0.2555 (0.6955)  Masked Language Modeling Loss: 1.7338 (1.8345)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1510 (4.6814)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8119)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8137)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8029)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8266)  Batch Accuracy (Choose Caption): 0.9531 (0.8646)  Batch Accuracy (Choose Image): 0.9531 (0.8680)  Masked Language Modeling Accuracy: 0.6391 (0.6357)  time: 0.9846 (1.0991)  data: 0.0498 (0.1427)  lr: 0.001000  max mem: 11254
2021-04-13 10:58:55,114 maskrcnn_benchmark.trainer INFO: eta: 1:33:23  iter: 34900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3214 (0.5508)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2680 (0.5390)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2636 (0.5651)  Cross-Entropy Loss (Align Words, Choose Image): 0.2371 (0.4939)  Image Caption Matching Loss: 0.2802 (0.6944)  Masked Language Modeling Loss: 1.4877 (1.8337)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9523 (4.6770)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8121)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8139)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8031)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8268)  Batch Accuracy (Choose Caption): 0.9375 (0.8648)  Batch Accuracy (Choose Image): 0.9688 (0.8682)  Masked Language Modeling Accuracy: 0.6625 (0.6358)  time: 0.9876 (1.0988)  data: 0.0554 (0.1425)  lr: 0.001000  max mem: 11254
2021-04-13 11:00:35,086 maskrcnn_benchmark.trainer INFO: eta: 1:31:32  iter: 35000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3209 (0.5502)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3543 (0.5384)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2680 (0.5643)  Cross-Entropy Loss (Align Words, Choose Image): 0.2810 (0.4932)  Image Caption Matching Loss: 0.2747 (0.6932)  Masked Language Modeling Loss: 1.6964 (1.8331)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0540 (4.6725)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8124)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8141)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8034)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8270)  Batch Accuracy (Choose Caption): 0.9375 (0.8651)  Batch Accuracy (Choose Image): 0.9375 (0.8684)  Masked Language Modeling Accuracy: 0.6614 (0.6359)  time: 0.9957 (1.0985)  data: 0.0472 (0.1422)  lr: 0.000100  max mem: 11254
2021-04-13 11:00:35,826 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0035000.pth
2021-04-13 11:01:58,894 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 1:31:32  iter: 35000  loss: 1.1794 (1.2448)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2544 (0.2368)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2287 (0.2515)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2347 (0.2644)  Cross-Entropy Loss (Align Words, Choose Image): 0.2119 (0.2167)  Image Caption Matching Loss: 0.2846 (0.2754)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9212)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9156)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9091)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9229)  Batch Accuracy (Choose Caption): 0.9531 (0.9497)  Batch Accuracy (Choose Image): 0.9375 (0.9466)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 11254
2021-04-13 11:03:38,273 maskrcnn_benchmark.trainer INFO: eta: 1:29:52  iter: 35100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3293 (0.5496)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3015 (0.5378)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2682 (0.5636)  Cross-Entropy Loss (Align Words, Choose Image): 0.2392 (0.4926)  Image Caption Matching Loss: 0.2526 (0.6921)  Masked Language Modeling Loss: 1.5306 (1.8326)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0167 (4.6681)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8126)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8143)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8037)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8273)  Batch Accuracy (Choose Caption): 0.9531 (0.8653)  Batch Accuracy (Choose Image): 0.9375 (0.8686)  Masked Language Modeling Accuracy: 0.6614 (0.6360)  time: 0.9782 (1.1006)  data: 0.0505 (0.1444)  lr: 0.000100  max mem: 11254
2021-04-13 11:05:17,811 maskrcnn_benchmark.trainer INFO: eta: 1:28:01  iter: 35200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3193 (0.5489)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3467 (0.5372)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2506 (0.5628)  Cross-Entropy Loss (Align Words, Choose Image): 0.2462 (0.4919)  Image Caption Matching Loss: 0.2847 (0.6909)  Masked Language Modeling Loss: 1.5283 (1.8319)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1346 (4.6636)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8128)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8145)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8040)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8275)  Batch Accuracy (Choose Caption): 0.9531 (0.8655)  Batch Accuracy (Choose Image): 0.9375 (0.8688)  Masked Language Modeling Accuracy: 0.6755 (0.6361)  time: 1.0059 (1.1003)  data: 0.0502 (0.1441)  lr: 0.000100  max mem: 11254
2021-04-13 11:06:57,705 maskrcnn_benchmark.trainer INFO: eta: 1:26:10  iter: 35300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3284 (0.5483)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3447 (0.5366)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2689 (0.5620)  Cross-Entropy Loss (Align Words, Choose Image): 0.2380 (0.4912)  Image Caption Matching Loss: 0.2285 (0.6898)  Masked Language Modeling Loss: 1.5374 (1.8313)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1388 (4.6591)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8130)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8147)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8042)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8277)  Batch Accuracy (Choose Caption): 0.9531 (0.8658)  Batch Accuracy (Choose Image): 0.9531 (0.8690)  Masked Language Modeling Accuracy: 0.6782 (0.6362)  time: 1.0211 (1.1000)  data: 0.0578 (0.1439)  lr: 0.000100  max mem: 11254
2021-04-13 11:08:36,932 maskrcnn_benchmark.trainer INFO: eta: 1:24:18  iter: 35400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3065 (0.5476)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2788 (0.5359)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2425 (0.5612)  Cross-Entropy Loss (Align Words, Choose Image): 0.2324 (0.4905)  Image Caption Matching Loss: 0.2276 (0.6886)  Masked Language Modeling Loss: 1.5900 (1.8306)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0233 (4.6544)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8132)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8149)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8045)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8280)  Batch Accuracy (Choose Caption): 0.9531 (0.8660)  Batch Accuracy (Choose Image): 0.9375 (0.8692)  Masked Language Modeling Accuracy: 0.6500 (0.6362)  time: 1.0006 (1.0997)  data: 0.0573 (0.1436)  lr: 0.000100  max mem: 11254
2021-04-13 11:10:16,597 maskrcnn_benchmark.trainer INFO: eta: 1:22:27  iter: 35500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2870 (0.5470)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2993 (0.5352)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3046 (0.5604)  Cross-Entropy Loss (Align Words, Choose Image): 0.2188 (0.4898)  Image Caption Matching Loss: 0.2841 (0.6875)  Masked Language Modeling Loss: 1.5977 (1.8301)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9967 (4.6500)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8135)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8152)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8048)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8282)  Batch Accuracy (Choose Caption): 0.9531 (0.8662)  Batch Accuracy (Choose Image): 0.9531 (0.8694)  Masked Language Modeling Accuracy: 0.6510 (0.6363)  time: 0.9919 (1.0994)  data: 0.0561 (0.1434)  lr: 0.000100  max mem: 11254
2021-04-13 11:11:56,436 maskrcnn_benchmark.trainer INFO: eta: 1:20:36  iter: 35600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3700 (0.5464)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3055 (0.5346)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3156 (0.5597)  Cross-Entropy Loss (Align Words, Choose Image): 0.2578 (0.4892)  Image Caption Matching Loss: 0.2776 (0.6864)  Masked Language Modeling Loss: 1.5729 (1.8295)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1904 (4.6458)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8137)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8154)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8050)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8284)  Batch Accuracy (Choose Caption): 0.9375 (0.8664)  Batch Accuracy (Choose Image): 0.9531 (0.8696)  Masked Language Modeling Accuracy: 0.6587 (0.6364)  time: 1.0015 (1.0991)  data: 0.0565 (0.1431)  lr: 0.000100  max mem: 11254
2021-04-13 11:13:35,981 maskrcnn_benchmark.trainer INFO: eta: 1:18:45  iter: 35700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3061 (0.5457)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2777 (0.5340)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2539 (0.5589)  Cross-Entropy Loss (Align Words, Choose Image): 0.2408 (0.4885)  Image Caption Matching Loss: 0.2505 (0.6852)  Masked Language Modeling Loss: 1.5883 (1.8289)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0208 (4.6413)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8139)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8156)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8053)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8287)  Batch Accuracy (Choose Caption): 0.9531 (0.8667)  Batch Accuracy (Choose Image): 0.9531 (0.8699)  Masked Language Modeling Accuracy: 0.6631 (0.6365)  time: 1.0002 (1.0988)  data: 0.0559 (0.1429)  lr: 0.000100  max mem: 11254
2021-04-13 11:15:15,414 maskrcnn_benchmark.trainer INFO: eta: 1:16:53  iter: 35800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2730 (0.5451)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2555 (0.5334)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2204 (0.5581)  Cross-Entropy Loss (Align Words, Choose Image): 0.2023 (0.4879)  Image Caption Matching Loss: 0.1986 (0.6841)  Masked Language Modeling Loss: 1.5977 (1.8282)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.6847 (4.6368)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8141)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8158)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8055)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8289)  Batch Accuracy (Choose Caption): 0.9531 (0.8669)  Batch Accuracy (Choose Image): 0.9531 (0.8701)  Masked Language Modeling Accuracy: 0.6758 (0.6366)  time: 0.9894 (1.0986)  data: 0.0537 (0.1427)  lr: 0.000100  max mem: 11254
2021-04-13 11:16:54,851 maskrcnn_benchmark.trainer INFO: eta: 1:15:02  iter: 35900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2969 (0.5445)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3032 (0.5328)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2684 (0.5574)  Cross-Entropy Loss (Align Words, Choose Image): 0.2145 (0.4872)  Image Caption Matching Loss: 0.2595 (0.6830)  Masked Language Modeling Loss: 1.5267 (1.8276)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8998 (4.6325)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8143)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8160)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8058)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8291)  Batch Accuracy (Choose Caption): 0.9375 (0.8671)  Batch Accuracy (Choose Image): 0.9375 (0.8702)  Masked Language Modeling Accuracy: 0.6801 (0.6367)  time: 0.9962 (1.0983)  data: 0.0669 (0.1424)  lr: 0.000100  max mem: 11254
2021-04-13 11:18:34,295 maskrcnn_benchmark.trainer INFO: eta: 1:13:11  iter: 36000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3158 (0.5439)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2567 (0.5322)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2470 (0.5566)  Cross-Entropy Loss (Align Words, Choose Image): 0.2073 (0.4866)  Image Caption Matching Loss: 0.2018 (0.6819)  Masked Language Modeling Loss: 1.6150 (1.8268)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9990 (4.6280)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8146)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8162)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8061)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8293)  Batch Accuracy (Choose Caption): 0.9531 (0.8673)  Batch Accuracy (Choose Image): 0.9531 (0.8704)  Masked Language Modeling Accuracy: 0.6705 (0.6368)  time: 0.9900 (1.0980)  data: 0.0517 (0.1422)  lr: 0.000100  max mem: 11254
2021-04-13 11:18:34,997 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0036000.pth
2021-04-13 11:19:58,210 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 1:13:11  iter: 36000  loss: 1.1699 (1.1881)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2202 (0.2202)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2031 (0.2413)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2585 (0.2521)  Cross-Entropy Loss (Align Words, Choose Image): 0.1981 (0.2108)  Image Caption Matching Loss: 0.2609 (0.2638)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9251)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9166)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9119)  Batch Accuracy (Align Words, Choose Image): 0.9375 (0.9268)  Batch Accuracy (Choose Caption): 0.9375 (0.9466)  Batch Accuracy (Choose Image): 0.9375 (0.9479)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 11254
2021-04-13 11:21:37,518 maskrcnn_benchmark.trainer INFO: eta: 1:11:30  iter: 36100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3342 (0.5433)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3713 (0.5316)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3030 (0.5559)  Cross-Entropy Loss (Align Words, Choose Image): 0.2704 (0.4859)  Image Caption Matching Loss: 0.3284 (0.6809)  Masked Language Modeling Loss: 1.4502 (1.8262)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2286 (4.6237)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8148)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8164)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8063)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8296)  Batch Accuracy (Choose Caption): 0.9375 (0.8675)  Batch Accuracy (Choose Image): 0.9219 (0.8706)  Masked Language Modeling Accuracy: 0.6771 (0.6369)  time: 1.0014 (1.1000)  data: 0.0506 (0.1443)  lr: 0.000100  max mem: 11254
2021-04-13 11:23:16,971 maskrcnn_benchmark.trainer INFO: eta: 1:09:38  iter: 36200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3279 (0.5427)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3162 (0.5310)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2733 (0.5551)  Cross-Entropy Loss (Align Words, Choose Image): 0.2416 (0.4853)  Image Caption Matching Loss: 0.2494 (0.6797)  Masked Language Modeling Loss: 1.5646 (1.8255)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0928 (4.6192)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8150)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8166)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8066)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8298)  Batch Accuracy (Choose Caption): 0.9531 (0.8677)  Batch Accuracy (Choose Image): 0.9375 (0.8708)  Masked Language Modeling Accuracy: 0.6587 (0.6370)  time: 1.0007 (1.0997)  data: 0.0595 (0.1440)  lr: 0.000100  max mem: 11254
2021-04-13 11:24:56,578 maskrcnn_benchmark.trainer INFO: eta: 1:07:47  iter: 36300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3171 (0.5420)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2909 (0.5304)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2877 (0.5544)  Cross-Entropy Loss (Align Words, Choose Image): 0.2334 (0.4846)  Image Caption Matching Loss: 0.2407 (0.6786)  Masked Language Modeling Loss: 1.6187 (1.8248)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8987 (4.6148)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8152)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8169)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8069)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8300)  Batch Accuracy (Choose Caption): 0.9375 (0.8680)  Batch Accuracy (Choose Image): 0.9531 (0.8710)  Masked Language Modeling Accuracy: 0.6561 (0.6371)  time: 0.9835 (1.0994)  data: 0.0597 (0.1438)  lr: 0.000100  max mem: 11254
2021-04-13 11:26:36,472 maskrcnn_benchmark.trainer INFO: eta: 1:05:56  iter: 36400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3232 (0.5414)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3083 (0.5298)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2589 (0.5536)  Cross-Entropy Loss (Align Words, Choose Image): 0.2503 (0.4840)  Image Caption Matching Loss: 0.2889 (0.6775)  Masked Language Modeling Loss: 1.5959 (1.8241)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0588 (4.6103)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8155)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8171)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8071)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8302)  Batch Accuracy (Choose Caption): 0.9375 (0.8682)  Batch Accuracy (Choose Image): 0.9219 (0.8712)  Masked Language Modeling Accuracy: 0.6677 (0.6371)  time: 0.9811 (1.0992)  data: 0.0564 (0.1436)  lr: 0.000100  max mem: 11254
2021-04-13 11:28:15,765 maskrcnn_benchmark.trainer INFO: eta: 1:04:06  iter: 36500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2848 (0.5408)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2517 (0.5292)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2631 (0.5529)  Cross-Entropy Loss (Align Words, Choose Image): 0.2187 (0.4834)  Image Caption Matching Loss: 0.2347 (0.6765)  Masked Language Modeling Loss: 1.6574 (1.8235)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9266 (4.6061)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8157)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8173)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8074)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8305)  Batch Accuracy (Choose Caption): 0.9531 (0.8684)  Batch Accuracy (Choose Image): 0.9219 (0.8714)  Masked Language Modeling Accuracy: 0.6630 (0.6372)  time: 0.9808 (1.0989)  data: 0.0523 (0.1433)  lr: 0.000100  max mem: 11254
2021-04-13 11:29:55,403 maskrcnn_benchmark.trainer INFO: eta: 1:02:15  iter: 36600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3226 (0.5402)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2992 (0.5286)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2599 (0.5522)  Cross-Entropy Loss (Align Words, Choose Image): 0.2240 (0.4827)  Image Caption Matching Loss: 0.2472 (0.6754)  Masked Language Modeling Loss: 1.5240 (1.8229)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1195 (4.6020)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8159)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8175)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8076)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8307)  Batch Accuracy (Choose Caption): 0.9531 (0.8686)  Batch Accuracy (Choose Image): 0.9375 (0.8716)  Masked Language Modeling Accuracy: 0.6741 (0.6373)  time: 0.9953 (1.0986)  data: 0.0453 (0.1431)  lr: 0.000100  max mem: 11254
2021-04-13 11:31:35,818 maskrcnn_benchmark.trainer INFO: eta: 1:00:24  iter: 36700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2996 (0.5396)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3572 (0.5280)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2567 (0.5514)  Cross-Entropy Loss (Align Words, Choose Image): 0.2530 (0.4821)  Image Caption Matching Loss: 0.2826 (0.6743)  Masked Language Modeling Loss: 1.4362 (1.8223)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8820 (4.5978)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8161)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8177)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8079)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8309)  Batch Accuracy (Choose Caption): 0.9375 (0.8688)  Batch Accuracy (Choose Image): 0.9375 (0.8718)  Masked Language Modeling Accuracy: 0.6723 (0.6374)  time: 0.9976 (1.0983)  data: 0.0522 (0.1428)  lr: 0.000100  max mem: 11254
2021-04-13 11:33:15,354 maskrcnn_benchmark.trainer INFO: eta: 0:58:33  iter: 36800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3101 (0.5390)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2644 (0.5274)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2625 (0.5507)  Cross-Entropy Loss (Align Words, Choose Image): 0.2052 (0.4815)  Image Caption Matching Loss: 0.2418 (0.6733)  Masked Language Modeling Loss: 1.5933 (1.8217)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9868 (4.5935)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8163)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8179)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8081)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8311)  Batch Accuracy (Choose Caption): 0.9531 (0.8691)  Batch Accuracy (Choose Image): 0.9375 (0.8720)  Masked Language Modeling Accuracy: 0.6482 (0.6375)  time: 1.0038 (1.0981)  data: 0.0620 (0.1426)  lr: 0.000100  max mem: 11254
2021-04-13 11:34:55,464 maskrcnn_benchmark.trainer INFO: eta: 0:56:43  iter: 36900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2766 (0.5384)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2875 (0.5268)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2243 (0.5500)  Cross-Entropy Loss (Align Words, Choose Image): 0.1985 (0.4808)  Image Caption Matching Loss: 0.2386 (0.6722)  Masked Language Modeling Loss: 1.4520 (1.8212)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8019 (4.5894)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8165)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8181)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.8084)  Batch Accuracy (Align Words, Choose Image): 0.9375 (0.8313)  Batch Accuracy (Choose Caption): 0.9531 (0.8693)  Batch Accuracy (Choose Image): 0.9375 (0.8722)  Masked Language Modeling Accuracy: 0.6707 (0.6375)  time: 1.0057 (1.0978)  data: 0.0561 (0.1424)  lr: 0.000100  max mem: 11254
2021-04-13 11:36:34,750 maskrcnn_benchmark.trainer INFO: eta: 0:54:52  iter: 37000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2973 (0.5378)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2886 (0.5262)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2656 (0.5493)  Cross-Entropy Loss (Align Words, Choose Image): 0.2289 (0.4802)  Image Caption Matching Loss: 0.2550 (0.6712)  Masked Language Modeling Loss: 1.6801 (1.8206)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0342 (4.5853)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8167)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8183)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8086)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8316)  Batch Accuracy (Choose Caption): 0.9531 (0.8695)  Batch Accuracy (Choose Image): 0.9531 (0.8724)  Masked Language Modeling Accuracy: 0.6664 (0.6376)  time: 0.9909 (1.0975)  data: 0.0580 (0.1421)  lr: 0.000100  max mem: 11254
2021-04-13 11:36:35,558 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0037000.pth
2021-04-13 11:37:58,892 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:54:52  iter: 37000  loss: 1.1224 (1.1812)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.1875 (0.2175)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2162 (0.2328)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2488 (0.2578)  Cross-Entropy Loss (Align Words, Choose Image): 0.2250 (0.2074)  Image Caption Matching Loss: 0.2456 (0.2657)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9375 (0.9237)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9203)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.9095)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9268)  Batch Accuracy (Choose Caption): 0.9531 (0.9480)  Batch Accuracy (Choose Image): 0.9375 (0.9488)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 11254
2021-04-13 11:39:37,375 maskrcnn_benchmark.trainer INFO: eta: 0:53:08  iter: 37100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2506 (0.5372)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2434 (0.5256)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2522 (0.5485)  Cross-Entropy Loss (Align Words, Choose Image): 0.2473 (0.4796)  Image Caption Matching Loss: 0.2490 (0.6701)  Masked Language Modeling Loss: 1.5428 (1.8200)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8978 (4.5810)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8169)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8185)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8089)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8318)  Batch Accuracy (Choose Caption): 0.9531 (0.8697)  Batch Accuracy (Choose Image): 0.9531 (0.8726)  Masked Language Modeling Accuracy: 0.6857 (0.6377)  time: 0.9760 (1.0995)  data: 0.0568 (0.1442)  lr: 0.000100  max mem: 11254
2021-04-13 11:41:16,891 maskrcnn_benchmark.trainer INFO: eta: 0:51:17  iter: 37200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2757 (0.5366)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2967 (0.5251)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2849 (0.5478)  Cross-Entropy Loss (Align Words, Choose Image): 0.2225 (0.4790)  Image Caption Matching Loss: 0.2725 (0.6691)  Masked Language Modeling Loss: 1.4488 (1.8193)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.7965 (4.5769)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8171)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8187)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8091)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8320)  Batch Accuracy (Choose Caption): 0.9531 (0.8699)  Batch Accuracy (Choose Image): 0.9375 (0.8728)  Masked Language Modeling Accuracy: 0.6521 (0.6378)  time: 0.9903 (1.0992)  data: 0.0538 (0.1440)  lr: 0.000100  max mem: 11254
2021-04-13 11:42:56,766 maskrcnn_benchmark.trainer INFO: eta: 0:49:27  iter: 37300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2874 (0.5361)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2804 (0.5245)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2771 (0.5472)  Cross-Entropy Loss (Align Words, Choose Image): 0.2329 (0.4784)  Image Caption Matching Loss: 0.2445 (0.6682)  Masked Language Modeling Loss: 1.4922 (1.8188)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.7818 (4.5731)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8173)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8189)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8094)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8322)  Batch Accuracy (Choose Caption): 0.9531 (0.8701)  Batch Accuracy (Choose Image): 0.9219 (0.8730)  Masked Language Modeling Accuracy: 0.6523 (0.6379)  time: 0.9850 (1.0989)  data: 0.0550 (0.1437)  lr: 0.000100  max mem: 11254
2021-04-13 11:44:36,534 maskrcnn_benchmark.trainer INFO: eta: 0:47:36  iter: 37400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2642 (0.5355)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2524 (0.5239)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2450 (0.5465)  Cross-Entropy Loss (Align Words, Choose Image): 0.2057 (0.4778)  Image Caption Matching Loss: 0.2433 (0.6671)  Masked Language Modeling Loss: 1.5364 (1.8183)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9579 (4.5692)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8175)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8191)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8096)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8324)  Batch Accuracy (Choose Caption): 0.9531 (0.8703)  Batch Accuracy (Choose Image): 0.9531 (0.8731)  Masked Language Modeling Accuracy: 0.6695 (0.6379)  time: 0.9852 (1.0986)  data: 0.0544 (0.1435)  lr: 0.000100  max mem: 11254
2021-04-13 11:46:16,566 maskrcnn_benchmark.trainer INFO: eta: 0:45:45  iter: 37500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3044 (0.5350)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3579 (0.5234)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2726 (0.5458)  Cross-Entropy Loss (Align Words, Choose Image): 0.2521 (0.4772)  Image Caption Matching Loss: 0.2820 (0.6661)  Masked Language Modeling Loss: 1.5788 (1.8177)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0970 (4.5652)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8177)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8193)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8099)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8326)  Batch Accuracy (Choose Caption): 0.9375 (0.8705)  Batch Accuracy (Choose Image): 0.9375 (0.8733)  Masked Language Modeling Accuracy: 0.6529 (0.6380)  time: 0.9905 (1.0984)  data: 0.0527 (0.1433)  lr: 0.000100  max mem: 11254
2021-04-13 11:47:56,496 maskrcnn_benchmark.trainer INFO: eta: 0:43:55  iter: 37600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3101 (0.5344)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2482 (0.5228)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2896 (0.5451)  Cross-Entropy Loss (Align Words, Choose Image): 0.2429 (0.4766)  Image Caption Matching Loss: 0.2694 (0.6651)  Masked Language Modeling Loss: 1.6346 (1.8172)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0156 (4.5613)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8179)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8195)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8101)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8328)  Batch Accuracy (Choose Caption): 0.9531 (0.8707)  Batch Accuracy (Choose Image): 0.9375 (0.8735)  Masked Language Modeling Accuracy: 0.6454 (0.6381)  time: 0.9799 (1.0981)  data: 0.0579 (0.1430)  lr: 0.000100  max mem: 11254
2021-04-13 11:49:36,887 maskrcnn_benchmark.trainer INFO: eta: 0:42:05  iter: 37700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2918 (0.5338)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2819 (0.5223)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2807 (0.5444)  Cross-Entropy Loss (Align Words, Choose Image): 0.2461 (0.4760)  Image Caption Matching Loss: 0.2945 (0.6641)  Masked Language Modeling Loss: 1.5495 (1.8164)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9455 (4.5570)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8181)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8197)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8103)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8330)  Batch Accuracy (Choose Caption): 0.9531 (0.8709)  Batch Accuracy (Choose Image): 0.9375 (0.8737)  Masked Language Modeling Accuracy: 0.6694 (0.6382)  time: 1.0053 (1.0979)  data: 0.0510 (0.1428)  lr: 0.000100  max mem: 11254
2021-04-13 11:51:16,796 maskrcnn_benchmark.trainer INFO: eta: 0:40:14  iter: 37800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3238 (0.5333)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3060 (0.5217)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2865 (0.5437)  Cross-Entropy Loss (Align Words, Choose Image): 0.2404 (0.4754)  Image Caption Matching Loss: 0.2537 (0.6630)  Masked Language Modeling Loss: 1.5249 (1.8158)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9591 (4.5531)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8183)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8198)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8106)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8332)  Batch Accuracy (Choose Caption): 0.9531 (0.8711)  Batch Accuracy (Choose Image): 0.9531 (0.8739)  Masked Language Modeling Accuracy: 0.6793 (0.6383)  time: 0.9798 (1.0976)  data: 0.0547 (0.1426)  lr: 0.000100  max mem: 11254
2021-04-13 11:52:56,857 maskrcnn_benchmark.trainer INFO: eta: 0:38:24  iter: 37900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3329 (0.5327)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3247 (0.5212)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2981 (0.5430)  Cross-Entropy Loss (Align Words, Choose Image): 0.2186 (0.4748)  Image Caption Matching Loss: 0.2846 (0.6620)  Masked Language Modeling Loss: 1.6541 (1.8153)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0720 (4.5490)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8185)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8200)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8108)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8334)  Batch Accuracy (Choose Caption): 0.9375 (0.8713)  Batch Accuracy (Choose Image): 0.9531 (0.8741)  Masked Language Modeling Accuracy: 0.6528 (0.6383)  time: 0.9913 (1.0974)  data: 0.0568 (0.1424)  lr: 0.000100  max mem: 11254
2021-04-13 11:54:36,399 maskrcnn_benchmark.trainer INFO: eta: 0:36:34  iter: 38000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3138 (0.5322)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3036 (0.5206)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2793 (0.5424)  Cross-Entropy Loss (Align Words, Choose Image): 0.2042 (0.4742)  Image Caption Matching Loss: 0.2854 (0.6611)  Masked Language Modeling Loss: 1.5217 (1.8148)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0250 (4.5452)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8187)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8202)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8111)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8336)  Batch Accuracy (Choose Caption): 0.9375 (0.8715)  Batch Accuracy (Choose Image): 0.9375 (0.8742)  Masked Language Modeling Accuracy: 0.6814 (0.6384)  time: 0.9940 (1.0971)  data: 0.0539 (0.1421)  lr: 0.000100  max mem: 11254
2021-04-13 11:54:37,077 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0038000.pth
2021-04-13 11:56:00,579 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:36:34  iter: 38000  loss: 1.2432 (1.1796)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2140 (0.2176)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2262 (0.2453)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2592 (0.2439)  Cross-Entropy Loss (Align Words, Choose Image): 0.2265 (0.2112)  Image Caption Matching Loss: 0.3071 (0.2615)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9249)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9168)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.9138)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9215)  Batch Accuracy (Choose Caption): 0.9375 (0.9504)  Batch Accuracy (Choose Image): 0.9375 (0.9509)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 11254
2021-04-13 11:57:40,040 maskrcnn_benchmark.trainer INFO: eta: 0:34:48  iter: 38100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3146 (0.5317)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3330 (0.5201)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2763 (0.5417)  Cross-Entropy Loss (Align Words, Choose Image): 0.2537 (0.4737)  Image Caption Matching Loss: 0.2853 (0.6601)  Masked Language Modeling Loss: 1.5714 (1.8141)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0179 (4.5414)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8189)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8204)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8113)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8338)  Batch Accuracy (Choose Caption): 0.9531 (0.8717)  Batch Accuracy (Choose Image): 0.9375 (0.8744)  Masked Language Modeling Accuracy: 0.6699 (0.6385)  time: 1.0116 (1.0990)  data: 0.0585 (0.1441)  lr: 0.000100  max mem: 11254
2021-04-13 11:59:18,932 maskrcnn_benchmark.trainer INFO: eta: 0:32:57  iter: 38200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3441 (0.5312)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3141 (0.5197)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2669 (0.5410)  Cross-Entropy Loss (Align Words, Choose Image): 0.2357 (0.4731)  Image Caption Matching Loss: 0.3009 (0.6592)  Masked Language Modeling Loss: 1.4772 (1.8134)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9527 (4.5375)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8191)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8206)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8115)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8340)  Batch Accuracy (Choose Caption): 0.9531 (0.8719)  Batch Accuracy (Choose Image): 0.9375 (0.8746)  Masked Language Modeling Accuracy: 0.6865 (0.6386)  time: 0.9939 (1.0987)  data: 0.0480 (0.1439)  lr: 0.000100  max mem: 11254
2021-04-13 12:01:02,613 maskrcnn_benchmark.trainer INFO: eta: 0:31:07  iter: 38300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2781 (0.5306)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2935 (0.5191)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2680 (0.5404)  Cross-Entropy Loss (Align Words, Choose Image): 0.2489 (0.4726)  Image Caption Matching Loss: 0.2640 (0.6582)  Masked Language Modeling Loss: 1.6194 (1.8129)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0814 (4.5337)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8193)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8208)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8117)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8342)  Batch Accuracy (Choose Caption): 0.9531 (0.8721)  Batch Accuracy (Choose Image): 0.9375 (0.8748)  Masked Language Modeling Accuracy: 0.6681 (0.6387)  time: 0.9827 (1.0986)  data: 0.0524 (0.1437)  lr: 0.000100  max mem: 11254
2021-04-13 12:02:42,119 maskrcnn_benchmark.trainer INFO: eta: 0:29:17  iter: 38400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2984 (0.5301)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2812 (0.5185)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2871 (0.5397)  Cross-Entropy Loss (Align Words, Choose Image): 0.2208 (0.4720)  Image Caption Matching Loss: 0.2673 (0.6572)  Masked Language Modeling Loss: 1.5687 (1.8123)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9722 (4.5297)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8195)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8210)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8120)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8344)  Batch Accuracy (Choose Caption): 0.9375 (0.8722)  Batch Accuracy (Choose Image): 0.9375 (0.8749)  Masked Language Modeling Accuracy: 0.6860 (0.6388)  time: 1.0022 (1.0983)  data: 0.0516 (0.1435)  lr: 0.000100  max mem: 11254
2021-04-13 12:04:21,823 maskrcnn_benchmark.trainer INFO: eta: 0:27:27  iter: 38500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2575 (0.5295)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2754 (0.5180)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2288 (0.5390)  Cross-Entropy Loss (Align Words, Choose Image): 0.1854 (0.4714)  Image Caption Matching Loss: 0.2380 (0.6562)  Masked Language Modeling Loss: 1.5844 (1.8116)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8937 (4.5257)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.8197)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8212)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.8122)  Batch Accuracy (Align Words, Choose Image): 0.9375 (0.8346)  Batch Accuracy (Choose Caption): 0.9531 (0.8724)  Batch Accuracy (Choose Image): 0.9375 (0.8751)  Masked Language Modeling Accuracy: 0.6680 (0.6389)  time: 0.9833 (1.0980)  data: 0.0559 (0.1432)  lr: 0.000100  max mem: 11254
2021-04-13 12:06:01,868 maskrcnn_benchmark.trainer INFO: eta: 0:25:36  iter: 38600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3157 (0.5290)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3481 (0.5175)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3134 (0.5384)  Cross-Entropy Loss (Align Words, Choose Image): 0.2655 (0.4708)  Image Caption Matching Loss: 0.3273 (0.6553)  Masked Language Modeling Loss: 1.5860 (1.8111)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1660 (4.5220)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8199)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8213)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8124)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8348)  Batch Accuracy (Choose Caption): 0.9375 (0.8726)  Batch Accuracy (Choose Image): 0.9375 (0.8753)  Masked Language Modeling Accuracy: 0.6580 (0.6389)  time: 1.0145 (1.0978)  data: 0.0559 (0.1430)  lr: 0.000100  max mem: 11254
2021-04-13 12:07:41,327 maskrcnn_benchmark.trainer INFO: eta: 0:23:46  iter: 38700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3141 (0.5284)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2918 (0.5170)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2713 (0.5377)  Cross-Entropy Loss (Align Words, Choose Image): 0.2218 (0.4703)  Image Caption Matching Loss: 0.2507 (0.6543)  Masked Language Modeling Loss: 1.7551 (1.8107)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0427 (4.5183)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8201)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8215)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8127)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8350)  Batch Accuracy (Choose Caption): 0.9531 (0.8728)  Batch Accuracy (Choose Image): 0.9375 (0.8755)  Masked Language Modeling Accuracy: 0.6500 (0.6390)  time: 0.9864 (1.0975)  data: 0.0595 (0.1428)  lr: 0.000100  max mem: 11254
2021-04-13 12:09:20,821 maskrcnn_benchmark.trainer INFO: eta: 0:21:56  iter: 38800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2983 (0.5279)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2660 (0.5165)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2755 (0.5370)  Cross-Entropy Loss (Align Words, Choose Image): 0.2099 (0.4697)  Image Caption Matching Loss: 0.2654 (0.6534)  Masked Language Modeling Loss: 1.4820 (1.8102)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0001 (4.5146)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8202)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8217)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8129)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8352)  Batch Accuracy (Choose Caption): 0.9531 (0.8730)  Batch Accuracy (Choose Image): 0.9375 (0.8756)  Masked Language Modeling Accuracy: 0.6672 (0.6390)  time: 0.9790 (1.0973)  data: 0.0486 (0.1426)  lr: 0.000100  max mem: 11254
2021-04-13 12:11:00,070 maskrcnn_benchmark.trainer INFO: eta: 0:20:06  iter: 38900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2950 (0.5273)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2627 (0.5159)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2701 (0.5364)  Cross-Entropy Loss (Align Words, Choose Image): 0.2325 (0.4692)  Image Caption Matching Loss: 0.3003 (0.6525)  Masked Language Modeling Loss: 1.5995 (1.8096)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0125 (4.5109)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8204)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8219)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8131)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8354)  Batch Accuracy (Choose Caption): 0.9375 (0.8732)  Batch Accuracy (Choose Image): 0.9375 (0.8758)  Masked Language Modeling Accuracy: 0.6684 (0.6391)  time: 0.9794 (1.0970)  data: 0.0527 (0.1423)  lr: 0.000100  max mem: 11254
2021-04-13 12:12:40,192 maskrcnn_benchmark.trainer INFO: eta: 0:18:16  iter: 39000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3294 (0.5268)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2645 (0.5154)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2586 (0.5357)  Cross-Entropy Loss (Align Words, Choose Image): 0.1953 (0.4686)  Image Caption Matching Loss: 0.2276 (0.6515)  Masked Language Modeling Loss: 1.5402 (1.8090)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.7835 (4.5069)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8206)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8221)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8134)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8356)  Batch Accuracy (Choose Caption): 0.9531 (0.8734)  Batch Accuracy (Choose Image): 0.9531 (0.8760)  Masked Language Modeling Accuracy: 0.6663 (0.6392)  time: 0.9900 (1.0967)  data: 0.0592 (0.1421)  lr: 0.000100  max mem: 11254
2021-04-13 12:12:40,911 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0039000.pth
2021-04-13 12:14:05,257 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:18:16  iter: 39000  loss: 1.3202 (1.1435)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2521 (0.2175)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2237 (0.2206)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2658 (0.2425)  Cross-Entropy Loss (Align Words, Choose Image): 0.2055 (0.2074)  Image Caption Matching Loss: 0.2729 (0.2555)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9230)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9212)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9135)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9245)  Batch Accuracy (Choose Caption): 0.9375 (0.9527)  Batch Accuracy (Choose Image): 0.9531 (0.9496)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 11254
2021-04-13 12:15:44,298 maskrcnn_benchmark.trainer INFO: eta: 0:16:28  iter: 39100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3538 (0.5263)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3062 (0.5148)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2676 (0.5351)  Cross-Entropy Loss (Align Words, Choose Image): 0.2600 (0.4680)  Image Caption Matching Loss: 0.2331 (0.6505)  Masked Language Modeling Loss: 1.5529 (1.8086)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0261 (4.5033)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8208)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8223)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8136)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8358)  Batch Accuracy (Choose Caption): 0.9531 (0.8736)  Batch Accuracy (Choose Image): 0.9531 (0.8761)  Masked Language Modeling Accuracy: 0.6743 (0.6393)  time: 0.9831 (1.0986)  data: 0.0627 (0.1441)  lr: 0.000100  max mem: 11254
2021-04-13 12:17:23,490 maskrcnn_benchmark.trainer INFO: eta: 0:14:38  iter: 39200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3571 (0.5258)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3170 (0.5144)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2841 (0.5345)  Cross-Entropy Loss (Align Words, Choose Image): 0.2238 (0.4675)  Image Caption Matching Loss: 0.3116 (0.6496)  Masked Language Modeling Loss: 1.5197 (1.8081)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0909 (4.4998)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8210)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8224)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8138)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8360)  Batch Accuracy (Choose Caption): 0.9375 (0.8738)  Batch Accuracy (Choose Image): 0.9375 (0.8763)  Masked Language Modeling Accuracy: 0.6719 (0.6393)  time: 0.9839 (1.0984)  data: 0.0623 (0.1439)  lr: 0.000100  max mem: 11254
2021-04-13 12:19:02,958 maskrcnn_benchmark.trainer INFO: eta: 0:12:48  iter: 39300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2960 (0.5253)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3340 (0.5139)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3205 (0.5339)  Cross-Entropy Loss (Align Words, Choose Image): 0.2442 (0.4670)  Image Caption Matching Loss: 0.2670 (0.6487)  Masked Language Modeling Loss: 1.5346 (1.8076)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0916 (4.4963)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8212)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8226)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8140)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8361)  Batch Accuracy (Choose Caption): 0.9531 (0.8740)  Batch Accuracy (Choose Image): 0.9375 (0.8765)  Masked Language Modeling Accuracy: 0.6475 (0.6394)  time: 1.0149 (1.0981)  data: 0.0494 (0.1436)  lr: 0.000100  max mem: 11254
2021-04-13 12:20:42,884 maskrcnn_benchmark.trainer INFO: eta: 0:10:58  iter: 39400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3051 (0.5248)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2765 (0.5134)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2590 (0.5332)  Cross-Entropy Loss (Align Words, Choose Image): 0.2305 (0.4664)  Image Caption Matching Loss: 0.2416 (0.6477)  Masked Language Modeling Loss: 1.6218 (1.8070)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9390 (4.4925)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8213)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8228)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8143)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8363)  Batch Accuracy (Choose Caption): 0.9531 (0.8741)  Batch Accuracy (Choose Image): 0.9531 (0.8766)  Masked Language Modeling Accuracy: 0.6647 (0.6395)  time: 0.9987 (1.0979)  data: 0.0540 (0.1434)  lr: 0.000100  max mem: 11254
2021-04-13 12:22:22,444 maskrcnn_benchmark.trainer INFO: eta: 0:09:08  iter: 39500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3444 (0.5243)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3251 (0.5129)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2859 (0.5326)  Cross-Entropy Loss (Align Words, Choose Image): 0.2651 (0.4659)  Image Caption Matching Loss: 0.3334 (0.6468)  Masked Language Modeling Loss: 1.5503 (1.8064)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2234 (4.4889)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8215)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8230)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8145)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8365)  Batch Accuracy (Choose Caption): 0.9219 (0.8743)  Batch Accuracy (Choose Image): 0.9375 (0.8768)  Masked Language Modeling Accuracy: 0.6559 (0.6396)  time: 0.9848 (1.0976)  data: 0.0513 (0.1432)  lr: 0.000100  max mem: 11254
2021-04-13 12:24:02,148 maskrcnn_benchmark.trainer INFO: eta: 0:07:18  iter: 39600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3315 (0.5239)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2613 (0.5124)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2607 (0.5320)  Cross-Entropy Loss (Align Words, Choose Image): 0.2218 (0.4654)  Image Caption Matching Loss: 0.2515 (0.6459)  Masked Language Modeling Loss: 1.5613 (1.8059)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8101 (4.4855)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8217)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8231)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8147)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8367)  Batch Accuracy (Choose Caption): 0.9531 (0.8745)  Batch Accuracy (Choose Image): 0.9531 (0.8770)  Masked Language Modeling Accuracy: 0.6776 (0.6396)  time: 0.9879 (1.0974)  data: 0.0552 (0.1430)  lr: 0.000100  max mem: 11254
2021-04-13 12:25:42,038 maskrcnn_benchmark.trainer INFO: eta: 0:05:29  iter: 39700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2957 (0.5234)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2960 (0.5119)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2570 (0.5314)  Cross-Entropy Loss (Align Words, Choose Image): 0.2375 (0.4648)  Image Caption Matching Loss: 0.2627 (0.6450)  Masked Language Modeling Loss: 1.4949 (1.8054)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9634 (4.4819)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8218)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8233)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8149)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8369)  Batch Accuracy (Choose Caption): 0.9375 (0.8747)  Batch Accuracy (Choose Image): 0.9375 (0.8771)  Masked Language Modeling Accuracy: 0.6819 (0.6397)  time: 0.9902 (1.0971)  data: 0.0612 (0.1428)  lr: 0.000100  max mem: 11254
2021-04-13 12:27:21,674 maskrcnn_benchmark.trainer INFO: eta: 0:03:39  iter: 39800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3393 (0.5229)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3194 (0.5114)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2644 (0.5307)  Cross-Entropy Loss (Align Words, Choose Image): 0.2339 (0.4643)  Image Caption Matching Loss: 0.3244 (0.6440)  Masked Language Modeling Loss: 1.7496 (1.8048)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2613 (4.4781)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8220)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8235)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8151)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8371)  Batch Accuracy (Choose Caption): 0.9375 (0.8749)  Batch Accuracy (Choose Image): 0.9375 (0.8773)  Masked Language Modeling Accuracy: 0.6687 (0.6398)  time: 1.0007 (1.0968)  data: 0.0532 (0.1425)  lr: 0.000100  max mem: 11254
2021-04-13 12:29:00,941 maskrcnn_benchmark.trainer INFO: eta: 0:01:49  iter: 39900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3080 (0.5224)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3095 (0.5109)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2497 (0.5301)  Cross-Entropy Loss (Align Words, Choose Image): 0.2516 (0.4637)  Image Caption Matching Loss: 0.3255 (0.6432)  Masked Language Modeling Loss: 1.6083 (1.8043)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1236 (4.4746)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8222)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8236)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.8154)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8373)  Batch Accuracy (Choose Caption): 0.9531 (0.8750)  Batch Accuracy (Choose Image): 0.9375 (0.8775)  Masked Language Modeling Accuracy: 0.6546 (0.6399)  time: 0.9777 (1.0966)  data: 0.0532 (0.1423)  lr: 0.000100  max mem: 11254
2021-04-13 12:30:38,501 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 40000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2552 (0.5218)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2882 (0.5104)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2604 (0.5294)  Cross-Entropy Loss (Align Words, Choose Image): 0.2635 (0.4632)  Image Caption Matching Loss: 0.2735 (0.6423)  Masked Language Modeling Loss: 1.5595 (1.8038)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9935 (4.4709)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8224)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8238)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8156)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8374)  Batch Accuracy (Choose Caption): 0.9375 (0.8752)  Batch Accuracy (Choose Image): 0.9375 (0.8776)  Masked Language Modeling Accuracy: 0.6712 (0.6399)  time: 0.9530 (1.0963)  data: 0.0464 (0.1421)  lr: 0.000100  max mem: 11254
2021-04-13 12:30:39,091 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_0040000.pth
2021-04-13 12:32:03,584 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:00:00  iter: 40000  loss: 1.0814 (1.1607)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2118 (0.2269)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2139 (0.2326)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2292 (0.2336)  Cross-Entropy Loss (Align Words, Choose Image): 0.2131 (0.2092)  Image Caption Matching Loss: 0.2380 (0.2584)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9201)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9185)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9147)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9262)  Batch Accuracy (Choose Caption): 0.9375 (0.9507)  Batch Accuracy (Choose Image): 0.9531 (0.9502)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 11254
2021-04-13 12:32:04,794 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain_02/model_final.pth
2021-04-13 12:32:06,221 maskrcnn_benchmark.trainer INFO: Total training time: 12:12:19.307896 (1.0985 s / it)
2021-04-13 12:32:06,657 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2021-04-13 12:32:06,727 maskrcnn_benchmark.inference INFO: Start evaluation on coco_captions_val dataset(5000 images).
2021-04-13 12:50:12,376 maskrcnn_benchmark INFO: Using 8 GPUs
2021-04-13 12:50:12,397 maskrcnn_benchmark INFO: Namespace(config_file='configs/mmss_v07.yaml', distributed=True, local_rank=0, opts=['OUTPUT_DIR', '/mnt/lustre/lixiangtai/runs/vltrain_02'], skip_test=False)
2021-04-13 12:50:12,397 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2021-04-13 12:50:52,842 maskrcnn_benchmark INFO: 
PyTorch version: 1.4.0
Is debug build: No
CUDA used to build PyTorch: 10.1

OS: CentOS Linux 7 (Core)
GCC version: (GCC) 5.4.0
CMake version: version 3.14.0

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: Tesla V100-SXM2-32GB
GPU 1: Tesla V100-SXM2-32GB
GPU 2: Tesla V100-SXM2-32GB
GPU 3: Tesla V100-SXM2-32GB
GPU 4: Tesla V100-SXM2-32GB
GPU 5: Tesla V100-SXM2-32GB
GPU 6: Tesla V100-SXM2-32GB
GPU 7: Tesla V100-SXM2-32GB

Nvidia driver version: 418.67
cuDNN version: /usr/local/cuda-9.0/lib64/libcudnn.so.7.0.4

Versions of relevant libraries:
[pip] numpy==1.17.5
[pip] torch==1.4.0
[pip] torchvision==0.5.0
[conda] magma-cuda101             2.5.2                         1    <unknown>
[conda] mkl                       2020.1                      217  
[conda] mkl-include               2020.1                      217  
[conda] torch                     1.4.0                    pypi_0    pypi
[conda] torchvision               0.5.0                    pypi_0    pypi
        Pillow (7.1.2)
2021-04-13 12:50:52,859 maskrcnn_benchmark INFO: Loaded configuration file configs/mmss_v07.yaml
2021-04-13 12:50:52,859 maskrcnn_benchmark INFO: 
MODEL:
  # This is what indicates we want image-caption training not object detection
  META_ARCHITECTURE: "MMSS-GCNN"
  # URL to the initial weights, trained for imagenet classification
  WEIGHT: "/mnt/lustre/lixiangtai/pretrained/R-50.pkl"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
  BACKBONE:
    # a full resnet, including stem and 4 blocks
    CONV_BODY: "R-50-C5"
    # don't freeze any layer, train everything
    FREEZE_CONV_BODY_AT: 0
  LANGUAGE_BACKBONE:
    # make a BERT model to process captions
    TYPE: "BERT-Base"
    # and freeze it (loaded from original pretrained bert of huggingface)
    FREEZE: True
  MMSS_HEAD:
    # We want both a grounding head and a transformer head on top of image and caption,
    # each of which defines its own objective functions.
    TYPES: ("GroundingHead", "TransformerHead")
    DEFAULT_HEAD: "GroundingHead"
    # Share the weights of the vision to language projection between the two heads.
    # Use the one on the grounding head because that is the default (see above)
    TIE_VL_PROJECTION_WEIGHTS: True
    # Randomly keep up to 100 visual regions from each image. This is to save memory.
    SPATIAL_DROPOUT: 100
    GROUNDING:
      # Use dot product for grounding. This could be cosine or euclidean too.
      LOCAL_METRIC: "dot"
      # After aligning words to regions, sum the local distances to compute global distance.
      GLOBAL_METRIC: "aligned_local"
      # Use softmax to softly align each word to regions, and vice versa.
      # This could be for instance hardmax, which aligns to the most similar
      ALIGNMENT: "softmax"
      # Typical good values are 100.0 for euclidean, 10.0 for dot, 0.01 for cosine
      ALIGNMENT_TEMPERATURE: 10.0
      # This loss is to choose the right caption out of all captions in the batch,
      # And similarly choose the right image. Could be triplet loss instead.
      LOSS: "cross_entropy"
      # Whether to find a region for each word
      ALIGN_WORDS_TO_REGIONS: True
      # Whether to find a word for a region
      # At least one of these two should be True
      ALIGN_REGIONS_TO_WORDS: True
    TRANSFORMER:
      # Whether to perform masked language modeling (randomly mask words from captions
      # and have the model reconstruct them)
      MASKED_LANGUAGE_MODELING: True
      # Whether to do that during validation as well. That is not good if you want to
      # measure image-caption matching scores.
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      # For now this is not implemented, so keep it False and ''
      MASKED_VISUAL_MODELING: False
      MVM_LOSS: ''
      # For Multimedia Matching loss, cross-entropy works just like in the grounding head
      MMM_LOSS: 'cross_entropy'
      # Typical BERT configs as in Huggingface
      BERT_CONFIG:
        num_hidden_layers: 6
        num_attention_heads: 8
        intermediate_size: 768
DATASETS:
  TRAIN: ("coco_captions_train",)
  TEST: ("coco_captions_val",)
  DATASET_CLASS: "COCOCaptionsDataset"
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS: (20000, 35000)
  MAX_ITER: 40000
  IMS_PER_BATCH: 64
  TEST_PERIOD: 1000
  CHECKPOINT_PERIOD: 1000
  LOG_PERIOD: 100
  CLIP_GRAD_NORM_AT: 5.0
  # A value of more than one means accumulate gradients for several batches before updating
  GRADIENT_ACCUMULATION_STEPS: 1
  # If true, it calls model.train() before computing validation loss. Needed for some models.
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
TEST:
  DO_EVAL: False
  IMS_PER_BATCH: 64
2021-04-13 12:50:52,869 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DROP_LAST: False
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 0
DATASETS:
  DATASET_ARGS:
    EMB_DIM: 300
    EMB_KEY: GloVE
    LOAD_EMBEDDINGS: False
    MULTI_LABEL_MODE: False
  DATASET_CLASS: COCOCaptionsDataset
  TEST: ('coco_captions_val',)
  TRAIN: ('coco_captions_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-50-C5
    FREEZE_CONV_BODY_AT: 0
  BACKBONE_PREFIX: 
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    ADD_POSITION_EMBEDDING: False
    EMBEDDING_PATH: 
    FREEZE: True
    TYPE: BERT-Base
  LOAD_CLASSIFIER: True
  LOAD_EMB_PRED_FROM_MMSS_HEAD: False
  LOAD_TRAINER_STATE: True
  MASK_ON: False
  META_ARCHITECTURE: MMSS-GCNN
  MMSS_HEAD:
    DEFAULT_HEAD: GroundingHead
    GROUNDING:
      ALIGNMENT: softmax
      ALIGNMENT_TEMPERATURE: 10.0
      ALIGN_REGIONS_TO_WORDS: True
      ALIGN_WORDS_TO_REGIONS: True
      GLOBAL_METRIC: aligned_local
      LOCAL_METRIC: dot
      LOSS: cross_entropy
      NEGATIVE_MINING: random
      TRIPLET_MARGIN: 1.0
    SPATIAL_DROPOUT: 100
    TIE_VL_PROJECTION_WEIGHTS: True
    TRANSFORMER:
      BERT_CONFIG:
        attention_probs_dropout_prob: 0.1
        gradient_checkpointing: False
        hidden_act: gelu
        hidden_dropout_prob: 0.1
        hidden_size: 768
        initializer_range: 0.02
        intermediate_size: 768
        layer_norm_eps: 1e-12
        max_position_embeddings: 512
        num_attention_heads: 8
        num_hidden_layers: 6
        pad_token_id: 0
        type_vocab_size: 2
        vocab_size: 30522
      MASKED_LANGUAGE_MODELING: True
      MASKED_LANGUAGE_MODELING_PROB: 0.15
      MASKED_LANGUAGE_MODELING_PROB_MASK: 0.9
      MASKED_LANGUAGE_MODELING_PROB_NOISE: 0.0
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      MASKED_VISUAL_MODELING: False
      MMM_LOSS: cross_entropy
      MVM_LOSS: 
      MVM_LOSS_NUM_NEGATIVE: 128
    TYPES: ('GroundingHead', 'TransformerHead')
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    EMBEDDING_BASED: False
    EMB_DIM: 300
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    FREEZE_EMB_PRED: False
    FREEZE_FEATURE_EXTRACTOR: False
    LOSS_WEIGHT_BACKGROUND: 1.0
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
    WSDDN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    DONT_TRAIN: False
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  WEIGHT: /mnt/lustre/lixiangtai/pretrained/R-50.pkl
OUTPUT_DIR: /mnt/lustre/lixiangtai/runs/vltrain_02
PATHS_CATALOG: /mnt/lustre/lixiangtai/project/ovr-cnn/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 1000
  CLIP_GRAD_NORM_AT: 5.0
  GAMMA: 0.1
  GRADIENT_ACCUMULATION_STEPS: 1
  IMS_PER_BATCH: 64
  LOG_PERIOD: 100
  MAX_ITER: 40000
  MOMENTUM: 0.9
  SKIP_VAL_LOSS: False
  STEPS: (20000, 35000)
  TEST_PERIOD: 1000
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  DO_EVAL: False
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 64
2021-04-13 12:50:52,869 maskrcnn_benchmark INFO: Saving config into: /mnt/lustre/lixiangtai/runs/vltrain_02/config.yml
2021-04-13 12:51:04,942 maskrcnn_benchmark.make_optimizer INFO: The following parameters will be trained: 
2021-04-13 12:51:04,944 maskrcnn_benchmark.make_optimizer INFO: backbone.body.stem.conv1.weight
2021-04-13 12:51:04,944 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.downsample.0.weight
2021-04-13 12:51:04,944 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv1.weight
2021-04-13 12:51:04,944 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv2.weight
2021-04-13 12:51:04,945 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv3.weight
2021-04-13 12:51:04,945 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv1.weight
2021-04-13 12:51:04,945 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv2.weight
2021-04-13 12:51:04,945 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv3.weight
2021-04-13 12:51:04,945 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv1.weight
2021-04-13 12:51:04,945 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv2.weight
2021-04-13 12:51:04,945 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv3.weight
2021-04-13 12:51:04,946 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.downsample.0.weight
2021-04-13 12:51:04,946 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv1.weight
2021-04-13 12:51:04,946 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv2.weight
2021-04-13 12:51:04,946 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv3.weight
2021-04-13 12:51:04,946 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv1.weight
2021-04-13 12:51:04,946 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv2.weight
2021-04-13 12:51:04,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv3.weight
2021-04-13 12:51:04,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv1.weight
2021-04-13 12:51:04,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv2.weight
2021-04-13 12:51:04,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv3.weight
2021-04-13 12:51:04,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv1.weight
2021-04-13 12:51:04,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv2.weight
2021-04-13 12:51:04,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv3.weight
2021-04-13 12:51:04,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.downsample.0.weight
2021-04-13 12:51:04,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv1.weight
2021-04-13 12:51:04,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv2.weight
2021-04-13 12:51:04,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv3.weight
2021-04-13 12:51:04,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv1.weight
2021-04-13 12:51:04,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv2.weight
2021-04-13 12:51:04,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv3.weight
2021-04-13 12:51:04,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv1.weight
2021-04-13 12:51:04,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv2.weight
2021-04-13 12:51:04,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv3.weight
2021-04-13 12:51:04,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv1.weight
2021-04-13 12:51:04,950 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv2.weight
2021-04-13 12:51:04,950 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv3.weight
2021-04-13 12:51:04,950 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv1.weight
2021-04-13 12:51:04,950 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv2.weight
2021-04-13 12:51:04,950 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv3.weight
2021-04-13 12:51:04,950 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv1.weight
2021-04-13 12:51:04,951 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv2.weight
2021-04-13 12:51:04,951 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv3.weight
2021-04-13 12:51:04,951 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.downsample.0.weight
2021-04-13 12:51:04,951 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv1.weight
2021-04-13 12:51:04,951 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv2.weight
2021-04-13 12:51:04,951 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv3.weight
2021-04-13 12:51:04,951 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv1.weight
2021-04-13 12:51:04,951 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv2.weight
2021-04-13 12:51:04,952 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv3.weight
2021-04-13 12:51:04,952 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv1.weight
2021-04-13 12:51:04,952 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv2.weight
2021-04-13 12:51:04,952 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv3.weight
2021-04-13 12:51:04,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.GroundingHead.v2l_projection.weight
2021-04-13 12:51:04,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.GroundingHead.v2l_projection.bias
2021-04-13 12:51:04,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_embeddings.weight
2021-04-13 12:51:04,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_embeddings.bias
2021-04-13 12:51:04,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_location_embeddings.weight
2021-04-13 12:51:04,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_location_embeddings.bias
2021-04-13 12:51:04,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.LayerNorm.weight
2021-04-13 12:51:04,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.LayerNorm.bias
2021-04-13 12:51:04,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.weight
2021-04-13 12:51:04,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.bias
2021-04-13 12:51:04,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.weight
2021-04-13 12:51:04,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.bias
2021-04-13 12:51:04,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.weight
2021-04-13 12:51:04,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.bias
2021-04-13 12:51:04,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.weight
2021-04-13 12:51:04,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.bias
2021-04-13 12:51:04,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.weight
2021-04-13 12:51:04,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.bias
2021-04-13 12:51:04,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.weight
2021-04-13 12:51:04,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.bias
2021-04-13 12:51:04,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.dense.weight
2021-04-13 12:51:04,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.dense.bias
2021-04-13 12:51:04,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.weight
2021-04-13 12:51:04,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.bias
2021-04-13 12:51:04,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.weight
2021-04-13 12:51:04,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.bias
2021-04-13 12:51:04,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.weight
2021-04-13 12:51:04,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.bias
2021-04-13 12:51:04,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.weight
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.bias
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.weight
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.bias
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.weight
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.bias
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.weight
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.bias
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.dense.weight
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.dense.bias
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.weight
2021-04-13 12:51:04,957 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.bias
2021-04-13 12:51:04,958 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.weight
2021-04-13 12:51:04,958 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.bias
2021-04-13 12:51:04,958 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.weight
2021-04-13 12:51:04,958 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.bias
2021-04-13 12:51:04,958 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.weight
2021-04-13 12:51:04,958 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.bias
2021-04-13 12:51:04,958 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.weight
2021-04-13 12:51:04,958 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.bias
2021-04-13 12:51:04,958 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.weight
2021-04-13 12:51:04,958 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.bias
2021-04-13 12:51:04,959 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.weight
2021-04-13 12:51:04,959 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.bias
2021-04-13 12:51:04,959 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.dense.weight
2021-04-13 12:51:04,959 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.dense.bias
2021-04-13 12:51:04,959 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.weight
2021-04-13 12:51:04,959 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.bias
2021-04-13 12:51:04,959 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.weight
2021-04-13 12:51:04,959 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.bias
2021-04-13 12:51:04,959 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.weight
2021-04-13 12:51:04,959 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.bias
2021-04-13 12:51:04,960 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.weight
2021-04-13 12:51:04,960 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.bias
2021-04-13 12:51:04,960 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.weight
2021-04-13 12:51:04,960 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.bias
2021-04-13 12:51:04,960 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.weight
2021-04-13 12:51:04,960 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.bias
2021-04-13 12:51:04,960 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.weight
2021-04-13 12:51:04,960 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.bias
2021-04-13 12:51:04,960 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.dense.weight
2021-04-13 12:51:04,960 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.dense.bias
2021-04-13 12:51:04,961 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.weight
2021-04-13 12:51:04,961 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.bias
2021-04-13 12:51:04,961 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.weight
2021-04-13 12:51:04,961 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.bias
2021-04-13 12:51:04,961 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.weight
2021-04-13 12:51:04,961 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.bias
2021-04-13 12:51:04,961 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.weight
2021-04-13 12:51:04,961 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.bias
2021-04-13 12:51:04,961 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.weight
2021-04-13 12:51:04,962 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.bias
2021-04-13 12:51:04,962 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.weight
2021-04-13 12:51:04,962 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.bias
2021-04-13 12:51:04,962 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.weight
2021-04-13 12:51:04,962 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.bias
2021-04-13 12:51:04,962 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.dense.weight
2021-04-13 12:51:04,962 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.dense.bias
2021-04-13 12:51:04,962 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.weight
2021-04-13 12:51:04,962 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.bias
2021-04-13 12:51:04,963 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.weight
2021-04-13 12:51:04,963 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.bias
2021-04-13 12:51:04,963 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.weight
2021-04-13 12:51:04,963 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.bias
2021-04-13 12:51:04,963 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.weight
2021-04-13 12:51:04,963 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.bias
2021-04-13 12:51:04,963 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.weight
2021-04-13 12:51:04,963 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.bias
2021-04-13 12:51:04,964 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.weight
2021-04-13 12:51:04,964 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.bias
2021-04-13 12:51:04,964 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.weight
2021-04-13 12:51:04,964 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.bias
2021-04-13 12:51:04,964 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.dense.weight
2021-04-13 12:51:04,964 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.dense.bias
2021-04-13 12:51:04,964 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.weight
2021-04-13 12:51:04,964 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.bias
2021-04-13 12:51:04,964 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.pooler.dense.weight
2021-04-13 12:51:04,965 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.pooler.dense.bias
2021-04-13 12:51:04,965 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.bias
2021-04-13 12:51:04,965 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.dense.weight
2021-04-13 12:51:04,965 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.dense.bias
2021-04-13 12:51:04,965 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.weight
2021-04-13 12:51:04,965 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.bias
2021-04-13 12:51:04,965 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.bi_seq_relationship.weight
2021-04-13 12:51:04,965 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.bi_seq_relationship.bias
2021-04-13 12:51:06,415 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /mnt/lustre/lixiangtai/runs/vltrain_02/model_final.pth
2021-04-13 12:51:11,505 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn1.bias                                                                   loaded from backbone.body.layer1.0.bn1.bias                                                                   of shape (64,)
2021-04-13 12:51:11,505 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn1.running_mean                                                           loaded from backbone.body.layer1.0.bn1.running_mean                                                           of shape (64,)
2021-04-13 12:51:11,506 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn1.running_var                                                            loaded from backbone.body.layer1.0.bn1.running_var                                                            of shape (64,)
2021-04-13 12:51:11,506 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn1.weight                                                                 loaded from backbone.body.layer1.0.bn1.weight                                                                 of shape (64,)
2021-04-13 12:51:11,506 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn2.bias                                                                   loaded from backbone.body.layer1.0.bn2.bias                                                                   of shape (64,)
2021-04-13 12:51:11,506 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn2.running_mean                                                           loaded from backbone.body.layer1.0.bn2.running_mean                                                           of shape (64,)
2021-04-13 12:51:11,506 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn2.running_var                                                            loaded from backbone.body.layer1.0.bn2.running_var                                                            of shape (64,)
2021-04-13 12:51:11,506 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn2.weight                                                                 loaded from backbone.body.layer1.0.bn2.weight                                                                 of shape (64,)
2021-04-13 12:51:11,506 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn3.bias                                                                   loaded from backbone.body.layer1.0.bn3.bias                                                                   of shape (256,)
2021-04-13 12:51:11,506 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn3.running_mean                                                           loaded from backbone.body.layer1.0.bn3.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,506 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn3.running_var                                                            loaded from backbone.body.layer1.0.bn3.running_var                                                            of shape (256,)
2021-04-13 12:51:11,507 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn3.weight                                                                 loaded from backbone.body.layer1.0.bn3.weight                                                                 of shape (256,)
2021-04-13 12:51:11,507 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv1.weight                                                               loaded from backbone.body.layer1.0.conv1.weight                                                               of shape (64, 64, 1, 1)
2021-04-13 12:51:11,507 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv2.weight                                                               loaded from backbone.body.layer1.0.conv2.weight                                                               of shape (64, 64, 3, 3)
2021-04-13 12:51:11,507 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv3.weight                                                               loaded from backbone.body.layer1.0.conv3.weight                                                               of shape (256, 64, 1, 1)
2021-04-13 12:51:11,507 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.0.weight                                                        loaded from backbone.body.layer1.0.downsample.0.weight                                                        of shape (256, 64, 1, 1)
2021-04-13 12:51:11,507 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.1.bias                                                          loaded from backbone.body.layer1.0.downsample.1.bias                                                          of shape (256,)
2021-04-13 12:51:11,507 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.1.running_mean                                                  loaded from backbone.body.layer1.0.downsample.1.running_mean                                                  of shape (256,)
2021-04-13 12:51:11,507 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.1.running_var                                                   loaded from backbone.body.layer1.0.downsample.1.running_var                                                   of shape (256,)
2021-04-13 12:51:11,507 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.1.weight                                                        loaded from backbone.body.layer1.0.downsample.1.weight                                                        of shape (256,)
2021-04-13 12:51:11,508 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn1.bias                                                                   loaded from backbone.body.layer1.1.bn1.bias                                                                   of shape (64,)
2021-04-13 12:51:11,508 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn1.running_mean                                                           loaded from backbone.body.layer1.1.bn1.running_mean                                                           of shape (64,)
2021-04-13 12:51:11,508 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn1.running_var                                                            loaded from backbone.body.layer1.1.bn1.running_var                                                            of shape (64,)
2021-04-13 12:51:11,508 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn1.weight                                                                 loaded from backbone.body.layer1.1.bn1.weight                                                                 of shape (64,)
2021-04-13 12:51:11,508 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn2.bias                                                                   loaded from backbone.body.layer1.1.bn2.bias                                                                   of shape (64,)
2021-04-13 12:51:11,508 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn2.running_mean                                                           loaded from backbone.body.layer1.1.bn2.running_mean                                                           of shape (64,)
2021-04-13 12:51:11,508 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn2.running_var                                                            loaded from backbone.body.layer1.1.bn2.running_var                                                            of shape (64,)
2021-04-13 12:51:11,508 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn2.weight                                                                 loaded from backbone.body.layer1.1.bn2.weight                                                                 of shape (64,)
2021-04-13 12:51:11,508 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn3.bias                                                                   loaded from backbone.body.layer1.1.bn3.bias                                                                   of shape (256,)
2021-04-13 12:51:11,508 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn3.running_mean                                                           loaded from backbone.body.layer1.1.bn3.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,509 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn3.running_var                                                            loaded from backbone.body.layer1.1.bn3.running_var                                                            of shape (256,)
2021-04-13 12:51:11,509 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn3.weight                                                                 loaded from backbone.body.layer1.1.bn3.weight                                                                 of shape (256,)
2021-04-13 12:51:11,509 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv1.weight                                                               loaded from backbone.body.layer1.1.conv1.weight                                                               of shape (64, 256, 1, 1)
2021-04-13 12:51:11,509 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv2.weight                                                               loaded from backbone.body.layer1.1.conv2.weight                                                               of shape (64, 64, 3, 3)
2021-04-13 12:51:11,509 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv3.weight                                                               loaded from backbone.body.layer1.1.conv3.weight                                                               of shape (256, 64, 1, 1)
2021-04-13 12:51:11,509 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn1.bias                                                                   loaded from backbone.body.layer1.2.bn1.bias                                                                   of shape (64,)
2021-04-13 12:51:11,509 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn1.running_mean                                                           loaded from backbone.body.layer1.2.bn1.running_mean                                                           of shape (64,)
2021-04-13 12:51:11,509 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn1.running_var                                                            loaded from backbone.body.layer1.2.bn1.running_var                                                            of shape (64,)
2021-04-13 12:51:11,509 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn1.weight                                                                 loaded from backbone.body.layer1.2.bn1.weight                                                                 of shape (64,)
2021-04-13 12:51:11,510 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn2.bias                                                                   loaded from backbone.body.layer1.2.bn2.bias                                                                   of shape (64,)
2021-04-13 12:51:11,510 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn2.running_mean                                                           loaded from backbone.body.layer1.2.bn2.running_mean                                                           of shape (64,)
2021-04-13 12:51:11,510 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn2.running_var                                                            loaded from backbone.body.layer1.2.bn2.running_var                                                            of shape (64,)
2021-04-13 12:51:11,510 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn2.weight                                                                 loaded from backbone.body.layer1.2.bn2.weight                                                                 of shape (64,)
2021-04-13 12:51:11,510 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn3.bias                                                                   loaded from backbone.body.layer1.2.bn3.bias                                                                   of shape (256,)
2021-04-13 12:51:11,510 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn3.running_mean                                                           loaded from backbone.body.layer1.2.bn3.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,510 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn3.running_var                                                            loaded from backbone.body.layer1.2.bn3.running_var                                                            of shape (256,)
2021-04-13 12:51:11,510 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn3.weight                                                                 loaded from backbone.body.layer1.2.bn3.weight                                                                 of shape (256,)
2021-04-13 12:51:11,510 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv1.weight                                                               loaded from backbone.body.layer1.2.conv1.weight                                                               of shape (64, 256, 1, 1)
2021-04-13 12:51:11,510 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv2.weight                                                               loaded from backbone.body.layer1.2.conv2.weight                                                               of shape (64, 64, 3, 3)
2021-04-13 12:51:11,511 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv3.weight                                                               loaded from backbone.body.layer1.2.conv3.weight                                                               of shape (256, 64, 1, 1)
2021-04-13 12:51:11,511 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn1.bias                                                                   loaded from backbone.body.layer2.0.bn1.bias                                                                   of shape (128,)
2021-04-13 12:51:11,511 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn1.running_mean                                                           loaded from backbone.body.layer2.0.bn1.running_mean                                                           of shape (128,)
2021-04-13 12:51:11,511 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn1.running_var                                                            loaded from backbone.body.layer2.0.bn1.running_var                                                            of shape (128,)
2021-04-13 12:51:11,511 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn1.weight                                                                 loaded from backbone.body.layer2.0.bn1.weight                                                                 of shape (128,)
2021-04-13 12:51:11,511 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn2.bias                                                                   loaded from backbone.body.layer2.0.bn2.bias                                                                   of shape (128,)
2021-04-13 12:51:11,511 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn2.running_mean                                                           loaded from backbone.body.layer2.0.bn2.running_mean                                                           of shape (128,)
2021-04-13 12:51:11,511 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn2.running_var                                                            loaded from backbone.body.layer2.0.bn2.running_var                                                            of shape (128,)
2021-04-13 12:51:11,511 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn2.weight                                                                 loaded from backbone.body.layer2.0.bn2.weight                                                                 of shape (128,)
2021-04-13 12:51:11,512 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn3.bias                                                                   loaded from backbone.body.layer2.0.bn3.bias                                                                   of shape (512,)
2021-04-13 12:51:11,512 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn3.running_mean                                                           loaded from backbone.body.layer2.0.bn3.running_mean                                                           of shape (512,)
2021-04-13 12:51:11,512 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn3.running_var                                                            loaded from backbone.body.layer2.0.bn3.running_var                                                            of shape (512,)
2021-04-13 12:51:11,512 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn3.weight                                                                 loaded from backbone.body.layer2.0.bn3.weight                                                                 of shape (512,)
2021-04-13 12:51:11,512 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv1.weight                                                               loaded from backbone.body.layer2.0.conv1.weight                                                               of shape (128, 256, 1, 1)
2021-04-13 12:51:11,512 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv2.weight                                                               loaded from backbone.body.layer2.0.conv2.weight                                                               of shape (128, 128, 3, 3)
2021-04-13 12:51:11,512 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv3.weight                                                               loaded from backbone.body.layer2.0.conv3.weight                                                               of shape (512, 128, 1, 1)
2021-04-13 12:51:11,512 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.0.weight                                                        loaded from backbone.body.layer2.0.downsample.0.weight                                                        of shape (512, 256, 1, 1)
2021-04-13 12:51:11,512 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.1.bias                                                          loaded from backbone.body.layer2.0.downsample.1.bias                                                          of shape (512,)
2021-04-13 12:51:11,513 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.1.running_mean                                                  loaded from backbone.body.layer2.0.downsample.1.running_mean                                                  of shape (512,)
2021-04-13 12:51:11,513 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.1.running_var                                                   loaded from backbone.body.layer2.0.downsample.1.running_var                                                   of shape (512,)
2021-04-13 12:51:11,513 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.1.weight                                                        loaded from backbone.body.layer2.0.downsample.1.weight                                                        of shape (512,)
2021-04-13 12:51:11,513 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn1.bias                                                                   loaded from backbone.body.layer2.1.bn1.bias                                                                   of shape (128,)
2021-04-13 12:51:11,513 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn1.running_mean                                                           loaded from backbone.body.layer2.1.bn1.running_mean                                                           of shape (128,)
2021-04-13 12:51:11,513 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn1.running_var                                                            loaded from backbone.body.layer2.1.bn1.running_var                                                            of shape (128,)
2021-04-13 12:51:11,513 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn1.weight                                                                 loaded from backbone.body.layer2.1.bn1.weight                                                                 of shape (128,)
2021-04-13 12:51:11,513 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn2.bias                                                                   loaded from backbone.body.layer2.1.bn2.bias                                                                   of shape (128,)
2021-04-13 12:51:11,513 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn2.running_mean                                                           loaded from backbone.body.layer2.1.bn2.running_mean                                                           of shape (128,)
2021-04-13 12:51:11,514 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn2.running_var                                                            loaded from backbone.body.layer2.1.bn2.running_var                                                            of shape (128,)
2021-04-13 12:51:11,514 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn2.weight                                                                 loaded from backbone.body.layer2.1.bn2.weight                                                                 of shape (128,)
2021-04-13 12:51:11,514 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn3.bias                                                                   loaded from backbone.body.layer2.1.bn3.bias                                                                   of shape (512,)
2021-04-13 12:51:11,514 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn3.running_mean                                                           loaded from backbone.body.layer2.1.bn3.running_mean                                                           of shape (512,)
2021-04-13 12:51:11,514 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn3.running_var                                                            loaded from backbone.body.layer2.1.bn3.running_var                                                            of shape (512,)
2021-04-13 12:51:11,514 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn3.weight                                                                 loaded from backbone.body.layer2.1.bn3.weight                                                                 of shape (512,)
2021-04-13 12:51:11,514 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv1.weight                                                               loaded from backbone.body.layer2.1.conv1.weight                                                               of shape (128, 512, 1, 1)
2021-04-13 12:51:11,514 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv2.weight                                                               loaded from backbone.body.layer2.1.conv2.weight                                                               of shape (128, 128, 3, 3)
2021-04-13 12:51:11,514 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv3.weight                                                               loaded from backbone.body.layer2.1.conv3.weight                                                               of shape (512, 128, 1, 1)
2021-04-13 12:51:11,514 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn1.bias                                                                   loaded from backbone.body.layer2.2.bn1.bias                                                                   of shape (128,)
2021-04-13 12:51:11,515 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn1.running_mean                                                           loaded from backbone.body.layer2.2.bn1.running_mean                                                           of shape (128,)
2021-04-13 12:51:11,515 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn1.running_var                                                            loaded from backbone.body.layer2.2.bn1.running_var                                                            of shape (128,)
2021-04-13 12:51:11,515 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn1.weight                                                                 loaded from backbone.body.layer2.2.bn1.weight                                                                 of shape (128,)
2021-04-13 12:51:11,515 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn2.bias                                                                   loaded from backbone.body.layer2.2.bn2.bias                                                                   of shape (128,)
2021-04-13 12:51:11,515 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn2.running_mean                                                           loaded from backbone.body.layer2.2.bn2.running_mean                                                           of shape (128,)
2021-04-13 12:51:11,515 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn2.running_var                                                            loaded from backbone.body.layer2.2.bn2.running_var                                                            of shape (128,)
2021-04-13 12:51:11,515 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn2.weight                                                                 loaded from backbone.body.layer2.2.bn2.weight                                                                 of shape (128,)
2021-04-13 12:51:11,515 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn3.bias                                                                   loaded from backbone.body.layer2.2.bn3.bias                                                                   of shape (512,)
2021-04-13 12:51:11,515 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn3.running_mean                                                           loaded from backbone.body.layer2.2.bn3.running_mean                                                           of shape (512,)
2021-04-13 12:51:11,516 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn3.running_var                                                            loaded from backbone.body.layer2.2.bn3.running_var                                                            of shape (512,)
2021-04-13 12:51:11,516 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn3.weight                                                                 loaded from backbone.body.layer2.2.bn3.weight                                                                 of shape (512,)
2021-04-13 12:51:11,516 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv1.weight                                                               loaded from backbone.body.layer2.2.conv1.weight                                                               of shape (128, 512, 1, 1)
2021-04-13 12:51:11,516 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv2.weight                                                               loaded from backbone.body.layer2.2.conv2.weight                                                               of shape (128, 128, 3, 3)
2021-04-13 12:51:11,516 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv3.weight                                                               loaded from backbone.body.layer2.2.conv3.weight                                                               of shape (512, 128, 1, 1)
2021-04-13 12:51:11,516 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn1.bias                                                                   loaded from backbone.body.layer2.3.bn1.bias                                                                   of shape (128,)
2021-04-13 12:51:11,516 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn1.running_mean                                                           loaded from backbone.body.layer2.3.bn1.running_mean                                                           of shape (128,)
2021-04-13 12:51:11,516 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn1.running_var                                                            loaded from backbone.body.layer2.3.bn1.running_var                                                            of shape (128,)
2021-04-13 12:51:11,516 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn1.weight                                                                 loaded from backbone.body.layer2.3.bn1.weight                                                                 of shape (128,)
2021-04-13 12:51:11,517 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn2.bias                                                                   loaded from backbone.body.layer2.3.bn2.bias                                                                   of shape (128,)
2021-04-13 12:51:11,517 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn2.running_mean                                                           loaded from backbone.body.layer2.3.bn2.running_mean                                                           of shape (128,)
2021-04-13 12:51:11,517 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn2.running_var                                                            loaded from backbone.body.layer2.3.bn2.running_var                                                            of shape (128,)
2021-04-13 12:51:11,517 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn2.weight                                                                 loaded from backbone.body.layer2.3.bn2.weight                                                                 of shape (128,)
2021-04-13 12:51:11,517 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn3.bias                                                                   loaded from backbone.body.layer2.3.bn3.bias                                                                   of shape (512,)
2021-04-13 12:51:11,517 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn3.running_mean                                                           loaded from backbone.body.layer2.3.bn3.running_mean                                                           of shape (512,)
2021-04-13 12:51:11,517 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn3.running_var                                                            loaded from backbone.body.layer2.3.bn3.running_var                                                            of shape (512,)
2021-04-13 12:51:11,517 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn3.weight                                                                 loaded from backbone.body.layer2.3.bn3.weight                                                                 of shape (512,)
2021-04-13 12:51:11,517 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv1.weight                                                               loaded from backbone.body.layer2.3.conv1.weight                                                               of shape (128, 512, 1, 1)
2021-04-13 12:51:11,517 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv2.weight                                                               loaded from backbone.body.layer2.3.conv2.weight                                                               of shape (128, 128, 3, 3)
2021-04-13 12:51:11,518 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv3.weight                                                               loaded from backbone.body.layer2.3.conv3.weight                                                               of shape (512, 128, 1, 1)
2021-04-13 12:51:11,518 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn1.bias                                                                   loaded from backbone.body.layer3.0.bn1.bias                                                                   of shape (256,)
2021-04-13 12:51:11,518 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn1.running_mean                                                           loaded from backbone.body.layer3.0.bn1.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,518 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn1.running_var                                                            loaded from backbone.body.layer3.0.bn1.running_var                                                            of shape (256,)
2021-04-13 12:51:11,518 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn1.weight                                                                 loaded from backbone.body.layer3.0.bn1.weight                                                                 of shape (256,)
2021-04-13 12:51:11,518 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn2.bias                                                                   loaded from backbone.body.layer3.0.bn2.bias                                                                   of shape (256,)
2021-04-13 12:51:11,518 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn2.running_mean                                                           loaded from backbone.body.layer3.0.bn2.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,518 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn2.running_var                                                            loaded from backbone.body.layer3.0.bn2.running_var                                                            of shape (256,)
2021-04-13 12:51:11,518 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn2.weight                                                                 loaded from backbone.body.layer3.0.bn2.weight                                                                 of shape (256,)
2021-04-13 12:51:11,519 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn3.bias                                                                   loaded from backbone.body.layer3.0.bn3.bias                                                                   of shape (1024,)
2021-04-13 12:51:11,519 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn3.running_mean                                                           loaded from backbone.body.layer3.0.bn3.running_mean                                                           of shape (1024,)
2021-04-13 12:51:11,519 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn3.running_var                                                            loaded from backbone.body.layer3.0.bn3.running_var                                                            of shape (1024,)
2021-04-13 12:51:11,519 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn3.weight                                                                 loaded from backbone.body.layer3.0.bn3.weight                                                                 of shape (1024,)
2021-04-13 12:51:11,519 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv1.weight                                                               loaded from backbone.body.layer3.0.conv1.weight                                                               of shape (256, 512, 1, 1)
2021-04-13 12:51:11,519 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv2.weight                                                               loaded from backbone.body.layer3.0.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-13 12:51:11,519 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv3.weight                                                               loaded from backbone.body.layer3.0.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-13 12:51:11,519 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.0.weight                                                        loaded from backbone.body.layer3.0.downsample.0.weight                                                        of shape (1024, 512, 1, 1)
2021-04-13 12:51:11,519 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.1.bias                                                          loaded from backbone.body.layer3.0.downsample.1.bias                                                          of shape (1024,)
2021-04-13 12:51:11,520 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.1.running_mean                                                  loaded from backbone.body.layer3.0.downsample.1.running_mean                                                  of shape (1024,)
2021-04-13 12:51:11,520 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.1.running_var                                                   loaded from backbone.body.layer3.0.downsample.1.running_var                                                   of shape (1024,)
2021-04-13 12:51:11,520 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.1.weight                                                        loaded from backbone.body.layer3.0.downsample.1.weight                                                        of shape (1024,)
2021-04-13 12:51:11,520 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn1.bias                                                                   loaded from backbone.body.layer3.1.bn1.bias                                                                   of shape (256,)
2021-04-13 12:51:11,520 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn1.running_mean                                                           loaded from backbone.body.layer3.1.bn1.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,520 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn1.running_var                                                            loaded from backbone.body.layer3.1.bn1.running_var                                                            of shape (256,)
2021-04-13 12:51:11,520 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn1.weight                                                                 loaded from backbone.body.layer3.1.bn1.weight                                                                 of shape (256,)
2021-04-13 12:51:11,520 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn2.bias                                                                   loaded from backbone.body.layer3.1.bn2.bias                                                                   of shape (256,)
2021-04-13 12:51:11,520 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn2.running_mean                                                           loaded from backbone.body.layer3.1.bn2.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,521 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn2.running_var                                                            loaded from backbone.body.layer3.1.bn2.running_var                                                            of shape (256,)
2021-04-13 12:51:11,521 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn2.weight                                                                 loaded from backbone.body.layer3.1.bn2.weight                                                                 of shape (256,)
2021-04-13 12:51:11,521 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn3.bias                                                                   loaded from backbone.body.layer3.1.bn3.bias                                                                   of shape (1024,)
2021-04-13 12:51:11,521 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn3.running_mean                                                           loaded from backbone.body.layer3.1.bn3.running_mean                                                           of shape (1024,)
2021-04-13 12:51:11,521 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn3.running_var                                                            loaded from backbone.body.layer3.1.bn3.running_var                                                            of shape (1024,)
2021-04-13 12:51:11,521 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn3.weight                                                                 loaded from backbone.body.layer3.1.bn3.weight                                                                 of shape (1024,)
2021-04-13 12:51:11,521 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv1.weight                                                               loaded from backbone.body.layer3.1.conv1.weight                                                               of shape (256, 1024, 1, 1)
2021-04-13 12:51:11,521 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv2.weight                                                               loaded from backbone.body.layer3.1.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-13 12:51:11,521 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv3.weight                                                               loaded from backbone.body.layer3.1.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-13 12:51:11,521 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn1.bias                                                                   loaded from backbone.body.layer3.2.bn1.bias                                                                   of shape (256,)
2021-04-13 12:51:11,522 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn1.running_mean                                                           loaded from backbone.body.layer3.2.bn1.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,522 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn1.running_var                                                            loaded from backbone.body.layer3.2.bn1.running_var                                                            of shape (256,)
2021-04-13 12:51:11,522 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn1.weight                                                                 loaded from backbone.body.layer3.2.bn1.weight                                                                 of shape (256,)
2021-04-13 12:51:11,522 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn2.bias                                                                   loaded from backbone.body.layer3.2.bn2.bias                                                                   of shape (256,)
2021-04-13 12:51:11,522 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn2.running_mean                                                           loaded from backbone.body.layer3.2.bn2.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,522 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn2.running_var                                                            loaded from backbone.body.layer3.2.bn2.running_var                                                            of shape (256,)
2021-04-13 12:51:11,522 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn2.weight                                                                 loaded from backbone.body.layer3.2.bn2.weight                                                                 of shape (256,)
2021-04-13 12:51:11,522 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn3.bias                                                                   loaded from backbone.body.layer3.2.bn3.bias                                                                   of shape (1024,)
2021-04-13 12:51:11,522 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn3.running_mean                                                           loaded from backbone.body.layer3.2.bn3.running_mean                                                           of shape (1024,)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn3.running_var                                                            loaded from backbone.body.layer3.2.bn3.running_var                                                            of shape (1024,)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn3.weight                                                                 loaded from backbone.body.layer3.2.bn3.weight                                                                 of shape (1024,)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv1.weight                                                               loaded from backbone.body.layer3.2.conv1.weight                                                               of shape (256, 1024, 1, 1)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv2.weight                                                               loaded from backbone.body.layer3.2.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv3.weight                                                               loaded from backbone.body.layer3.2.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn1.bias                                                                   loaded from backbone.body.layer3.3.bn1.bias                                                                   of shape (256,)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn1.running_mean                                                           loaded from backbone.body.layer3.3.bn1.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn1.running_var                                                            loaded from backbone.body.layer3.3.bn1.running_var                                                            of shape (256,)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn1.weight                                                                 loaded from backbone.body.layer3.3.bn1.weight                                                                 of shape (256,)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn2.bias                                                                   loaded from backbone.body.layer3.3.bn2.bias                                                                   of shape (256,)
2021-04-13 12:51:11,523 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn2.running_mean                                                           loaded from backbone.body.layer3.3.bn2.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,524 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn2.running_var                                                            loaded from backbone.body.layer3.3.bn2.running_var                                                            of shape (256,)
2021-04-13 12:51:11,524 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn2.weight                                                                 loaded from backbone.body.layer3.3.bn2.weight                                                                 of shape (256,)
2021-04-13 12:51:11,524 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn3.bias                                                                   loaded from backbone.body.layer3.3.bn3.bias                                                                   of shape (1024,)
2021-04-13 12:51:11,524 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn3.running_mean                                                           loaded from backbone.body.layer3.3.bn3.running_mean                                                           of shape (1024,)
2021-04-13 12:51:11,524 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn3.running_var                                                            loaded from backbone.body.layer3.3.bn3.running_var                                                            of shape (1024,)
2021-04-13 12:51:11,524 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn3.weight                                                                 loaded from backbone.body.layer3.3.bn3.weight                                                                 of shape (1024,)
2021-04-13 12:51:11,524 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv1.weight                                                               loaded from backbone.body.layer3.3.conv1.weight                                                               of shape (256, 1024, 1, 1)
2021-04-13 12:51:11,524 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv2.weight                                                               loaded from backbone.body.layer3.3.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-13 12:51:11,524 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv3.weight                                                               loaded from backbone.body.layer3.3.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-13 12:51:11,524 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn1.bias                                                                   loaded from backbone.body.layer3.4.bn1.bias                                                                   of shape (256,)
2021-04-13 12:51:11,525 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn1.running_mean                                                           loaded from backbone.body.layer3.4.bn1.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,525 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn1.running_var                                                            loaded from backbone.body.layer3.4.bn1.running_var                                                            of shape (256,)
2021-04-13 12:51:11,525 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn1.weight                                                                 loaded from backbone.body.layer3.4.bn1.weight                                                                 of shape (256,)
2021-04-13 12:51:11,525 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn2.bias                                                                   loaded from backbone.body.layer3.4.bn2.bias                                                                   of shape (256,)
2021-04-13 12:51:11,525 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn2.running_mean                                                           loaded from backbone.body.layer3.4.bn2.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,525 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn2.running_var                                                            loaded from backbone.body.layer3.4.bn2.running_var                                                            of shape (256,)
2021-04-13 12:51:11,525 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn2.weight                                                                 loaded from backbone.body.layer3.4.bn2.weight                                                                 of shape (256,)
2021-04-13 12:51:11,525 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn3.bias                                                                   loaded from backbone.body.layer3.4.bn3.bias                                                                   of shape (1024,)
2021-04-13 12:51:11,525 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn3.running_mean                                                           loaded from backbone.body.layer3.4.bn3.running_mean                                                           of shape (1024,)
2021-04-13 12:51:11,525 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn3.running_var                                                            loaded from backbone.body.layer3.4.bn3.running_var                                                            of shape (1024,)
2021-04-13 12:51:11,526 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn3.weight                                                                 loaded from backbone.body.layer3.4.bn3.weight                                                                 of shape (1024,)
2021-04-13 12:51:11,526 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv1.weight                                                               loaded from backbone.body.layer3.4.conv1.weight                                                               of shape (256, 1024, 1, 1)
2021-04-13 12:51:11,526 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv2.weight                                                               loaded from backbone.body.layer3.4.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-13 12:51:11,526 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv3.weight                                                               loaded from backbone.body.layer3.4.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-13 12:51:11,526 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn1.bias                                                                   loaded from backbone.body.layer3.5.bn1.bias                                                                   of shape (256,)
2021-04-13 12:51:11,526 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn1.running_mean                                                           loaded from backbone.body.layer3.5.bn1.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,526 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn1.running_var                                                            loaded from backbone.body.layer3.5.bn1.running_var                                                            of shape (256,)
2021-04-13 12:51:11,526 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn1.weight                                                                 loaded from backbone.body.layer3.5.bn1.weight                                                                 of shape (256,)
2021-04-13 12:51:11,526 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn2.bias                                                                   loaded from backbone.body.layer3.5.bn2.bias                                                                   of shape (256,)
2021-04-13 12:51:11,527 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn2.running_mean                                                           loaded from backbone.body.layer3.5.bn2.running_mean                                                           of shape (256,)
2021-04-13 12:51:11,527 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn2.running_var                                                            loaded from backbone.body.layer3.5.bn2.running_var                                                            of shape (256,)
2021-04-13 12:51:11,527 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn2.weight                                                                 loaded from backbone.body.layer3.5.bn2.weight                                                                 of shape (256,)
2021-04-13 12:51:11,527 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn3.bias                                                                   loaded from backbone.body.layer3.5.bn3.bias                                                                   of shape (1024,)
2021-04-13 12:51:11,527 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn3.running_mean                                                           loaded from backbone.body.layer3.5.bn3.running_mean                                                           of shape (1024,)
2021-04-13 12:51:11,527 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn3.running_var                                                            loaded from backbone.body.layer3.5.bn3.running_var                                                            of shape (1024,)
2021-04-13 12:51:11,527 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn3.weight                                                                 loaded from backbone.body.layer3.5.bn3.weight                                                                 of shape (1024,)
2021-04-13 12:51:11,527 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv1.weight                                                               loaded from backbone.body.layer3.5.conv1.weight                                                               of shape (256, 1024, 1, 1)
2021-04-13 12:51:11,527 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv2.weight                                                               loaded from backbone.body.layer3.5.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-13 12:51:11,527 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv3.weight                                                               loaded from backbone.body.layer3.5.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-13 12:51:11,528 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn1.bias                                                                   loaded from backbone.body.layer4.0.bn1.bias                                                                   of shape (512,)
2021-04-13 12:51:11,528 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn1.running_mean                                                           loaded from backbone.body.layer4.0.bn1.running_mean                                                           of shape (512,)
2021-04-13 12:51:11,528 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn1.running_var                                                            loaded from backbone.body.layer4.0.bn1.running_var                                                            of shape (512,)
2021-04-13 12:51:11,528 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn1.weight                                                                 loaded from backbone.body.layer4.0.bn1.weight                                                                 of shape (512,)
2021-04-13 12:51:11,528 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn2.bias                                                                   loaded from backbone.body.layer4.0.bn2.bias                                                                   of shape (512,)
2021-04-13 12:51:11,528 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn2.running_mean                                                           loaded from backbone.body.layer4.0.bn2.running_mean                                                           of shape (512,)
2021-04-13 12:51:11,528 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn2.running_var                                                            loaded from backbone.body.layer4.0.bn2.running_var                                                            of shape (512,)
2021-04-13 12:51:11,528 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn2.weight                                                                 loaded from backbone.body.layer4.0.bn2.weight                                                                 of shape (512,)
2021-04-13 12:51:11,528 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn3.bias                                                                   loaded from backbone.body.layer4.0.bn3.bias                                                                   of shape (2048,)
2021-04-13 12:51:11,528 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn3.running_mean                                                           loaded from backbone.body.layer4.0.bn3.running_mean                                                           of shape (2048,)
2021-04-13 12:51:11,529 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn3.running_var                                                            loaded from backbone.body.layer4.0.bn3.running_var                                                            of shape (2048,)
2021-04-13 12:51:11,529 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn3.weight                                                                 loaded from backbone.body.layer4.0.bn3.weight                                                                 of shape (2048,)
2021-04-13 12:51:11,529 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv1.weight                                                               loaded from backbone.body.layer4.0.conv1.weight                                                               of shape (512, 1024, 1, 1)
2021-04-13 12:51:11,529 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv2.weight                                                               loaded from backbone.body.layer4.0.conv2.weight                                                               of shape (512, 512, 3, 3)
2021-04-13 12:51:11,529 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv3.weight                                                               loaded from backbone.body.layer4.0.conv3.weight                                                               of shape (2048, 512, 1, 1)
2021-04-13 12:51:11,529 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.0.weight                                                        loaded from backbone.body.layer4.0.downsample.0.weight                                                        of shape (2048, 1024, 1, 1)
2021-04-13 12:51:11,529 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.1.bias                                                          loaded from backbone.body.layer4.0.downsample.1.bias                                                          of shape (2048,)
2021-04-13 12:51:11,529 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.1.running_mean                                                  loaded from backbone.body.layer4.0.downsample.1.running_mean                                                  of shape (2048,)
2021-04-13 12:51:11,529 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.1.running_var                                                   loaded from backbone.body.layer4.0.downsample.1.running_var                                                   of shape (2048,)
2021-04-13 12:51:11,530 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.1.weight                                                        loaded from backbone.body.layer4.0.downsample.1.weight                                                        of shape (2048,)
2021-04-13 12:51:11,530 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn1.bias                                                                   loaded from backbone.body.layer4.1.bn1.bias                                                                   of shape (512,)
2021-04-13 12:51:11,530 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn1.running_mean                                                           loaded from backbone.body.layer4.1.bn1.running_mean                                                           of shape (512,)
2021-04-13 12:51:11,530 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn1.running_var                                                            loaded from backbone.body.layer4.1.bn1.running_var                                                            of shape (512,)
2021-04-13 12:51:11,530 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn1.weight                                                                 loaded from backbone.body.layer4.1.bn1.weight                                                                 of shape (512,)
2021-04-13 12:51:11,530 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn2.bias                                                                   loaded from backbone.body.layer4.1.bn2.bias                                                                   of shape (512,)
2021-04-13 12:51:11,530 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn2.running_mean                                                           loaded from backbone.body.layer4.1.bn2.running_mean                                                           of shape (512,)
2021-04-13 12:51:11,530 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn2.running_var                                                            loaded from backbone.body.layer4.1.bn2.running_var                                                            of shape (512,)
2021-04-13 12:51:11,530 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn2.weight                                                                 loaded from backbone.body.layer4.1.bn2.weight                                                                 of shape (512,)
2021-04-13 12:51:11,530 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn3.bias                                                                   loaded from backbone.body.layer4.1.bn3.bias                                                                   of shape (2048,)
2021-04-13 12:51:11,531 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn3.running_mean                                                           loaded from backbone.body.layer4.1.bn3.running_mean                                                           of shape (2048,)
2021-04-13 12:51:11,531 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn3.running_var                                                            loaded from backbone.body.layer4.1.bn3.running_var                                                            of shape (2048,)
2021-04-13 12:51:11,531 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn3.weight                                                                 loaded from backbone.body.layer4.1.bn3.weight                                                                 of shape (2048,)
2021-04-13 12:51:11,531 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv1.weight                                                               loaded from backbone.body.layer4.1.conv1.weight                                                               of shape (512, 2048, 1, 1)
2021-04-13 12:51:11,531 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv2.weight                                                               loaded from backbone.body.layer4.1.conv2.weight                                                               of shape (512, 512, 3, 3)
2021-04-13 12:51:11,531 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv3.weight                                                               loaded from backbone.body.layer4.1.conv3.weight                                                               of shape (2048, 512, 1, 1)
2021-04-13 12:51:11,531 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn1.bias                                                                   loaded from backbone.body.layer4.2.bn1.bias                                                                   of shape (512,)
2021-04-13 12:51:11,531 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn1.running_mean                                                           loaded from backbone.body.layer4.2.bn1.running_mean                                                           of shape (512,)
2021-04-13 12:51:11,531 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn1.running_var                                                            loaded from backbone.body.layer4.2.bn1.running_var                                                            of shape (512,)
2021-04-13 12:51:11,532 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn1.weight                                                                 loaded from backbone.body.layer4.2.bn1.weight                                                                 of shape (512,)
2021-04-13 12:51:11,532 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn2.bias                                                                   loaded from backbone.body.layer4.2.bn2.bias                                                                   of shape (512,)
2021-04-13 12:51:11,532 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn2.running_mean                                                           loaded from backbone.body.layer4.2.bn2.running_mean                                                           of shape (512,)
2021-04-13 12:51:11,532 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn2.running_var                                                            loaded from backbone.body.layer4.2.bn2.running_var                                                            of shape (512,)
2021-04-13 12:51:11,532 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn2.weight                                                                 loaded from backbone.body.layer4.2.bn2.weight                                                                 of shape (512,)
2021-04-13 12:51:11,532 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn3.bias                                                                   loaded from backbone.body.layer4.2.bn3.bias                                                                   of shape (2048,)
2021-04-13 12:51:11,532 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn3.running_mean                                                           loaded from backbone.body.layer4.2.bn3.running_mean                                                           of shape (2048,)
2021-04-13 12:51:11,532 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn3.running_var                                                            loaded from backbone.body.layer4.2.bn3.running_var                                                            of shape (2048,)
2021-04-13 12:51:11,532 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn3.weight                                                                 loaded from backbone.body.layer4.2.bn3.weight                                                                 of shape (2048,)
2021-04-13 12:51:11,532 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv1.weight                                                               loaded from backbone.body.layer4.2.conv1.weight                                                               of shape (512, 2048, 1, 1)
2021-04-13 12:51:11,533 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv2.weight                                                               loaded from backbone.body.layer4.2.conv2.weight                                                               of shape (512, 512, 3, 3)
2021-04-13 12:51:11,533 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv3.weight                                                               loaded from backbone.body.layer4.2.conv3.weight                                                               of shape (2048, 512, 1, 1)
2021-04-13 12:51:11,533 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.bn1.bias                                                                       loaded from backbone.body.stem.bn1.bias                                                                       of shape (64,)
2021-04-13 12:51:11,533 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.bn1.running_mean                                                               loaded from backbone.body.stem.bn1.running_mean                                                               of shape (64,)
2021-04-13 12:51:11,533 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.bn1.running_var                                                                loaded from backbone.body.stem.bn1.running_var                                                                of shape (64,)
2021-04-13 12:51:11,533 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.bn1.weight                                                                     loaded from backbone.body.stem.bn1.weight                                                                     of shape (64,)
2021-04-13 12:51:11,533 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.conv1.weight                                                                   loaded from backbone.body.stem.conv1.weight                                                                   of shape (64, 3, 7, 7)
2021-04-13 12:51:11,533 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.embeddings.LayerNorm.bias                                       loaded from language_backbone.body.bert_model.embeddings.LayerNorm.bias                                       of shape (768,)
2021-04-13 12:51:11,533 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.embeddings.LayerNorm.weight                                     loaded from language_backbone.body.bert_model.embeddings.LayerNorm.weight                                     of shape (768,)
2021-04-13 12:51:11,534 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.embeddings.position_embeddings.weight                           loaded from language_backbone.body.bert_model.embeddings.position_embeddings.weight                           of shape (512, 768)
2021-04-13 12:51:11,534 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.embeddings.token_type_embeddings.weight                         loaded from language_backbone.body.bert_model.embeddings.token_type_embeddings.weight                         of shape (2, 768)
2021-04-13 12:51:11,534 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.embeddings.word_embeddings.weight                               loaded from language_backbone.body.bert_model.embeddings.word_embeddings.weight                               of shape (30522, 768)
2021-04-13 12:51:11,534 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.0.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-13 12:51:11,534 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.0.attention.output.LayerNorm.weight               of shape (768,)
2021-04-13 12:51:11,534 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.0.attention.output.dense.bias                     of shape (768,)
2021-04-13 12:51:11,534 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.0.attention.output.dense.weight                   of shape (768, 768)
2021-04-13 12:51:11,534 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.key.bias                         of shape (768,)
2021-04-13 12:51:11,534 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.key.weight                       of shape (768, 768)
2021-04-13 12:51:11,535 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.query.bias                       of shape (768,)
2021-04-13 12:51:11,535 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.query.weight                     of shape (768, 768)
2021-04-13 12:51:11,535 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.value.bias                       of shape (768,)
2021-04-13 12:51:11,535 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.value.weight                     of shape (768, 768)
2021-04-13 12:51:11,535 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.0.intermediate.dense.bias                         of shape (3072,)
2021-04-13 12:51:11,535 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.0.intermediate.dense.weight                       of shape (3072, 768)
2021-04-13 12:51:11,535 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.0.output.LayerNorm.bias                           of shape (768,)
2021-04-13 12:51:11,535 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.0.output.LayerNorm.weight                         of shape (768,)
2021-04-13 12:51:11,535 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.0.output.dense.bias                               of shape (768,)
2021-04-13 12:51:11,536 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.0.output.dense.weight                             of shape (768, 3072)
2021-04-13 12:51:11,536 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.1.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-13 12:51:11,536 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.1.attention.output.LayerNorm.weight               of shape (768,)
2021-04-13 12:51:11,536 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.1.attention.output.dense.bias                     of shape (768,)
2021-04-13 12:51:11,536 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.1.attention.output.dense.weight                   of shape (768, 768)
2021-04-13 12:51:11,536 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.key.bias                         of shape (768,)
2021-04-13 12:51:11,536 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.key.weight                       of shape (768, 768)
2021-04-13 12:51:11,536 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.query.bias                       of shape (768,)
2021-04-13 12:51:11,536 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.query.weight                     of shape (768, 768)
2021-04-13 12:51:11,537 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.value.bias                       of shape (768,)
2021-04-13 12:51:11,537 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.value.weight                     of shape (768, 768)
2021-04-13 12:51:11,537 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.1.intermediate.dense.bias                         of shape (3072,)
2021-04-13 12:51:11,537 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.1.intermediate.dense.weight                       of shape (3072, 768)
2021-04-13 12:51:11,537 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.1.output.LayerNorm.bias                           of shape (768,)
2021-04-13 12:51:11,537 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.1.output.LayerNorm.weight                         of shape (768,)
2021-04-13 12:51:11,537 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.1.output.dense.bias                               of shape (768,)
2021-04-13 12:51:11,537 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.1.output.dense.weight                             of shape (768, 3072)
2021-04-13 12:51:11,537 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.output.LayerNorm.bias                loaded from language_backbone.body.bert_model.encoder.layer.10.attention.output.LayerNorm.bias                of shape (768,)
2021-04-13 12:51:11,537 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.output.LayerNorm.weight              loaded from language_backbone.body.bert_model.encoder.layer.10.attention.output.LayerNorm.weight              of shape (768,)
2021-04-13 12:51:11,538 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.output.dense.bias                    loaded from language_backbone.body.bert_model.encoder.layer.10.attention.output.dense.bias                    of shape (768,)
2021-04-13 12:51:11,538 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.output.dense.weight                  loaded from language_backbone.body.bert_model.encoder.layer.10.attention.output.dense.weight                  of shape (768, 768)
2021-04-13 12:51:11,538 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.key.bias                        loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.key.bias                        of shape (768,)
2021-04-13 12:51:11,538 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.key.weight                      loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.key.weight                      of shape (768, 768)
2021-04-13 12:51:11,538 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.query.bias                      loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.query.bias                      of shape (768,)
2021-04-13 12:51:11,538 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.query.weight                    loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.query.weight                    of shape (768, 768)
2021-04-13 12:51:11,538 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.value.bias                      loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.value.bias                      of shape (768,)
2021-04-13 12:51:11,538 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.value.weight                    loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.value.weight                    of shape (768, 768)
2021-04-13 12:51:11,538 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.intermediate.dense.bias                        loaded from language_backbone.body.bert_model.encoder.layer.10.intermediate.dense.bias                        of shape (3072,)
2021-04-13 12:51:11,539 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.intermediate.dense.weight                      loaded from language_backbone.body.bert_model.encoder.layer.10.intermediate.dense.weight                      of shape (3072, 768)
2021-04-13 12:51:11,539 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.output.LayerNorm.bias                          loaded from language_backbone.body.bert_model.encoder.layer.10.output.LayerNorm.bias                          of shape (768,)
2021-04-13 12:51:11,539 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.output.LayerNorm.weight                        loaded from language_backbone.body.bert_model.encoder.layer.10.output.LayerNorm.weight                        of shape (768,)
2021-04-13 12:51:11,539 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.output.dense.bias                              loaded from language_backbone.body.bert_model.encoder.layer.10.output.dense.bias                              of shape (768,)
2021-04-13 12:51:11,539 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.output.dense.weight                            loaded from language_backbone.body.bert_model.encoder.layer.10.output.dense.weight                            of shape (768, 3072)
2021-04-13 12:51:11,539 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.output.LayerNorm.bias                loaded from language_backbone.body.bert_model.encoder.layer.11.attention.output.LayerNorm.bias                of shape (768,)
2021-04-13 12:51:11,539 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.output.LayerNorm.weight              loaded from language_backbone.body.bert_model.encoder.layer.11.attention.output.LayerNorm.weight              of shape (768,)
2021-04-13 12:51:11,539 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.output.dense.bias                    loaded from language_backbone.body.bert_model.encoder.layer.11.attention.output.dense.bias                    of shape (768,)
2021-04-13 12:51:11,539 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.output.dense.weight                  loaded from language_backbone.body.bert_model.encoder.layer.11.attention.output.dense.weight                  of shape (768, 768)
2021-04-13 12:51:11,540 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.key.bias                        loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.key.bias                        of shape (768,)
2021-04-13 12:51:11,540 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.key.weight                      loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.key.weight                      of shape (768, 768)
2021-04-13 12:51:11,540 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.query.bias                      loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.query.bias                      of shape (768,)
2021-04-13 12:51:11,540 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.query.weight                    loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.query.weight                    of shape (768, 768)
2021-04-13 12:51:11,540 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.value.bias                      loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.value.bias                      of shape (768,)
2021-04-13 12:51:11,540 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.value.weight                    loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.value.weight                    of shape (768, 768)
2021-04-13 12:51:11,540 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.intermediate.dense.bias                        loaded from language_backbone.body.bert_model.encoder.layer.11.intermediate.dense.bias                        of shape (3072,)
2021-04-13 12:51:11,540 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.intermediate.dense.weight                      loaded from language_backbone.body.bert_model.encoder.layer.11.intermediate.dense.weight                      of shape (3072, 768)
2021-04-13 12:51:11,540 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.output.LayerNorm.bias                          loaded from language_backbone.body.bert_model.encoder.layer.11.output.LayerNorm.bias                          of shape (768,)
2021-04-13 12:51:11,541 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.output.LayerNorm.weight                        loaded from language_backbone.body.bert_model.encoder.layer.11.output.LayerNorm.weight                        of shape (768,)
2021-04-13 12:51:11,541 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.output.dense.bias                              loaded from language_backbone.body.bert_model.encoder.layer.11.output.dense.bias                              of shape (768,)
2021-04-13 12:51:11,541 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.output.dense.weight                            loaded from language_backbone.body.bert_model.encoder.layer.11.output.dense.weight                            of shape (768, 3072)
2021-04-13 12:51:11,541 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.2.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-13 12:51:11,541 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.2.attention.output.LayerNorm.weight               of shape (768,)
2021-04-13 12:51:11,541 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.2.attention.output.dense.bias                     of shape (768,)
2021-04-13 12:51:11,541 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.2.attention.output.dense.weight                   of shape (768, 768)
2021-04-13 12:51:11,541 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.key.bias                         of shape (768,)
2021-04-13 12:51:11,541 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.key.weight                       of shape (768, 768)
2021-04-13 12:51:11,541 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.query.bias                       of shape (768,)
2021-04-13 12:51:11,542 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.query.weight                     of shape (768, 768)
2021-04-13 12:51:11,542 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.value.bias                       of shape (768,)
2021-04-13 12:51:11,542 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.value.weight                     of shape (768, 768)
2021-04-13 12:51:11,542 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.2.intermediate.dense.bias                         of shape (3072,)
2021-04-13 12:51:11,542 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.2.intermediate.dense.weight                       of shape (3072, 768)
2021-04-13 12:51:11,542 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.2.output.LayerNorm.bias                           of shape (768,)
2021-04-13 12:51:11,542 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.2.output.LayerNorm.weight                         of shape (768,)
2021-04-13 12:51:11,542 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.2.output.dense.bias                               of shape (768,)
2021-04-13 12:51:11,543 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.2.output.dense.weight                             of shape (768, 3072)
2021-04-13 12:51:11,543 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.3.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-13 12:51:11,543 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.3.attention.output.LayerNorm.weight               of shape (768,)
2021-04-13 12:51:11,543 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.3.attention.output.dense.bias                     of shape (768,)
2021-04-13 12:51:11,543 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.3.attention.output.dense.weight                   of shape (768, 768)
2021-04-13 12:51:11,543 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.key.bias                         of shape (768,)
2021-04-13 12:51:11,543 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.key.weight                       of shape (768, 768)
2021-04-13 12:51:11,543 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.query.bias                       of shape (768,)
2021-04-13 12:51:11,543 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.query.weight                     of shape (768, 768)
2021-04-13 12:51:11,544 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.value.bias                       of shape (768,)
2021-04-13 12:51:11,544 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.value.weight                     of shape (768, 768)
2021-04-13 12:51:11,544 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.3.intermediate.dense.bias                         of shape (3072,)
2021-04-13 12:51:11,544 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.3.intermediate.dense.weight                       of shape (3072, 768)
2021-04-13 12:51:11,544 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.3.output.LayerNorm.bias                           of shape (768,)
2021-04-13 12:51:11,544 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.3.output.LayerNorm.weight                         of shape (768,)
2021-04-13 12:51:11,544 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.3.output.dense.bias                               of shape (768,)
2021-04-13 12:51:11,544 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.3.output.dense.weight                             of shape (768, 3072)
2021-04-13 12:51:11,545 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.4.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-13 12:51:11,545 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.4.attention.output.LayerNorm.weight               of shape (768,)
2021-04-13 12:51:11,545 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.4.attention.output.dense.bias                     of shape (768,)
2021-04-13 12:51:11,545 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.4.attention.output.dense.weight                   of shape (768, 768)
2021-04-13 12:51:11,545 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.key.bias                         of shape (768,)
2021-04-13 12:51:11,545 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.key.weight                       of shape (768, 768)
2021-04-13 12:51:11,545 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.query.bias                       of shape (768,)
2021-04-13 12:51:11,545 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.query.weight                     of shape (768, 768)
2021-04-13 12:51:11,546 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.value.bias                       of shape (768,)
2021-04-13 12:51:11,546 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.value.weight                     of shape (768, 768)
2021-04-13 12:51:11,546 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.4.intermediate.dense.bias                         of shape (3072,)
2021-04-13 12:51:11,546 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.4.intermediate.dense.weight                       of shape (3072, 768)
2021-04-13 12:51:11,546 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.4.output.LayerNorm.bias                           of shape (768,)
2021-04-13 12:51:11,546 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.4.output.LayerNorm.weight                         of shape (768,)
2021-04-13 12:51:11,546 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.4.output.dense.bias                               of shape (768,)
2021-04-13 12:51:11,546 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.4.output.dense.weight                             of shape (768, 3072)
2021-04-13 12:51:11,546 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.5.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-13 12:51:11,547 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.5.attention.output.LayerNorm.weight               of shape (768,)
2021-04-13 12:51:11,547 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.5.attention.output.dense.bias                     of shape (768,)
2021-04-13 12:51:11,547 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.5.attention.output.dense.weight                   of shape (768, 768)
2021-04-13 12:51:11,547 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.key.bias                         of shape (768,)
2021-04-13 12:51:11,547 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.key.weight                       of shape (768, 768)
2021-04-13 12:51:11,547 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.query.bias                       of shape (768,)
2021-04-13 12:51:11,547 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.query.weight                     of shape (768, 768)
2021-04-13 12:51:11,547 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.value.bias                       of shape (768,)
2021-04-13 12:51:11,548 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.value.weight                     of shape (768, 768)
2021-04-13 12:51:11,548 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.5.intermediate.dense.bias                         of shape (3072,)
2021-04-13 12:51:11,548 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.5.intermediate.dense.weight                       of shape (3072, 768)
2021-04-13 12:51:11,548 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.5.output.LayerNorm.bias                           of shape (768,)
2021-04-13 12:51:11,548 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.5.output.LayerNorm.weight                         of shape (768,)
2021-04-13 12:51:11,548 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.5.output.dense.bias                               of shape (768,)
2021-04-13 12:51:11,548 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.5.output.dense.weight                             of shape (768, 3072)
2021-04-13 12:51:11,548 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.6.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-13 12:51:11,548 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.6.attention.output.LayerNorm.weight               of shape (768,)
2021-04-13 12:51:11,549 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.6.attention.output.dense.bias                     of shape (768,)
2021-04-13 12:51:11,549 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.6.attention.output.dense.weight                   of shape (768, 768)
2021-04-13 12:51:11,549 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.key.bias                         of shape (768,)
2021-04-13 12:51:11,549 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.key.weight                       of shape (768, 768)
2021-04-13 12:51:11,549 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.query.bias                       of shape (768,)
2021-04-13 12:51:11,549 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.query.weight                     of shape (768, 768)
2021-04-13 12:51:11,549 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.value.bias                       of shape (768,)
2021-04-13 12:51:11,549 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.value.weight                     of shape (768, 768)
2021-04-13 12:51:11,550 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.6.intermediate.dense.bias                         of shape (3072,)
2021-04-13 12:51:11,550 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.6.intermediate.dense.weight                       of shape (3072, 768)
2021-04-13 12:51:11,550 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.6.output.LayerNorm.bias                           of shape (768,)
2021-04-13 12:51:11,550 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.6.output.LayerNorm.weight                         of shape (768,)
2021-04-13 12:51:11,550 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.6.output.dense.bias                               of shape (768,)
2021-04-13 12:51:11,550 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.6.output.dense.weight                             of shape (768, 3072)
2021-04-13 12:51:11,550 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.7.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-13 12:51:11,550 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.7.attention.output.LayerNorm.weight               of shape (768,)
2021-04-13 12:51:11,551 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.7.attention.output.dense.bias                     of shape (768,)
2021-04-13 12:51:11,551 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.7.attention.output.dense.weight                   of shape (768, 768)
2021-04-13 12:51:11,551 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.key.bias                         of shape (768,)
2021-04-13 12:51:11,551 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.key.weight                       of shape (768, 768)
2021-04-13 12:51:11,551 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.query.bias                       of shape (768,)
2021-04-13 12:51:11,551 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.query.weight                     of shape (768, 768)
2021-04-13 12:51:11,551 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.value.bias                       of shape (768,)
2021-04-13 12:51:11,551 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.value.weight                     of shape (768, 768)
2021-04-13 12:51:11,551 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.7.intermediate.dense.bias                         of shape (3072,)
2021-04-13 12:51:11,552 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.7.intermediate.dense.weight                       of shape (3072, 768)
2021-04-13 12:51:11,552 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.7.output.LayerNorm.bias                           of shape (768,)
2021-04-13 12:51:11,552 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.7.output.LayerNorm.weight                         of shape (768,)
2021-04-13 12:51:11,552 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.7.output.dense.bias                               of shape (768,)
2021-04-13 12:51:11,552 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.7.output.dense.weight                             of shape (768, 3072)
2021-04-13 12:51:11,552 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.8.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-13 12:51:11,552 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.8.attention.output.LayerNorm.weight               of shape (768,)
2021-04-13 12:51:11,552 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.8.attention.output.dense.bias                     of shape (768,)
2021-04-13 12:51:11,552 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.8.attention.output.dense.weight                   of shape (768, 768)
2021-04-13 12:51:11,553 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.key.bias                         of shape (768,)
2021-04-13 12:51:11,553 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.key.weight                       of shape (768, 768)
2021-04-13 12:51:11,553 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.query.bias                       of shape (768,)
2021-04-13 12:51:11,553 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.query.weight                     of shape (768, 768)
2021-04-13 12:51:11,553 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.value.bias                       of shape (768,)
2021-04-13 12:51:11,553 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.value.weight                     of shape (768, 768)
2021-04-13 12:51:11,553 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.8.intermediate.dense.bias                         of shape (3072,)
2021-04-13 12:51:11,553 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.8.intermediate.dense.weight                       of shape (3072, 768)
2021-04-13 12:51:11,554 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.8.output.LayerNorm.bias                           of shape (768,)
2021-04-13 12:51:11,554 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.8.output.LayerNorm.weight                         of shape (768,)
2021-04-13 12:51:11,554 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.8.output.dense.bias                               of shape (768,)
2021-04-13 12:51:11,554 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.8.output.dense.weight                             of shape (768, 3072)
2021-04-13 12:51:11,554 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.9.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-13 12:51:11,554 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.9.attention.output.LayerNorm.weight               of shape (768,)
2021-04-13 12:51:11,554 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.9.attention.output.dense.bias                     of shape (768,)
2021-04-13 12:51:11,554 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.9.attention.output.dense.weight                   of shape (768, 768)
2021-04-13 12:51:11,554 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.key.bias                         of shape (768,)
2021-04-13 12:51:11,555 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.key.weight                       of shape (768, 768)
2021-04-13 12:51:11,555 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.query.bias                       of shape (768,)
2021-04-13 12:51:11,555 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.query.weight                     of shape (768, 768)
2021-04-13 12:51:11,555 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.value.bias                       of shape (768,)
2021-04-13 12:51:11,555 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.value.weight                     of shape (768, 768)
2021-04-13 12:51:11,555 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.9.intermediate.dense.bias                         of shape (3072,)
2021-04-13 12:51:11,555 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.9.intermediate.dense.weight                       of shape (3072, 768)
2021-04-13 12:51:11,555 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.9.output.LayerNorm.bias                           of shape (768,)
2021-04-13 12:51:11,555 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.9.output.LayerNorm.weight                         of shape (768,)
2021-04-13 12:51:11,556 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.9.output.dense.bias                               of shape (768,)
2021-04-13 12:51:11,556 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.9.output.dense.weight                             of shape (768, 3072)
2021-04-13 12:51:11,556 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.pooler.dense.bias                                               loaded from language_backbone.body.bert_model.pooler.dense.bias                                               of shape (768,)
2021-04-13 12:51:11,556 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.pooler.dense.weight                                             loaded from language_backbone.body.bert_model.pooler.dense.weight                                             of shape (768, 768)
2021-04-13 12:51:11,556 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.embeddings                                                                 loaded from language_backbone.body.embeddings                                                                 of shape (30522, 768)
2021-04-13 12:51:11,556 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.GroundingHead.v2l_projection.bias                                                      loaded from mmss_heads.GroundingHead.v2l_projection.bias                                                      of shape (768,)
2021-04-13 12:51:11,556 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.GroundingHead.v2l_projection.weight                                                    loaded from mmss_heads.GroundingHead.v2l_projection.weight                                                    of shape (768, 2048)
2021-04-13 12:51:11,557 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.embeddings.LayerNorm.bias                          loaded from mmss_heads.TransformerHead.backbone.bert_model.embeddings.LayerNorm.bias                          of shape (768,)
2021-04-13 12:51:11,557 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.embeddings.LayerNorm.weight                        loaded from mmss_heads.TransformerHead.backbone.bert_model.embeddings.LayerNorm.weight                        of shape (768,)
2021-04-13 12:51:11,557 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.embeddings.position_embeddings.weight              loaded from mmss_heads.TransformerHead.backbone.bert_model.embeddings.position_embeddings.weight              of shape (512, 768)
2021-04-13 12:51:11,557 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.embeddings.token_type_embeddings.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.embeddings.token_type_embeddings.weight            of shape (2, 768)
2021-04-13 12:51:11,557 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.embeddings.word_embeddings.weight                  loaded from mmss_heads.TransformerHead.backbone.bert_model.embeddings.word_embeddings.weight                  of shape (30522, 768)
2021-04-13 12:51:11,557 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.LayerNorm.bias    of shape (768,)
2021-04-13 12:51:11,557 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.LayerNorm.weight  of shape (768,)
2021-04-13 12:51:11,557 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.dense.bias        of shape (768,)
2021-04-13 12:51:11,557 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.dense.weight      of shape (768, 768)
2021-04-13 12:51:11,558 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.key.bias            of shape (768,)
2021-04-13 12:51:11,558 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.key.weight          of shape (768, 768)
2021-04-13 12:51:11,558 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.query.bias          of shape (768,)
2021-04-13 12:51:11,558 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.query.weight        of shape (768, 768)
2021-04-13 12:51:11,558 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.value.bias          of shape (768,)
2021-04-13 12:51:11,558 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.value.weight        of shape (768, 768)
2021-04-13 12:51:11,558 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.intermediate.dense.bias            of shape (3072,)
2021-04-13 12:51:11,558 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.intermediate.dense.weight          of shape (3072, 768)
2021-04-13 12:51:11,558 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.LayerNorm.bias              of shape (768,)
2021-04-13 12:51:11,559 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.LayerNorm.weight            of shape (768,)
2021-04-13 12:51:11,559 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.dense.bias                  of shape (768,)
2021-04-13 12:51:11,559 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.dense.weight                of shape (768, 3072)
2021-04-13 12:51:11,559 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.LayerNorm.bias    of shape (768,)
2021-04-13 12:51:11,559 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.LayerNorm.weight  of shape (768,)
2021-04-13 12:51:11,559 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.dense.bias        of shape (768,)
2021-04-13 12:51:11,559 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.dense.weight      of shape (768, 768)
2021-04-13 12:51:11,559 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.key.bias            of shape (768,)
2021-04-13 12:51:11,560 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.key.weight          of shape (768, 768)
2021-04-13 12:51:11,560 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.query.bias          of shape (768,)
2021-04-13 12:51:11,560 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.query.weight        of shape (768, 768)
2021-04-13 12:51:11,560 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.value.bias          of shape (768,)
2021-04-13 12:51:11,560 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.value.weight        of shape (768, 768)
2021-04-13 12:51:11,560 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.intermediate.dense.bias            of shape (3072,)
2021-04-13 12:51:11,560 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.intermediate.dense.weight          of shape (3072, 768)
2021-04-13 12:51:11,560 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.LayerNorm.bias              of shape (768,)
2021-04-13 12:51:11,560 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.LayerNorm.weight            of shape (768,)
2021-04-13 12:51:11,561 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.dense.bias                  of shape (768,)
2021-04-13 12:51:11,561 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.dense.weight                of shape (768, 3072)
2021-04-13 12:51:11,561 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.LayerNorm.bias   loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.LayerNorm.bias   of shape (768,)
2021-04-13 12:51:11,561 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.LayerNorm.weight loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.LayerNorm.weight of shape (768,)
2021-04-13 12:51:11,561 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.dense.bias       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.dense.bias       of shape (768,)
2021-04-13 12:51:11,561 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.dense.weight     loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.dense.weight     of shape (768, 768)
2021-04-13 12:51:11,561 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.key.bias           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.key.bias           of shape (768,)
2021-04-13 12:51:11,561 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.key.weight         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.key.weight         of shape (768, 768)
2021-04-13 12:51:11,561 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.query.bias         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.query.bias         of shape (768,)
2021-04-13 12:51:11,562 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.query.weight       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.query.weight       of shape (768, 768)
2021-04-13 12:51:11,562 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.value.bias         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.value.bias         of shape (768,)
2021-04-13 12:51:11,562 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.value.weight       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.value.weight       of shape (768, 768)
2021-04-13 12:51:11,562 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.intermediate.dense.bias           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.intermediate.dense.bias           of shape (3072,)
2021-04-13 12:51:11,562 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.intermediate.dense.weight         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.intermediate.dense.weight         of shape (3072, 768)
2021-04-13 12:51:11,562 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.LayerNorm.bias             loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.LayerNorm.bias             of shape (768,)
2021-04-13 12:51:11,562 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.LayerNorm.weight           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.LayerNorm.weight           of shape (768,)
2021-04-13 12:51:11,563 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.dense.bias                 loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.dense.bias                 of shape (768,)
2021-04-13 12:51:11,563 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.dense.weight               loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.dense.weight               of shape (768, 3072)
2021-04-13 12:51:11,563 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.LayerNorm.bias   loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.LayerNorm.bias   of shape (768,)
2021-04-13 12:51:11,563 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.LayerNorm.weight loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.LayerNorm.weight of shape (768,)
2021-04-13 12:51:11,563 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.dense.bias       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.dense.bias       of shape (768,)
2021-04-13 12:51:11,563 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.dense.weight     loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.dense.weight     of shape (768, 768)
2021-04-13 12:51:11,563 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.key.bias           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.key.bias           of shape (768,)
2021-04-13 12:51:11,564 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.key.weight         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.key.weight         of shape (768, 768)
2021-04-13 12:51:11,564 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.query.bias         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.query.bias         of shape (768,)
2021-04-13 12:51:11,564 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.query.weight       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.query.weight       of shape (768, 768)
2021-04-13 12:51:11,564 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.value.bias         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.value.bias         of shape (768,)
2021-04-13 12:51:11,564 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.value.weight       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.value.weight       of shape (768, 768)
2021-04-13 12:51:11,564 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.intermediate.dense.bias           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.intermediate.dense.bias           of shape (3072,)
2021-04-13 12:51:11,564 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.intermediate.dense.weight         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.intermediate.dense.weight         of shape (3072, 768)
2021-04-13 12:51:11,564 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.LayerNorm.bias             loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.LayerNorm.bias             of shape (768,)
2021-04-13 12:51:11,565 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.LayerNorm.weight           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.LayerNorm.weight           of shape (768,)
2021-04-13 12:51:11,565 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.dense.bias                 loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.dense.bias                 of shape (768,)
2021-04-13 12:51:11,565 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.dense.weight               loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.dense.weight               of shape (768, 3072)
2021-04-13 12:51:11,565 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.LayerNorm.bias    of shape (768,)
2021-04-13 12:51:11,565 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.LayerNorm.weight  of shape (768,)
2021-04-13 12:51:11,565 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.dense.bias        of shape (768,)
2021-04-13 12:51:11,565 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.dense.weight      of shape (768, 768)
2021-04-13 12:51:11,565 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.key.bias            of shape (768,)
2021-04-13 12:51:11,566 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.key.weight          of shape (768, 768)
2021-04-13 12:51:11,566 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.query.bias          of shape (768,)
2021-04-13 12:51:11,566 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.query.weight        of shape (768, 768)
2021-04-13 12:51:11,566 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.value.bias          of shape (768,)
2021-04-13 12:51:11,566 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.value.weight        of shape (768, 768)
2021-04-13 12:51:11,566 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.intermediate.dense.bias            of shape (3072,)
2021-04-13 12:51:11,567 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.intermediate.dense.weight          of shape (3072, 768)
2021-04-13 12:51:11,567 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.LayerNorm.bias              of shape (768,)
2021-04-13 12:51:11,567 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.LayerNorm.weight            of shape (768,)
2021-04-13 12:51:11,567 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.dense.bias                  of shape (768,)
2021-04-13 12:51:11,567 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.dense.weight                of shape (768, 3072)
2021-04-13 12:51:11,567 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.LayerNorm.bias    of shape (768,)
2021-04-13 12:51:11,567 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.LayerNorm.weight  of shape (768,)
2021-04-13 12:51:11,567 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.dense.bias        of shape (768,)
2021-04-13 12:51:11,568 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.dense.weight      of shape (768, 768)
2021-04-13 12:51:11,568 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.key.bias            of shape (768,)
2021-04-13 12:51:11,568 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.key.weight          of shape (768, 768)
2021-04-13 12:51:11,568 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.query.bias          of shape (768,)
2021-04-13 12:51:11,568 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.query.weight        of shape (768, 768)
2021-04-13 12:51:11,568 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.value.bias          of shape (768,)
2021-04-13 12:51:11,568 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.value.weight        of shape (768, 768)
2021-04-13 12:51:11,569 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.intermediate.dense.bias            of shape (3072,)
2021-04-13 12:51:11,569 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.intermediate.dense.weight          of shape (3072, 768)
2021-04-13 12:51:11,569 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.LayerNorm.bias              of shape (768,)
2021-04-13 12:51:11,569 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.LayerNorm.weight            of shape (768,)
2021-04-13 12:51:11,569 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.dense.bias                  of shape (768,)
2021-04-13 12:51:11,569 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.dense.weight                of shape (768, 3072)
2021-04-13 12:51:11,569 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.LayerNorm.bias    of shape (768,)
2021-04-13 12:51:11,569 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.LayerNorm.weight  of shape (768,)
2021-04-13 12:51:11,569 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.dense.bias        of shape (768,)
2021-04-13 12:51:11,570 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.dense.weight      of shape (768, 768)
2021-04-13 12:51:11,570 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.key.bias            of shape (768,)
2021-04-13 12:51:11,570 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.key.weight          of shape (768, 768)
2021-04-13 12:51:11,570 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.query.bias          of shape (768,)
2021-04-13 12:51:11,570 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.query.weight        of shape (768, 768)
2021-04-13 12:51:11,570 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.value.bias          of shape (768,)
2021-04-13 12:51:11,570 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.value.weight        of shape (768, 768)
2021-04-13 12:51:11,571 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.intermediate.dense.bias            of shape (3072,)
2021-04-13 12:51:11,571 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.intermediate.dense.weight          of shape (3072, 768)
2021-04-13 12:51:11,571 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.LayerNorm.bias              of shape (768,)
2021-04-13 12:51:11,571 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.LayerNorm.weight            of shape (768,)
2021-04-13 12:51:11,571 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.dense.bias                  of shape (768,)
2021-04-13 12:51:11,571 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.dense.weight                of shape (768, 3072)
2021-04-13 12:51:11,571 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.LayerNorm.bias    of shape (768,)
2021-04-13 12:51:11,571 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.LayerNorm.weight  of shape (768,)
2021-04-13 12:51:11,571 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.dense.bias        of shape (768,)
2021-04-13 12:51:11,572 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.dense.weight      of shape (768, 768)
2021-04-13 12:51:11,572 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.key.bias            of shape (768,)
2021-04-13 12:51:11,572 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.key.weight          of shape (768, 768)
2021-04-13 12:51:11,572 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.query.bias          of shape (768,)
2021-04-13 12:51:11,572 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.query.weight        of shape (768, 768)
2021-04-13 12:51:11,572 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.value.bias          of shape (768,)
2021-04-13 12:51:11,573 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.value.weight        of shape (768, 768)
2021-04-13 12:51:11,573 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.intermediate.dense.bias            of shape (3072,)
2021-04-13 12:51:11,573 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.intermediate.dense.weight          of shape (3072, 768)
2021-04-13 12:51:11,573 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.LayerNorm.bias              of shape (768,)
2021-04-13 12:51:11,573 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.LayerNorm.weight            of shape (768,)
2021-04-13 12:51:11,573 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.dense.bias                  of shape (768,)
2021-04-13 12:51:11,573 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.dense.weight                of shape (768, 3072)
2021-04-13 12:51:11,574 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.LayerNorm.bias    of shape (768,)
2021-04-13 12:51:11,574 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.LayerNorm.weight  of shape (768,)
2021-04-13 12:51:11,574 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.dense.bias        of shape (768,)
2021-04-13 12:51:11,574 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.dense.weight      of shape (768, 768)
2021-04-13 12:51:11,574 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.key.bias            of shape (768,)
2021-04-13 12:51:11,574 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.key.weight          of shape (768, 768)
2021-04-13 12:51:11,574 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.query.bias          of shape (768,)
2021-04-13 12:51:11,574 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.query.weight        of shape (768, 768)
2021-04-13 12:51:11,575 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.value.bias          of shape (768,)
2021-04-13 12:51:11,575 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.value.weight        of shape (768, 768)
2021-04-13 12:51:11,575 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.intermediate.dense.bias            of shape (3072,)
2021-04-13 12:51:11,575 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.intermediate.dense.weight          of shape (3072, 768)
2021-04-13 12:51:11,575 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.LayerNorm.bias              of shape (768,)
2021-04-13 12:51:11,575 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.LayerNorm.weight            of shape (768,)
2021-04-13 12:51:11,575 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.dense.bias                  of shape (768,)
2021-04-13 12:51:11,575 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.dense.weight                of shape (768, 3072)
2021-04-13 12:51:11,576 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.LayerNorm.bias    of shape (768,)
2021-04-13 12:51:11,576 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.LayerNorm.weight  of shape (768,)
2021-04-13 12:51:11,576 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.dense.bias        of shape (768,)
2021-04-13 12:51:11,576 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.dense.weight      of shape (768, 768)
2021-04-13 12:51:11,576 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.key.bias            of shape (768,)
2021-04-13 12:51:11,576 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.key.weight          of shape (768, 768)
2021-04-13 12:51:11,576 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.query.bias          of shape (768,)
2021-04-13 12:51:11,576 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.query.weight        of shape (768, 768)
2021-04-13 12:51:11,577 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.value.bias          of shape (768,)
2021-04-13 12:51:11,577 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.value.weight        of shape (768, 768)
2021-04-13 12:51:11,577 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.intermediate.dense.bias            of shape (3072,)
2021-04-13 12:51:11,577 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.intermediate.dense.weight          of shape (3072, 768)
2021-04-13 12:51:11,577 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.LayerNorm.bias              of shape (768,)
2021-04-13 12:51:11,577 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.LayerNorm.weight            of shape (768,)
2021-04-13 12:51:11,577 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.dense.bias                  of shape (768,)
2021-04-13 12:51:11,577 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.dense.weight                of shape (768, 3072)
2021-04-13 12:51:11,578 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.LayerNorm.bias    of shape (768,)
2021-04-13 12:51:11,578 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.LayerNorm.weight  of shape (768,)
2021-04-13 12:51:11,578 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.dense.bias        of shape (768,)
2021-04-13 12:51:11,578 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.dense.weight      of shape (768, 768)
2021-04-13 12:51:11,578 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.key.bias            of shape (768,)
2021-04-13 12:51:11,578 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.key.weight          of shape (768, 768)
2021-04-13 12:51:11,579 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.query.bias          of shape (768,)
2021-04-13 12:51:11,579 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.query.weight        of shape (768, 768)
2021-04-13 12:51:11,579 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.value.bias          of shape (768,)
2021-04-13 12:51:11,579 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.value.weight        of shape (768, 768)
2021-04-13 12:51:11,579 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.intermediate.dense.bias            of shape (3072,)
2021-04-13 12:51:11,579 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.intermediate.dense.weight          of shape (3072, 768)
2021-04-13 12:51:11,579 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.LayerNorm.bias              of shape (768,)
2021-04-13 12:51:11,580 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.LayerNorm.weight            of shape (768,)
2021-04-13 12:51:11,580 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.dense.bias                  of shape (768,)
2021-04-13 12:51:11,580 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.dense.weight                of shape (768, 3072)
2021-04-13 12:51:11,580 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.LayerNorm.bias    of shape (768,)
2021-04-13 12:51:11,580 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.LayerNorm.weight  of shape (768,)
2021-04-13 12:51:11,580 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.dense.bias        of shape (768,)
2021-04-13 12:51:11,580 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.dense.weight      of shape (768, 768)
2021-04-13 12:51:11,580 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.key.bias            of shape (768,)
2021-04-13 12:51:11,581 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.key.weight          of shape (768, 768)
2021-04-13 12:51:11,581 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.query.bias          of shape (768,)
2021-04-13 12:51:11,581 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.query.weight        of shape (768, 768)
2021-04-13 12:51:11,581 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.value.bias          of shape (768,)
2021-04-13 12:51:11,581 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.value.weight        of shape (768, 768)
2021-04-13 12:51:11,581 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.intermediate.dense.bias            of shape (3072,)
2021-04-13 12:51:11,581 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.intermediate.dense.weight          of shape (3072, 768)
2021-04-13 12:51:11,582 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.LayerNorm.bias              of shape (768,)
2021-04-13 12:51:11,582 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.LayerNorm.weight            of shape (768,)
2021-04-13 12:51:11,582 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.dense.bias                  of shape (768,)
2021-04-13 12:51:11,582 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.dense.weight                of shape (768, 3072)
2021-04-13 12:51:11,582 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.pooler.dense.bias                                  loaded from mmss_heads.TransformerHead.backbone.bert_model.pooler.dense.bias                                  of shape (768,)
2021-04-13 12:51:11,582 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.pooler.dense.weight                                loaded from mmss_heads.TransformerHead.backbone.bert_model.pooler.dense.weight                                of shape (768, 768)
2021-04-13 12:51:11,582 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.embeddings                                                    loaded from mmss_heads.TransformerHead.backbone.embeddings                                                    of shape (30522, 768)
2021-04-13 12:51:11,582 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-13 12:51:11,582 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-13 12:51:11,582 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.bias                            of shape (768,)
2021-04-13 12:51:11,583 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.weight                          of shape (768, 768)
2021-04-13 12:51:11,583 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.bias                                of shape (768,)
2021-04-13 12:51:11,583 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.weight                              of shape (768, 768)
2021-04-13 12:51:11,583 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.bias                              of shape (768,)
2021-04-13 12:51:11,583 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.weight                            of shape (768, 768)
2021-04-13 12:51:11,583 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.bias                              of shape (768,)
2021-04-13 12:51:11,584 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.weight                            of shape (768, 768)
2021-04-13 12:51:11,584 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.bias                                of shape (768,)
2021-04-13 12:51:11,584 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.weight                              of shape (768, 768)
2021-04-13 12:51:11,584 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.bias                                  of shape (768,)
2021-04-13 12:51:11,584 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.weight                                of shape (768,)
2021-04-13 12:51:11,584 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.0.output.dense.bias                                      of shape (768,)
2021-04-13 12:51:11,585 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.0.output.dense.weight                                    of shape (768, 768)
2021-04-13 12:51:11,585 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-13 12:51:11,585 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-13 12:51:11,585 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.bias                            of shape (768,)
2021-04-13 12:51:11,585 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.weight                          of shape (768, 768)
2021-04-13 12:51:11,585 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.bias                                of shape (768,)
2021-04-13 12:51:11,585 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.weight                              of shape (768, 768)
2021-04-13 12:51:11,586 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.bias                              of shape (768,)
2021-04-13 12:51:11,586 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.weight                            of shape (768, 768)
2021-04-13 12:51:11,586 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.bias                              of shape (768,)
2021-04-13 12:51:11,586 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.weight                            of shape (768, 768)
2021-04-13 12:51:11,586 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.bias                                of shape (768,)
2021-04-13 12:51:11,586 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.weight                              of shape (768, 768)
2021-04-13 12:51:11,587 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.bias                                  of shape (768,)
2021-04-13 12:51:11,587 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.weight                                of shape (768,)
2021-04-13 12:51:11,587 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.1.output.dense.bias                                      of shape (768,)
2021-04-13 12:51:11,587 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.1.output.dense.weight                                    of shape (768, 768)
2021-04-13 12:51:11,587 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-13 12:51:11,587 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-13 12:51:11,587 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.bias                            of shape (768,)
2021-04-13 12:51:11,588 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.weight                          of shape (768, 768)
2021-04-13 12:51:11,588 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.bias                                of shape (768,)
2021-04-13 12:51:11,588 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.weight                              of shape (768, 768)
2021-04-13 12:51:11,588 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.bias                              of shape (768,)
2021-04-13 12:51:11,588 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.weight                            of shape (768, 768)
2021-04-13 12:51:11,588 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.bias                              of shape (768,)
2021-04-13 12:51:11,588 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.weight                            of shape (768, 768)
2021-04-13 12:51:11,589 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.bias                                of shape (768,)
2021-04-13 12:51:11,589 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.weight                              of shape (768, 768)
2021-04-13 12:51:11,589 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.bias                                  of shape (768,)
2021-04-13 12:51:11,589 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.weight                                of shape (768,)
2021-04-13 12:51:11,589 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.2.output.dense.bias                                      of shape (768,)
2021-04-13 12:51:11,589 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.2.output.dense.weight                                    of shape (768, 768)
2021-04-13 12:51:11,590 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-13 12:51:11,590 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-13 12:51:11,590 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.bias                            of shape (768,)
2021-04-13 12:51:11,590 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.weight                          of shape (768, 768)
2021-04-13 12:51:11,590 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.bias                                of shape (768,)
2021-04-13 12:51:11,590 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.weight                              of shape (768, 768)
2021-04-13 12:51:11,590 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.bias                              of shape (768,)
2021-04-13 12:51:11,591 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.weight                            of shape (768, 768)
2021-04-13 12:51:11,591 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.bias                              of shape (768,)
2021-04-13 12:51:11,591 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.weight                            of shape (768, 768)
2021-04-13 12:51:11,591 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.bias                                of shape (768,)
2021-04-13 12:51:11,591 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.weight                              of shape (768, 768)
2021-04-13 12:51:11,591 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.bias                                  of shape (768,)
2021-04-13 12:51:11,592 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.weight                                of shape (768,)
2021-04-13 12:51:11,592 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.3.output.dense.bias                                      of shape (768,)
2021-04-13 12:51:11,592 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.3.output.dense.weight                                    of shape (768, 768)
2021-04-13 12:51:11,592 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-13 12:51:11,592 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-13 12:51:11,592 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.bias                            of shape (768,)
2021-04-13 12:51:11,593 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.weight                          of shape (768, 768)
2021-04-13 12:51:11,593 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.bias                                of shape (768,)
2021-04-13 12:51:11,593 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.weight                              of shape (768, 768)
2021-04-13 12:51:11,593 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.bias                              of shape (768,)
2021-04-13 12:51:11,593 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.weight                            of shape (768, 768)
2021-04-13 12:51:11,593 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.bias                              of shape (768,)
2021-04-13 12:51:11,593 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.weight                            of shape (768, 768)
2021-04-13 12:51:11,594 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.bias                                of shape (768,)
2021-04-13 12:51:11,594 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.weight                              of shape (768, 768)
2021-04-13 12:51:11,594 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.bias                                  of shape (768,)
2021-04-13 12:51:11,594 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.weight                                of shape (768,)
2021-04-13 12:51:11,594 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.4.output.dense.bias                                      of shape (768,)
2021-04-13 12:51:11,594 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.4.output.dense.weight                                    of shape (768, 768)
2021-04-13 12:51:11,595 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-13 12:51:11,595 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-13 12:51:11,595 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.bias                            of shape (768,)
2021-04-13 12:51:11,595 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.weight                          of shape (768, 768)
2021-04-13 12:51:11,595 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.bias                                of shape (768,)
2021-04-13 12:51:11,595 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.weight                              of shape (768, 768)
2021-04-13 12:51:11,596 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.bias                              of shape (768,)
2021-04-13 12:51:11,596 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.weight                            of shape (768, 768)
2021-04-13 12:51:11,596 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.bias                              of shape (768,)
2021-04-13 12:51:11,596 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.weight                            of shape (768, 768)
2021-04-13 12:51:11,596 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.bias                                of shape (768,)
2021-04-13 12:51:11,596 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.weight                              of shape (768, 768)
2021-04-13 12:51:11,597 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.bias                                  of shape (768,)
2021-04-13 12:51:11,597 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.weight                                of shape (768,)
2021-04-13 12:51:11,597 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.5.output.dense.bias                                      of shape (768,)
2021-04-13 12:51:11,597 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.5.output.dense.weight                                    of shape (768, 768)
2021-04-13 12:51:11,597 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.bi_seq_relationship.bias                                         loaded from mmss_heads.TransformerHead.heads.bi_seq_relationship.bias                                         of shape (2,)
2021-04-13 12:51:11,597 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.bi_seq_relationship.weight                                       loaded from mmss_heads.TransformerHead.heads.bi_seq_relationship.weight                                       of shape (2, 768)
2021-04-13 12:51:11,597 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.decoder.bias                                    loaded from mmss_heads.TransformerHead.heads.imagePredictions.decoder.bias                                    of shape (2048,)
2021-04-13 12:51:11,598 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.decoder.weight                                  loaded from mmss_heads.TransformerHead.heads.imagePredictions.decoder.weight                                  of shape (2048, 768)
2021-04-13 12:51:11,598 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.transform.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.heads.imagePredictions.transform.LayerNorm.bias                        of shape (768,)
2021-04-13 12:51:11,598 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.transform.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.heads.imagePredictions.transform.LayerNorm.weight                      of shape (768,)
2021-04-13 12:51:11,598 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.transform.dense.bias                            loaded from mmss_heads.TransformerHead.heads.imagePredictions.transform.dense.bias                            of shape (768,)
2021-04-13 12:51:11,598 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.transform.dense.weight                          loaded from mmss_heads.TransformerHead.heads.imagePredictions.transform.dense.weight                          of shape (768, 768)
2021-04-13 12:51:11,598 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.bias                                                 loaded from mmss_heads.TransformerHead.heads.predictions.bias                                                 of shape (30522,)
2021-04-13 12:51:11,599 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.decoder.bias                                         loaded from mmss_heads.TransformerHead.heads.predictions.decoder.bias                                         of shape (30522,)
2021-04-13 12:51:11,599 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.decoder.weight                                       loaded from mmss_heads.TransformerHead.heads.predictions.decoder.weight                                       of shape (30522, 768)
2021-04-13 12:51:11,599 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.bias                             loaded from mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.bias                             of shape (768,)
2021-04-13 12:51:11,599 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.weight                           loaded from mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.weight                           of shape (768,)
2021-04-13 12:51:11,599 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.transform.dense.bias                                 loaded from mmss_heads.TransformerHead.heads.predictions.transform.dense.bias                                 of shape (768,)
2021-04-13 12:51:11,599 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.transform.dense.weight                               loaded from mmss_heads.TransformerHead.heads.predictions.transform.dense.weight                               of shape (768, 768)
2021-04-13 12:51:11,599 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.pooler.dense.bias                                                      loaded from mmss_heads.TransformerHead.pooler.dense.bias                                                      of shape (768,)
2021-04-13 12:51:11,600 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.pooler.dense.weight                                                    loaded from mmss_heads.TransformerHead.pooler.dense.weight                                                    of shape (768, 768)
2021-04-13 12:51:11,600 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.v2l_projection.bias                                                    loaded from mmss_heads.TransformerHead.v2l_projection.bias                                                    of shape (768,)
2021-04-13 12:51:11,600 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.v2l_projection.weight                                                  loaded from mmss_heads.TransformerHead.v2l_projection.weight                                                  of shape (768, 2048)
2021-04-13 12:51:11,600 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.LayerNorm.bias                                              loaded from mmss_heads.TransformerHead.visual_emb.LayerNorm.bias                                              of shape (768,)
2021-04-13 12:51:11,600 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.LayerNorm.weight                                            loaded from mmss_heads.TransformerHead.visual_emb.LayerNorm.weight                                            of shape (768,)
2021-04-13 12:51:11,600 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.image_embeddings.bias                                       loaded from mmss_heads.TransformerHead.visual_emb.image_embeddings.bias                                       of shape (768,)
2021-04-13 12:51:11,601 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.image_embeddings.weight                                     loaded from mmss_heads.TransformerHead.visual_emb.image_embeddings.weight                                     of shape (768, 768)
2021-04-13 12:51:11,601 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.image_location_embeddings.bias                              loaded from mmss_heads.TransformerHead.visual_emb.image_location_embeddings.bias                              of shape (768,)
2021-04-13 12:51:11,601 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.image_location_embeddings.weight                            loaded from mmss_heads.TransformerHead.visual_emb.image_location_embeddings.weight                            of shape (768, 2)
2021-04-13 12:51:12,207 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from /mnt/lustre/lixiangtai/runs/vltrain_02/model_final.pth
2021-04-13 12:51:12,339 maskrcnn_benchmark.utils.checkpoint INFO: Loading scheduler from /mnt/lustre/lixiangtai/runs/vltrain_02/model_final.pth
2021-04-13 12:51:12,339 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2021-04-13 12:51:23,360 maskrcnn_benchmark.utils.miscellaneous WARNING: Dataset [COCOCaptionsDataset] has no categories attribute, labels.json file won't be created
2021-04-13 12:51:23,710 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2021-04-13 12:51:23,898 maskrcnn_benchmark.trainer INFO: Start training
2021-04-13 12:51:24,655 maskrcnn_benchmark.trainer INFO: Total training time: 0:00:00.753399 (0.0000 s / it)
2021-04-13 12:51:25,115 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2021-04-13 12:51:25,262 maskrcnn_benchmark.inference INFO: Start evaluation on coco_captions_val dataset(5000 images).
