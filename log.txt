2021-04-01 20:19:59,983 maskrcnn_benchmark INFO: Using 8 GPUs
2021-04-01 20:19:59,985 maskrcnn_benchmark INFO: Namespace(config_file='configs/mmss_v07.yaml', distributed=True, local_rank=0, opts=['OUTPUT_DIR', '/mnt/lustre/lixiangtai/runs/vltrain/121'], skip_test=True)
2021-04-01 20:19:59,985 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2021-04-01 20:21:05,682 maskrcnn_benchmark INFO:
PyTorch version: 1.3.1+cuda90_cudnn7.6.3_lms
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: CentOS Linux 7 (Core)
GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
CMake version: version 2.8.12.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration:
GPU 0: Tesla V100-SXM2-32GB
GPU 1: Tesla V100-SXM2-32GB
GPU 2: Tesla V100-SXM2-32GB
GPU 3: Tesla V100-SXM2-32GB
GPU 4: Tesla V100-SXM2-32GB
GPU 5: Tesla V100-SXM2-32GB
GPU 6: Tesla V100-SXM2-32GB
GPU 7: Tesla V100-SXM2-32GB

Nvidia driver version: 418.67
cuDNN version: /usr/local/cuda-9.0/lib64/libcudnn.so.7.0.4

Versions of relevant libraries:
[pip3] numpy==1.17.3
[conda] linklink                  0.3.1+cuda9.0.torch131.mvapich2.pmi2          pypi_0    pypi
[conda] torch                     1.3.1+cuda90.cudnn7.6.3.lms          pypi_0    pypi
[conda] torchvision               0.4.2                    pypi_0    pypi
        Pillow (7.1.2)
2021-04-01 20:21:05,726 maskrcnn_benchmark INFO: Loaded configuration file configs/mmss_v07.yaml
2021-04-01 20:21:05,726 maskrcnn_benchmark INFO:
MODEL:
  # This is what indicates we want image-caption training not object detection
  META_ARCHITECTURE: "MMSS-GCNN"
  # URL to the initial weights, trained for imagenet classification
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-50"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
  BACKBONE:
    # a full resnet, including stem and 4 blocks
    CONV_BODY: "R-50-C5"
    # don't freeze any layer, train everything
    FREEZE_CONV_BODY_AT: 0
  LANGUAGE_BACKBONE:
    # make a BERT model to process captions
    TYPE: "BERT-Base"
    # and freeze it (loaded from original pretrained bert of huggingface)
    FREEZE: True
  MMSS_HEAD:
    # We want both a grounding head and a transformer head on top of image and caption,
    # each of which defines its own objective functions.
    TYPES: ("GroundingHead", "TransformerHead")
    DEFAULT_HEAD: "GroundingHead"
    # Share the weights of the vision to language projection between the two heads.
    # Use the one on the grounding head because that is the default (see above)
    TIE_VL_PROJECTION_WEIGHTS: True
    # Randomly keep up to 100 visual regions from each image. This is to save memory.
    SPATIAL_DROPOUT: 100
    GROUNDING:
      # Use dot product for grounding. This could be cosine or euclidean too.
      LOCAL_METRIC: "dot"
      # After aligning words to regions, sum the local distances to compute global distance.
      GLOBAL_METRIC: "aligned_local"
      # Use softmax to softly align each word to regions, and vice versa.
      # This could be for instance hardmax, which aligns to the most similar
      ALIGNMENT: "softmax"
      # Typical good values are 100.0 for euclidean, 10.0 for dot, 0.01 for cosine
      ALIGNMENT_TEMPERATURE: 10.0
      # This loss is to choose the right caption out of all captions in the batch,
      # And similarly choose the right image. Could be triplet loss instead.
      LOSS: "cross_entropy"
      # Whether to find a region for each word
      ALIGN_WORDS_TO_REGIONS: True
      # Whether to find a word for a region
      # At least one of these two should be True
      ALIGN_REGIONS_TO_WORDS: True
    TRANSFORMER:
      # Whether to perform masked language modeling (randomly mask words from captions
      # and have the model reconstruct them)
      MASKED_LANGUAGE_MODELING: True
      # Whether to do that during validation as well. That is not good if you want to
      # measure image-caption matching scores.
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      # For now this is not implemented, so keep it False and ''
      MASKED_VISUAL_MODELING: False
      MVM_LOSS: ''
      # For Multimedia Matching loss, cross-entropy works just like in the grounding head
      MMM_LOSS: 'cross_entropy'
      # Typical BERT configs as in Huggingface
      BERT_CONFIG:
        num_hidden_layers: 6
        num_attention_heads: 8
        intermediate_size: 768
DATASETS:
  TRAIN: ("coco_captions_train",)
  TEST: ("coco_captions_val",)
  DATASET_CLASS: "COCOCaptionsDataset"
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS: (20000, 35000)
  MAX_ITER: 40000
  IMS_PER_BATCH: 64
  TEST_PERIOD: 1000
  CHECKPOINT_PERIOD: 1000
  LOG_PERIOD: 100
  CLIP_GRAD_NORM_AT: 5.0
  # A value of more than one means accumulate gradients for several batches before updating
  GRADIENT_ACCUMULATION_STEPS: 1
  # If true, it calls model.train() before computing validation loss. Needed for some models.
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
TEST:
  DO_EVAL: False
  IMS_PER_BATCH: 64

2021-04-01 20:21:05,751 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DROP_LAST: False
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 0
DATASETS:
  DATASET_ARGS:
    EMB_DIM: 300
    EMB_KEY: GloVE
    LOAD_EMBEDDINGS: False
    MULTI_LABEL_MODE: False
  DATASET_CLASS: COCOCaptionsDataset
  TEST: ('coco_captions_val',)
  TRAIN: ('coco_captions_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-50-C5
    FREEZE_CONV_BODY_AT: 0
  BACKBONE_PREFIX:
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF:
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE:
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    ADD_POSITION_EMBEDDING: False
    EMBEDDING_PATH:
    FREEZE: True
    TYPE: BERT-Base
  LOAD_CLASSIFIER: True
  LOAD_EMB_PRED_FROM_MMSS_HEAD: False
  LOAD_TRAINER_STATE: True
  MASK_ON: False
  META_ARCHITECTURE: MMSS-GCNN
  MMSS_HEAD:
    DEFAULT_HEAD: GroundingHead
    GROUNDING:
      ALIGNMENT: softmax
      ALIGNMENT_TEMPERATURE: 10.0
      ALIGN_REGIONS_TO_WORDS: True
      ALIGN_WORDS_TO_REGIONS: True
      GLOBAL_METRIC: aligned_local
      LOCAL_METRIC: dot
      LOSS: cross_entropy
      NEGATIVE_MINING: random
      TRIPLET_MARGIN: 1.0
    SPATIAL_DROPOUT: 100
    TIE_VL_PROJECTION_WEIGHTS: True
    TRANSFORMER:
      BERT_CONFIG:
        attention_probs_dropout_prob: 0.1
        gradient_checkpointing: False
        hidden_act: gelu
        hidden_dropout_prob: 0.1
        hidden_size: 768
        initializer_range: 0.02
        intermediate_size: 768
        layer_norm_eps: 1e-12
        max_position_embeddings: 512
        num_attention_heads: 8
        num_hidden_layers: 6
        pad_token_id: 0
        type_vocab_size: 2
        vocab_size: 30522
      MASKED_LANGUAGE_MODELING: True
      MASKED_LANGUAGE_MODELING_PROB: 0.15
      MASKED_LANGUAGE_MODELING_PROB_MASK: 0.9
      MASKED_LANGUAGE_MODELING_PROB_NOISE: 0.0
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      MASKED_VISUAL_MODELING: False
      MMM_LOSS: cross_entropy
      MVM_LOSS:
      MVM_LOSS_NUM_NEGATIVE: 128
    TYPES: ('GroundingHead', 'TransformerHead')
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    EMBEDDING_BASED: False
    EMB_DIM: 300
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    FREEZE_EMB_PRED: False
    FREEZE_FEATURE_EXTRACTOR: False
    LOSS_WEIGHT_BACKGROUND: 1.0
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
    WSDDN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    DONT_TRAIN: False
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  WEIGHT: catalog://ImageNetPretrained/MSRA/R-50
OUTPUT_DIR: /mnt/lustre/lixiangtai/runs/vltrain/121
PATHS_CATALOG: /mnt/lustre/lixiangtai/project/ovr-cnn/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 1000
  CLIP_GRAD_NORM_AT: 5.0
  GAMMA: 0.1
  GRADIENT_ACCUMULATION_STEPS: 1
  IMS_PER_BATCH: 64
  LOG_PERIOD: 100
  MAX_ITER: 40000
  MOMENTUM: 0.9
  SKIP_VAL_LOSS: False
  STEPS: (20000, 35000)
  TEST_PERIOD: 1000
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  DO_EVAL: False
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 64
2021-04-01 20:21:05,753 maskrcnn_benchmark INFO: Saving config into: /mnt/lustre/lixiangtai/runs/vltrain/121/config.yml
2021-04-01 20:33:07,677 maskrcnn_benchmark INFO: Using 8 GPUs
2021-04-01 20:33:07,679 maskrcnn_benchmark INFO: Namespace(config_file='configs/mmss_v07.yaml', distributed=True, local_rank=0, opts=['OUTPUT_DIR', '/mnt/lustre/lixiangtai/runs/vltrain/121'], skip_test=True)
2021-04-01 20:33:07,679 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2021-04-01 20:34:11,820 maskrcnn_benchmark INFO:
PyTorch version: 1.3.1+cuda90_cudnn7.6.3_lms
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: CentOS Linux 7 (Core)
GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
CMake version: version 2.8.12.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration:
GPU 0: Tesla V100-SXM2-32GB
GPU 1: Tesla V100-SXM2-32GB
GPU 2: Tesla V100-SXM2-32GB
GPU 3: Tesla V100-SXM2-32GB
GPU 4: Tesla V100-SXM2-32GB
GPU 5: Tesla V100-SXM2-32GB
GPU 6: Tesla V100-SXM2-32GB
GPU 7: Tesla V100-SXM2-32GB

Nvidia driver version: 418.67
cuDNN version: /usr/local/cuda-9.0/lib64/libcudnn.so.7.0.4

Versions of relevant libraries:
[pip3] numpy==1.17.3
[conda] linklink                  0.3.1+cuda9.0.torch131.mvapich2.pmi2          pypi_0    pypi
[conda] torch                     1.3.1+cuda90.cudnn7.6.3.lms          pypi_0    pypi
[conda] torchvision               0.4.2                    pypi_0    pypi
        Pillow (7.1.2)
2021-04-01 20:34:11,866 maskrcnn_benchmark INFO: Loaded configuration file configs/mmss_v07.yaml
2021-04-01 20:34:11,867 maskrcnn_benchmark INFO:
MODEL:
  # This is what indicates we want image-caption training not object detection
  META_ARCHITECTURE: "MMSS-GCNN"
  # URL to the initial weights, trained for imagenet classification
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-50"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
  BACKBONE:
    # a full resnet, including stem and 4 blocks
    CONV_BODY: "R-50-C5"
    # don't freeze any layer, train everything
    FREEZE_CONV_BODY_AT: 0
  LANGUAGE_BACKBONE:
    # make a BERT model to process captions
    TYPE: "BERT-Base"
    # and freeze it (loaded from original pretrained bert of huggingface)
    FREEZE: True
  MMSS_HEAD:
    # We want both a grounding head and a transformer head on top of image and caption,
    # each of which defines its own objective functions.
    TYPES: ("GroundingHead", "TransformerHead")
    DEFAULT_HEAD: "GroundingHead"
    # Share the weights of the vision to language projection between the two heads.
    # Use the one on the grounding head because that is the default (see above)
    TIE_VL_PROJECTION_WEIGHTS: True
    # Randomly keep up to 100 visual regions from each image. This is to save memory.
    SPATIAL_DROPOUT: 100
    GROUNDING:
      # Use dot product for grounding. This could be cosine or euclidean too.
      LOCAL_METRIC: "dot"
      # After aligning words to regions, sum the local distances to compute global distance.
      GLOBAL_METRIC: "aligned_local"
      # Use softmax to softly align each word to regions, and vice versa.
      # This could be for instance hardmax, which aligns to the most similar
      ALIGNMENT: "softmax"
      # Typical good values are 100.0 for euclidean, 10.0 for dot, 0.01 for cosine
      ALIGNMENT_TEMPERATURE: 10.0
      # This loss is to choose the right caption out of all captions in the batch,
      # And similarly choose the right image. Could be triplet loss instead.
      LOSS: "cross_entropy"
      # Whether to find a region for each word
      ALIGN_WORDS_TO_REGIONS: True
      # Whether to find a word for a region
      # At least one of these two should be True
      ALIGN_REGIONS_TO_WORDS: True
    TRANSFORMER:
      # Whether to perform masked language modeling (randomly mask words from captions
      # and have the model reconstruct them)
      MASKED_LANGUAGE_MODELING: True
      # Whether to do that during validation as well. That is not good if you want to
      # measure image-caption matching scores.
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      # For now this is not implemented, so keep it False and ''
      MASKED_VISUAL_MODELING: False
      MVM_LOSS: ''
      # For Multimedia Matching loss, cross-entropy works just like in the grounding head
      MMM_LOSS: 'cross_entropy'
      # Typical BERT configs as in Huggingface
      BERT_CONFIG:
        num_hidden_layers: 6
        num_attention_heads: 8
        intermediate_size: 768
DATASETS:
  TRAIN: ("coco_captions_train",)
  TEST: ("coco_captions_val",)
  DATASET_CLASS: "COCOCaptionsDataset"
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS: (20000, 35000)
  MAX_ITER: 40000
  IMS_PER_BATCH: 64
  TEST_PERIOD: 1000
  CHECKPOINT_PERIOD: 1000
  LOG_PERIOD: 100
  CLIP_GRAD_NORM_AT: 5.0
  # A value of more than one means accumulate gradients for several batches before updating
  GRADIENT_ACCUMULATION_STEPS: 1
  # If true, it calls model.train() before computing validation loss. Needed for some models.
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
TEST:
  DO_EVAL: False
  IMS_PER_BATCH: 64

2021-04-01 20:34:11,891 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DROP_LAST: False
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 0
DATASETS:
  DATASET_ARGS:
    EMB_DIM: 300
    EMB_KEY: GloVE
    LOAD_EMBEDDINGS: False
    MULTI_LABEL_MODE: False
  DATASET_CLASS: COCOCaptionsDataset
  TEST: ('coco_captions_val',)
  TRAIN: ('coco_captions_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-50-C5
    FREEZE_CONV_BODY_AT: 0
  BACKBONE_PREFIX:
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF:
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE:
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    ADD_POSITION_EMBEDDING: False
    EMBEDDING_PATH:
    FREEZE: True
    TYPE: BERT-Base
  LOAD_CLASSIFIER: True
  LOAD_EMB_PRED_FROM_MMSS_HEAD: False
  LOAD_TRAINER_STATE: True
  MASK_ON: False
  META_ARCHITECTURE: MMSS-GCNN
  MMSS_HEAD:
    DEFAULT_HEAD: GroundingHead
    GROUNDING:
      ALIGNMENT: softmax
      ALIGNMENT_TEMPERATURE: 10.0
      ALIGN_REGIONS_TO_WORDS: True
      ALIGN_WORDS_TO_REGIONS: True
      GLOBAL_METRIC: aligned_local
      LOCAL_METRIC: dot
      LOSS: cross_entropy
      NEGATIVE_MINING: random
      TRIPLET_MARGIN: 1.0
    SPATIAL_DROPOUT: 100
    TIE_VL_PROJECTION_WEIGHTS: True
    TRANSFORMER:
      BERT_CONFIG:
        attention_probs_dropout_prob: 0.1
        gradient_checkpointing: False
        hidden_act: gelu
        hidden_dropout_prob: 0.1
        hidden_size: 768
        initializer_range: 0.02
        intermediate_size: 768
        layer_norm_eps: 1e-12
        max_position_embeddings: 512
        num_attention_heads: 8
        num_hidden_layers: 6
        pad_token_id: 0
        type_vocab_size: 2
        vocab_size: 30522
      MASKED_LANGUAGE_MODELING: True
      MASKED_LANGUAGE_MODELING_PROB: 0.15
      MASKED_LANGUAGE_MODELING_PROB_MASK: 0.9
      MASKED_LANGUAGE_MODELING_PROB_NOISE: 0.0
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      MASKED_VISUAL_MODELING: False
      MMM_LOSS: cross_entropy
      MVM_LOSS:
      MVM_LOSS_NUM_NEGATIVE: 128
    TYPES: ('GroundingHead', 'TransformerHead')
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    EMBEDDING_BASED: False
    EMB_DIM: 300
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    FREEZE_EMB_PRED: False
    FREEZE_FEATURE_EXTRACTOR: False
    LOSS_WEIGHT_BACKGROUND: 1.0
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
    WSDDN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    DONT_TRAIN: False
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  WEIGHT: catalog://ImageNetPretrained/MSRA/R-50
OUTPUT_DIR: /mnt/lustre/lixiangtai/runs/vltrain/121
PATHS_CATALOG: /mnt/lustre/lixiangtai/project/ovr-cnn/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 1000
  CLIP_GRAD_NORM_AT: 5.0
  GAMMA: 0.1
  GRADIENT_ACCUMULATION_STEPS: 1
  IMS_PER_BATCH: 64
  LOG_PERIOD: 100
  MAX_ITER: 40000
  MOMENTUM: 0.9
  SKIP_VAL_LOSS: False
  STEPS: (20000, 35000)
  TEST_PERIOD: 1000
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  DO_EVAL: False
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 64
2021-04-01 20:34:11,893 maskrcnn_benchmark INFO: Saving config into: /mnt/lustre/lixiangtai/runs/vltrain/121/config.yml
2021-04-01 20:47:37,087 maskrcnn_benchmark INFO: Using 8 GPUs
2021-04-01 20:47:37,091 maskrcnn_benchmark INFO: Namespace(config_file='configs/mmss_v07.yaml', distributed=True, local_rank=0, opts=['OUTPUT_DIR', '/mnt/lustre/lixiangtai/runs/vltrain/121'], skip_test=True)
2021-04-01 20:47:37,091 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2021-04-01 20:48:41,821 maskrcnn_benchmark INFO:
PyTorch version: 1.3.1+cuda90_cudnn7.6.3_lms
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: CentOS Linux 7 (Core)
GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
CMake version: version 2.8.12.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration:
GPU 0: Tesla V100-SXM2-32GB
GPU 1: Tesla V100-SXM2-32GB
GPU 2: Tesla V100-SXM2-32GB
GPU 3: Tesla V100-SXM2-32GB
GPU 4: Tesla V100-SXM2-32GB
GPU 5: Tesla V100-SXM2-32GB
GPU 6: Tesla V100-SXM2-32GB
GPU 7: Tesla V100-SXM2-32GB

Nvidia driver version: 418.67
cuDNN version: /usr/local/cuda-9.0/lib64/libcudnn.so.7.0.4

Versions of relevant libraries:
[pip3] numpy==1.17.3
[conda] linklink                  0.3.1+cuda9.0.torch131.mvapich2.pmi2          pypi_0    pypi
[conda] torch                     1.3.1+cuda90.cudnn7.6.3.lms          pypi_0    pypi
[conda] torchvision               0.4.2                    pypi_0    pypi
        Pillow (7.1.2)
2021-04-01 20:48:41,869 maskrcnn_benchmark INFO: Loaded configuration file configs/mmss_v07.yaml
2021-04-01 20:48:41,870 maskrcnn_benchmark INFO:
MODEL:
  # This is what indicates we want image-caption training not object detection
  META_ARCHITECTURE: "MMSS-GCNN"
  # URL to the initial weights, trained for imagenet classification
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-50"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
  BACKBONE:
    # a full resnet, including stem and 4 blocks
    CONV_BODY: "R-50-C5"
    # don't freeze any layer, train everything
    FREEZE_CONV_BODY_AT: 0
  LANGUAGE_BACKBONE:
    # make a BERT model to process captions
    TYPE: "BERT-Base"
    # and freeze it (loaded from original pretrained bert of huggingface)
    FREEZE: True
  MMSS_HEAD:
    # We want both a grounding head and a transformer head on top of image and caption,
    # each of which defines its own objective functions.
    TYPES: ("GroundingHead", "TransformerHead")
    DEFAULT_HEAD: "GroundingHead"
    # Share the weights of the vision to language projection between the two heads.
    # Use the one on the grounding head because that is the default (see above)
    TIE_VL_PROJECTION_WEIGHTS: True
    # Randomly keep up to 100 visual regions from each image. This is to save memory.
    SPATIAL_DROPOUT: 100
    GROUNDING:
      # Use dot product for grounding. This could be cosine or euclidean too.
      LOCAL_METRIC: "dot"
      # After aligning words to regions, sum the local distances to compute global distance.
      GLOBAL_METRIC: "aligned_local"
      # Use softmax to softly align each word to regions, and vice versa.
      # This could be for instance hardmax, which aligns to the most similar
      ALIGNMENT: "softmax"
      # Typical good values are 100.0 for euclidean, 10.0 for dot, 0.01 for cosine
      ALIGNMENT_TEMPERATURE: 10.0
      # This loss is to choose the right caption out of all captions in the batch,
      # And similarly choose the right image. Could be triplet loss instead.
      LOSS: "cross_entropy"
      # Whether to find a region for each word
      ALIGN_WORDS_TO_REGIONS: True
      # Whether to find a word for a region
      # At least one of these two should be True
      ALIGN_REGIONS_TO_WORDS: True
    TRANSFORMER:
      # Whether to perform masked language modeling (randomly mask words from captions
      # and have the model reconstruct them)
      MASKED_LANGUAGE_MODELING: True
      # Whether to do that during validation as well. That is not good if you want to
      # measure image-caption matching scores.
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      # For now this is not implemented, so keep it False and ''
      MASKED_VISUAL_MODELING: False
      MVM_LOSS: ''
      # For Multimedia Matching loss, cross-entropy works just like in the grounding head
      MMM_LOSS: 'cross_entropy'
      # Typical BERT configs as in Huggingface
      BERT_CONFIG:
        num_hidden_layers: 6
        num_attention_heads: 8
        intermediate_size: 768
DATASETS:
  TRAIN: ("coco_captions_train",)
  TEST: ("coco_captions_val",)
  DATASET_CLASS: "COCOCaptionsDataset"
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS: (20000, 35000)
  MAX_ITER: 40000
  IMS_PER_BATCH: 64
  TEST_PERIOD: 1000
  CHECKPOINT_PERIOD: 1000
  LOG_PERIOD: 100
  CLIP_GRAD_NORM_AT: 5.0
  # A value of more than one means accumulate gradients for several batches before updating
  GRADIENT_ACCUMULATION_STEPS: 1
  # If true, it calls model.train() before computing validation loss. Needed for some models.
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
TEST:
  DO_EVAL: False
  IMS_PER_BATCH: 64

2021-04-01 20:48:41,893 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DROP_LAST: False
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 0
DATASETS:
  DATASET_ARGS:
    EMB_DIM: 300
    EMB_KEY: GloVE
    LOAD_EMBEDDINGS: False
    MULTI_LABEL_MODE: False
  DATASET_CLASS: COCOCaptionsDataset
  TEST: ('coco_captions_val',)
  TRAIN: ('coco_captions_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-50-C5
    FREEZE_CONV_BODY_AT: 0
  BACKBONE_PREFIX:
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF:
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE:
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    ADD_POSITION_EMBEDDING: False
    EMBEDDING_PATH:
    FREEZE: True
    TYPE: BERT-Base
  LOAD_CLASSIFIER: True
  LOAD_EMB_PRED_FROM_MMSS_HEAD: False
  LOAD_TRAINER_STATE: True
  MASK_ON: False
  META_ARCHITECTURE: MMSS-GCNN
  MMSS_HEAD:
    DEFAULT_HEAD: GroundingHead
    GROUNDING:
      ALIGNMENT: softmax
      ALIGNMENT_TEMPERATURE: 10.0
      ALIGN_REGIONS_TO_WORDS: True
      ALIGN_WORDS_TO_REGIONS: True
      GLOBAL_METRIC: aligned_local
      LOCAL_METRIC: dot
      LOSS: cross_entropy
      NEGATIVE_MINING: random
      TRIPLET_MARGIN: 1.0
    SPATIAL_DROPOUT: 100
    TIE_VL_PROJECTION_WEIGHTS: True
    TRANSFORMER:
      BERT_CONFIG:
        attention_probs_dropout_prob: 0.1
        gradient_checkpointing: False
        hidden_act: gelu
        hidden_dropout_prob: 0.1
        hidden_size: 768
        initializer_range: 0.02
        intermediate_size: 768
        layer_norm_eps: 1e-12
        max_position_embeddings: 512
        num_attention_heads: 8
        num_hidden_layers: 6
        pad_token_id: 0
        type_vocab_size: 2
        vocab_size: 30522
      MASKED_LANGUAGE_MODELING: True
      MASKED_LANGUAGE_MODELING_PROB: 0.15
      MASKED_LANGUAGE_MODELING_PROB_MASK: 0.9
      MASKED_LANGUAGE_MODELING_PROB_NOISE: 0.0
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      MASKED_VISUAL_MODELING: False
      MMM_LOSS: cross_entropy
      MVM_LOSS:
      MVM_LOSS_NUM_NEGATIVE: 128
    TYPES: ('GroundingHead', 'TransformerHead')
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    EMBEDDING_BASED: False
    EMB_DIM: 300
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    FREEZE_EMB_PRED: False
    FREEZE_FEATURE_EXTRACTOR: False
    LOSS_WEIGHT_BACKGROUND: 1.0
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
    WSDDN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    DONT_TRAIN: False
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  WEIGHT: catalog://ImageNetPretrained/MSRA/R-50
OUTPUT_DIR: /mnt/lustre/lixiangtai/runs/vltrain/121
PATHS_CATALOG: /mnt/lustre/lixiangtai/project/ovr-cnn/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 1000
  CLIP_GRAD_NORM_AT: 5.0
  GAMMA: 0.1
  GRADIENT_ACCUMULATION_STEPS: 1
  IMS_PER_BATCH: 64
  LOG_PERIOD: 100
  MAX_ITER: 40000
  MOMENTUM: 0.9
  SKIP_VAL_LOSS: False
  STEPS: (20000, 35000)
  TEST_PERIOD: 1000
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  DO_EVAL: False
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 64
2021-04-01 20:48:41,895 maskrcnn_benchmark INFO: Saving config into: /mnt/lustre/lixiangtai/runs/vltrain/121/config.yml
2021-04-01 20:48:51,946 maskrcnn_benchmark.make_optimizer INFO: The following parameters will be trained:
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.stem.conv1.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.downsample.0.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv1.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv2.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv3.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv1.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv2.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv3.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv1.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv2.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv3.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.downsample.0.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv1.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv2.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv3.weight
2021-04-01 20:48:51,947 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv1.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv2.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv3.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv1.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv2.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv3.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv1.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv2.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv3.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.downsample.0.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv1.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv2.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv3.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv1.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv2.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv3.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv1.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv2.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv3.weight
2021-04-01 20:48:51,948 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv1.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv2.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv3.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv1.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv2.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv3.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv1.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv2.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv3.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.downsample.0.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv1.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv2.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv3.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv1.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv2.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv3.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv1.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv2.weight
2021-04-01 20:48:51,949 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv3.weight
2021-04-01 20:48:51,950 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.GroundingHead.v2l_projection.weight
2021-04-01 20:48:51,950 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.GroundingHead.v2l_projection.bias
2021-04-01 20:48:51,950 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_embeddings.weight
2021-04-01 20:48:51,950 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_embeddings.bias
2021-04-01 20:48:51,950 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_location_embeddings.weight
2021-04-01 20:48:51,950 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_location_embeddings.bias
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.LayerNorm.weight
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.LayerNorm.bias
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.weight
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.bias
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.weight
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.bias
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.weight
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.bias
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.weight
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.bias
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.weight
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.bias
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.weight
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.bias
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.dense.weight
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.dense.bias
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.weight
2021-04-01 20:48:51,951 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.bias
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.weight
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.bias
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.weight
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.bias
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.weight
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.bias
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.weight
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.bias
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.weight
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.bias
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.weight
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.bias
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.dense.weight
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.dense.bias
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.weight
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.bias
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.weight
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.bias
2021-04-01 20:48:51,952 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.weight
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.bias
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.weight
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.bias
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.weight
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.bias
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.weight
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.bias
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.weight
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.bias
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.dense.weight
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.dense.bias
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.weight
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.bias
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.weight
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.bias
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.weight
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.bias
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.weight
2021-04-01 20:48:51,953 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.bias
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.weight
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.bias
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.weight
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.bias
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.weight
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.bias
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.dense.weight
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.dense.bias
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.weight
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.bias
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.weight
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.bias
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.weight
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.bias
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.weight
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.bias
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.weight
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.bias
2021-04-01 20:48:51,954 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.weight
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.bias
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.weight
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.bias
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.dense.weight
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.dense.bias
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.weight
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.bias
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.weight
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.bias
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.weight
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.bias
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.weight
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.bias
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.weight
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.bias
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.weight
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.bias
2021-04-01 20:48:51,955 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.weight
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.bias
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.dense.weight
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.dense.bias
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.weight
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.bias
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.pooler.dense.weight
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.pooler.dense.bias
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.bias
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.dense.weight
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.dense.bias
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.weight
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.bias
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.bi_seq_relationship.weight
2021-04-01 20:48:51,956 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.bi_seq_relationship.bias
2021-04-01 20:48:52,655 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from catalog://ImageNetPretrained/MSRA/R-50
2021-04-01 20:48:52,874 maskrcnn_benchmark.utils.checkpoint INFO: catalog://ImageNetPretrained/MSRA/R-50 points to https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-50.pkl
2021-04-01 21:01:26,862 maskrcnn_benchmark INFO: Using 8 GPUs
2021-04-01 21:01:26,864 maskrcnn_benchmark INFO: Namespace(config_file='configs/mmss_v07.yaml', distributed=True, local_rank=0, opts=['OUTPUT_DIR', '/mnt/lustre/lixiangtai/runs/vltrain/121'], skip_test=True)
2021-04-01 21:01:26,864 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2021-04-01 21:02:30,781 maskrcnn_benchmark INFO:
PyTorch version: 1.3.1+cuda90_cudnn7.6.3_lms
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: CentOS Linux 7 (Core)
GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
CMake version: version 2.8.12.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration:
GPU 0: Tesla V100-SXM2-32GB
GPU 1: Tesla V100-SXM2-32GB
GPU 2: Tesla V100-SXM2-32GB
GPU 3: Tesla V100-SXM2-32GB
GPU 4: Tesla V100-SXM2-32GB
GPU 5: Tesla V100-SXM2-32GB
GPU 6: Tesla V100-SXM2-32GB
GPU 7: Tesla V100-SXM2-32GB

Nvidia driver version: 418.67
cuDNN version: /usr/local/cuda-9.0/lib64/libcudnn.so.7.0.4

Versions of relevant libraries:
[pip3] numpy==1.17.3
[conda] linklink                  0.3.1+cuda9.0.torch131.mvapich2.pmi2          pypi_0    pypi
[conda] torch                     1.3.1+cuda90.cudnn7.6.3.lms          pypi_0    pypi
[conda] torchvision               0.4.2                    pypi_0    pypi
        Pillow (7.1.2)
2021-04-01 21:02:30,827 maskrcnn_benchmark INFO: Loaded configuration file configs/mmss_v07.yaml
2021-04-01 21:02:30,828 maskrcnn_benchmark INFO:
MODEL:
  # This is what indicates we want image-caption training not object detection
  META_ARCHITECTURE: "MMSS-GCNN"
  # URL to the initial weights, trained for imagenet classification
  WEIGHT: "/mnt/lustreold/lixiangtai/pretrained/R-50.pkl"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
  BACKBONE:
    # a full resnet, including stem and 4 blocks
    CONV_BODY: "R-50-C5"
    # don't freeze any layer, train everything
    FREEZE_CONV_BODY_AT: 0
  LANGUAGE_BACKBONE:
    # make a BERT model to process captions
    TYPE: "BERT-Base"
    # and freeze it (loaded from original pretrained bert of huggingface)
    FREEZE: True
  MMSS_HEAD:
    # We want both a grounding head and a transformer head on top of image and caption,
    # each of which defines its own objective functions.
    TYPES: ("GroundingHead", "TransformerHead")
    DEFAULT_HEAD: "GroundingHead"
    # Share the weights of the vision to language projection between the two heads.
    # Use the one on the grounding head because that is the default (see above)
    TIE_VL_PROJECTION_WEIGHTS: True
    # Randomly keep up to 100 visual regions from each image. This is to save memory.
    SPATIAL_DROPOUT: 100
    GROUNDING:
      # Use dot product for grounding. This could be cosine or euclidean too.
      LOCAL_METRIC: "dot"
      # After aligning words to regions, sum the local distances to compute global distance.
      GLOBAL_METRIC: "aligned_local"
      # Use softmax to softly align each word to regions, and vice versa.
      # This could be for instance hardmax, which aligns to the most similar
      ALIGNMENT: "softmax"
      # Typical good values are 100.0 for euclidean, 10.0 for dot, 0.01 for cosine
      ALIGNMENT_TEMPERATURE: 10.0
      # This loss is to choose the right caption out of all captions in the batch,
      # And similarly choose the right image. Could be triplet loss instead.
      LOSS: "cross_entropy"
      # Whether to find a region for each word
      ALIGN_WORDS_TO_REGIONS: True
      # Whether to find a word for a region
      # At least one of these two should be True
      ALIGN_REGIONS_TO_WORDS: True
    TRANSFORMER:
      # Whether to perform masked language modeling (randomly mask words from captions
      # and have the model reconstruct them)
      MASKED_LANGUAGE_MODELING: True
      # Whether to do that during validation as well. That is not good if you want to
      # measure image-caption matching scores.
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      # For now this is not implemented, so keep it False and ''
      MASKED_VISUAL_MODELING: False
      MVM_LOSS: ''
      # For Multimedia Matching loss, cross-entropy works just like in the grounding head
      MMM_LOSS: 'cross_entropy'
      # Typical BERT configs as in Huggingface
      BERT_CONFIG:
        num_hidden_layers: 6
        num_attention_heads: 8
        intermediate_size: 768
DATASETS:
  TRAIN: ("coco_captions_train",)
  TEST: ("coco_captions_val",)
  DATASET_CLASS: "COCOCaptionsDataset"
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS: (20000, 35000)
  MAX_ITER: 40000
  IMS_PER_BATCH: 64
  TEST_PERIOD: 1000
  CHECKPOINT_PERIOD: 1000
  LOG_PERIOD: 100
  CLIP_GRAD_NORM_AT: 5.0
  # A value of more than one means accumulate gradients for several batches before updating
  GRADIENT_ACCUMULATION_STEPS: 1
  # If true, it calls model.train() before computing validation loss. Needed for some models.
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
TEST:
  DO_EVAL: False
  IMS_PER_BATCH: 64

2021-04-01 21:02:30,853 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DROP_LAST: False
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 0
DATASETS:
  DATASET_ARGS:
    EMB_DIM: 300
    EMB_KEY: GloVE
    LOAD_EMBEDDINGS: False
    MULTI_LABEL_MODE: False
  DATASET_CLASS: COCOCaptionsDataset
  TEST: ('coco_captions_val',)
  TRAIN: ('coco_captions_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-50-C5
    FREEZE_CONV_BODY_AT: 0
  BACKBONE_PREFIX:
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF:
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE:
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    ADD_POSITION_EMBEDDING: False
    EMBEDDING_PATH:
    FREEZE: True
    TYPE: BERT-Base
  LOAD_CLASSIFIER: True
  LOAD_EMB_PRED_FROM_MMSS_HEAD: False
  LOAD_TRAINER_STATE: True
  MASK_ON: False
  META_ARCHITECTURE: MMSS-GCNN
  MMSS_HEAD:
    DEFAULT_HEAD: GroundingHead
    GROUNDING:
      ALIGNMENT: softmax
      ALIGNMENT_TEMPERATURE: 10.0
      ALIGN_REGIONS_TO_WORDS: True
      ALIGN_WORDS_TO_REGIONS: True
      GLOBAL_METRIC: aligned_local
      LOCAL_METRIC: dot
      LOSS: cross_entropy
      NEGATIVE_MINING: random
      TRIPLET_MARGIN: 1.0
    SPATIAL_DROPOUT: 100
    TIE_VL_PROJECTION_WEIGHTS: True
    TRANSFORMER:
      BERT_CONFIG:
        attention_probs_dropout_prob: 0.1
        gradient_checkpointing: False
        hidden_act: gelu
        hidden_dropout_prob: 0.1
        hidden_size: 768
        initializer_range: 0.02
        intermediate_size: 768
        layer_norm_eps: 1e-12
        max_position_embeddings: 512
        num_attention_heads: 8
        num_hidden_layers: 6
        pad_token_id: 0
        type_vocab_size: 2
        vocab_size: 30522
      MASKED_LANGUAGE_MODELING: True
      MASKED_LANGUAGE_MODELING_PROB: 0.15
      MASKED_LANGUAGE_MODELING_PROB_MASK: 0.9
      MASKED_LANGUAGE_MODELING_PROB_NOISE: 0.0
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      MASKED_VISUAL_MODELING: False
      MMM_LOSS: cross_entropy
      MVM_LOSS:
      MVM_LOSS_NUM_NEGATIVE: 128
    TYPES: ('GroundingHead', 'TransformerHead')
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    EMBEDDING_BASED: False
    EMB_DIM: 300
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    FREEZE_EMB_PRED: False
    FREEZE_FEATURE_EXTRACTOR: False
    LOSS_WEIGHT_BACKGROUND: 1.0
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
    WSDDN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    DONT_TRAIN: False
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  WEIGHT: /mnt/lustreold/lixiangtai/pretrained/R-50.pkl
OUTPUT_DIR: /mnt/lustre/lixiangtai/runs/vltrain/121
PATHS_CATALOG: /mnt/lustre/lixiangtai/project/ovr-cnn/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 1000
  CLIP_GRAD_NORM_AT: 5.0
  GAMMA: 0.1
  GRADIENT_ACCUMULATION_STEPS: 1
  IMS_PER_BATCH: 64
  LOG_PERIOD: 100
  MAX_ITER: 40000
  MOMENTUM: 0.9
  SKIP_VAL_LOSS: False
  STEPS: (20000, 35000)
  TEST_PERIOD: 1000
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  DO_EVAL: False
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 64
2021-04-01 21:02:30,854 maskrcnn_benchmark INFO: Saving config into: /mnt/lustre/lixiangtai/runs/vltrain/121/config.yml
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: The following parameters will be trained:
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.stem.conv1.weight
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.downsample.0.weight
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv1.weight
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv2.weight
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv3.weight
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv1.weight
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv2.weight
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv3.weight
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv1.weight
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv2.weight
2021-04-01 21:02:40,920 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv3.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.downsample.0.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv1.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv2.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv3.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv1.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv2.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv3.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv1.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv2.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv3.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv1.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv2.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv3.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.downsample.0.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv1.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv2.weight
2021-04-01 21:02:40,921 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv3.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv1.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv2.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv3.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv1.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv2.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv3.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv1.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv2.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv3.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv1.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv2.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv3.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv1.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv2.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv3.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.downsample.0.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv1.weight
2021-04-01 21:02:40,922 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv2.weight
2021-04-01 21:02:40,923 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv3.weight
2021-04-01 21:02:40,923 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv1.weight
2021-04-01 21:02:40,923 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv2.weight
2021-04-01 21:02:40,923 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv3.weight
2021-04-01 21:02:40,923 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv1.weight
2021-04-01 21:02:40,923 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv2.weight
2021-04-01 21:02:40,923 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv3.weight
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.GroundingHead.v2l_projection.weight
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.GroundingHead.v2l_projection.bias
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_embeddings.weight
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_embeddings.bias
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_location_embeddings.weight
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_location_embeddings.bias
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.LayerNorm.weight
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.LayerNorm.bias
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.weight
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.bias
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.weight
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.bias
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.weight
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.bias
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.weight
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.bias
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.weight
2021-04-01 21:02:40,924 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.bias
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.weight
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.bias
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.dense.weight
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.dense.bias
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.weight
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.bias
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.weight
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.bias
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.weight
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.bias
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.weight
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.bias
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.weight
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.bias
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.weight
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.bias
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.weight
2021-04-01 21:02:40,925 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.bias
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.dense.weight
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.dense.bias
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.weight
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.bias
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.weight
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.bias
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.weight
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.bias
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.weight
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.bias
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.weight
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.bias
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.weight
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.bias
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.weight
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.bias
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.dense.weight
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.dense.bias
2021-04-01 21:02:40,926 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.weight
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.bias
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.weight
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.bias
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.weight
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.bias
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.weight
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.bias
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.weight
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.bias
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.weight
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.bias
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.weight
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.bias
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.dense.weight
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.dense.bias
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.weight
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.bias
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.weight
2021-04-01 21:02:40,927 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.bias
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.weight
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.bias
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.weight
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.bias
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.weight
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.bias
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.weight
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.bias
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.weight
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.bias
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.dense.weight
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.dense.bias
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.weight
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.bias
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.weight
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.bias
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.weight
2021-04-01 21:02:40,928 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.bias
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.weight
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.bias
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.weight
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.bias
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.weight
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.bias
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.weight
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.bias
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.dense.weight
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.dense.bias
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.weight
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.bias
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.pooler.dense.weight
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.pooler.dense.bias
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.bias
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.dense.weight
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.dense.bias
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.weight
2021-04-01 21:02:40,929 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.bias
2021-04-01 21:02:40,930 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.bi_seq_relationship.weight
2021-04-01 21:02:40,930 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.bi_seq_relationship.bias
2021-04-01 21:02:42,115 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /mnt/lustreold/lixiangtai/pretrained/R-50.pkl
2021-04-01 21:02:43,910 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping C2 weights
2021-04-01 21:02:43,913 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_b                         mapped name: conv1.bias
2021-04-01 21:02:43,913 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_w                         mapped name: conv1.weight
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_b                        mapped name: fc1000.bias
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_w                        mapped name: fc1000.weight
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_beta          mapped name: layer1.0.downsample.1.biaseta
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_gamma         mapped name: layer1.0.downsample.1.gamma
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_running_mean  mapped name: layer1.0.downsample.1.running.mean
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_running_var   mapped name: layer1.0.downsample.1.running.var
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w                mapped name: layer1.0.downsample.0.weight
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_beta         mapped name: layer1.0.bn1.biaseta
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_gamma        mapped name: layer1.0.bn1.gamma
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_running_mean mapped name: layer1.0.bn1.running.mean
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_running_var  mapped name: layer1.0.bn1.running.var
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w               mapped name: layer1.0.conv1.weight
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_beta         mapped name: layer1.0.bn2.biaseta
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_gamma        mapped name: layer1.0.bn2.gamma
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_running_mean mapped name: layer1.0.bn2.running.mean
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_running_var  mapped name: layer1.0.bn2.running.var
2021-04-01 21:02:43,914 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w               mapped name: layer1.0.conv2.weight
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_beta         mapped name: layer1.0.bn3.biaseta
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_gamma        mapped name: layer1.0.bn3.gamma
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_running_mean mapped name: layer1.0.bn3.running.mean
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_running_var  mapped name: layer1.0.bn3.running.var
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w               mapped name: layer1.0.conv3.weight
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_beta         mapped name: layer1.1.bn1.biaseta
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_gamma        mapped name: layer1.1.bn1.gamma
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_running_mean mapped name: layer1.1.bn1.running.mean
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_running_var  mapped name: layer1.1.bn1.running.var
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w               mapped name: layer1.1.conv1.weight
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_beta         mapped name: layer1.1.bn2.biaseta
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_gamma        mapped name: layer1.1.bn2.gamma
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_running_mean mapped name: layer1.1.bn2.running.mean
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_running_var  mapped name: layer1.1.bn2.running.var
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w               mapped name: layer1.1.conv2.weight
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_beta         mapped name: layer1.1.bn3.biaseta
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_gamma        mapped name: layer1.1.bn3.gamma
2021-04-01 21:02:43,915 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_running_mean mapped name: layer1.1.bn3.running.mean
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_running_var  mapped name: layer1.1.bn3.running.var
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w               mapped name: layer1.1.conv3.weight
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_beta         mapped name: layer1.2.bn1.biaseta
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_gamma        mapped name: layer1.2.bn1.gamma
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_running_mean mapped name: layer1.2.bn1.running.mean
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_running_var  mapped name: layer1.2.bn1.running.var
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w               mapped name: layer1.2.conv1.weight
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_beta         mapped name: layer1.2.bn2.biaseta
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_gamma        mapped name: layer1.2.bn2.gamma
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_running_mean mapped name: layer1.2.bn2.running.mean
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_running_var  mapped name: layer1.2.bn2.running.var
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w               mapped name: layer1.2.conv2.weight
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_beta         mapped name: layer1.2.bn3.biaseta
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_gamma        mapped name: layer1.2.bn3.gamma
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_running_mean mapped name: layer1.2.bn3.running.mean
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_running_var  mapped name: layer1.2.bn3.running.var
2021-04-01 21:02:43,916 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w               mapped name: layer1.2.conv3.weight
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_beta          mapped name: layer2.0.downsample.1.biaseta
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_gamma         mapped name: layer2.0.downsample.1.gamma
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_running_mean  mapped name: layer2.0.downsample.1.running.mean
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_running_var   mapped name: layer2.0.downsample.1.running.var
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w                mapped name: layer2.0.downsample.0.weight
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_beta         mapped name: layer2.0.bn1.biaseta
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_gamma        mapped name: layer2.0.bn1.gamma
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_running_mean mapped name: layer2.0.bn1.running.mean
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_running_var  mapped name: layer2.0.bn1.running.var
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w               mapped name: layer2.0.conv1.weight
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_beta         mapped name: layer2.0.bn2.biaseta
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_gamma        mapped name: layer2.0.bn2.gamma
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_running_mean mapped name: layer2.0.bn2.running.mean
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_running_var  mapped name: layer2.0.bn2.running.var
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w               mapped name: layer2.0.conv2.weight
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_beta         mapped name: layer2.0.bn3.biaseta
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_gamma        mapped name: layer2.0.bn3.gamma
2021-04-01 21:02:43,917 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_running_mean mapped name: layer2.0.bn3.running.mean
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_running_var  mapped name: layer2.0.bn3.running.var
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w               mapped name: layer2.0.conv3.weight
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_beta         mapped name: layer2.1.bn1.biaseta
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_gamma        mapped name: layer2.1.bn1.gamma
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_running_mean mapped name: layer2.1.bn1.running.mean
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_running_var  mapped name: layer2.1.bn1.running.var
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w               mapped name: layer2.1.conv1.weight
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_beta         mapped name: layer2.1.bn2.biaseta
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_gamma        mapped name: layer2.1.bn2.gamma
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_running_mean mapped name: layer2.1.bn2.running.mean
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_running_var  mapped name: layer2.1.bn2.running.var
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w               mapped name: layer2.1.conv2.weight
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_beta         mapped name: layer2.1.bn3.biaseta
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_gamma        mapped name: layer2.1.bn3.gamma
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_running_mean mapped name: layer2.1.bn3.running.mean
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_running_var  mapped name: layer2.1.bn3.running.var
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w               mapped name: layer2.1.conv3.weight
2021-04-01 21:02:43,918 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_beta         mapped name: layer2.2.bn1.biaseta
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_gamma        mapped name: layer2.2.bn1.gamma
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_running_mean mapped name: layer2.2.bn1.running.mean
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_running_var  mapped name: layer2.2.bn1.running.var
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w               mapped name: layer2.2.conv1.weight
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_beta         mapped name: layer2.2.bn2.biaseta
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_gamma        mapped name: layer2.2.bn2.gamma
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_running_mean mapped name: layer2.2.bn2.running.mean
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_running_var  mapped name: layer2.2.bn2.running.var
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w               mapped name: layer2.2.conv2.weight
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_beta         mapped name: layer2.2.bn3.biaseta
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_gamma        mapped name: layer2.2.bn3.gamma
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_running_mean mapped name: layer2.2.bn3.running.mean
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_running_var  mapped name: layer2.2.bn3.running.var
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w               mapped name: layer2.2.conv3.weight
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_beta         mapped name: layer2.3.bn1.biaseta
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_gamma        mapped name: layer2.3.bn1.gamma
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_running_mean mapped name: layer2.3.bn1.running.mean
2021-04-01 21:02:43,919 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_running_var  mapped name: layer2.3.bn1.running.var
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w               mapped name: layer2.3.conv1.weight
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_beta         mapped name: layer2.3.bn2.biaseta
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_gamma        mapped name: layer2.3.bn2.gamma
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_running_mean mapped name: layer2.3.bn2.running.mean
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_running_var  mapped name: layer2.3.bn2.running.var
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w               mapped name: layer2.3.conv2.weight
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_beta         mapped name: layer2.3.bn3.biaseta
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_gamma        mapped name: layer2.3.bn3.gamma
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_running_mean mapped name: layer2.3.bn3.running.mean
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_running_var  mapped name: layer2.3.bn3.running.var
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w               mapped name: layer2.3.conv3.weight
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_beta          mapped name: layer3.0.downsample.1.biaseta
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_gamma         mapped name: layer3.0.downsample.1.gamma
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_running_mean  mapped name: layer3.0.downsample.1.running.mean
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_running_var   mapped name: layer3.0.downsample.1.running.var
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w                mapped name: layer3.0.downsample.0.weight
2021-04-01 21:02:43,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_beta         mapped name: layer3.0.bn1.biaseta
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_gamma        mapped name: layer3.0.bn1.gamma
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_running_mean mapped name: layer3.0.bn1.running.mean
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_running_var  mapped name: layer3.0.bn1.running.var
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w               mapped name: layer3.0.conv1.weight
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_beta         mapped name: layer3.0.bn2.biaseta
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_gamma        mapped name: layer3.0.bn2.gamma
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_running_mean mapped name: layer3.0.bn2.running.mean
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_running_var  mapped name: layer3.0.bn2.running.var
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w               mapped name: layer3.0.conv2.weight
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_beta         mapped name: layer3.0.bn3.biaseta
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_gamma        mapped name: layer3.0.bn3.gamma
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_running_mean mapped name: layer3.0.bn3.running.mean
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_running_var  mapped name: layer3.0.bn3.running.var
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w               mapped name: layer3.0.conv3.weight
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_beta         mapped name: layer3.1.bn1.biaseta
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_gamma        mapped name: layer3.1.bn1.gamma
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_running_mean mapped name: layer3.1.bn1.running.mean
2021-04-01 21:02:43,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_running_var  mapped name: layer3.1.bn1.running.var
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w               mapped name: layer3.1.conv1.weight
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_beta         mapped name: layer3.1.bn2.biaseta
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_gamma        mapped name: layer3.1.bn2.gamma
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_running_mean mapped name: layer3.1.bn2.running.mean
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_running_var  mapped name: layer3.1.bn2.running.var
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w               mapped name: layer3.1.conv2.weight
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_beta         mapped name: layer3.1.bn3.biaseta
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_gamma        mapped name: layer3.1.bn3.gamma
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_running_mean mapped name: layer3.1.bn3.running.mean
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_running_var  mapped name: layer3.1.bn3.running.var
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w               mapped name: layer3.1.conv3.weight
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_beta         mapped name: layer3.2.bn1.biaseta
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_gamma        mapped name: layer3.2.bn1.gamma
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_running_mean mapped name: layer3.2.bn1.running.mean
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_running_var  mapped name: layer3.2.bn1.running.var
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w               mapped name: layer3.2.conv1.weight
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_beta         mapped name: layer3.2.bn2.biaseta
2021-04-01 21:02:43,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_gamma        mapped name: layer3.2.bn2.gamma
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_running_mean mapped name: layer3.2.bn2.running.mean
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_running_var  mapped name: layer3.2.bn2.running.var
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w               mapped name: layer3.2.conv2.weight
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_beta         mapped name: layer3.2.bn3.biaseta
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_gamma        mapped name: layer3.2.bn3.gamma
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_running_mean mapped name: layer3.2.bn3.running.mean
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_running_var  mapped name: layer3.2.bn3.running.var
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w               mapped name: layer3.2.conv3.weight
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_beta         mapped name: layer3.3.bn1.biaseta
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_gamma        mapped name: layer3.3.bn1.gamma
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_running_mean mapped name: layer3.3.bn1.running.mean
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_running_var  mapped name: layer3.3.bn1.running.var
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w               mapped name: layer3.3.conv1.weight
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_beta         mapped name: layer3.3.bn2.biaseta
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_gamma        mapped name: layer3.3.bn2.gamma
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_running_mean mapped name: layer3.3.bn2.running.mean
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_running_var  mapped name: layer3.3.bn2.running.var
2021-04-01 21:02:43,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w               mapped name: layer3.3.conv2.weight
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_beta         mapped name: layer3.3.bn3.biaseta
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_gamma        mapped name: layer3.3.bn3.gamma
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_running_mean mapped name: layer3.3.bn3.running.mean
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_running_var  mapped name: layer3.3.bn3.running.var
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w               mapped name: layer3.3.conv3.weight
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_beta         mapped name: layer3.4.bn1.biaseta
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_gamma        mapped name: layer3.4.bn1.gamma
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_running_mean mapped name: layer3.4.bn1.running.mean
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_running_var  mapped name: layer3.4.bn1.running.var
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w               mapped name: layer3.4.conv1.weight
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_beta         mapped name: layer3.4.bn2.biaseta
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_gamma        mapped name: layer3.4.bn2.gamma
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_running_mean mapped name: layer3.4.bn2.running.mean
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_running_var  mapped name: layer3.4.bn2.running.var
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w               mapped name: layer3.4.conv2.weight
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_beta         mapped name: layer3.4.bn3.biaseta
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_gamma        mapped name: layer3.4.bn3.gamma
2021-04-01 21:02:43,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_running_mean mapped name: layer3.4.bn3.running.mean
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_running_var  mapped name: layer3.4.bn3.running.var
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w               mapped name: layer3.4.conv3.weight
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_beta         mapped name: layer3.5.bn1.biaseta
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_gamma        mapped name: layer3.5.bn1.gamma
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_running_mean mapped name: layer3.5.bn1.running.mean
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_running_var  mapped name: layer3.5.bn1.running.var
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w               mapped name: layer3.5.conv1.weight
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_beta         mapped name: layer3.5.bn2.biaseta
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_gamma        mapped name: layer3.5.bn2.gamma
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_running_mean mapped name: layer3.5.bn2.running.mean
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_running_var  mapped name: layer3.5.bn2.running.var
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w               mapped name: layer3.5.conv2.weight
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_beta         mapped name: layer3.5.bn3.biaseta
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_gamma        mapped name: layer3.5.bn3.gamma
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_running_mean mapped name: layer3.5.bn3.running.mean
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_running_var  mapped name: layer3.5.bn3.running.var
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w               mapped name: layer3.5.conv3.weight
2021-04-01 21:02:43,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_beta          mapped name: layer4.0.downsample.1.biaseta
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_gamma         mapped name: layer4.0.downsample.1.gamma
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_running_mean  mapped name: layer4.0.downsample.1.running.mean
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_running_var   mapped name: layer4.0.downsample.1.running.var
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w                mapped name: layer4.0.downsample.0.weight
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_beta         mapped name: layer4.0.bn1.biaseta
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_gamma        mapped name: layer4.0.bn1.gamma
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_running_mean mapped name: layer4.0.bn1.running.mean
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_running_var  mapped name: layer4.0.bn1.running.var
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w               mapped name: layer4.0.conv1.weight
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_beta         mapped name: layer4.0.bn2.biaseta
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_gamma        mapped name: layer4.0.bn2.gamma
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_running_mean mapped name: layer4.0.bn2.running.mean
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_running_var  mapped name: layer4.0.bn2.running.var
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w               mapped name: layer4.0.conv2.weight
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_beta         mapped name: layer4.0.bn3.biaseta
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_gamma        mapped name: layer4.0.bn3.gamma
2021-04-01 21:02:43,926 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_running_mean mapped name: layer4.0.bn3.running.mean
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_running_var  mapped name: layer4.0.bn3.running.var
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w               mapped name: layer4.0.conv3.weight
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_beta         mapped name: layer4.1.bn1.biaseta
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_gamma        mapped name: layer4.1.bn1.gamma
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_running_mean mapped name: layer4.1.bn1.running.mean
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_running_var  mapped name: layer4.1.bn1.running.var
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w               mapped name: layer4.1.conv1.weight
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_beta         mapped name: layer4.1.bn2.biaseta
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_gamma        mapped name: layer4.1.bn2.gamma
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_running_mean mapped name: layer4.1.bn2.running.mean
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_running_var  mapped name: layer4.1.bn2.running.var
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w               mapped name: layer4.1.conv2.weight
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_beta         mapped name: layer4.1.bn3.biaseta
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_gamma        mapped name: layer4.1.bn3.gamma
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_running_mean mapped name: layer4.1.bn3.running.mean
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_running_var  mapped name: layer4.1.bn3.running.var
2021-04-01 21:02:43,927 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w               mapped name: layer4.1.conv3.weight
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_beta         mapped name: layer4.2.bn1.biaseta
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_gamma        mapped name: layer4.2.bn1.gamma
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_running_mean mapped name: layer4.2.bn1.running.mean
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_running_var  mapped name: layer4.2.bn1.running.var
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w               mapped name: layer4.2.conv1.weight
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_beta         mapped name: layer4.2.bn2.biaseta
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_gamma        mapped name: layer4.2.bn2.gamma
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_running_mean mapped name: layer4.2.bn2.running.mean
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_running_var  mapped name: layer4.2.bn2.running.var
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w               mapped name: layer4.2.conv2.weight
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_beta         mapped name: layer4.2.bn3.biaseta
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_gamma        mapped name: layer4.2.bn3.gamma
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_running_mean mapped name: layer4.2.bn3.running.mean
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_running_var  mapped name: layer4.2.bn3.running.var
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w               mapped name: layer4.2.conv3.weight
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_beta               mapped name: bn1.biaseta
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_gamma              mapped name: bn1.gamma
2021-04-01 21:02:43,928 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_running_mean       mapped name: bn1.running.mean
2021-04-01 21:02:43,929 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_running_var        mapped name: bn1.running.var
2021-04-01 21:02:43,929 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping conv weights for deformable conv weights
2021-04-01 21:02:44,501 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv1.weight                                                               loaded from layer1.0.conv1.weight              of shape (64, 64, 1, 1)
2021-04-01 21:02:44,501 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv2.weight                                                               loaded from layer1.0.conv2.weight              of shape (64, 64, 3, 3)
2021-04-01 21:02:44,501 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv3.weight                                                               loaded from layer1.0.conv3.weight              of shape (256, 64, 1, 1)
2021-04-01 21:02:44,501 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.0.weight                                                        loaded from layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
2021-04-01 21:02:44,501 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv1.weight                                                               loaded from layer1.1.conv1.weight              of shape (64, 256, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv2.weight                                                               loaded from layer1.1.conv2.weight              of shape (64, 64, 3, 3)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv3.weight                                                               loaded from layer1.1.conv3.weight              of shape (256, 64, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv1.weight                                                               loaded from layer1.2.conv1.weight              of shape (64, 256, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv2.weight                                                               loaded from layer1.2.conv2.weight              of shape (64, 64, 3, 3)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv3.weight                                                               loaded from layer1.2.conv3.weight              of shape (256, 64, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv1.weight                                                               loaded from layer2.0.conv1.weight              of shape (128, 256, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv2.weight                                                               loaded from layer2.0.conv2.weight              of shape (128, 128, 3, 3)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv3.weight                                                               loaded from layer2.0.conv3.weight              of shape (512, 128, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.0.weight                                                        loaded from layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv1.weight                                                               loaded from layer2.1.conv1.weight              of shape (128, 512, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv2.weight                                                               loaded from layer2.1.conv2.weight              of shape (128, 128, 3, 3)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv3.weight                                                               loaded from layer2.1.conv3.weight              of shape (512, 128, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv1.weight                                                               loaded from layer2.2.conv1.weight              of shape (128, 512, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv2.weight                                                               loaded from layer2.2.conv2.weight              of shape (128, 128, 3, 3)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv3.weight                                                               loaded from layer2.2.conv3.weight              of shape (512, 128, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv1.weight                                                               loaded from layer2.3.conv1.weight              of shape (128, 512, 1, 1)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv2.weight                                                               loaded from layer2.3.conv2.weight              of shape (128, 128, 3, 3)
2021-04-01 21:02:44,502 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv3.weight                                                               loaded from layer2.3.conv3.weight              of shape (512, 128, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv1.weight                                                               loaded from layer3.0.conv1.weight              of shape (256, 512, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv2.weight                                                               loaded from layer3.0.conv2.weight              of shape (256, 256, 3, 3)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv3.weight                                                               loaded from layer3.0.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.0.weight                                                        loaded from layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv1.weight                                                               loaded from layer3.1.conv1.weight              of shape (256, 1024, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv2.weight                                                               loaded from layer3.1.conv2.weight              of shape (256, 256, 3, 3)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv3.weight                                                               loaded from layer3.1.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv1.weight                                                               loaded from layer3.2.conv1.weight              of shape (256, 1024, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv2.weight                                                               loaded from layer3.2.conv2.weight              of shape (256, 256, 3, 3)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv3.weight                                                               loaded from layer3.2.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv1.weight                                                               loaded from layer3.3.conv1.weight              of shape (256, 1024, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv2.weight                                                               loaded from layer3.3.conv2.weight              of shape (256, 256, 3, 3)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv3.weight                                                               loaded from layer3.3.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv1.weight                                                               loaded from layer3.4.conv1.weight              of shape (256, 1024, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv2.weight                                                               loaded from layer3.4.conv2.weight              of shape (256, 256, 3, 3)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv3.weight                                                               loaded from layer3.4.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv1.weight                                                               loaded from layer3.5.conv1.weight              of shape (256, 1024, 1, 1)
2021-04-01 21:02:44,503 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv2.weight                                                               loaded from layer3.5.conv2.weight              of shape (256, 256, 3, 3)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv3.weight                                                               loaded from layer3.5.conv3.weight              of shape (1024, 256, 1, 1)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv1.weight                                                               loaded from layer4.0.conv1.weight              of shape (512, 1024, 1, 1)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv2.weight                                                               loaded from layer4.0.conv2.weight              of shape (512, 512, 3, 3)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv3.weight                                                               loaded from layer4.0.conv3.weight              of shape (2048, 512, 1, 1)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.0.weight                                                        loaded from layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv1.weight                                                               loaded from layer4.1.conv1.weight              of shape (512, 2048, 1, 1)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv2.weight                                                               loaded from layer4.1.conv2.weight              of shape (512, 512, 3, 3)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv3.weight                                                               loaded from layer4.1.conv3.weight              of shape (2048, 512, 1, 1)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv1.weight                                                               loaded from layer4.2.conv1.weight              of shape (512, 2048, 1, 1)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv2.weight                                                               loaded from layer4.2.conv2.weight              of shape (512, 512, 3, 3)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv3.weight                                                               loaded from layer4.2.conv3.weight              of shape (2048, 512, 1, 1)
2021-04-01 21:02:44,504 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.conv1.weight                                                                   loaded from conv1.weight                       of shape (64, 3, 7, 7)
2021-04-01 21:02:44,608 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2021-04-01 21:02:51,382 maskrcnn_benchmark.utils.miscellaneous WARNING: Dataset [COCOCaptionsDataset] has no categories attribute, labels.json file won't be created
2021-04-01 21:02:51,601 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2021-04-01 21:02:51,917 maskrcnn_benchmark.trainer INFO: Start training
2021-04-01 21:04:09,954 maskrcnn_benchmark.trainer INFO: eta: 8:37:29  iter: 100  Cross-Entropy Loss (Align Regions, Choose Caption): 1.9200 (2.0069)  Cross-Entropy Loss (Align Regions, Choose Image): 1.9222 (1.9985)  Cross-Entropy Loss (Align Words, Choose Caption): 1.9885 (2.0371)  Cross-Entropy Loss (Align Words, Choose Image): 1.9789 (2.0298)  Image Caption Matching Loss: 4.1458 (4.1600)  Masked Language Modeling Loss: 4.6994 (5.5807)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 16.5868 (17.8130)  Batch Accuracy (Align Regions, Choose Caption): 0.2344 (0.1917)  Batch Accuracy (Align Regions, Choose Image): 0.2812 (0.2108)  Batch Accuracy (Align Words, Choose Caption): 0.2344 (0.1809)  Batch Accuracy (Align Words, Choose Image): 0.2188 (0.1855)  Batch Accuracy (Choose Caption): 0.1406 (0.1263)  Batch Accuracy (Choose Image): 0.1406 (0.1295)  Masked Language Modeling Accuracy: 0.3151 (0.2421)  time: 0.6838 (0.7782)  data: 0.0342 (0.0740)  lr: 0.004667  max mem: 11645
2021-04-01 21:05:19,303 maskrcnn_benchmark.trainer INFO: eta: 8:08:16  iter: 200  Cross-Entropy Loss (Align Regions, Choose Caption): 1.7981 (1.9275)  Cross-Entropy Loss (Align Regions, Choose Image): 1.8074 (1.9250)  Cross-Entropy Loss (Align Words, Choose Caption): 1.9194 (1.9875)  Cross-Entropy Loss (Align Words, Choose Image): 1.8949 (1.9761)  Image Caption Matching Loss: 4.1132 (4.1482)  Masked Language Modeling Loss: 3.6663 (4.8237)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 15.2777 (16.7881)  Batch Accuracy (Align Regions, Choose Caption): 0.3125 (0.2404)  Batch Accuracy (Align Regions, Choose Image): 0.3125 (0.2584)  Batch Accuracy (Align Words, Choose Caption): 0.2656 (0.2190)  Batch Accuracy (Align Words, Choose Image): 0.2812 (0.2259)  Batch Accuracy (Choose Caption): 0.1719 (0.1384)  Batch Accuracy (Choose Image): 0.1406 (0.1433)  Masked Language Modeling Accuracy: 0.4275 (0.3185)  time: 0.6799 (0.7361)  data: 0.0327 (0.0542)  lr: 0.006000  max mem: 11645
2021-04-01 21:06:29,280 maskrcnn_benchmark.trainer INFO: eta: 7:59:01  iter: 300  Cross-Entropy Loss (Align Regions, Choose Caption): 1.7358 (1.8720)  Cross-Entropy Loss (Align Regions, Choose Image): 1.7931 (1.8712)  Cross-Entropy Loss (Align Words, Choose Caption): 1.8551 (1.9502)  Cross-Entropy Loss (Align Words, Choose Image): 1.8239 (1.9322)  Image Caption Matching Loss: 3.8751 (4.0848)  Masked Language Modeling Loss: 3.3410 (4.3881)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 14.4131 (16.0986)  Batch Accuracy (Align Regions, Choose Caption): 0.3281 (0.2737)  Batch Accuracy (Align Regions, Choose Image): 0.3281 (0.2878)  Batch Accuracy (Align Words, Choose Caption): 0.3281 (0.2448)  Batch Accuracy (Align Words, Choose Image): 0.3281 (0.2528)  Batch Accuracy (Choose Caption): 0.2031 (0.1596)  Batch Accuracy (Choose Image): 0.1719 (0.1614)  Masked Language Modeling Accuracy: 0.4632 (0.3615)  time: 0.6844 (0.7240)  data: 0.0276 (0.0478)  lr: 0.007333  max mem: 11645
2021-04-01 21:07:38,725 maskrcnn_benchmark.trainer INFO: eta: 7:53:00  iter: 400  Cross-Entropy Loss (Align Regions, Choose Caption): 1.5802 (1.8197)  Cross-Entropy Loss (Align Regions, Choose Image): 1.5797 (1.8151)  Cross-Entropy Loss (Align Words, Choose Caption): 1.7964 (1.9170)  Cross-Entropy Loss (Align Words, Choose Image): 1.7013 (1.8896)  Image Caption Matching Loss: 3.6645 (3.9879)  Masked Language Modeling Loss: 3.1735 (4.1031)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 13.3513 (15.5324)  Batch Accuracy (Align Regions, Choose Caption): 0.4219 (0.3018)  Batch Accuracy (Align Regions, Choose Image): 0.4062 (0.3137)  Batch Accuracy (Align Words, Choose Caption): 0.3438 (0.2641)  Batch Accuracy (Align Words, Choose Image): 0.3438 (0.2754)  Batch Accuracy (Choose Caption): 0.2812 (0.1854)  Batch Accuracy (Choose Image): 0.2812 (0.1839)  Masked Language Modeling Accuracy: 0.4574 (0.3880)  time: 0.6802 (0.7167)  data: 0.0252 (0.0435)  lr: 0.008667  max mem: 11645
2021-04-01 21:08:51,882 maskrcnn_benchmark.trainer INFO: eta: 7:53:43  iter: 500  Cross-Entropy Loss (Align Regions, Choose Caption): 1.5908 (1.7794)  Cross-Entropy Loss (Align Regions, Choose Image): 1.5610 (1.7714)  Cross-Entropy Loss (Align Words, Choose Caption): 1.7585 (1.8902)  Cross-Entropy Loss (Align Words, Choose Image): 1.6713 (1.8540)  Image Caption Matching Loss: 3.3284 (3.8813)  Masked Language Modeling Loss: 2.9853 (3.8858)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 12.8125 (15.0620)  Batch Accuracy (Align Regions, Choose Caption): 0.4062 (0.3234)  Batch Accuracy (Align Regions, Choose Image): 0.4375 (0.3358)  Batch Accuracy (Align Words, Choose Caption): 0.3594 (0.2794)  Batch Accuracy (Align Words, Choose Image): 0.3906 (0.2946)  Batch Accuracy (Choose Caption): 0.3281 (0.2117)  Batch Accuracy (Choose Image): 0.3281 (0.2102)  Masked Language Modeling Accuracy: 0.4983 (0.4088)  time: 0.6736 (0.7196)  data: 0.0287 (0.0409)  lr: 0.010000  max mem: 11645
2021-04-01 21:10:01,374 maskrcnn_benchmark.trainer INFO: eta: 7:49:49  iter: 600  Cross-Entropy Loss (Align Regions, Choose Caption): 1.5885 (1.7451)  Cross-Entropy Loss (Align Regions, Choose Image): 1.5629 (1.7398)  Cross-Entropy Loss (Align Words, Choose Caption): 1.7232 (1.8648)  Cross-Entropy Loss (Align Words, Choose Image): 1.6481 (1.8221)  Image Caption Matching Loss: 3.1766 (3.7667)  Masked Language Modeling Loss: 2.8044 (3.7171)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 12.4049 (14.6556)  Batch Accuracy (Align Regions, Choose Caption): 0.4375 (0.3410)  Batch Accuracy (Align Regions, Choose Image): 0.4375 (0.3525)  Batch Accuracy (Align Words, Choose Caption): 0.3594 (0.2924)  Batch Accuracy (Align Words, Choose Image): 0.3906 (0.3107)  Batch Accuracy (Choose Caption): 0.3750 (0.2375)  Batch Accuracy (Choose Image): 0.3906 (0.2387)  Masked Language Modeling Accuracy: 0.5232 (0.4258)  time: 0.6797 (0.7155)  data: 0.0217 (0.0394)  lr: 0.010000  max mem: 11645
2021-04-01 21:11:12,898 maskrcnn_benchmark.trainer INFO: eta: 7:48:36  iter: 700  Cross-Entropy Loss (Align Regions, Choose Caption): 1.4908 (1.7123)  Cross-Entropy Loss (Align Regions, Choose Image): 1.4596 (1.7051)  Cross-Entropy Loss (Align Words, Choose Caption): 1.6909 (1.8385)  Cross-Entropy Loss (Align Words, Choose Image): 1.5970 (1.7890)  Image Caption Matching Loss: 2.9416 (3.6523)  Masked Language Modeling Loss: 2.8849 (3.5842)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 12.0720 (14.2814)  Batch Accuracy (Align Regions, Choose Caption): 0.4219 (0.3569)  Batch Accuracy (Align Regions, Choose Image): 0.4219 (0.3680)  Batch Accuracy (Align Words, Choose Caption): 0.3906 (0.3052)  Batch Accuracy (Align Words, Choose Image): 0.4219 (0.3269)  Batch Accuracy (Choose Caption): 0.4219 (0.2631)  Batch Accuracy (Choose Image): 0.4219 (0.2661)  Masked Language Modeling Accuracy: 0.4920 (0.4394)  time: 0.6793 (0.7154)  data: 0.0269 (0.0379)  lr: 0.010000  max mem: 11645
2021-04-01 21:12:22,381 maskrcnn_benchmark.trainer INFO: eta: 7:45:44  iter: 800  Cross-Entropy Loss (Align Regions, Choose Caption): 1.3694 (1.6755)  Cross-Entropy Loss (Align Regions, Choose Image): 1.3903 (1.6703)  Cross-Entropy Loss (Align Words, Choose Caption): 1.5955 (1.8126)  Cross-Entropy Loss (Align Words, Choose Image): 1.5137 (1.7570)  Image Caption Matching Loss: 2.6724 (3.5388)  Masked Language Modeling Loss: 2.7845 (3.4832)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 11.1616 (13.9374)  Batch Accuracy (Align Regions, Choose Caption): 0.5000 (0.3744)  Batch Accuracy (Align Regions, Choose Image): 0.5312 (0.3846)  Batch Accuracy (Align Words, Choose Caption): 0.4219 (0.3184)  Batch Accuracy (Align Words, Choose Image): 0.4688 (0.3430)  Batch Accuracy (Choose Caption): 0.4844 (0.2887)  Batch Accuracy (Choose Image): 0.4688 (0.2929)  Masked Language Modeling Accuracy: 0.5235 (0.4494)  time: 0.6772 (0.7129)  data: 0.0261 (0.0369)  lr: 0.010000  max mem: 11645
2021-04-01 21:13:32,243 maskrcnn_benchmark.trainer INFO: eta: 7:43:31  iter: 900  Cross-Entropy Loss (Align Regions, Choose Caption): 1.3762 (1.6477)  Cross-Entropy Loss (Align Regions, Choose Image): 1.3778 (1.6427)  Cross-Entropy Loss (Align Words, Choose Caption): 1.6075 (1.7913)  Cross-Entropy Loss (Align Words, Choose Image): 1.4759 (1.7297)  Image Caption Matching Loss: 2.5842 (3.4426)  Masked Language Modeling Loss: 2.5882 (3.3949)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 10.9616 (13.6489)  Batch Accuracy (Align Regions, Choose Caption): 0.5156 (0.3873)  Batch Accuracy (Align Regions, Choose Image): 0.5000 (0.3979)  Batch Accuracy (Align Words, Choose Caption): 0.4219 (0.3290)  Batch Accuracy (Align Words, Choose Image): 0.4688 (0.3564)  Batch Accuracy (Choose Caption): 0.5000 (0.3098)  Batch Accuracy (Choose Image): 0.4844 (0.3154)  Masked Language Modeling Accuracy: 0.5519 (0.4589)  time: 0.6806 (0.7113)  data: 0.0227 (0.0362)  lr: 0.010000  max mem: 11769
2021-04-01 21:14:42,003 maskrcnn_benchmark.trainer INFO: eta: 7:41:26  iter: 1000  Cross-Entropy Loss (Align Regions, Choose Caption): 1.3205 (1.6192)  Cross-Entropy Loss (Align Regions, Choose Image): 1.3038 (1.6142)  Cross-Entropy Loss (Align Words, Choose Caption): 1.5117 (1.7686)  Cross-Entropy Loss (Align Words, Choose Image): 1.4026 (1.7014)  Image Caption Matching Loss: 2.5281 (3.3512)  Masked Language Modeling Loss: 2.5439 (3.3131)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 10.7036 (13.3678)  Batch Accuracy (Align Regions, Choose Caption): 0.5156 (0.4001)  Batch Accuracy (Align Regions, Choose Image): 0.5312 (0.4102)  Batch Accuracy (Align Words, Choose Caption): 0.4219 (0.3393)  Batch Accuracy (Align Words, Choose Image): 0.4688 (0.3680)  Batch Accuracy (Choose Caption): 0.4844 (0.3284)  Batch Accuracy (Choose Image): 0.5156 (0.3356)  Masked Language Modeling Accuracy: 0.5397 (0.4669)  time: 0.6766 (0.7099)  data: 0.0274 (0.0356)  lr: 0.010000  max mem: 11769
2021-04-01 21:14:42,294 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0001000.pth
2021-04-01 21:15:51,531 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:41:26  iter: 1000  loss: 8.1675 (8.2079)  Cross-Entropy Loss (Align Regions, Choose Caption): 1.2434 (1.2502)  Cross-Entropy Loss (Align Regions, Choose Image): 1.2658 (1.2626)  Cross-Entropy Loss (Align Words, Choose Caption): 1.5715 (1.5489)  Cross-Entropy Loss (Align Words, Choose Image): 1.3603 (1.3566)  Image Caption Matching Loss: 2.7330 (2.7896)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.5469 (0.5399)  Batch Accuracy (Align Regions, Choose Image): 0.5469 (0.5663)  Batch Accuracy (Align Words, Choose Caption): 0.4219 (0.4373)  Batch Accuracy (Align Words, Choose Image): 0.4688 (0.4996)  Batch Accuracy (Choose Caption): 0.4531 (0.4673)  Batch Accuracy (Choose Image): 0.4531 (0.4550)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11769
2021-04-01 21:17:02,485 maskrcnn_benchmark.trainer INFO: eta: 8:21:12  iter: 1100  Cross-Entropy Loss (Align Regions, Choose Caption): 1.3255 (1.5895)  Cross-Entropy Loss (Align Regions, Choose Image): 1.2630 (1.5844)  Cross-Entropy Loss (Align Words, Choose Caption): 1.4386 (1.7438)  Cross-Entropy Loss (Align Words, Choose Image): 1.3425 (1.6728)  Image Caption Matching Loss: 2.2282 (3.2620)  Masked Language Modeling Loss: 2.4888 (3.2459)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 10.2683 (13.0984)  Batch Accuracy (Align Regions, Choose Caption): 0.5312 (0.4130)  Batch Accuracy (Align Regions, Choose Image): 0.5625 (0.4229)  Batch Accuracy (Align Words, Choose Caption): 0.4688 (0.3505)  Batch Accuracy (Align Words, Choose Image): 0.5312 (0.3806)  Batch Accuracy (Choose Caption): 0.5469 (0.3468)  Batch Accuracy (Choose Image): 0.5781 (0.3542)  Masked Language Modeling Accuracy: 0.5491 (0.4739)  time: 0.6824 (0.7731)  data: 0.0281 (0.0986)  lr: 0.010000  max mem: 11769
2021-04-01 21:18:12,817 maskrcnn_benchmark.trainer INFO: eta: 8:16:10  iter: 1200  Cross-Entropy Loss (Align Regions, Choose Caption): 1.2218 (1.5638)  Cross-Entropy Loss (Align Regions, Choose Image): 1.2050 (1.5589)  Cross-Entropy Loss (Align Words, Choose Caption): 1.4464 (1.7224)  Cross-Entropy Loss (Align Words, Choose Image): 1.3006 (1.6477)  Image Caption Matching Loss: 2.1105 (3.1820)  Masked Language Modeling Loss: 2.5561 (3.1889)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 9.8243 (12.8638)  Batch Accuracy (Align Regions, Choose Caption): 0.5625 (0.4238)  Batch Accuracy (Align Regions, Choose Image): 0.5781 (0.4334)  Batch Accuracy (Align Words, Choose Caption): 0.4844 (0.3606)  Batch Accuracy (Align Words, Choose Image): 0.5156 (0.3920)  Batch Accuracy (Choose Caption): 0.5781 (0.3640)  Batch Accuracy (Choose Image): 0.5938 (0.3720)  Masked Language Modeling Accuracy: 0.5255 (0.4796)  time: 0.6792 (0.7673)  data: 0.0263 (0.0931)  lr: 0.010000  max mem: 11769
2021-04-01 21:19:22,614 maskrcnn_benchmark.trainer INFO: eta: 8:11:27  iter: 1300  Cross-Entropy Loss (Align Regions, Choose Caption): 1.2751 (1.5408)  Cross-Entropy Loss (Align Regions, Choose Image): 1.2574 (1.5345)  Cross-Entropy Loss (Align Words, Choose Caption): 1.4819 (1.7036)  Cross-Entropy Loss (Align Words, Choose Image): 1.3761 (1.6243)  Image Caption Matching Loss: 2.1058 (3.1104)  Masked Language Modeling Loss: 2.5686 (3.1376)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 10.2145 (12.6511)  Batch Accuracy (Align Regions, Choose Caption): 0.5625 (0.4331)  Batch Accuracy (Align Regions, Choose Image): 0.5469 (0.4429)  Batch Accuracy (Align Words, Choose Caption): 0.4531 (0.3689)  Batch Accuracy (Align Words, Choose Image): 0.5312 (0.4019)  Batch Accuracy (Choose Caption): 0.5469 (0.3787)  Batch Accuracy (Choose Image): 0.5938 (0.3876)  Masked Language Modeling Accuracy: 0.5479 (0.4850)  time: 0.6770 (0.7620)  data: 0.0277 (0.0883)  lr: 0.010000  max mem: 11769
2021-04-01 21:20:32,326 maskrcnn_benchmark.trainer INFO: eta: 8:07:12  iter: 1400  Cross-Entropy Loss (Align Regions, Choose Caption): 1.1374 (1.5167)  Cross-Entropy Loss (Align Regions, Choose Image): 1.1291 (1.5107)  Cross-Entropy Loss (Align Words, Choose Caption): 1.3701 (1.6828)  Cross-Entropy Loss (Align Words, Choose Image): 1.2553 (1.6004)  Image Caption Matching Loss: 2.0963 (3.0432)  Masked Language Modeling Loss: 2.4950 (3.0902)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 9.4999 (12.4440)  Batch Accuracy (Align Regions, Choose Caption): 0.5781 (0.4427)  Batch Accuracy (Align Regions, Choose Image): 0.5625 (0.4524)  Batch Accuracy (Align Words, Choose Caption): 0.5000 (0.3779)  Batch Accuracy (Align Words, Choose Image): 0.5469 (0.4116)  Batch Accuracy (Choose Caption): 0.5781 (0.3922)  Batch Accuracy (Choose Image): 0.6094 (0.4021)  Masked Language Modeling Accuracy: 0.5604 (0.4903)  time: 0.6752 (0.7573)  data: 0.0222 (0.0841)  lr: 0.010000  max mem: 11769
2021-04-01 21:21:41,986 maskrcnn_benchmark.trainer INFO: eta: 8:03:20  iter: 1500  Cross-Entropy Loss (Align Regions, Choose Caption): 1.1290 (1.4949)  Cross-Entropy Loss (Align Regions, Choose Image): 1.1305 (1.4883)  Cross-Entropy Loss (Align Words, Choose Caption): 1.3499 (1.6629)  Cross-Entropy Loss (Align Words, Choose Image): 1.1834 (1.5782)  Image Caption Matching Loss: 2.0890 (2.9777)  Masked Language Modeling Loss: 2.3204 (3.0458)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 9.0220 (12.2479)  Batch Accuracy (Align Regions, Choose Caption): 0.5938 (0.4519)  Batch Accuracy (Align Regions, Choose Image): 0.5781 (0.4612)  Batch Accuracy (Align Words, Choose Caption): 0.5156 (0.3866)  Batch Accuracy (Align Words, Choose Image): 0.5625 (0.4208)  Batch Accuracy (Choose Caption): 0.6250 (0.4062)  Batch Accuracy (Choose Image): 0.6094 (0.4156)  Masked Language Modeling Accuracy: 0.5693 (0.4948)  time: 0.6742 (0.7533)  data: 0.0236 (0.0805)  lr: 0.010000  max mem: 11769
2021-04-01 21:22:51,714 maskrcnn_benchmark.trainer INFO: eta: 7:59:51  iter: 1600  Cross-Entropy Loss (Align Regions, Choose Caption): 1.2064 (1.4740)  Cross-Entropy Loss (Align Regions, Choose Image): 1.1558 (1.4657)  Cross-Entropy Loss (Align Words, Choose Caption): 1.3350 (1.6432)  Cross-Entropy Loss (Align Words, Choose Image): 1.2077 (1.5551)  Image Caption Matching Loss: 2.1046 (2.9159)  Masked Language Modeling Loss: 2.3474 (3.0080)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 9.2833 (12.0620)  Batch Accuracy (Align Regions, Choose Caption): 0.5781 (0.4609)  Batch Accuracy (Align Regions, Choose Image): 0.5938 (0.4702)  Batch Accuracy (Align Words, Choose Caption): 0.5000 (0.3951)  Batch Accuracy (Align Words, Choose Image): 0.6094 (0.4305)  Batch Accuracy (Choose Caption): 0.5625 (0.4191)  Batch Accuracy (Choose Image): 0.5781 (0.4287)  Masked Language Modeling Accuracy: 0.5588 (0.4989)  time: 0.6777 (0.7498)  data: 0.0231 (0.0773)  lr: 0.010000  max mem: 11769
2021-04-01 21:24:02,034 maskrcnn_benchmark.trainer INFO: eta: 7:56:51  iter: 1700  Cross-Entropy Loss (Align Regions, Choose Caption): 1.1056 (1.4548)  Cross-Entropy Loss (Align Regions, Choose Image): 1.0689 (1.4458)  Cross-Entropy Loss (Align Words, Choose Caption): 1.2479 (1.6249)  Cross-Entropy Loss (Align Words, Choose Image): 1.1386 (1.5345)  Image Caption Matching Loss: 1.8911 (2.8584)  Masked Language Modeling Loss: 2.4085 (2.9702)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 9.1991 (11.8887)  Batch Accuracy (Align Regions, Choose Caption): 0.5938 (0.4681)  Batch Accuracy (Align Regions, Choose Image): 0.6094 (0.4780)  Batch Accuracy (Align Words, Choose Caption): 0.5625 (0.4030)  Batch Accuracy (Align Words, Choose Image): 0.5625 (0.4390)  Batch Accuracy (Choose Caption): 0.6406 (0.4312)  Batch Accuracy (Choose Image): 0.6562 (0.4411)  Masked Language Modeling Accuracy: 0.5686 (0.5032)  time: 0.6832 (0.7470)  data: 0.0248 (0.0746)  lr: 0.010000  max mem: 11769
2021-04-01 21:25:13,796 maskrcnn_benchmark.trainer INFO: eta: 7:54:34  iter: 1800  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0812 (1.4357)  Cross-Entropy Loss (Align Regions, Choose Image): 1.0803 (1.4258)  Cross-Entropy Loss (Align Words, Choose Caption): 1.2926 (1.6059)  Cross-Entropy Loss (Align Words, Choose Image): 1.1483 (1.5135)  Image Caption Matching Loss: 1.7587 (2.8043)  Masked Language Modeling Loss: 2.2842 (2.9355)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.7510 (11.7206)  Batch Accuracy (Align Regions, Choose Caption): 0.6094 (0.4759)  Batch Accuracy (Align Regions, Choose Image): 0.6094 (0.4857)  Batch Accuracy (Align Words, Choose Caption): 0.5625 (0.4112)  Batch Accuracy (Align Words, Choose Image): 0.5938 (0.4473)  Batch Accuracy (Choose Caption): 0.6406 (0.4419)  Batch Accuracy (Choose Image): 0.6406 (0.4524)  Masked Language Modeling Accuracy: 0.5682 (0.5069)  time: 0.6808 (0.7454)  data: 0.0228 (0.0721)  lr: 0.010000  max mem: 11769
2021-04-01 21:26:23,482 maskrcnn_benchmark.trainer INFO: eta: 7:51:42  iter: 1900  Cross-Entropy Loss (Align Regions, Choose Caption): 1.1050 (1.4177)  Cross-Entropy Loss (Align Regions, Choose Image): 1.0676 (1.4070)  Cross-Entropy Loss (Align Words, Choose Caption): 1.3100 (1.5894)  Cross-Entropy Loss (Align Words, Choose Image): 1.1561 (1.4935)  Image Caption Matching Loss: 1.7968 (2.7530)  Masked Language Modeling Loss: 2.3178 (2.9033)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.9681 (11.5639)  Batch Accuracy (Align Regions, Choose Caption): 0.6094 (0.4837)  Batch Accuracy (Align Regions, Choose Image): 0.6250 (0.4933)  Batch Accuracy (Align Words, Choose Caption): 0.5312 (0.4182)  Batch Accuracy (Align Words, Choose Image): 0.5781 (0.4549)  Batch Accuracy (Choose Caption): 0.6094 (0.4523)  Batch Accuracy (Choose Image): 0.6562 (0.4633)  Masked Language Modeling Accuracy: 0.5675 (0.5106)  time: 0.6751 (0.7428)  data: 0.0223 (0.0699)  lr: 0.010000  max mem: 11769
2021-04-01 21:27:34,166 maskrcnn_benchmark.trainer INFO: eta: 7:49:19  iter: 2000  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0120 (1.4005)  Cross-Entropy Loss (Align Regions, Choose Image): 1.0253 (1.3888)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1901 (1.5718)  Cross-Entropy Loss (Align Words, Choose Image): 1.0414 (1.4738)  Image Caption Matching Loss: 1.6324 (2.7033)  Masked Language Modeling Loss: 2.2289 (2.8741)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.2235 (11.4123)  Batch Accuracy (Align Regions, Choose Caption): 0.6406 (0.4906)  Batch Accuracy (Align Regions, Choose Image): 0.6250 (0.5003)  Batch Accuracy (Align Words, Choose Caption): 0.5625 (0.4255)  Batch Accuracy (Align Words, Choose Image): 0.6250 (0.4627)  Batch Accuracy (Choose Caption): 0.6719 (0.4619)  Batch Accuracy (Choose Image): 0.6875 (0.4738)  Masked Language Modeling Accuracy: 0.5797 (0.5136)  time: 0.6761 (0.7410)  data: 0.0269 (0.0679)  lr: 0.010000  max mem: 12148
2021-04-01 21:27:34,483 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0002000.pth
2021-04-01 21:28:43,213 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:49:19  iter: 2000  loss: 5.7898 (5.9660)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9271 (0.9241)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8959 (0.9250)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1518 (1.1509)  Cross-Entropy Loss (Align Words, Choose Image): 0.9779 (1.0314)  Image Caption Matching Loss: 1.8639 (1.9346)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.6406 (0.6758)  Batch Accuracy (Align Regions, Choose Image): 0.6979 (0.6813)  Batch Accuracy (Align Words, Choose Caption): 0.5781 (0.5848)  Batch Accuracy (Align Words, Choose Image): 0.6250 (0.6389)  Batch Accuracy (Choose Caption): 0.6406 (0.6477)  Batch Accuracy (Choose Image): 0.6094 (0.6117)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12148
2021-04-01 21:29:53,567 maskrcnn_benchmark.trainer INFO: eta: 8:07:43  iter: 2100  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0636 (1.3845)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9788 (1.3720)  Cross-Entropy Loss (Align Words, Choose Caption): 1.2163 (1.5557)  Cross-Entropy Loss (Align Words, Choose Image): 1.0838 (1.4553)  Image Caption Matching Loss: 1.7744 (2.6575)  Masked Language Modeling Loss: 2.3008 (2.8473)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.5003 (11.2722)  Batch Accuracy (Align Regions, Choose Caption): 0.6250 (0.4971)  Batch Accuracy (Align Regions, Choose Image): 0.6406 (0.5070)  Batch Accuracy (Align Words, Choose Caption): 0.5781 (0.4320)  Batch Accuracy (Align Words, Choose Image): 0.5938 (0.4699)  Batch Accuracy (Choose Caption): 0.6250 (0.4710)  Batch Accuracy (Choose Image): 0.6562 (0.4833)  Masked Language Modeling Accuracy: 0.5746 (0.5166)  time: 0.6827 (0.7721)  data: 0.0229 (0.0991)  lr: 0.010000  max mem: 12148
2021-04-01 21:31:06,417 maskrcnn_benchmark.trainer INFO: eta: 8:05:12  iter: 2200  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0006 (1.3683)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9830 (1.3549)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1313 (1.5393)  Cross-Entropy Loss (Align Words, Choose Image): 1.0114 (1.4370)  Image Caption Matching Loss: 1.5253 (2.6118)  Masked Language Modeling Loss: 2.1946 (2.8227)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.9476 (11.1340)  Batch Accuracy (Align Regions, Choose Caption): 0.6562 (0.5038)  Batch Accuracy (Align Regions, Choose Image): 0.6562 (0.5138)  Batch Accuracy (Align Words, Choose Caption): 0.5938 (0.4389)  Batch Accuracy (Align Words, Choose Image): 0.6406 (0.4774)  Batch Accuracy (Choose Caption): 0.6719 (0.4804)  Batch Accuracy (Choose Image): 0.7188 (0.4926)  Masked Language Modeling Accuracy: 0.6029 (0.5193)  time: 0.6947 (0.7702)  data: 0.0261 (0.0960)  lr: 0.010000  max mem: 12148
2021-04-01 21:32:17,008 maskrcnn_benchmark.trainer INFO: eta: 8:02:09  iter: 2300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9862 (1.3524)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9540 (1.3386)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1441 (1.5233)  Cross-Entropy Loss (Align Words, Choose Image): 0.9845 (1.4194)  Image Caption Matching Loss: 1.6377 (2.5703)  Masked Language Modeling Loss: 2.2555 (2.8002)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.8692 (11.0043)  Batch Accuracy (Align Regions, Choose Caption): 0.6562 (0.5100)  Batch Accuracy (Align Regions, Choose Image): 0.6562 (0.5199)  Batch Accuracy (Align Words, Choose Caption): 0.5781 (0.4453)  Batch Accuracy (Align Words, Choose Image): 0.6562 (0.4843)  Batch Accuracy (Choose Caption): 0.6719 (0.4889)  Batch Accuracy (Choose Image): 0.7031 (0.5012)  Masked Language Modeling Accuracy: 0.5960 (0.5214)  time: 0.6916 (0.7674)  data: 0.0298 (0.0932)  lr: 0.010000  max mem: 12148
2021-04-01 21:33:28,353 maskrcnn_benchmark.trainer INFO: eta: 7:59:28  iter: 2400  Cross-Entropy Loss (Align Regions, Choose Caption): 1.0783 (1.3382)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9432 (1.3230)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1411 (1.5087)  Cross-Entropy Loss (Align Words, Choose Image): 1.0179 (1.4032)  Image Caption Matching Loss: 1.6589 (2.5317)  Masked Language Modeling Loss: 2.2299 (2.7797)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.1995 (10.8846)  Batch Accuracy (Align Regions, Choose Caption): 0.6250 (0.5157)  Batch Accuracy (Align Regions, Choose Image): 0.6562 (0.5257)  Batch Accuracy (Align Words, Choose Caption): 0.5781 (0.4512)  Batch Accuracy (Align Words, Choose Image): 0.6250 (0.4906)  Batch Accuracy (Choose Caption): 0.6875 (0.4968)  Batch Accuracy (Choose Image): 0.6719 (0.5093)  Masked Language Modeling Accuracy: 0.5771 (0.5235)  time: 0.6941 (0.7651)  data: 0.0297 (0.0908)  lr: 0.010000  max mem: 12148
2021-04-01 21:34:38,105 maskrcnn_benchmark.trainer INFO: eta: 7:56:30  iter: 2500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9606 (1.3242)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9468 (1.3087)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1898 (1.4942)  Cross-Entropy Loss (Align Words, Choose Image): 1.0663 (1.3875)  Image Caption Matching Loss: 1.5041 (2.4933)  Masked Language Modeling Loss: 2.1668 (2.7578)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.9575 (10.7658)  Batch Accuracy (Align Regions, Choose Caption): 0.6406 (0.5213)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.5314)  Batch Accuracy (Align Words, Choose Caption): 0.5781 (0.4570)  Batch Accuracy (Align Words, Choose Image): 0.6250 (0.4971)  Batch Accuracy (Choose Caption): 0.7031 (0.5047)  Batch Accuracy (Choose Image): 0.7031 (0.5172)  Masked Language Modeling Accuracy: 0.5925 (0.5258)  time: 0.6905 (0.7624)  data: 0.0289 (0.0885)  lr: 0.010000  max mem: 12148
2021-04-01 21:35:49,793 maskrcnn_benchmark.trainer INFO: eta: 7:54:07  iter: 2600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9647 (1.3101)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9309 (1.2941)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0817 (1.4793)  Cross-Entropy Loss (Align Words, Choose Image): 0.9881 (1.3716)  Image Caption Matching Loss: 1.5014 (2.4571)  Masked Language Modeling Loss: 2.1445 (2.7361)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.5489 (10.6483)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5271)  Batch Accuracy (Align Regions, Choose Image): 0.6875 (0.5368)  Batch Accuracy (Align Words, Choose Caption): 0.6094 (0.4630)  Batch Accuracy (Align Words, Choose Image): 0.6250 (0.5032)  Batch Accuracy (Choose Caption): 0.7031 (0.5119)  Batch Accuracy (Choose Image): 0.7344 (0.5245)  Masked Language Modeling Accuracy: 0.5821 (0.5282)  time: 0.6931 (0.7606)  data: 0.0299 (0.0865)  lr: 0.010000  max mem: 12148
2021-04-01 21:37:00,905 maskrcnn_benchmark.trainer INFO: eta: 7:51:44  iter: 2700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9984 (1.2976)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9597 (1.2808)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0990 (1.4654)  Cross-Entropy Loss (Align Words, Choose Image): 1.0080 (1.3568)  Image Caption Matching Loss: 1.5557 (2.4219)  Masked Language Modeling Loss: 2.1128 (2.7158)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.7623 (10.5383)  Batch Accuracy (Align Regions, Choose Caption): 0.6719 (0.5322)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.5420)  Batch Accuracy (Align Words, Choose Caption): 0.6250 (0.4686)  Batch Accuracy (Align Words, Choose Image): 0.6562 (0.5089)  Batch Accuracy (Choose Caption): 0.7031 (0.5191)  Batch Accuracy (Choose Image): 0.6875 (0.5318)  Masked Language Modeling Accuracy: 0.5997 (0.5302)  time: 0.6927 (0.7588)  data: 0.0321 (0.0846)  lr: 0.010000  max mem: 12148
2021-04-01 21:38:12,604 maskrcnn_benchmark.trainer INFO: eta: 7:49:32  iter: 2800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9619 (1.2863)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8991 (1.2690)  Cross-Entropy Loss (Align Words, Choose Caption): 1.1515 (1.4522)  Cross-Entropy Loss (Align Words, Choose Image): 0.9582 (1.3428)  Image Caption Matching Loss: 1.4308 (2.3893)  Masked Language Modeling Loss: 2.1240 (2.6974)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.7218 (10.4370)  Batch Accuracy (Align Regions, Choose Caption): 0.6562 (0.5366)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.5465)  Batch Accuracy (Align Words, Choose Caption): 0.6250 (0.4739)  Batch Accuracy (Align Words, Choose Image): 0.6719 (0.5143)  Batch Accuracy (Choose Caption): 0.6875 (0.5257)  Batch Accuracy (Choose Image): 0.7344 (0.5385)  Masked Language Modeling Accuracy: 0.5950 (0.5322)  time: 0.6849 (0.7573)  data: 0.0300 (0.0828)  lr: 0.010000  max mem: 12148
2021-04-01 21:39:23,126 maskrcnn_benchmark.trainer INFO: eta: 7:47:10  iter: 2900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9763 (1.2745)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9080 (1.2567)  Cross-Entropy Loss (Align Words, Choose Caption): 1.2002 (1.4393)  Cross-Entropy Loss (Align Words, Choose Image): 0.9556 (1.3290)  Image Caption Matching Loss: 1.6227 (2.3584)  Masked Language Modeling Loss: 2.3248 (2.6832)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 8.0647 (10.3410)  Batch Accuracy (Align Regions, Choose Caption): 0.6562 (0.5414)  Batch Accuracy (Align Regions, Choose Image): 0.6875 (0.5511)  Batch Accuracy (Align Words, Choose Caption): 0.5781 (0.4790)  Batch Accuracy (Align Words, Choose Image): 0.6719 (0.5196)  Batch Accuracy (Choose Caption): 0.6875 (0.5321)  Batch Accuracy (Choose Image): 0.7031 (0.5449)  Masked Language Modeling Accuracy: 0.5592 (0.5337)  time: 0.6885 (0.7555)  data: 0.0302 (0.0812)  lr: 0.010000  max mem: 12148
2021-04-01 21:40:34,228 maskrcnn_benchmark.trainer INFO: eta: 7:44:59  iter: 3000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9406 (1.2634)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8595 (1.2447)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9810 (1.4266)  Cross-Entropy Loss (Align Words, Choose Image): 0.8801 (1.3156)  Image Caption Matching Loss: 1.2729 (2.3267)  Masked Language Modeling Loss: 2.1729 (2.6679)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.2948 (10.2450)  Batch Accuracy (Align Regions, Choose Caption): 0.6719 (0.5456)  Batch Accuracy (Align Regions, Choose Image): 0.6875 (0.5557)  Batch Accuracy (Align Words, Choose Caption): 0.6094 (0.4840)  Batch Accuracy (Align Words, Choose Image): 0.6562 (0.5250)  Batch Accuracy (Choose Caption): 0.7031 (0.5382)  Batch Accuracy (Choose Image): 0.7344 (0.5511)  Masked Language Modeling Accuracy: 0.6046 (0.5356)  time: 0.6824 (0.7540)  data: 0.0269 (0.0796)  lr: 0.010000  max mem: 12148
2021-04-01 21:40:34,547 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0003000.pth
2021-04-01 21:41:46,210 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:44:59  iter: 3000  loss: 4.8142 (4.5817)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7612 (0.7519)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7799 (0.7618)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9379 (0.9097)  Cross-Entropy Loss (Align Words, Choose Image): 0.8386 (0.8121)  Image Caption Matching Loss: 1.3603 (1.3463)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.7031 (0.7415)  Batch Accuracy (Align Regions, Choose Image): 0.7135 (0.7299)  Batch Accuracy (Align Words, Choose Caption): 0.6250 (0.6718)  Batch Accuracy (Align Words, Choose Image): 0.7031 (0.7076)  Batch Accuracy (Choose Caption): 0.7344 (0.7483)  Batch Accuracy (Choose Image): 0.7188 (0.7315)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12148
2021-04-01 21:42:57,437 maskrcnn_benchmark.trainer INFO: eta: 7:57:11  iter: 3100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8594 (1.2516)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8623 (1.2330)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9798 (1.4143)  Cross-Entropy Loss (Align Words, Choose Image): 0.8755 (1.3021)  Image Caption Matching Loss: 1.3340 (2.2966)  Masked Language Modeling Loss: 2.2089 (2.6521)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.1019 (10.1497)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5501)  Batch Accuracy (Align Regions, Choose Image): 0.6719 (0.5601)  Batch Accuracy (Align Words, Choose Caption): 0.6250 (0.4889)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.5301)  Batch Accuracy (Choose Caption): 0.7344 (0.5444)  Batch Accuracy (Choose Image): 0.7500 (0.5573)  Masked Language Modeling Accuracy: 0.5762 (0.5374)  time: 0.6821 (0.7759)  data: 0.0269 (0.1013)  lr: 0.010000  max mem: 12148
2021-04-01 21:44:08,554 maskrcnn_benchmark.trainer INFO: eta: 7:54:39  iter: 3200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8975 (1.2412)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9056 (1.2226)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0367 (1.4020)  Cross-Entropy Loss (Align Words, Choose Image): 0.8921 (1.2893)  Image Caption Matching Loss: 1.3618 (2.2697)  Masked Language Modeling Loss: 2.0529 (2.6377)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.0548 (10.0625)  Batch Accuracy (Align Regions, Choose Caption): 0.6719 (0.5543)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5643)  Batch Accuracy (Align Words, Choose Caption): 0.6250 (0.4939)  Batch Accuracy (Align Words, Choose Image): 0.7031 (0.5351)  Batch Accuracy (Choose Caption): 0.7344 (0.5498)  Batch Accuracy (Choose Image): 0.7344 (0.5630)  Masked Language Modeling Accuracy: 0.6097 (0.5390)  time: 0.6844 (0.7739)  data: 0.0282 (0.0992)  lr: 0.010000  max mem: 12148
2021-04-01 21:45:22,317 maskrcnn_benchmark.trainer INFO: eta: 7:52:41  iter: 3300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.9267 (1.2315)  Cross-Entropy Loss (Align Regions, Choose Image): 0.9133 (1.2119)  Cross-Entropy Loss (Align Words, Choose Caption): 1.0268 (1.3904)  Cross-Entropy Loss (Align Words, Choose Image): 0.8548 (1.2764)  Image Caption Matching Loss: 1.3969 (2.2431)  Masked Language Modeling Loss: 2.1512 (2.6232)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.5857 (9.9766)  Batch Accuracy (Align Regions, Choose Caption): 0.6719 (0.5582)  Batch Accuracy (Align Regions, Choose Image): 0.6875 (0.5682)  Batch Accuracy (Align Words, Choose Caption): 0.6406 (0.4984)  Batch Accuracy (Align Words, Choose Image): 0.7031 (0.5401)  Batch Accuracy (Choose Caption): 0.7031 (0.5551)  Batch Accuracy (Choose Image): 0.7344 (0.5685)  Masked Language Modeling Accuracy: 0.5851 (0.5407)  time: 0.6827 (0.7728)  data: 0.0270 (0.0972)  lr: 0.010000  max mem: 12148
2021-04-01 21:46:32,762 maskrcnn_benchmark.trainer INFO: eta: 7:50:10  iter: 3400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8967 (1.2216)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8597 (1.2017)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9851 (1.3794)  Cross-Entropy Loss (Align Words, Choose Image): 0.8344 (1.2645)  Image Caption Matching Loss: 1.2652 (2.2153)  Masked Language Modeling Loss: 2.1903 (2.6098)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.0092 (9.8922)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5623)  Batch Accuracy (Align Regions, Choose Image): 0.6875 (0.5720)  Batch Accuracy (Align Words, Choose Caption): 0.6562 (0.5029)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.5446)  Batch Accuracy (Choose Caption): 0.7500 (0.5607)  Batch Accuracy (Choose Image): 0.7500 (0.5741)  Masked Language Modeling Accuracy: 0.5911 (0.5422)  time: 0.6901 (0.7708)  data: 0.0277 (0.0954)  lr: 0.010000  max mem: 12148
2021-04-01 21:47:43,664 maskrcnn_benchmark.trainer INFO: eta: 7:47:49  iter: 3500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8900 (1.2124)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8360 (1.1922)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9872 (1.3690)  Cross-Entropy Loss (Align Words, Choose Image): 0.8747 (1.2536)  Image Caption Matching Loss: 1.3070 (2.1903)  Masked Language Modeling Loss: 2.0971 (2.5978)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.1105 (9.8153)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5658)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5756)  Batch Accuracy (Align Words, Choose Caption): 0.6406 (0.5071)  Batch Accuracy (Align Words, Choose Image): 0.6875 (0.5490)  Batch Accuracy (Choose Caption): 0.7500 (0.5657)  Batch Accuracy (Choose Image): 0.7656 (0.5793)  Masked Language Modeling Accuracy: 0.5700 (0.5435)  time: 0.6912 (0.7690)  data: 0.0296 (0.0936)  lr: 0.010000  max mem: 12148
2021-04-01 21:48:54,424 maskrcnn_benchmark.trainer INFO: eta: 7:45:30  iter: 3600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8101 (1.2017)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7925 (1.1818)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9146 (1.3573)  Cross-Entropy Loss (Align Words, Choose Image): 0.7853 (1.2415)  Image Caption Matching Loss: 1.1513 (2.1636)  Masked Language Modeling Loss: 2.0432 (2.5850)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.6115 (9.7310)  Batch Accuracy (Align Regions, Choose Caption): 0.7031 (0.5699)  Batch Accuracy (Align Regions, Choose Image): 0.7344 (0.5795)  Batch Accuracy (Align Words, Choose Caption): 0.6719 (0.5117)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.5537)  Batch Accuracy (Choose Caption): 0.7812 (0.5711)  Batch Accuracy (Choose Image): 0.7656 (0.5848)  Masked Language Modeling Accuracy: 0.5880 (0.5450)  time: 0.6838 (0.7673)  data: 0.0265 (0.0919)  lr: 0.010000  max mem: 12148
2021-04-01 21:50:04,902 maskrcnn_benchmark.trainer INFO: eta: 7:43:12  iter: 3700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7885 (1.1920)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7596 (1.1715)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8632 (1.3463)  Cross-Entropy Loss (Align Words, Choose Image): 0.8013 (1.2304)  Image Caption Matching Loss: 1.1829 (2.1397)  Masked Language Modeling Loss: 2.0331 (2.5738)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.3851 (9.6538)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.5737)  Batch Accuracy (Align Regions, Choose Image): 0.7254 (0.5833)  Batch Accuracy (Align Words, Choose Caption): 0.6927 (0.5160)  Batch Accuracy (Align Words, Choose Image): 0.7396 (0.5580)  Batch Accuracy (Choose Caption): 0.7812 (0.5761)  Batch Accuracy (Choose Image): 0.7656 (0.5897)  Masked Language Modeling Accuracy: 0.6190 (0.5463)  time: 0.6917 (0.7656)  data: 0.0302 (0.0903)  lr: 0.010000  max mem: 12148
2021-04-01 21:51:15,397 maskrcnn_benchmark.trainer INFO: eta: 7:40:57  iter: 3800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8256 (1.1835)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8772 (1.1627)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9825 (1.3370)  Cross-Entropy Loss (Align Words, Choose Image): 0.8340 (1.2203)  Image Caption Matching Loss: 1.2716 (2.1163)  Masked Language Modeling Loss: 2.3009 (2.5625)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 7.1370 (9.5821)  Batch Accuracy (Align Regions, Choose Caption): 0.6875 (0.5770)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5866)  Batch Accuracy (Align Words, Choose Caption): 0.6406 (0.5198)  Batch Accuracy (Align Words, Choose Image): 0.7031 (0.5620)  Batch Accuracy (Choose Caption): 0.7344 (0.5805)  Batch Accuracy (Choose Image): 0.7500 (0.5943)  Masked Language Modeling Accuracy: 0.5631 (0.5476)  time: 0.6841 (0.7640)  data: 0.0286 (0.0888)  lr: 0.010000  max mem: 12148
2021-04-01 21:52:26,130 maskrcnn_benchmark.trainer INFO: eta: 7:38:48  iter: 3900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7858 (1.1745)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8004 (1.1535)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8319 (1.3265)  Cross-Entropy Loss (Align Words, Choose Image): 0.7480 (1.2092)  Image Caption Matching Loss: 1.0670 (2.0934)  Masked Language Modeling Loss: 2.0616 (2.5513)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.6073 (9.5084)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.5806)  Batch Accuracy (Align Regions, Choose Image): 0.7188 (0.5901)  Batch Accuracy (Align Words, Choose Caption): 0.6719 (0.5239)  Batch Accuracy (Align Words, Choose Image): 0.7188 (0.5662)  Batch Accuracy (Choose Caption): 0.7812 (0.5852)  Batch Accuracy (Choose Image): 0.7656 (0.5989)  Masked Language Modeling Accuracy: 0.6005 (0.5490)  time: 0.6852 (0.7626)  data: 0.0252 (0.0874)  lr: 0.010000  max mem: 12148
2021-04-01 21:53:36,670 maskrcnn_benchmark.trainer INFO: eta: 7:36:41  iter: 4000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8284 (1.1655)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8557 (1.1445)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9081 (1.3161)  Cross-Entropy Loss (Align Words, Choose Image): 0.7969 (1.1985)  Image Caption Matching Loss: 1.1711 (2.0711)  Masked Language Modeling Loss: 2.1426 (2.5390)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.7164 (9.4347)  Batch Accuracy (Align Regions, Choose Caption): 0.7031 (0.5840)  Batch Accuracy (Align Regions, Choose Image): 0.7188 (0.5936)  Batch Accuracy (Align Words, Choose Caption): 0.6562 (0.5277)  Batch Accuracy (Align Words, Choose Image): 0.7188 (0.5703)  Batch Accuracy (Choose Caption): 0.7344 (0.5897)  Batch Accuracy (Choose Image): 0.7812 (0.6032)  Masked Language Modeling Accuracy: 0.5887 (0.5502)  time: 0.6826 (0.7611)  data: 0.0287 (0.0861)  lr: 0.010000  max mem: 12148
2021-04-01 21:53:36,985 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0004000.pth
2021-04-01 21:54:46,162 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:36:41  iter: 4000  loss: 4.0303 (4.0396)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6881 (0.6914)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6898 (0.6851)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8479 (0.8241)  Cross-Entropy Loss (Align Words, Choose Image): 0.7267 (0.7163)  Image Caption Matching Loss: 1.0963 (1.1226)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.7600)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.7750)  Batch Accuracy (Align Words, Choose Caption): 0.6719 (0.7005)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.7531)  Batch Accuracy (Choose Caption): 0.8125 (0.7888)  Batch Accuracy (Choose Image): 0.7656 (0.7842)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12148
2021-04-01 21:55:59,295 maskrcnn_benchmark.trainer INFO: eta: 7:45:07  iter: 4100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7586 (1.1572)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7617 (1.1363)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9239 (1.3063)  Cross-Entropy Loss (Align Words, Choose Image): 0.7433 (1.1885)  Image Caption Matching Loss: 1.1944 (2.0497)  Masked Language Modeling Loss: 2.1042 (2.5292)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.5844 (9.3672)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.5872)  Batch Accuracy (Align Regions, Choose Image): 0.7188 (0.5967)  Batch Accuracy (Align Words, Choose Caption): 0.6719 (0.5315)  Batch Accuracy (Align Words, Choose Image): 0.7031 (0.5740)  Batch Accuracy (Choose Caption): 0.7656 (0.5939)  Batch Accuracy (Choose Image): 0.7812 (0.6075)  Masked Language Modeling Accuracy: 0.5869 (0.5514)  time: 0.6847 (0.7774)  data: 0.0273 (0.1017)  lr: 0.010000  max mem: 12148
2021-04-01 21:57:09,697 maskrcnn_benchmark.trainer INFO: eta: 7:42:47  iter: 4200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8773 (1.1483)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8297 (1.1274)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9286 (1.2964)  Cross-Entropy Loss (Align Words, Choose Image): 0.7865 (1.1783)  Image Caption Matching Loss: 1.1943 (2.0284)  Masked Language Modeling Loss: 2.0287 (2.5191)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.6151 (9.2980)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.5907)  Batch Accuracy (Align Regions, Choose Image): 0.7031 (0.5999)  Batch Accuracy (Align Words, Choose Caption): 0.6719 (0.5354)  Batch Accuracy (Align Words, Choose Image): 0.7188 (0.5778)  Batch Accuracy (Choose Caption): 0.7656 (0.5983)  Batch Accuracy (Choose Image): 0.7656 (0.6118)  Masked Language Modeling Accuracy: 0.5885 (0.5526)  time: 0.6827 (0.7756)  data: 0.0272 (0.1001)  lr: 0.010000  max mem: 12148
2021-04-01 21:58:21,329 maskrcnn_benchmark.trainer INFO: eta: 7:40:39  iter: 4300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7469 (1.1403)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7693 (1.1193)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8396 (1.2872)  Cross-Entropy Loss (Align Words, Choose Image): 0.7322 (1.1689)  Image Caption Matching Loss: 1.0370 (2.0083)  Masked Language Modeling Loss: 2.1178 (2.5103)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.3094 (9.2342)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.5937)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6030)  Batch Accuracy (Align Words, Choose Caption): 0.6875 (0.5389)  Batch Accuracy (Align Words, Choose Image): 0.7656 (0.5814)  Batch Accuracy (Choose Caption): 0.7812 (0.6025)  Batch Accuracy (Choose Image): 0.7812 (0.6157)  Masked Language Modeling Accuracy: 0.6014 (0.5536)  time: 0.6957 (0.7742)  data: 0.0287 (0.0986)  lr: 0.010000  max mem: 12148
2021-04-01 21:59:33,618 maskrcnn_benchmark.trainer INFO: eta: 7:38:41  iter: 4400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7798 (1.1324)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7749 (1.1115)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7922 (1.2779)  Cross-Entropy Loss (Align Words, Choose Image): 0.7208 (1.1599)  Image Caption Matching Loss: 1.0950 (1.9893)  Masked Language Modeling Loss: 1.9919 (2.5013)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.2964 (9.1722)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.5966)  Batch Accuracy (Align Regions, Choose Image): 0.7188 (0.6059)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.5424)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.5849)  Batch Accuracy (Choose Caption): 0.7812 (0.6063)  Batch Accuracy (Choose Image): 0.7969 (0.6195)  Masked Language Modeling Accuracy: 0.5817 (0.5547)  time: 0.6880 (0.7731)  data: 0.0274 (0.0972)  lr: 0.010000  max mem: 12159
2021-04-01 22:00:47,062 maskrcnn_benchmark.trainer INFO: eta: 7:36:53  iter: 4500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8849 (1.1247)  Cross-Entropy Loss (Align Regions, Choose Image): 0.8569 (1.1039)  Cross-Entropy Loss (Align Words, Choose Caption): 0.9030 (1.2688)  Cross-Entropy Loss (Align Words, Choose Image): 0.7819 (1.1508)  Image Caption Matching Loss: 1.1410 (1.9704)  Masked Language Modeling Loss: 2.0141 (2.4911)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.5938 (9.1096)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.5996)  Batch Accuracy (Align Regions, Choose Image): 0.6875 (0.6087)  Batch Accuracy (Align Words, Choose Caption): 0.6719 (0.5458)  Batch Accuracy (Align Words, Choose Image): 0.7031 (0.5883)  Batch Accuracy (Choose Caption): 0.7656 (0.6102)  Batch Accuracy (Choose Image): 0.7656 (0.6233)  Masked Language Modeling Accuracy: 0.5882 (0.5558)  time: 0.6872 (0.7722)  data: 0.0285 (0.0957)  lr: 0.010000  max mem: 12159
2021-04-01 22:01:58,189 maskrcnn_benchmark.trainer INFO: eta: 7:34:49  iter: 4600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7439 (1.1177)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6963 (1.0963)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8553 (1.2604)  Cross-Entropy Loss (Align Words, Choose Image): 0.7228 (1.1422)  Image Caption Matching Loss: 1.0830 (1.9526)  Masked Language Modeling Loss: 2.0465 (2.4818)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.1711 (9.0510)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6023)  Batch Accuracy (Align Regions, Choose Image): 0.7344 (0.6114)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5491)  Batch Accuracy (Align Words, Choose Image): 0.7188 (0.5914)  Batch Accuracy (Choose Caption): 0.7812 (0.6137)  Batch Accuracy (Choose Image): 0.7969 (0.6268)  Masked Language Modeling Accuracy: 0.6116 (0.5569)  time: 0.6822 (0.7709)  data: 0.0266 (0.0944)  lr: 0.010000  max mem: 12159
2021-04-01 22:03:08,811 maskrcnn_benchmark.trainer INFO: eta: 7:32:43  iter: 4700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6827 (1.1099)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7436 (1.0889)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8013 (1.2515)  Cross-Entropy Loss (Align Words, Choose Image): 0.6662 (1.1330)  Image Caption Matching Loss: 1.0507 (1.9342)  Masked Language Modeling Loss: 1.9241 (2.4730)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.9972 (8.9905)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6052)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6142)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.5524)  Batch Accuracy (Align Words, Choose Image): 0.7656 (0.5950)  Batch Accuracy (Choose Caption): 0.7969 (0.6175)  Batch Accuracy (Choose Image): 0.8125 (0.6306)  Masked Language Modeling Accuracy: 0.6055 (0.5579)  time: 0.6836 (0.7695)  data: 0.0267 (0.0931)  lr: 0.010000  max mem: 12159
2021-04-01 22:04:19,601 maskrcnn_benchmark.trainer INFO: eta: 7:30:41  iter: 4800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7974 (1.1029)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7638 (1.0819)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8158 (1.2435)  Cross-Entropy Loss (Align Words, Choose Image): 0.6919 (1.1246)  Image Caption Matching Loss: 1.0731 (1.9164)  Masked Language Modeling Loss: 1.9174 (2.4648)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.0285 (8.9341)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.6078)  Batch Accuracy (Align Regions, Choose Image): 0.7344 (0.6168)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.5555)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.5982)  Batch Accuracy (Choose Caption): 0.8125 (0.6208)  Batch Accuracy (Choose Image): 0.7969 (0.6341)  Masked Language Modeling Accuracy: 0.6158 (0.5588)  time: 0.6852 (0.7682)  data: 0.0324 (0.0918)  lr: 0.010000  max mem: 12159
2021-04-01 22:05:33,145 maskrcnn_benchmark.trainer INFO: eta: 7:29:01  iter: 4900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7227 (1.0957)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7627 (1.0744)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8425 (1.2351)  Cross-Entropy Loss (Align Words, Choose Image): 0.7385 (1.1162)  Image Caption Matching Loss: 1.0231 (1.8984)  Masked Language Modeling Loss: 2.2222 (2.4562)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.4122 (8.8759)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6106)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6195)  Batch Accuracy (Align Words, Choose Caption): 0.6875 (0.5586)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.6014)  Batch Accuracy (Choose Caption): 0.7656 (0.6245)  Batch Accuracy (Choose Image): 0.8125 (0.6376)  Masked Language Modeling Accuracy: 0.5855 (0.5598)  time: 0.6938 (0.7676)  data: 0.0288 (0.0907)  lr: 0.010000  max mem: 12159
2021-04-01 22:06:46,212 maskrcnn_benchmark.trainer INFO: eta: 7:27:18  iter: 5000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7300 (1.0886)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7267 (1.0676)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7969 (1.2268)  Cross-Entropy Loss (Align Words, Choose Image): 0.6857 (1.1080)  Image Caption Matching Loss: 1.0882 (1.8811)  Masked Language Modeling Loss: 2.1001 (2.4487)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.2884 (8.8209)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6132)  Batch Accuracy (Align Regions, Choose Image): 0.7344 (0.6221)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.5618)  Batch Accuracy (Align Words, Choose Image): 0.7188 (0.6044)  Batch Accuracy (Choose Caption): 0.7656 (0.6279)  Batch Accuracy (Choose Image): 0.7969 (0.6410)  Masked Language Modeling Accuracy: 0.6123 (0.5606)  time: 0.6861 (0.7668)  data: 0.0274 (0.0895)  lr: 0.010000  max mem: 12159
2021-04-01 22:06:46,532 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0005000.pth
2021-04-01 22:07:56,229 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:27:18  iter: 5000  loss: 3.5293 (3.5293)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5702 (0.5881)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5949 (0.5925)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7229 (0.7374)  Cross-Entropy Loss (Align Words, Choose Image): 0.6383 (0.6301)  Image Caption Matching Loss: 0.9317 (0.9811)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.8016)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.8004)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.7411)  Batch Accuracy (Align Words, Choose Image): 0.7656 (0.7811)  Batch Accuracy (Choose Caption): 0.8281 (0.8135)  Batch Accuracy (Choose Image): 0.8415 (0.8204)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12159
2021-04-01 22:09:07,103 maskrcnn_benchmark.trainer INFO: eta: 7:33:21  iter: 5100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6860 (1.0817)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6992 (1.0608)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7200 (1.2185)  Cross-Entropy Loss (Align Words, Choose Image): 0.6767 (1.1002)  Image Caption Matching Loss: 1.0626 (1.8645)  Masked Language Modeling Loss: 2.1079 (2.4415)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.9774 (8.7673)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6158)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6246)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.5650)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6074)  Batch Accuracy (Choose Caption): 0.8125 (0.6311)  Batch Accuracy (Choose Image): 0.8125 (0.6443)  Masked Language Modeling Accuracy: 0.5978 (0.5615)  time: 0.6815 (0.7794)  data: 0.0270 (0.1021)  lr: 0.010000  max mem: 12159
2021-04-01 22:10:18,176 maskrcnn_benchmark.trainer INFO: eta: 7:31:17  iter: 5200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7730 (1.0757)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7304 (1.0547)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8000 (1.2110)  Cross-Entropy Loss (Align Words, Choose Image): 0.6619 (1.0925)  Image Caption Matching Loss: 1.0743 (1.8486)  Masked Language Modeling Loss: 2.0581 (2.4337)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.0369 (8.7160)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6181)  Batch Accuracy (Align Regions, Choose Image): 0.7344 (0.6269)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5679)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6103)  Batch Accuracy (Choose Caption): 0.7812 (0.6343)  Batch Accuracy (Choose Image): 0.8125 (0.6475)  Masked Language Modeling Accuracy: 0.5949 (0.5623)  time: 0.6849 (0.7781)  data: 0.0264 (0.1008)  lr: 0.010000  max mem: 12159
2021-04-01 22:11:29,194 maskrcnn_benchmark.trainer INFO: eta: 7:29:15  iter: 5300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.8034 (1.0696)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7901 (1.0488)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7731 (1.2031)  Cross-Entropy Loss (Align Words, Choose Image): 0.6984 (1.0849)  Image Caption Matching Loss: 1.0352 (1.8328)  Masked Language Modeling Loss: 1.9024 (2.4258)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.0617 (8.6651)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.6205)  Batch Accuracy (Align Regions, Choose Image): 0.7188 (0.6290)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.5708)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.6132)  Batch Accuracy (Choose Caption): 0.7969 (0.6374)  Batch Accuracy (Choose Image): 0.7969 (0.6506)  Masked Language Modeling Accuracy: 0.6271 (0.5632)  time: 0.6872 (0.7768)  data: 0.0265 (0.0995)  lr: 0.010000  max mem: 12159
2021-04-01 22:12:42,309 maskrcnn_benchmark.trainer INFO: eta: 7:27:28  iter: 5400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7698 (1.0638)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7059 (1.0424)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8176 (1.1961)  Cross-Entropy Loss (Align Words, Choose Image): 0.6822 (1.0774)  Image Caption Matching Loss: 1.1323 (1.8183)  Masked Language Modeling Loss: 2.2140 (2.4192)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.4284 (8.6172)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6227)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6314)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5735)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.6159)  Batch Accuracy (Choose Caption): 0.7812 (0.6403)  Batch Accuracy (Choose Image): 0.7812 (0.6535)  Masked Language Modeling Accuracy: 0.5687 (0.5639)  time: 0.6842 (0.7760)  data: 0.0255 (0.0983)  lr: 0.010000  max mem: 12159
2021-04-01 22:13:52,876 maskrcnn_benchmark.trainer INFO: eta: 7:25:26  iter: 5500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7457 (1.0578)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7041 (1.0363)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7759 (1.1889)  Cross-Entropy Loss (Align Words, Choose Image): 0.6849 (1.0701)  Image Caption Matching Loss: 0.9343 (1.8037)  Masked Language Modeling Loss: 1.8605 (2.4126)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.6826 (8.5695)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6251)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6337)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.5763)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6187)  Batch Accuracy (Choose Caption): 0.7969 (0.6433)  Batch Accuracy (Choose Image): 0.8125 (0.6563)  Masked Language Modeling Accuracy: 0.6221 (0.5646)  time: 0.6801 (0.7747)  data: 0.0268 (0.0970)  lr: 0.010000  max mem: 12159
2021-04-01 22:15:03,467 maskrcnn_benchmark.trainer INFO: eta: 7:23:26  iter: 5600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7670 (1.0519)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6934 (1.0305)  Cross-Entropy Loss (Align Words, Choose Caption): 0.8223 (1.1818)  Cross-Entropy Loss (Align Words, Choose Image): 0.6472 (1.0630)  Image Caption Matching Loss: 1.0123 (1.7894)  Masked Language Modeling Loss: 1.9570 (2.4059)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.1067 (8.5226)  Batch Accuracy (Align Regions, Choose Caption): 0.7344 (0.6273)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6358)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.5790)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6213)  Batch Accuracy (Choose Caption): 0.7812 (0.6461)  Batch Accuracy (Choose Image): 0.8125 (0.6591)  Masked Language Modeling Accuracy: 0.6016 (0.5654)  time: 0.6845 (0.7735)  data: 0.0264 (0.0959)  lr: 0.010000  max mem: 12159
2021-04-01 22:16:13,435 maskrcnn_benchmark.trainer INFO: eta: 7:21:25  iter: 5700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6448 (1.0461)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6107 (1.0246)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7103 (1.1747)  Cross-Entropy Loss (Align Words, Choose Image): 0.5813 (1.0559)  Image Caption Matching Loss: 0.8161 (1.7752)  Masked Language Modeling Loss: 1.9945 (2.3996)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.5437 (8.4761)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6295)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6379)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.5817)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6240)  Batch Accuracy (Choose Caption): 0.8281 (0.6490)  Batch Accuracy (Choose Image): 0.8438 (0.6619)  Masked Language Modeling Accuracy: 0.5920 (0.5661)  time: 0.6861 (0.7722)  data: 0.0273 (0.0947)  lr: 0.010000  max mem: 12159
2021-04-01 22:17:28,053 maskrcnn_benchmark.trainer INFO: eta: 7:19:52  iter: 5800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6692 (1.0402)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6796 (1.0188)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6758 (1.1679)  Cross-Entropy Loss (Align Words, Choose Image): 0.6508 (1.0491)  Image Caption Matching Loss: 0.9287 (1.7610)  Masked Language Modeling Loss: 1.9888 (2.3931)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.7503 (8.4301)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6317)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6400)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.5841)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6265)  Batch Accuracy (Choose Caption): 0.8125 (0.6518)  Batch Accuracy (Choose Image): 0.8281 (0.6646)  Masked Language Modeling Accuracy: 0.6132 (0.5669)  time: 0.6874 (0.7717)  data: 0.0269 (0.0936)  lr: 0.010000  max mem: 12159
2021-04-01 22:18:41,504 maskrcnn_benchmark.trainer INFO: eta: 7:18:14  iter: 5900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7279 (1.0346)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6713 (1.0133)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7675 (1.1612)  Cross-Entropy Loss (Align Words, Choose Image): 0.6588 (1.0423)  Image Caption Matching Loss: 0.9314 (1.7479)  Masked Language Modeling Loss: 2.0226 (2.3867)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.0793 (8.3861)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6339)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6420)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5868)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6291)  Batch Accuracy (Choose Caption): 0.7969 (0.6544)  Batch Accuracy (Choose Image): 0.8281 (0.6672)  Masked Language Modeling Accuracy: 0.6197 (0.5676)  time: 0.6865 (0.7711)  data: 0.0244 (0.0925)  lr: 0.010000  max mem: 12159
2021-04-01 22:19:51,595 maskrcnn_benchmark.trainer INFO: eta: 7:16:17  iter: 6000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7010 (1.0292)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6192 (1.0080)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7720 (1.1543)  Cross-Entropy Loss (Align Words, Choose Image): 0.6911 (1.0358)  Image Caption Matching Loss: 0.9089 (1.7340)  Masked Language Modeling Loss: 2.0934 (2.3801)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.6358 (8.3414)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6360)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6441)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.5892)  Batch Accuracy (Align Words, Choose Image): 0.7344 (0.6314)  Batch Accuracy (Choose Caption): 0.8438 (0.6572)  Batch Accuracy (Choose Image): 0.8125 (0.6700)  Masked Language Modeling Accuracy: 0.5976 (0.5684)  time: 0.6857 (0.7699)  data: 0.0254 (0.0915)  lr: 0.010000  max mem: 12159
2021-04-01 22:19:51,879 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0006000.pth
2021-04-01 22:21:00,028 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:16:17  iter: 6000  loss: 3.1541 (3.2567)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4783 (0.5234)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5663 (0.5696)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6467 (0.6770)  Cross-Entropy Loss (Align Words, Choose Image): 0.5209 (0.5566)  Image Caption Matching Loss: 0.8863 (0.9301)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8099)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.8019)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.7683)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.8063)  Batch Accuracy (Choose Caption): 0.8229 (0.8153)  Batch Accuracy (Choose Image): 0.8281 (0.8256)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12159
2021-04-01 22:22:10,407 maskrcnn_benchmark.trainer INFO: eta: 7:20:43  iter: 6100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7594 (1.0241)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6752 (1.0029)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7525 (1.1482)  Cross-Entropy Loss (Align Words, Choose Image): 0.6396 (1.0296)  Image Caption Matching Loss: 0.9930 (1.7211)  Masked Language Modeling Loss: 1.8802 (2.3739)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.5821 (8.2999)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6380)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6460)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.5916)  Batch Accuracy (Align Words, Choose Image): 0.7656 (0.6338)  Batch Accuracy (Choose Caption): 0.7969 (0.6598)  Batch Accuracy (Choose Image): 0.8281 (0.6725)  Masked Language Modeling Accuracy: 0.6171 (0.5691)  time: 0.6892 (0.7801)  data: 0.0310 (0.1018)  lr: 0.010000  max mem: 12159
2021-04-01 22:23:21,053 maskrcnn_benchmark.trainer INFO: eta: 7:18:45  iter: 6200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7618 (1.0188)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7463 (0.9977)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7766 (1.1421)  Cross-Entropy Loss (Align Words, Choose Image): 0.6323 (1.0236)  Image Caption Matching Loss: 0.9747 (1.7084)  Masked Language Modeling Loss: 2.0246 (2.3680)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 6.2083 (8.2586)  Batch Accuracy (Align Regions, Choose Caption): 0.7188 (0.6401)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6479)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.5938)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6361)  Batch Accuracy (Choose Caption): 0.7969 (0.6623)  Batch Accuracy (Choose Image): 0.8125 (0.6750)  Masked Language Modeling Accuracy: 0.5935 (0.5699)  time: 0.6857 (0.7789)  data: 0.0257 (0.1007)  lr: 0.010000  max mem: 12159
2021-04-01 22:24:32,733 maskrcnn_benchmark.trainer INFO: eta: 7:16:54  iter: 6300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6759 (1.0135)  Cross-Entropy Loss (Align Regions, Choose Image): 0.7153 (0.9925)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7571 (1.1359)  Cross-Entropy Loss (Align Words, Choose Image): 0.6546 (1.0173)  Image Caption Matching Loss: 0.8998 (1.6964)  Masked Language Modeling Loss: 1.9574 (2.3618)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.7248 (8.2174)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6420)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6499)  Batch Accuracy (Align Words, Choose Caption): 0.7031 (0.5961)  Batch Accuracy (Align Words, Choose Image): 0.7656 (0.6385)  Batch Accuracy (Choose Caption): 0.8125 (0.6647)  Batch Accuracy (Choose Image): 0.8125 (0.6774)  Masked Language Modeling Accuracy: 0.6200 (0.5707)  time: 0.6867 (0.7779)  data: 0.0253 (0.0996)  lr: 0.010000  max mem: 12159
2021-04-01 22:25:43,974 maskrcnn_benchmark.trainer INFO: eta: 7:15:01  iter: 6400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6309 (1.0085)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6460 (0.9874)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7098 (1.1297)  Cross-Entropy Loss (Align Words, Choose Image): 0.5393 (1.0112)  Image Caption Matching Loss: 0.7733 (1.6839)  Masked Language Modeling Loss: 1.8774 (2.3558)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1658 (8.1764)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6439)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6518)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.5984)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6407)  Batch Accuracy (Choose Caption): 0.8594 (0.6672)  Batch Accuracy (Choose Image): 0.8438 (0.6798)  Masked Language Modeling Accuracy: 0.6228 (0.5715)  time: 0.6883 (0.7768)  data: 0.0251 (0.0985)  lr: 0.010000  max mem: 12159
2021-04-01 22:26:54,612 maskrcnn_benchmark.trainer INFO: eta: 7:13:08  iter: 6500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7261 (1.0037)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6952 (0.9826)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7490 (1.1237)  Cross-Entropy Loss (Align Words, Choose Image): 0.6645 (1.0054)  Image Caption Matching Loss: 0.9204 (1.6726)  Masked Language Modeling Loss: 2.0106 (2.3501)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.8706 (8.1380)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6458)  Batch Accuracy (Align Regions, Choose Image): 0.7344 (0.6535)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6006)  Batch Accuracy (Align Words, Choose Image): 0.7500 (0.6429)  Batch Accuracy (Choose Caption): 0.8125 (0.6696)  Batch Accuracy (Choose Image): 0.8281 (0.6821)  Masked Language Modeling Accuracy: 0.6012 (0.5722)  time: 0.6803 (0.7758)  data: 0.0269 (0.0976)  lr: 0.010000  max mem: 12159
2021-04-01 22:28:05,425 maskrcnn_benchmark.trainer INFO: eta: 7:11:16  iter: 6600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.7086 (0.9990)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6675 (0.9779)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7373 (1.1182)  Cross-Entropy Loss (Align Words, Choose Image): 0.6161 (0.9998)  Image Caption Matching Loss: 0.9154 (1.6612)  Masked Language Modeling Loss: 1.9059 (2.3447)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.3906 (8.1007)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6476)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6553)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6026)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6450)  Batch Accuracy (Choose Caption): 0.8125 (0.6718)  Batch Accuracy (Choose Image): 0.8281 (0.6844)  Masked Language Modeling Accuracy: 0.6109 (0.5728)  time: 0.6799 (0.7747)  data: 0.0259 (0.0966)  lr: 0.010000  max mem: 12159
2021-04-01 22:29:16,545 maskrcnn_benchmark.trainer INFO: eta: 7:09:27  iter: 6700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6535 (0.9945)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6556 (0.9735)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6644 (1.1128)  Cross-Entropy Loss (Align Words, Choose Image): 0.5671 (0.9943)  Image Caption Matching Loss: 0.8079 (1.6504)  Masked Language Modeling Loss: 1.9007 (2.3393)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.2342 (8.0647)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6492)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6570)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.6046)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6471)  Batch Accuracy (Choose Caption): 0.8281 (0.6740)  Batch Accuracy (Choose Image): 0.8438 (0.6865)  Masked Language Modeling Accuracy: 0.6194 (0.5734)  time: 0.6830 (0.7738)  data: 0.0259 (0.0957)  lr: 0.010000  max mem: 12159
2021-04-01 22:30:27,275 maskrcnn_benchmark.trainer INFO: eta: 7:07:37  iter: 6800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6894 (0.9902)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6545 (0.9692)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7548 (1.1076)  Cross-Entropy Loss (Align Words, Choose Image): 0.5921 (0.9891)  Image Caption Matching Loss: 0.9069 (1.6396)  Masked Language Modeling Loss: 2.0381 (2.3341)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.8248 (8.0298)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6507)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6586)  Batch Accuracy (Align Words, Choose Caption): 0.7188 (0.6066)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6490)  Batch Accuracy (Choose Caption): 0.8125 (0.6761)  Batch Accuracy (Choose Image): 0.8281 (0.6886)  Masked Language Modeling Accuracy: 0.6061 (0.5741)  time: 0.6871 (0.7728)  data: 0.0265 (0.0947)  lr: 0.010000  max mem: 12159
2021-04-01 22:31:38,092 maskrcnn_benchmark.trainer INFO: eta: 7:05:49  iter: 6900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6057 (0.9853)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6180 (0.9644)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6585 (1.1017)  Cross-Entropy Loss (Align Words, Choose Image): 0.5596 (0.9835)  Image Caption Matching Loss: 0.8098 (1.6284)  Masked Language Modeling Loss: 1.8508 (2.3288)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.2593 (7.9921)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6526)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6603)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6088)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6511)  Batch Accuracy (Choose Caption): 0.8125 (0.6784)  Batch Accuracy (Choose Image): 0.8281 (0.6908)  Masked Language Modeling Accuracy: 0.6251 (0.5747)  time: 0.6766 (0.7719)  data: 0.0235 (0.0938)  lr: 0.010000  max mem: 12159
2021-04-01 22:32:51,400 maskrcnn_benchmark.trainer INFO: eta: 7:04:13  iter: 7000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6244 (0.9810)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6394 (0.9603)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7427 (1.0966)  Cross-Entropy Loss (Align Words, Choose Image): 0.6273 (0.9784)  Image Caption Matching Loss: 0.8895 (1.6182)  Masked Language Modeling Loss: 2.0111 (2.3236)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.5220 (7.9580)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6543)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6619)  Batch Accuracy (Align Words, Choose Caption): 0.7344 (0.6107)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6529)  Batch Accuracy (Choose Caption): 0.8438 (0.6804)  Batch Accuracy (Choose Image): 0.8125 (0.6928)  Masked Language Modeling Accuracy: 0.6171 (0.5753)  time: 0.6860 (0.7713)  data: 0.0243 (0.0929)  lr: 0.010000  max mem: 12159
2021-04-01 22:32:51,714 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0007000.pth
2021-04-01 22:33:59,977 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 7:04:13  iter: 7000  loss: 3.1954 (3.0941)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5132 (0.5328)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4848 (0.5175)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6450 (0.6250)  Cross-Entropy Loss (Align Words, Choose Image): 0.5387 (0.5357)  Image Caption Matching Loss: 0.8206 (0.8830)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8125)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8154)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.7807)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.8100)  Batch Accuracy (Choose Caption): 0.8438 (0.8398)  Batch Accuracy (Choose Image): 0.8594 (0.8269)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12159
2021-04-01 22:35:12,812 maskrcnn_benchmark.trainer INFO: eta: 7:07:54  iter: 7100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6679 (0.9767)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5874 (0.9560)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6964 (1.0913)  Cross-Entropy Loss (Align Words, Choose Image): 0.5561 (0.9734)  Image Caption Matching Loss: 0.9046 (1.6083)  Masked Language Modeling Loss: 1.8747 (2.3185)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.4480 (7.9242)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6559)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6635)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6126)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6548)  Batch Accuracy (Choose Caption): 0.8281 (0.6824)  Batch Accuracy (Choose Image): 0.8125 (0.6948)  Masked Language Modeling Accuracy: 0.6222 (0.5759)  time: 0.6818 (0.7804)  data: 0.0255 (0.1017)  lr: 0.010000  max mem: 12159
2021-04-01 22:36:23,169 maskrcnn_benchmark.trainer INFO: eta: 7:06:01  iter: 7200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5997 (0.9725)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6078 (0.9517)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6704 (1.0860)  Cross-Entropy Loss (Align Words, Choose Image): 0.5482 (0.9681)  Image Caption Matching Loss: 0.7602 (1.5976)  Masked Language Modeling Loss: 1.9757 (2.3138)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.2831 (7.8896)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6575)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6650)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6146)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6567)  Batch Accuracy (Choose Caption): 0.8594 (0.6846)  Batch Accuracy (Choose Image): 0.8438 (0.6968)  Masked Language Modeling Accuracy: 0.6094 (0.5764)  time: 0.6830 (0.7793)  data: 0.0258 (0.1007)  lr: 0.010000  max mem: 12159
2021-04-01 22:37:33,223 maskrcnn_benchmark.trainer INFO: eta: 7:04:08  iter: 7300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6927 (0.9680)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6674 (0.9473)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6937 (1.0808)  Cross-Entropy Loss (Align Words, Choose Image): 0.6230 (0.9630)  Image Caption Matching Loss: 0.8662 (1.5872)  Masked Language Modeling Loss: 1.9076 (2.3092)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.4749 (7.8554)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6592)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6668)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6164)  Batch Accuracy (Align Words, Choose Image): 0.7656 (0.6586)  Batch Accuracy (Choose Caption): 0.8438 (0.6867)  Batch Accuracy (Choose Image): 0.8438 (0.6988)  Masked Language Modeling Accuracy: 0.6178 (0.5769)  time: 0.6839 (0.7782)  data: 0.0241 (0.0997)  lr: 0.010000  max mem: 12159
2021-04-01 22:38:45,675 maskrcnn_benchmark.trainer INFO: eta: 7:02:26  iter: 7400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6176 (0.9638)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6172 (0.9431)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6643 (1.0755)  Cross-Entropy Loss (Align Words, Choose Image): 0.5437 (0.9580)  Image Caption Matching Loss: 0.8001 (1.5769)  Masked Language Modeling Loss: 1.8706 (2.3038)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1100 (7.8211)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6608)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6683)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6182)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6604)  Batch Accuracy (Choose Caption): 0.8438 (0.6888)  Batch Accuracy (Choose Image): 0.8594 (0.7008)  Masked Language Modeling Accuracy: 0.6247 (0.5776)  time: 0.6826 (0.7775)  data: 0.0243 (0.0988)  lr: 0.010000  max mem: 12159
2021-04-01 22:39:56,788 maskrcnn_benchmark.trainer INFO: eta: 7:00:40  iter: 7500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6626 (0.9598)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6278 (0.9394)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6627 (1.0705)  Cross-Entropy Loss (Align Words, Choose Image): 0.5990 (0.9534)  Image Caption Matching Loss: 0.8335 (1.5672)  Masked Language Modeling Loss: 1.9900 (2.2992)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.5397 (7.7896)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6624)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6697)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6200)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6621)  Batch Accuracy (Choose Caption): 0.8281 (0.6907)  Batch Accuracy (Choose Image): 0.8281 (0.7027)  Masked Language Modeling Accuracy: 0.5931 (0.5782)  time: 0.6828 (0.7766)  data: 0.0269 (0.0979)  lr: 0.010000  max mem: 12159
2021-04-01 22:41:07,443 maskrcnn_benchmark.trainer INFO: eta: 6:58:52  iter: 7600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6187 (0.9557)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6391 (0.9352)  Cross-Entropy Loss (Align Words, Choose Caption): 0.7043 (1.0656)  Cross-Entropy Loss (Align Words, Choose Image): 0.5917 (0.9486)  Image Caption Matching Loss: 0.8345 (1.5576)  Masked Language Modeling Loss: 1.9934 (2.2941)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.4358 (7.7568)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6639)  Batch Accuracy (Align Regions, Choose Image): 0.7500 (0.6713)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6219)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6639)  Batch Accuracy (Choose Caption): 0.8281 (0.6926)  Batch Accuracy (Choose Image): 0.8125 (0.7045)  Masked Language Modeling Accuracy: 0.6091 (0.5788)  time: 0.6783 (0.7757)  data: 0.0268 (0.0970)  lr: 0.010000  max mem: 12159
2021-04-01 22:42:18,352 maskrcnn_benchmark.trainer INFO: eta: 6:57:07  iter: 7700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6494 (0.9521)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6173 (0.9316)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6212 (1.0607)  Cross-Entropy Loss (Align Words, Choose Image): 0.5666 (0.9440)  Image Caption Matching Loss: 0.8326 (1.5481)  Masked Language Modeling Loss: 1.9326 (2.2893)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.2952 (7.7259)  Batch Accuracy (Align Regions, Choose Caption): 0.7500 (0.6653)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6726)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6237)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6656)  Batch Accuracy (Choose Caption): 0.8281 (0.6945)  Batch Accuracy (Choose Image): 0.8438 (0.7064)  Masked Language Modeling Accuracy: 0.6149 (0.5794)  time: 0.6766 (0.7748)  data: 0.0263 (0.0962)  lr: 0.010000  max mem: 12159
2021-04-01 22:43:28,796 maskrcnn_benchmark.trainer INFO: eta: 6:55:20  iter: 7800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5881 (0.9480)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5515 (0.9279)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6909 (1.0558)  Cross-Entropy Loss (Align Words, Choose Image): 0.4972 (0.9394)  Image Caption Matching Loss: 0.7095 (1.5389)  Masked Language Modeling Loss: 1.9338 (2.2848)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0921 (7.6947)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.6669)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6740)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6255)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6674)  Batch Accuracy (Choose Caption): 0.8438 (0.6964)  Batch Accuracy (Choose Image): 0.8594 (0.7082)  Masked Language Modeling Accuracy: 0.6146 (0.5800)  time: 0.6775 (0.7739)  data: 0.0258 (0.0953)  lr: 0.010000  max mem: 12159
2021-04-01 22:44:39,314 maskrcnn_benchmark.trainer INFO: eta: 6:53:35  iter: 7900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6190 (0.9444)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5820 (0.9243)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6746 (1.0513)  Cross-Entropy Loss (Align Words, Choose Image): 0.5639 (0.9349)  Image Caption Matching Loss: 0.7839 (1.5299)  Masked Language Modeling Loss: 1.9738 (2.2803)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1334 (7.6650)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6682)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6753)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6272)  Batch Accuracy (Align Words, Choose Image): 0.7812 (0.6690)  Batch Accuracy (Choose Caption): 0.8281 (0.6982)  Batch Accuracy (Choose Image): 0.8281 (0.7100)  Masked Language Modeling Accuracy: 0.6206 (0.5805)  time: 0.6816 (0.7731)  data: 0.0250 (0.0945)  lr: 0.010000  max mem: 12159
2021-04-01 22:45:48,829 maskrcnn_benchmark.trainer INFO: eta: 6:51:46  iter: 8000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6348 (0.9408)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6681 (0.9207)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6841 (1.0467)  Cross-Entropy Loss (Align Words, Choose Image): 0.5868 (0.9305)  Image Caption Matching Loss: 0.8686 (1.5214)  Masked Language Modeling Loss: 1.9371 (2.2754)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.4743 (7.6354)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6696)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6767)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6289)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6706)  Batch Accuracy (Choose Caption): 0.8281 (0.6999)  Batch Accuracy (Choose Image): 0.8281 (0.7117)  Masked Language Modeling Accuracy: 0.6347 (0.5811)  time: 0.6848 (0.7721)  data: 0.0237 (0.0937)  lr: 0.010000  max mem: 12159
2021-04-01 22:45:49,142 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0008000.pth
2021-04-01 22:46:57,492 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 6:51:46  iter: 8000  loss: 2.7060 (2.7542)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4159 (0.4548)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4168 (0.4687)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5572 (0.6008)  Cross-Entropy Loss (Align Words, Choose Image): 0.4354 (0.4710)  Image Caption Matching Loss: 0.7410 (0.7590)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8409)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8403)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.7964)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8376)  Batch Accuracy (Choose Caption): 0.8750 (0.8553)  Batch Accuracy (Choose Image): 0.8728 (0.8639)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12159
2021-04-01 22:48:08,851 maskrcnn_benchmark.trainer INFO: eta: 6:54:37  iter: 8100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5761 (0.9369)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5812 (0.9169)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6223 (1.0421)  Cross-Entropy Loss (Align Words, Choose Image): 0.5256 (0.9262)  Image Caption Matching Loss: 0.7220 (1.5125)  Masked Language Modeling Loss: 1.9618 (2.2713)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0849 (7.6059)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6710)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.6780)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6306)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6722)  Batch Accuracy (Choose Caption): 0.8594 (0.7017)  Batch Accuracy (Choose Image): 0.8594 (0.7134)  Masked Language Modeling Accuracy: 0.6134 (0.5816)  time: 0.6788 (0.7798)  data: 0.0300 (0.1014)  lr: 0.010000  max mem: 12159
2021-04-01 22:49:18,767 maskrcnn_benchmark.trainer INFO: eta: 6:52:47  iter: 8200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6718 (0.9333)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6207 (0.9133)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6266 (1.0375)  Cross-Entropy Loss (Align Words, Choose Image): 0.5610 (0.9219)  Image Caption Matching Loss: 0.8706 (1.5040)  Masked Language Modeling Loss: 1.9496 (2.2674)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.2583 (7.5775)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6723)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6794)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6324)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6737)  Batch Accuracy (Choose Caption): 0.8281 (0.7034)  Batch Accuracy (Choose Image): 0.8594 (0.7150)  Masked Language Modeling Accuracy: 0.5949 (0.5820)  time: 0.6811 (0.7789)  data: 0.0279 (0.1006)  lr: 0.010000  max mem: 12159
2021-04-01 22:50:28,888 maskrcnn_benchmark.trainer INFO: eta: 6:51:00  iter: 8300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6036 (0.9294)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6038 (0.9095)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6542 (1.0326)  Cross-Entropy Loss (Align Words, Choose Image): 0.5522 (0.9173)  Image Caption Matching Loss: 0.7091 (1.4950)  Masked Language Modeling Loss: 1.8700 (2.2628)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.1285 (7.5467)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6737)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6808)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6342)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6754)  Batch Accuracy (Choose Caption): 0.8438 (0.7051)  Batch Accuracy (Choose Image): 0.8594 (0.7167)  Masked Language Modeling Accuracy: 0.6078 (0.5826)  time: 0.6885 (0.7779)  data: 0.0208 (0.0998)  lr: 0.010000  max mem: 12159
2021-04-01 22:51:38,720 maskrcnn_benchmark.trainer INFO: eta: 6:49:12  iter: 8400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6223 (0.9259)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5942 (0.9059)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6592 (1.0282)  Cross-Entropy Loss (Align Words, Choose Image): 0.5606 (0.9129)  Image Caption Matching Loss: 0.7985 (1.4866)  Masked Language Modeling Loss: 1.8656 (2.2582)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0723 (7.5178)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6750)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6821)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6358)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6770)  Batch Accuracy (Choose Caption): 0.8594 (0.7068)  Batch Accuracy (Choose Image): 0.8438 (0.7183)  Masked Language Modeling Accuracy: 0.6126 (0.5831)  time: 0.6895 (0.7770)  data: 0.0197 (0.0989)  lr: 0.010000  max mem: 12159
2021-04-01 22:52:49,198 maskrcnn_benchmark.trainer INFO: eta: 6:47:28  iter: 8500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5919 (0.9224)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5518 (0.9025)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6393 (1.0238)  Cross-Entropy Loss (Align Words, Choose Image): 0.5128 (0.9087)  Image Caption Matching Loss: 0.7194 (1.4787)  Masked Language Modeling Loss: 1.8564 (2.2541)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.9835 (7.4902)  Batch Accuracy (Align Regions, Choose Caption): 0.7656 (0.6762)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6834)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6374)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6785)  Batch Accuracy (Choose Caption): 0.8438 (0.7084)  Batch Accuracy (Choose Image): 0.8594 (0.7199)  Masked Language Modeling Accuracy: 0.5937 (0.5836)  time: 0.6809 (0.7761)  data: 0.0218 (0.0981)  lr: 0.010000  max mem: 12159
2021-04-01 22:54:00,105 maskrcnn_benchmark.trainer INFO: eta: 6:45:45  iter: 8600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6356 (0.9189)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6274 (0.8991)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6683 (1.0198)  Cross-Entropy Loss (Align Words, Choose Image): 0.5682 (0.9048)  Image Caption Matching Loss: 0.8209 (1.4710)  Masked Language Modeling Loss: 1.9857 (2.2503)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.3073 (7.4639)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6775)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6845)  Batch Accuracy (Align Words, Choose Caption): 0.7500 (0.6390)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6800)  Batch Accuracy (Choose Caption): 0.8438 (0.7099)  Batch Accuracy (Choose Image): 0.8438 (0.7213)  Masked Language Modeling Accuracy: 0.5997 (0.5841)  time: 0.6851 (0.7753)  data: 0.0258 (0.0973)  lr: 0.010000  max mem: 12159
2021-04-01 22:55:10,324 maskrcnn_benchmark.trainer INFO: eta: 6:44:02  iter: 8700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6489 (0.9154)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5936 (0.8955)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6821 (1.0155)  Cross-Entropy Loss (Align Words, Choose Image): 0.5968 (0.9006)  Image Caption Matching Loss: 0.7465 (1.4628)  Masked Language Modeling Loss: 1.8340 (2.2461)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0649 (7.4359)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6788)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6858)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6406)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6815)  Batch Accuracy (Choose Caption): 0.8438 (0.7115)  Batch Accuracy (Choose Image): 0.8594 (0.7230)  Masked Language Modeling Accuracy: 0.6361 (0.5846)  time: 0.6914 (0.7745)  data: 0.0199 (0.0965)  lr: 0.010000  max mem: 12159
2021-04-01 22:56:21,610 maskrcnn_benchmark.trainer INFO: eta: 6:42:22  iter: 8800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5731 (0.9121)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5581 (0.8921)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6177 (1.0115)  Cross-Entropy Loss (Align Words, Choose Image): 0.5310 (0.8968)  Image Caption Matching Loss: 0.7380 (1.4550)  Masked Language Modeling Loss: 1.8370 (2.2421)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.8860 (7.4095)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6801)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6870)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6421)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.6830)  Batch Accuracy (Choose Caption): 0.8594 (0.7131)  Batch Accuracy (Choose Image): 0.8594 (0.7244)  Masked Language Modeling Accuracy: 0.6418 (0.5851)  time: 0.6836 (0.7738)  data: 0.0202 (0.0957)  lr: 0.010000  max mem: 12159
2021-04-01 22:57:31,394 maskrcnn_benchmark.trainer INFO: eta: 6:40:39  iter: 8900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6279 (0.9087)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6084 (0.8890)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6333 (1.0076)  Cross-Entropy Loss (Align Words, Choose Image): 0.5632 (0.8931)  Image Caption Matching Loss: 0.7479 (1.4477)  Masked Language Modeling Loss: 1.8837 (2.2384)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.3715 (7.3845)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6813)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6882)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6435)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6843)  Batch Accuracy (Choose Caption): 0.8438 (0.7145)  Batch Accuracy (Choose Image): 0.8594 (0.7258)  Masked Language Modeling Accuracy: 0.5795 (0.5856)  time: 0.6810 (0.7730)  data: 0.0205 (0.0949)  lr: 0.010000  max mem: 12159
2021-04-01 22:58:43,148 maskrcnn_benchmark.trainer INFO: eta: 6:39:02  iter: 9000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5697 (0.9055)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5707 (0.8858)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6016 (1.0037)  Cross-Entropy Loss (Align Words, Choose Image): 0.5341 (0.8893)  Image Caption Matching Loss: 0.7646 (1.4400)  Masked Language Modeling Loss: 1.8146 (2.2345)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.9516 (7.3589)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6825)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6893)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6449)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.6857)  Batch Accuracy (Choose Caption): 0.8438 (0.7161)  Batch Accuracy (Choose Image): 0.8594 (0.7273)  Masked Language Modeling Accuracy: 0.6459 (0.5861)  time: 0.6812 (0.7723)  data: 0.0193 (0.0941)  lr: 0.010000  max mem: 12159
2021-04-01 22:58:43,464 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0009000.pth
2021-04-01 22:59:51,372 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 6:39:02  iter: 9000  loss: 2.6963 (2.8529)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4629 (0.5176)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4725 (0.5034)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5916 (0.6073)  Cross-Entropy Loss (Align Words, Choose Image): 0.4535 (0.4763)  Image Caption Matching Loss: 0.7620 (0.7483)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8215)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8244)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.7890)  Batch Accuracy (Align Words, Choose Image): 0.8415 (0.8326)  Batch Accuracy (Choose Caption): 0.8594 (0.8583)  Batch Accuracy (Choose Image): 0.8750 (0.8668)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12159
2021-04-01 23:01:01,653 maskrcnn_benchmark.trainer INFO: eta: 6:41:13  iter: 9100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5839 (0.9022)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5705 (0.8826)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6849 (0.9999)  Cross-Entropy Loss (Align Words, Choose Image): 0.4971 (0.8855)  Image Caption Matching Loss: 0.6750 (1.4326)  Masked Language Modeling Loss: 1.8383 (2.2312)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0826 (7.3340)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6838)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6905)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6464)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6871)  Batch Accuracy (Choose Caption): 0.8750 (0.7176)  Batch Accuracy (Choose Image): 0.8750 (0.7288)  Masked Language Modeling Accuracy: 0.6208 (0.5864)  time: 0.6843 (0.7791)  data: 0.0235 (0.1009)  lr: 0.010000  max mem: 12159
2021-04-01 23:02:13,108 maskrcnn_benchmark.trainer INFO: eta: 6:39:33  iter: 9200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5971 (0.8992)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5564 (0.8794)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6238 (0.9961)  Cross-Entropy Loss (Align Words, Choose Image): 0.5116 (0.8818)  Image Caption Matching Loss: 0.7051 (1.4253)  Masked Language Modeling Loss: 1.8551 (2.2278)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.8308 (7.3095)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6849)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6917)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6478)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.6885)  Batch Accuracy (Choose Caption): 0.8594 (0.7191)  Batch Accuracy (Choose Image): 0.8750 (0.7302)  Masked Language Modeling Accuracy: 0.6186 (0.5868)  time: 0.6817 (0.7784)  data: 0.0210 (0.1002)  lr: 0.010000  max mem: 12159
2021-04-01 23:03:23,725 maskrcnn_benchmark.trainer INFO: eta: 6:37:52  iter: 9300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5569 (0.8963)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5525 (0.8764)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6520 (0.9924)  Cross-Entropy Loss (Align Words, Choose Image): 0.5577 (0.8782)  Image Caption Matching Loss: 0.7899 (1.4181)  Masked Language Modeling Loss: 1.8346 (2.2240)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.9428 (7.2854)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.6861)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.6928)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6492)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6898)  Batch Accuracy (Choose Caption): 0.8438 (0.7205)  Batch Accuracy (Choose Image): 0.8438 (0.7316)  Masked Language Modeling Accuracy: 0.6387 (0.5872)  time: 0.6837 (0.7776)  data: 0.0203 (0.0994)  lr: 0.010000  max mem: 12159
2021-04-01 23:04:33,659 maskrcnn_benchmark.trainer INFO: eta: 6:36:08  iter: 9400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4868 (0.8931)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4950 (0.8733)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5962 (0.9885)  Cross-Entropy Loss (Align Words, Choose Image): 0.4920 (0.8745)  Image Caption Matching Loss: 0.6463 (1.4107)  Masked Language Modeling Loss: 1.8020 (2.2201)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5746 (7.2602)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.6873)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.6940)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6505)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.6912)  Batch Accuracy (Choose Caption): 0.8906 (0.7220)  Batch Accuracy (Choose Image): 0.8750 (0.7331)  Masked Language Modeling Accuracy: 0.6344 (0.5877)  time: 0.6836 (0.7768)  data: 0.0195 (0.0986)  lr: 0.010000  max mem: 12159
2021-04-01 23:05:44,474 maskrcnn_benchmark.trainer INFO: eta: 6:34:29  iter: 9500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5589 (0.8901)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5238 (0.8704)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5847 (0.9847)  Cross-Entropy Loss (Align Words, Choose Image): 0.5379 (0.8710)  Image Caption Matching Loss: 0.6775 (1.4035)  Masked Language Modeling Loss: 1.8811 (2.2169)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.8620 (7.2366)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6885)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.6951)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6520)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.6925)  Batch Accuracy (Choose Caption): 0.8438 (0.7234)  Batch Accuracy (Choose Image): 0.8594 (0.7344)  Masked Language Modeling Accuracy: 0.6010 (0.5880)  time: 0.6877 (0.7760)  data: 0.0210 (0.0979)  lr: 0.010000  max mem: 12159
2021-04-01 23:06:54,549 maskrcnn_benchmark.trainer INFO: eta: 6:32:47  iter: 9600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5482 (0.8868)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6376 (0.8673)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6268 (0.9809)  Cross-Entropy Loss (Align Words, Choose Image): 0.5060 (0.8674)  Image Caption Matching Loss: 0.7115 (1.3965)  Masked Language Modeling Loss: 1.8288 (2.2133)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7487 (7.2123)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.6896)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.6962)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6534)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6938)  Batch Accuracy (Choose Caption): 0.8594 (0.7248)  Batch Accuracy (Choose Image): 0.8594 (0.7357)  Masked Language Modeling Accuracy: 0.6361 (0.5885)  time: 0.6863 (0.7753)  data: 0.0263 (0.0972)  lr: 0.010000  max mem: 12159
2021-04-01 23:08:05,349 maskrcnn_benchmark.trainer INFO: eta: 6:31:09  iter: 9700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5950 (0.8838)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5999 (0.8644)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6157 (0.9772)  Cross-Entropy Loss (Align Words, Choose Image): 0.5331 (0.8639)  Image Caption Matching Loss: 0.7792 (1.3895)  Masked Language Modeling Loss: 1.7333 (2.2102)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.8346 (7.1889)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6907)  Batch Accuracy (Align Regions, Choose Image): 0.7656 (0.6973)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6547)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.6951)  Batch Accuracy (Choose Caption): 0.8750 (0.7263)  Batch Accuracy (Choose Image): 0.8594 (0.7371)  Masked Language Modeling Accuracy: 0.6471 (0.5888)  time: 0.6860 (0.7746)  data: 0.0206 (0.0965)  lr: 0.010000  max mem: 12159
2021-04-01 23:09:15,408 maskrcnn_benchmark.trainer INFO: eta: 6:29:29  iter: 9800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5498 (0.8809)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5356 (0.8615)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5977 (0.9734)  Cross-Entropy Loss (Align Words, Choose Image): 0.4971 (0.8605)  Image Caption Matching Loss: 0.7208 (1.3829)  Masked Language Modeling Loss: 1.8744 (2.2069)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5923 (7.1661)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6918)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.6984)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6561)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.6963)  Batch Accuracy (Choose Caption): 0.8438 (0.7275)  Batch Accuracy (Choose Image): 0.8594 (0.7383)  Masked Language Modeling Accuracy: 0.6072 (0.5892)  time: 0.6801 (0.7738)  data: 0.0197 (0.0957)  lr: 0.010000  max mem: 12159
2021-04-01 23:10:26,099 maskrcnn_benchmark.trainer INFO: eta: 6:27:51  iter: 9900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5549 (0.8781)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5522 (0.8587)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6168 (0.9700)  Cross-Entropy Loss (Align Words, Choose Image): 0.4824 (0.8571)  Image Caption Matching Loss: 0.6582 (1.3764)  Masked Language Modeling Loss: 1.9051 (2.2036)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7189 (7.1439)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6929)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.6994)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6574)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.6976)  Batch Accuracy (Choose Caption): 0.8594 (0.7288)  Batch Accuracy (Choose Image): 0.8750 (0.7397)  Masked Language Modeling Accuracy: 0.6142 (0.5896)  time: 0.6780 (0.7731)  data: 0.0220 (0.0951)  lr: 0.010000  max mem: 12159
2021-04-01 23:11:36,430 maskrcnn_benchmark.trainer INFO: eta: 6:26:13  iter: 10000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5920 (0.8754)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5737 (0.8560)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5858 (0.9665)  Cross-Entropy Loss (Align Words, Choose Image): 0.5182 (0.8538)  Image Caption Matching Loss: 0.6669 (1.3698)  Masked Language Modeling Loss: 1.8456 (2.2004)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.8250 (7.1218)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6939)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7004)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6587)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.6989)  Batch Accuracy (Choose Caption): 0.8750 (0.7301)  Batch Accuracy (Choose Image): 0.8438 (0.7409)  Masked Language Modeling Accuracy: 0.6224 (0.5900)  time: 0.6837 (0.7724)  data: 0.0208 (0.0944)  lr: 0.010000  max mem: 12159
2021-04-01 23:11:36,724 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0010000.pth
2021-04-01 23:12:44,853 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 6:26:13  iter: 10000  loss: 2.5041 (2.5956)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4300 (0.4252)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3841 (0.4560)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5751 (0.5419)  Cross-Entropy Loss (Align Words, Choose Image): 0.4520 (0.4630)  Image Caption Matching Loss: 0.6774 (0.7095)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8536)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8433)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8088)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8364)  Batch Accuracy (Choose Caption): 0.8594 (0.8584)  Batch Accuracy (Choose Image): 0.8750 (0.8693)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12159
2021-04-01 23:13:55,300 maskrcnn_benchmark.trainer INFO: eta: 6:27:58  iter: 10100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5612 (0.8726)  Cross-Entropy Loss (Align Regions, Choose Image): 0.6376 (0.8532)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6023 (0.9632)  Cross-Entropy Loss (Align Words, Choose Image): 0.4912 (0.8506)  Image Caption Matching Loss: 0.8024 (1.3635)  Masked Language Modeling Loss: 1.8761 (2.1970)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0180 (7.1002)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.6949)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7015)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6600)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7000)  Batch Accuracy (Choose Caption): 0.8438 (0.7313)  Batch Accuracy (Choose Image): 0.8594 (0.7421)  Masked Language Modeling Accuracy: 0.6197 (0.5904)  time: 0.6810 (0.7785)  data: 0.0204 (0.1006)  lr: 0.010000  max mem: 12159
2021-04-01 23:15:06,024 maskrcnn_benchmark.trainer INFO: eta: 6:26:19  iter: 10200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5496 (0.8699)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5967 (0.8506)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5920 (0.9598)  Cross-Entropy Loss (Align Words, Choose Image): 0.4902 (0.8476)  Image Caption Matching Loss: 0.6959 (1.3572)  Masked Language Modeling Loss: 1.6611 (2.1937)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6215 (7.0786)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6959)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7024)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6613)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7011)  Batch Accuracy (Choose Caption): 0.8750 (0.7326)  Batch Accuracy (Choose Image): 0.8438 (0.7433)  Masked Language Modeling Accuracy: 0.6244 (0.5908)  time: 0.6884 (0.7778)  data: 0.0216 (0.0999)  lr: 0.010000  max mem: 12159
2021-04-01 23:16:16,875 maskrcnn_benchmark.trainer INFO: eta: 6:24:41  iter: 10300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6382 (0.8674)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5943 (0.8481)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5994 (0.9565)  Cross-Entropy Loss (Align Words, Choose Image): 0.5356 (0.8445)  Image Caption Matching Loss: 0.6801 (1.3509)  Masked Language Modeling Loss: 1.8501 (2.1904)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 5.0477 (7.0577)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.6969)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.7033)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6625)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7023)  Batch Accuracy (Choose Caption): 0.8594 (0.7338)  Batch Accuracy (Choose Image): 0.8594 (0.7445)  Masked Language Modeling Accuracy: 0.5997 (0.5912)  time: 0.6800 (0.7772)  data: 0.0261 (0.0992)  lr: 0.010000  max mem: 12159
2021-04-01 23:17:29,430 maskrcnn_benchmark.trainer INFO: eta: 6:23:09  iter: 10400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5389 (0.8647)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5666 (0.8455)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6005 (0.9531)  Cross-Entropy Loss (Align Words, Choose Image): 0.5133 (0.8414)  Image Caption Matching Loss: 0.6847 (1.3449)  Masked Language Modeling Loss: 1.8914 (2.1873)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.8206 (7.0370)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6979)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7043)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6637)  Batch Accuracy (Align Words, Choose Image): 0.7969 (0.7034)  Batch Accuracy (Choose Caption): 0.8594 (0.7350)  Batch Accuracy (Choose Image): 0.8594 (0.7457)  Masked Language Modeling Accuracy: 0.6204 (0.5915)  time: 0.6868 (0.7767)  data: 0.0279 (0.0985)  lr: 0.010000  max mem: 12159
2021-04-01 23:18:41,129 maskrcnn_benchmark.trainer INFO: eta: 6:21:34  iter: 10500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5908 (0.8622)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5948 (0.8430)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6084 (0.9499)  Cross-Entropy Loss (Align Words, Choose Image): 0.5097 (0.8383)  Image Caption Matching Loss: 0.6927 (1.3388)  Masked Language Modeling Loss: 1.7509 (2.1842)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7214 (7.0164)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.6988)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.7052)  Batch Accuracy (Align Words, Choose Caption): 0.7656 (0.6649)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7045)  Batch Accuracy (Choose Caption): 0.8594 (0.7363)  Batch Accuracy (Choose Image): 0.8594 (0.7468)  Masked Language Modeling Accuracy: 0.6435 (0.5919)  time: 0.6830 (0.7761)  data: 0.0218 (0.0979)  lr: 0.010000  max mem: 12159
2021-04-01 23:19:50,899 maskrcnn_benchmark.trainer INFO: eta: 6:19:55  iter: 10600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6197 (0.8594)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5652 (0.8403)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5755 (0.9466)  Cross-Entropy Loss (Align Words, Choose Image): 0.5258 (0.8351)  Image Caption Matching Loss: 0.7471 (1.3325)  Masked Language Modeling Loss: 1.8307 (2.1817)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.9674 (6.9957)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.6998)  Batch Accuracy (Align Regions, Choose Image): 0.7812 (0.7061)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6661)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7056)  Batch Accuracy (Choose Caption): 0.8750 (0.7376)  Batch Accuracy (Choose Image): 0.8594 (0.7481)  Masked Language Modeling Accuracy: 0.6189 (0.5922)  time: 0.6832 (0.7754)  data: 0.0208 (0.0973)  lr: 0.010000  max mem: 12203
2021-04-01 23:21:01,996 maskrcnn_benchmark.trainer INFO: eta: 6:18:20  iter: 10700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5513 (0.8570)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5663 (0.8378)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5921 (0.9434)  Cross-Entropy Loss (Align Words, Choose Image): 0.5012 (0.8322)  Image Caption Matching Loss: 0.6851 (1.3265)  Masked Language Modeling Loss: 1.8526 (2.1783)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6681 (6.9751)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7008)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7070)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6673)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7068)  Batch Accuracy (Choose Caption): 0.8750 (0.7388)  Batch Accuracy (Choose Image): 0.8750 (0.7492)  Masked Language Modeling Accuracy: 0.6197 (0.5926)  time: 0.6878 (0.7748)  data: 0.0219 (0.0966)  lr: 0.010000  max mem: 12203
2021-04-01 23:22:12,019 maskrcnn_benchmark.trainer INFO: eta: 6:16:42  iter: 10800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5424 (0.8545)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5522 (0.8353)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5523 (0.9403)  Cross-Entropy Loss (Align Words, Choose Image): 0.4889 (0.8293)  Image Caption Matching Loss: 0.6541 (1.3208)  Masked Language Modeling Loss: 1.8328 (2.1756)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7988 (6.9559)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.7017)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7079)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6684)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7078)  Batch Accuracy (Choose Caption): 0.8594 (0.7398)  Batch Accuracy (Choose Image): 0.8906 (0.7503)  Masked Language Modeling Accuracy: 0.6458 (0.5929)  time: 0.6805 (0.7741)  data: 0.0233 (0.0960)  lr: 0.010000  max mem: 12203
2021-04-01 23:23:21,089 maskrcnn_benchmark.trainer INFO: eta: 6:15:03  iter: 10900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5569 (0.8522)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5720 (0.8330)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5549 (0.9373)  Cross-Entropy Loss (Align Words, Choose Image): 0.4955 (0.8264)  Image Caption Matching Loss: 0.6575 (1.3149)  Masked Language Modeling Loss: 1.8665 (2.1729)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7658 (6.9367)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7025)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7088)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6695)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7088)  Batch Accuracy (Choose Caption): 0.8750 (0.7410)  Batch Accuracy (Choose Image): 0.8750 (0.7515)  Masked Language Modeling Accuracy: 0.6317 (0.5931)  time: 0.6796 (0.7733)  data: 0.0228 (0.0953)  lr: 0.010000  max mem: 12203
2021-04-01 23:24:30,827 maskrcnn_benchmark.trainer INFO: eta: 6:13:25  iter: 11000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5467 (0.8499)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5234 (0.8306)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5660 (0.9343)  Cross-Entropy Loss (Align Words, Choose Image): 0.4743 (0.8236)  Image Caption Matching Loss: 0.7248 (1.3094)  Masked Language Modeling Loss: 1.7374 (2.1698)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5144 (6.9176)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7034)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7096)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6706)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7099)  Batch Accuracy (Choose Caption): 0.8594 (0.7421)  Batch Accuracy (Choose Image): 0.8594 (0.7525)  Masked Language Modeling Accuracy: 0.6403 (0.5935)  time: 0.6767 (0.7726)  data: 0.0226 (0.0947)  lr: 0.010000  max mem: 12203
2021-04-01 23:24:31,228 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0011000.pth
2021-04-01 23:25:38,970 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 6:13:25  iter: 11000  loss: 2.5079 (2.5506)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3881 (0.4279)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4195 (0.4506)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5300 (0.5588)  Cross-Entropy Loss (Align Words, Choose Image): 0.4073 (0.4417)  Image Caption Matching Loss: 0.6711 (0.6716)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8571 (0.8517)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8482)  Batch Accuracy (Align Words, Choose Caption): 0.8073 (0.8112)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8468)  Batch Accuracy (Choose Caption): 0.8750 (0.8698)  Batch Accuracy (Choose Image): 0.8906 (0.8815)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12203
2021-04-01 23:26:50,693 maskrcnn_benchmark.trainer INFO: eta: 6:14:51  iter: 11100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5515 (0.8472)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5583 (0.8280)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5540 (0.9311)  Cross-Entropy Loss (Align Words, Choose Image): 0.4978 (0.8206)  Image Caption Matching Loss: 0.5409 (1.3034)  Masked Language Modeling Loss: 1.7063 (2.1669)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3825 (6.8972)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7044)  Batch Accuracy (Align Regions, Choose Image): 0.8177 (0.7106)  Batch Accuracy (Align Words, Choose Caption): 0.7894 (0.6718)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7110)  Batch Accuracy (Choose Caption): 0.8854 (0.7432)  Batch Accuracy (Choose Image): 0.8750 (0.7537)  Masked Language Modeling Accuracy: 0.6314 (0.5938)  time: 0.6772 (0.7783)  data: 0.0255 (0.1003)  lr: 0.010000  max mem: 12203
2021-04-01 23:28:00,386 maskrcnn_benchmark.trainer INFO: eta: 6:13:12  iter: 11200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5574 (0.8448)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5014 (0.8256)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5464 (0.9280)  Cross-Entropy Loss (Align Words, Choose Image): 0.4763 (0.8178)  Image Caption Matching Loss: 0.6890 (1.2978)  Masked Language Modeling Loss: 1.8016 (2.1640)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6693 (6.8781)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7053)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7115)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6729)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7120)  Batch Accuracy (Choose Caption): 0.8594 (0.7443)  Batch Accuracy (Choose Image): 0.8594 (0.7548)  Masked Language Modeling Accuracy: 0.6262 (0.5942)  time: 0.6817 (0.7775)  data: 0.0211 (0.0996)  lr: 0.010000  max mem: 12203
2021-04-01 23:29:10,109 maskrcnn_benchmark.trainer INFO: eta: 6:11:34  iter: 11300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5485 (0.8424)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5381 (0.8233)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5677 (0.9253)  Cross-Entropy Loss (Align Words, Choose Image): 0.5228 (0.8152)  Image Caption Matching Loss: 0.5788 (1.2924)  Masked Language Modeling Loss: 1.6733 (2.1614)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7199 (6.8600)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7062)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7123)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6740)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7130)  Batch Accuracy (Choose Caption): 0.8594 (0.7454)  Batch Accuracy (Choose Image): 0.8906 (0.7558)  Masked Language Modeling Accuracy: 0.6319 (0.5945)  time: 0.6796 (0.7768)  data: 0.0186 (0.0990)  lr: 0.010000  max mem: 12203
2021-04-01 23:30:21,332 maskrcnn_benchmark.trainer INFO: eta: 6:10:00  iter: 11400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4905 (0.8401)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5104 (0.8209)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6232 (0.9225)  Cross-Entropy Loss (Align Words, Choose Image): 0.4936 (0.8123)  Image Caption Matching Loss: 0.5661 (1.2870)  Masked Language Modeling Loss: 1.9087 (2.1586)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6636 (6.8415)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7070)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7132)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6750)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7140)  Batch Accuracy (Choose Caption): 0.8750 (0.7465)  Batch Accuracy (Choose Image): 0.8906 (0.7568)  Masked Language Modeling Accuracy: 0.6250 (0.5948)  time: 0.6839 (0.7762)  data: 0.0196 (0.0983)  lr: 0.010000  max mem: 12203
2021-04-01 23:31:30,978 maskrcnn_benchmark.trainer INFO: eta: 6:08:23  iter: 11500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5104 (0.8376)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5413 (0.8185)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5573 (0.9194)  Cross-Entropy Loss (Align Words, Choose Image): 0.4471 (0.8095)  Image Caption Matching Loss: 0.6262 (1.2817)  Masked Language Modeling Loss: 1.8734 (2.1563)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6171 (6.8231)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7079)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7140)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6762)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7150)  Batch Accuracy (Choose Caption): 0.8594 (0.7476)  Batch Accuracy (Choose Image): 0.8750 (0.7579)  Masked Language Modeling Accuracy: 0.6465 (0.5951)  time: 0.6764 (0.7756)  data: 0.0197 (0.0977)  lr: 0.010000  max mem: 12203
2021-04-01 23:32:41,059 maskrcnn_benchmark.trainer INFO: eta: 6:06:47  iter: 11600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5195 (0.8353)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5384 (0.8162)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5082 (0.9165)  Cross-Entropy Loss (Align Words, Choose Image): 0.4385 (0.8069)  Image Caption Matching Loss: 0.5528 (1.2762)  Masked Language Modeling Loss: 1.7283 (2.1534)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4622 (6.8046)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7088)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7149)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6772)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7160)  Batch Accuracy (Choose Caption): 0.8750 (0.7486)  Batch Accuracy (Choose Image): 0.9062 (0.7589)  Masked Language Modeling Accuracy: 0.6361 (0.5954)  time: 0.6880 (0.7749)  data: 0.0231 (0.0971)  lr: 0.010000  max mem: 12203
2021-04-01 23:33:51,309 maskrcnn_benchmark.trainer INFO: eta: 6:05:12  iter: 11700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5423 (0.8330)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5261 (0.8140)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6363 (0.9138)  Cross-Entropy Loss (Align Words, Choose Image): 0.4384 (0.8042)  Image Caption Matching Loss: 0.5953 (1.2710)  Masked Language Modeling Loss: 1.9184 (2.1510)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5001 (6.7871)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7097)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7157)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6783)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7170)  Batch Accuracy (Choose Caption): 0.8594 (0.7497)  Batch Accuracy (Choose Image): 0.8906 (0.7599)  Masked Language Modeling Accuracy: 0.6273 (0.5957)  time: 0.6783 (0.7743)  data: 0.0204 (0.0965)  lr: 0.010000  max mem: 12203
2021-04-01 23:35:04,079 maskrcnn_benchmark.trainer INFO: eta: 6:03:43  iter: 11800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4937 (0.8304)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4591 (0.8115)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5033 (0.9108)  Cross-Entropy Loss (Align Words, Choose Image): 0.4091 (0.8014)  Image Caption Matching Loss: 0.5973 (1.2656)  Masked Language Modeling Loss: 1.7928 (2.1483)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3915 (6.7680)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7106)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7166)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6794)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7180)  Batch Accuracy (Choose Caption): 0.8750 (0.7507)  Batch Accuracy (Choose Image): 0.8906 (0.7610)  Masked Language Modeling Accuracy: 0.6389 (0.5961)  time: 0.6817 (0.7739)  data: 0.0228 (0.0959)  lr: 0.010000  max mem: 12203
2021-04-01 23:36:14,216 maskrcnn_benchmark.trainer INFO: eta: 6:02:09  iter: 11900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5779 (0.8283)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5801 (0.8094)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5608 (0.9082)  Cross-Entropy Loss (Align Words, Choose Image): 0.4710 (0.7989)  Image Caption Matching Loss: 0.5758 (1.2608)  Masked Language Modeling Loss: 1.6557 (2.1456)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4513 (6.7511)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7114)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7173)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6804)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7189)  Batch Accuracy (Choose Caption): 0.8750 (0.7517)  Batch Accuracy (Choose Image): 0.8906 (0.7619)  Masked Language Modeling Accuracy: 0.6435 (0.5964)  time: 0.6812 (0.7733)  data: 0.0204 (0.0953)  lr: 0.010000  max mem: 12203
2021-04-01 23:37:25,109 maskrcnn_benchmark.trainer INFO: eta: 6:00:37  iter: 12000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5417 (0.8261)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4928 (0.8073)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5990 (0.9054)  Cross-Entropy Loss (Align Words, Choose Image): 0.4819 (0.7963)  Image Caption Matching Loss: 0.6026 (1.2557)  Masked Language Modeling Loss: 1.9025 (2.1429)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5499 (6.7338)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7123)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7181)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6814)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7198)  Batch Accuracy (Choose Caption): 0.8750 (0.7527)  Batch Accuracy (Choose Image): 0.8906 (0.7629)  Masked Language Modeling Accuracy: 0.6237 (0.5967)  time: 0.6788 (0.7728)  data: 0.0214 (0.0948)  lr: 0.010000  max mem: 12203
2021-04-01 23:37:25,401 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0012000.pth
2021-04-01 23:38:32,809 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 6:00:37  iter: 12000  loss: 2.3590 (2.3615)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3829 (0.4126)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3911 (0.4272)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4741 (0.4884)  Cross-Entropy Loss (Align Words, Choose Image): 0.3939 (0.4050)  Image Caption Matching Loss: 0.6245 (0.6284)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8628)  Batch Accuracy (Align Regions, Choose Image): 0.8698 (0.8518)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8287)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8556)  Batch Accuracy (Choose Caption): 0.8906 (0.8748)  Batch Accuracy (Choose Image): 0.8750 (0.8787)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12203
2021-04-01 23:39:43,039 maskrcnn_benchmark.trainer INFO: eta: 6:01:39  iter: 12100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5258 (0.8239)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4761 (0.8052)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5185 (0.9025)  Cross-Entropy Loss (Align Words, Choose Image): 0.4553 (0.7937)  Image Caption Matching Loss: 0.5947 (1.2508)  Masked Language Modeling Loss: 1.6634 (2.1402)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2033 (6.7164)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7131)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7189)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6824)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7207)  Batch Accuracy (Choose Caption): 0.8750 (0.7537)  Batch Accuracy (Choose Image): 0.8906 (0.7639)  Masked Language Modeling Accuracy: 0.6527 (0.5970)  time: 0.6847 (0.7778)  data: 0.0206 (0.0998)  lr: 0.010000  max mem: 12203
2021-04-01 23:40:53,582 maskrcnn_benchmark.trainer INFO: eta: 6:00:05  iter: 12200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5370 (0.8216)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5183 (0.8030)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5751 (0.8998)  Cross-Entropy Loss (Align Words, Choose Image): 0.4534 (0.7912)  Image Caption Matching Loss: 0.6748 (1.2457)  Masked Language Modeling Loss: 1.7971 (2.1375)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6470 (6.6989)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7139)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7197)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6834)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7216)  Batch Accuracy (Choose Caption): 0.8750 (0.7548)  Batch Accuracy (Choose Image): 0.8750 (0.7649)  Masked Language Modeling Accuracy: 0.6224 (0.5973)  time: 0.6823 (0.7772)  data: 0.0202 (0.0992)  lr: 0.010000  max mem: 12203
2021-04-01 23:42:04,126 maskrcnn_benchmark.trainer INFO: eta: 5:58:31  iter: 12300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5515 (0.8194)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5140 (0.8009)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5499 (0.8970)  Cross-Entropy Loss (Align Words, Choose Image): 0.4963 (0.7887)  Image Caption Matching Loss: 0.6942 (1.2407)  Masked Language Modeling Loss: 1.9870 (2.1349)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6897 (6.6816)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7147)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7205)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6845)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7226)  Batch Accuracy (Choose Caption): 0.8594 (0.7558)  Batch Accuracy (Choose Image): 0.8594 (0.7658)  Masked Language Modeling Accuracy: 0.6192 (0.5977)  time: 0.6804 (0.7766)  data: 0.0211 (0.0986)  lr: 0.010000  max mem: 12203
2021-04-01 23:43:14,418 maskrcnn_benchmark.trainer INFO: eta: 5:56:57  iter: 12400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5049 (0.8173)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4419 (0.7987)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5408 (0.8944)  Cross-Entropy Loss (Align Words, Choose Image): 0.4632 (0.7862)  Image Caption Matching Loss: 0.6950 (1.2360)  Masked Language Modeling Loss: 1.9167 (2.1326)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6490 (6.6652)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7155)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7213)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6855)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7234)  Batch Accuracy (Choose Caption): 0.8438 (0.7567)  Batch Accuracy (Choose Image): 0.8594 (0.7667)  Masked Language Modeling Accuracy: 0.6422 (0.5979)  time: 0.6800 (0.7760)  data: 0.0195 (0.0981)  lr: 0.010000  max mem: 12203
2021-04-01 23:44:24,346 maskrcnn_benchmark.trainer INFO: eta: 5:55:22  iter: 12500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6066 (0.8152)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5333 (0.7968)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5775 (0.8918)  Cross-Entropy Loss (Align Words, Choose Image): 0.4614 (0.7838)  Image Caption Matching Loss: 0.6424 (1.2312)  Masked Language Modeling Loss: 1.8712 (2.1303)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7520 (6.6490)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7163)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7220)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6864)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7243)  Batch Accuracy (Choose Caption): 0.8594 (0.7576)  Batch Accuracy (Choose Image): 0.8750 (0.7676)  Masked Language Modeling Accuracy: 0.6376 (0.5982)  time: 0.6767 (0.7754)  data: 0.0210 (0.0975)  lr: 0.010000  max mem: 12203
2021-04-01 23:45:33,329 maskrcnn_benchmark.trainer INFO: eta: 5:53:46  iter: 12600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5039 (0.8130)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5107 (0.7947)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5312 (0.8891)  Cross-Entropy Loss (Align Words, Choose Image): 0.4663 (0.7814)  Image Caption Matching Loss: 0.6301 (1.2266)  Masked Language Modeling Loss: 1.7874 (2.1276)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3886 (6.6324)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7171)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7228)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6874)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7252)  Batch Accuracy (Choose Caption): 0.8750 (0.7586)  Batch Accuracy (Choose Image): 0.8906 (0.7685)  Masked Language Modeling Accuracy: 0.6430 (0.5986)  time: 0.6815 (0.7747)  data: 0.0197 (0.0969)  lr: 0.010000  max mem: 12203
2021-04-01 23:46:43,285 maskrcnn_benchmark.trainer INFO: eta: 5:52:13  iter: 12700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5077 (0.8112)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4838 (0.7928)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5304 (0.8865)  Cross-Entropy Loss (Align Words, Choose Image): 0.4486 (0.7791)  Image Caption Matching Loss: 0.6058 (1.2221)  Masked Language Modeling Loss: 1.7370 (2.1249)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3552 (6.6166)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7178)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7235)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6884)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7260)  Batch Accuracy (Choose Caption): 0.8750 (0.7595)  Batch Accuracy (Choose Image): 0.8906 (0.7694)  Masked Language Modeling Accuracy: 0.6204 (0.5988)  time: 0.6732 (0.7741)  data: 0.0215 (0.0964)  lr: 0.010000  max mem: 12203
2021-04-01 23:47:53,120 maskrcnn_benchmark.trainer INFO: eta: 5:50:39  iter: 12800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5602 (0.8093)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5758 (0.7910)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5359 (0.8841)  Cross-Entropy Loss (Align Words, Choose Image): 0.4817 (0.7769)  Image Caption Matching Loss: 0.6529 (1.2177)  Masked Language Modeling Loss: 1.8196 (2.1226)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6928 (6.6016)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7184)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7242)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6892)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7268)  Batch Accuracy (Choose Caption): 0.8750 (0.7604)  Batch Accuracy (Choose Image): 0.8594 (0.7702)  Masked Language Modeling Accuracy: 0.6020 (0.5991)  time: 0.6758 (0.7735)  data: 0.0244 (0.0958)  lr: 0.010000  max mem: 12203
2021-04-01 23:49:03,181 maskrcnn_benchmark.trainer INFO: eta: 5:49:07  iter: 12900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5485 (0.8073)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5606 (0.7891)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5692 (0.8816)  Cross-Entropy Loss (Align Words, Choose Image): 0.4801 (0.7746)  Image Caption Matching Loss: 0.6288 (1.2132)  Masked Language Modeling Loss: 1.6989 (2.1198)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3900 (6.5857)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7192)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7249)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6901)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7277)  Batch Accuracy (Choose Caption): 0.8438 (0.7613)  Batch Accuracy (Choose Image): 0.8750 (0.7711)  Masked Language Modeling Accuracy: 0.6612 (0.5995)  time: 0.6840 (0.7730)  data: 0.0282 (0.0953)  lr: 0.010000  max mem: 12203
2021-04-01 23:50:12,357 maskrcnn_benchmark.trainer INFO: eta: 5:47:32  iter: 13000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5780 (0.8054)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5599 (0.7872)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6081 (0.8792)  Cross-Entropy Loss (Align Words, Choose Image): 0.5258 (0.7724)  Image Caption Matching Loss: 0.6200 (1.2086)  Masked Language Modeling Loss: 1.7471 (2.1174)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6884 (6.5701)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7199)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7256)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6910)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7285)  Batch Accuracy (Choose Caption): 0.8594 (0.7621)  Batch Accuracy (Choose Image): 0.9062 (0.7719)  Masked Language Modeling Accuracy: 0.6157 (0.5997)  time: 0.6791 (0.7723)  data: 0.0201 (0.0948)  lr: 0.010000  max mem: 12203
2021-04-01 23:50:12,653 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0013000.pth
2021-04-01 23:51:20,516 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 5:47:32  iter: 13000  loss: 2.3771 (2.3787)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4130 (0.4169)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4214 (0.4217)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4683 (0.5016)  Cross-Entropy Loss (Align Words, Choose Image): 0.4075 (0.4084)  Image Caption Matching Loss: 0.6357 (0.6301)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8655)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8617)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8231)  Batch Accuracy (Align Words, Choose Image): 0.8333 (0.8571)  Batch Accuracy (Choose Caption): 0.8594 (0.8801)  Batch Accuracy (Choose Image): 0.8884 (0.8786)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12203
2021-04-01 23:52:29,668 maskrcnn_benchmark.trainer INFO: eta: 5:48:18  iter: 13100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5543 (0.8035)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5216 (0.7854)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6051 (0.8768)  Cross-Entropy Loss (Align Words, Choose Image): 0.5062 (0.7702)  Image Caption Matching Loss: 0.6697 (1.2042)  Masked Language Modeling Loss: 1.7387 (2.1150)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6312 (6.5550)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7206)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7262)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6919)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7293)  Batch Accuracy (Choose Caption): 0.8594 (0.7630)  Batch Accuracy (Choose Image): 0.8750 (0.7728)  Masked Language Modeling Accuracy: 0.6304 (0.6000)  time: 0.6746 (0.7769)  data: 0.0223 (0.0995)  lr: 0.010000  max mem: 12203
2021-04-01 23:53:38,777 maskrcnn_benchmark.trainer INFO: eta: 5:46:43  iter: 13200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5461 (0.8014)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5166 (0.7834)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5132 (0.8743)  Cross-Entropy Loss (Align Words, Choose Image): 0.4175 (0.7679)  Image Caption Matching Loss: 0.6645 (1.1998)  Masked Language Modeling Loss: 1.7793 (2.1128)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4439 (6.5397)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7214)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7270)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.6928)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7301)  Batch Accuracy (Choose Caption): 0.8750 (0.7639)  Batch Accuracy (Choose Image): 0.8750 (0.7736)  Masked Language Modeling Accuracy: 0.6312 (0.6003)  time: 0.6803 (0.7763)  data: 0.0260 (0.0990)  lr: 0.010000  max mem: 12203
2021-04-01 23:54:51,564 maskrcnn_benchmark.trainer INFO: eta: 5:45:16  iter: 13300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5140 (0.7995)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5208 (0.7816)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4969 (0.8719)  Cross-Entropy Loss (Align Words, Choose Image): 0.4501 (0.7657)  Image Caption Matching Loss: 0.5284 (1.1955)  Masked Language Modeling Loss: 1.7361 (2.1106)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3428 (6.5248)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7221)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7276)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6937)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7310)  Batch Accuracy (Choose Caption): 0.8906 (0.7648)  Batch Accuracy (Choose Image): 0.8906 (0.7745)  Masked Language Modeling Accuracy: 0.6385 (0.6005)  time: 0.6790 (0.7759)  data: 0.0276 (0.0984)  lr: 0.010000  max mem: 12203
2021-04-01 23:56:02,590 maskrcnn_benchmark.trainer INFO: eta: 5:43:45  iter: 13400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6128 (0.7977)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5407 (0.7797)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5696 (0.8694)  Cross-Entropy Loss (Align Words, Choose Image): 0.4887 (0.7634)  Image Caption Matching Loss: 0.6757 (1.1913)  Masked Language Modeling Loss: 1.7240 (2.1083)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7424 (6.5098)  Batch Accuracy (Align Regions, Choose Caption): 0.7812 (0.7228)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.7283)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6946)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7317)  Batch Accuracy (Choose Caption): 0.8594 (0.7656)  Batch Accuracy (Choose Image): 0.8750 (0.7753)  Masked Language Modeling Accuracy: 0.6232 (0.6008)  time: 0.6790 (0.7754)  data: 0.0249 (0.0979)  lr: 0.010000  max mem: 12203
2021-04-01 23:57:11,718 maskrcnn_benchmark.trainer INFO: eta: 5:42:11  iter: 13500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5969 (0.7958)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5680 (0.7779)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5402 (0.8670)  Cross-Entropy Loss (Align Words, Choose Image): 0.5021 (0.7614)  Image Caption Matching Loss: 0.6239 (1.1871)  Masked Language Modeling Loss: 1.7997 (2.1061)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5998 (6.4952)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7235)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7290)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6955)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7325)  Batch Accuracy (Choose Caption): 0.8750 (0.7664)  Batch Accuracy (Choose Image): 0.8750 (0.7761)  Masked Language Modeling Accuracy: 0.6399 (0.6010)  time: 0.6773 (0.7748)  data: 0.0240 (0.0974)  lr: 0.010000  max mem: 12203
2021-04-01 23:58:21,841 maskrcnn_benchmark.trainer INFO: eta: 5:40:40  iter: 13600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5890 (0.7939)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5568 (0.7761)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6032 (0.8648)  Cross-Entropy Loss (Align Words, Choose Image): 0.5062 (0.7593)  Image Caption Matching Loss: 0.6849 (1.1830)  Masked Language Modeling Loss: 1.8176 (2.1036)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.7557 (6.4806)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7242)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7297)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.6964)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7333)  Batch Accuracy (Choose Caption): 0.8750 (0.7673)  Batch Accuracy (Choose Image): 0.8750 (0.7769)  Masked Language Modeling Accuracy: 0.6221 (0.6013)  time: 0.6830 (0.7742)  data: 0.0201 (0.0969)  lr: 0.010000  max mem: 12203
2021-04-01 23:59:31,337 maskrcnn_benchmark.trainer INFO: eta: 5:39:07  iter: 13700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5571 (0.7921)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5509 (0.7743)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5810 (0.8626)  Cross-Entropy Loss (Align Words, Choose Image): 0.4928 (0.7572)  Image Caption Matching Loss: 0.5755 (1.1790)  Masked Language Modeling Loss: 1.7533 (2.1015)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6299 (6.4667)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7249)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7304)  Batch Accuracy (Align Words, Choose Caption): 0.7812 (0.6972)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.7340)  Batch Accuracy (Choose Caption): 0.8750 (0.7681)  Batch Accuracy (Choose Image): 0.8750 (0.7777)  Masked Language Modeling Accuracy: 0.6369 (0.6015)  time: 0.6772 (0.7737)  data: 0.0206 (0.0964)  lr: 0.010000  max mem: 12203
2021-04-02 00:00:45,012 maskrcnn_benchmark.trainer INFO: eta: 5:37:43  iter: 13800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4909 (0.7902)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4701 (0.7725)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4851 (0.8602)  Cross-Entropy Loss (Align Words, Choose Image): 0.4285 (0.7552)  Image Caption Matching Loss: 0.5722 (1.1749)  Masked Language Modeling Loss: 1.7685 (2.0993)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4874 (6.4523)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7256)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7311)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.6981)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7348)  Batch Accuracy (Choose Caption): 0.8906 (0.7688)  Batch Accuracy (Choose Image): 0.8906 (0.7785)  Masked Language Modeling Accuracy: 0.6655 (0.6018)  time: 0.6748 (0.7734)  data: 0.0208 (0.0959)  lr: 0.010000  max mem: 12203
2021-04-02 00:01:57,074 maskrcnn_benchmark.trainer INFO: eta: 5:36:15  iter: 13900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5106 (0.7884)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4864 (0.7707)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5166 (0.8580)  Cross-Entropy Loss (Align Words, Choose Image): 0.4211 (0.7530)  Image Caption Matching Loss: 0.5588 (1.1708)  Masked Language Modeling Loss: 1.7555 (2.0973)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2866 (6.4382)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7262)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7318)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.6990)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7356)  Batch Accuracy (Choose Caption): 0.8750 (0.7696)  Batch Accuracy (Choose Image): 0.8906 (0.7793)  Masked Language Modeling Accuracy: 0.6486 (0.6021)  time: 0.6711 (0.7730)  data: 0.0223 (0.0954)  lr: 0.010000  max mem: 12203
2021-04-02 00:03:07,221 maskrcnn_benchmark.trainer INFO: eta: 5:34:45  iter: 14000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5107 (0.7866)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4364 (0.7689)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4917 (0.8556)  Cross-Entropy Loss (Align Words, Choose Image): 0.4400 (0.7510)  Image Caption Matching Loss: 0.5592 (1.1667)  Masked Language Modeling Loss: 1.7859 (2.0951)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2463 (6.4239)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7269)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7324)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.6998)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7364)  Batch Accuracy (Choose Caption): 0.9062 (0.7704)  Batch Accuracy (Choose Image): 0.9062 (0.7801)  Masked Language Modeling Accuracy: 0.6312 (0.6024)  time: 0.6788 (0.7725)  data: 0.0226 (0.0949)  lr: 0.010000  max mem: 12203
2021-04-02 00:03:07,539 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0014000.pth
2021-04-02 00:04:15,017 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 5:34:45  iter: 14000  loss: 2.1048 (2.1415)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3682 (0.3751)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3843 (0.3977)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4339 (0.4628)  Cross-Entropy Loss (Align Words, Choose Image): 0.3519 (0.3727)  Image Caption Matching Loss: 0.5515 (0.5331)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8745)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8670)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8413)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8693)  Batch Accuracy (Choose Caption): 0.9062 (0.8991)  Batch Accuracy (Choose Image): 0.9062 (0.9008)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 12203
2021-04-02 00:05:25,854 maskrcnn_benchmark.trainer INFO: eta: 5:35:20  iter: 14100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5556 (0.7848)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5538 (0.7672)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5343 (0.8534)  Cross-Entropy Loss (Align Words, Choose Image): 0.4917 (0.7490)  Image Caption Matching Loss: 0.6337 (1.1627)  Masked Language Modeling Loss: 1.7127 (2.0928)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5650 (6.4099)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7276)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7331)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7006)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.7371)  Batch Accuracy (Choose Caption): 0.8750 (0.7712)  Batch Accuracy (Choose Image): 0.8750 (0.7809)  Masked Language Modeling Accuracy: 0.6418 (0.6027)  time: 0.6851 (0.7769)  data: 0.0298 (0.0993)  lr: 0.010000  max mem: 12203
2021-04-02 00:06:37,161 maskrcnn_benchmark.trainer INFO: eta: 5:33:51  iter: 14200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5002 (0.7832)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5160 (0.7656)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5635 (0.8514)  Cross-Entropy Loss (Align Words, Choose Image): 0.4660 (0.7471)  Image Caption Matching Loss: 0.6006 (1.1590)  Masked Language Modeling Loss: 1.8307 (2.0910)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6029 (6.3973)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7282)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7337)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.7013)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7378)  Batch Accuracy (Choose Caption): 0.8906 (0.7720)  Batch Accuracy (Choose Image): 0.8750 (0.7815)  Masked Language Modeling Accuracy: 0.6286 (0.6029)  time: 0.6860 (0.7764)  data: 0.0311 (0.0989)  lr: 0.010000  max mem: 12203
2021-04-02 00:07:47,348 maskrcnn_benchmark.trainer INFO: eta: 5:32:20  iter: 14300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5291 (0.7814)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5196 (0.7640)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5271 (0.8493)  Cross-Entropy Loss (Align Words, Choose Image): 0.4113 (0.7452)  Image Caption Matching Loss: 0.5901 (1.1553)  Masked Language Modeling Loss: 1.7074 (2.0889)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1916 (6.3841)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7288)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7343)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7021)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.7385)  Batch Accuracy (Choose Caption): 0.8750 (0.7727)  Batch Accuracy (Choose Image): 0.9062 (0.7822)  Masked Language Modeling Accuracy: 0.6610 (0.6032)  time: 0.6879 (0.7759)  data: 0.0284 (0.0984)  lr: 0.010000  max mem: 12203
2021-04-02 00:08:59,561 maskrcnn_benchmark.trainer INFO: eta: 5:30:53  iter: 14400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4972 (0.7797)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5185 (0.7623)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5814 (0.8472)  Cross-Entropy Loss (Align Words, Choose Image): 0.4930 (0.7433)  Image Caption Matching Loss: 0.5924 (1.1515)  Masked Language Modeling Loss: 1.8008 (2.0866)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5029 (6.3706)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7295)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7349)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.7029)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7392)  Batch Accuracy (Choose Caption): 0.8906 (0.7735)  Batch Accuracy (Choose Image): 0.8750 (0.7829)  Masked Language Modeling Accuracy: 0.6491 (0.6035)  time: 0.6845 (0.7755)  data: 0.0308 (0.0980)  lr: 0.010000  max mem: 12203
2021-04-02 00:10:10,102 maskrcnn_benchmark.trainer INFO: eta: 5:29:23  iter: 14500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5510 (0.7781)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4642 (0.7607)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6033 (0.8452)  Cross-Entropy Loss (Align Words, Choose Image): 0.4958 (0.7414)  Image Caption Matching Loss: 0.5428 (1.1477)  Masked Language Modeling Loss: 1.6961 (2.0843)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2692 (6.3574)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.7301)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.7355)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.7036)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7398)  Batch Accuracy (Choose Caption): 0.8906 (0.7742)  Batch Accuracy (Choose Image): 0.9062 (0.7837)  Masked Language Modeling Accuracy: 0.6581 (0.6038)  time: 0.6841 (0.7750)  data: 0.0278 (0.0975)  lr: 0.010000  max mem: 12203
2021-04-02 00:11:20,562 maskrcnn_benchmark.trainer INFO: eta: 5:27:53  iter: 14600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4640 (0.7763)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4753 (0.7589)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5143 (0.8432)  Cross-Entropy Loss (Align Words, Choose Image): 0.4147 (0.7394)  Image Caption Matching Loss: 0.5255 (1.1439)  Masked Language Modeling Loss: 1.6416 (2.0822)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0754 (6.3439)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.7307)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7361)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.7043)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7405)  Batch Accuracy (Choose Caption): 0.8906 (0.7750)  Batch Accuracy (Choose Image): 0.8750 (0.7844)  Masked Language Modeling Accuracy: 0.6601 (0.6040)  time: 0.6878 (0.7746)  data: 0.0279 (0.0971)  lr: 0.010000  max mem: 12203
2021-04-02 00:12:31,586 maskrcnn_benchmark.trainer INFO: eta: 5:26:25  iter: 14700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5260 (0.7747)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4605 (0.7573)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4632 (0.8411)  Cross-Entropy Loss (Align Words, Choose Image): 0.4379 (0.7375)  Image Caption Matching Loss: 0.5647 (1.1402)  Masked Language Modeling Loss: 1.7771 (2.0803)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4437 (6.3311)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7312)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.7367)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.7051)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7412)  Batch Accuracy (Choose Caption): 0.8750 (0.7757)  Batch Accuracy (Choose Image): 0.8750 (0.7851)  Masked Language Modeling Accuracy: 0.6390 (0.6042)  time: 0.6824 (0.7741)  data: 0.0248 (0.0967)  lr: 0.010000  max mem: 12203
2021-04-02 00:13:41,630 maskrcnn_benchmark.trainer INFO: eta: 5:24:55  iter: 14800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4280 (0.7731)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4718 (0.7557)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4791 (0.8390)  Cross-Entropy Loss (Align Words, Choose Image): 0.4584 (0.7356)  Image Caption Matching Loss: 0.5093 (1.1365)  Masked Language Modeling Loss: 1.8167 (2.0784)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1625 (6.3184)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.7319)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7373)  Batch Accuracy (Align Words, Choose Caption): 0.8333 (0.7059)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7419)  Batch Accuracy (Choose Caption): 0.8906 (0.7765)  Batch Accuracy (Choose Image): 0.8906 (0.7858)  Masked Language Modeling Accuracy: 0.6364 (0.6045)  time: 0.6838 (0.7736)  data: 0.0242 (0.0963)  lr: 0.010000  max mem: 12203
2021-04-02 00:14:51,958 maskrcnn_benchmark.trainer INFO: eta: 5:23:25  iter: 14900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4484 (0.7713)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4699 (0.7541)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5404 (0.8369)  Cross-Entropy Loss (Align Words, Choose Image): 0.4170 (0.7338)  Image Caption Matching Loss: 0.5989 (1.1330)  Masked Language Modeling Loss: 1.6645 (2.0767)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2131 (6.3057)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.7325)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.7379)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.7066)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.7425)  Batch Accuracy (Choose Caption): 0.8750 (0.7771)  Batch Accuracy (Choose Image): 0.8750 (0.7865)  Masked Language Modeling Accuracy: 0.6437 (0.6046)  time: 0.6846 (0.7731)  data: 0.0250 (0.0958)  lr: 0.010000  max mem: 12203
2021-04-02 00:19:10,876 maskrcnn_benchmark INFO: Using 8 GPUs
2021-04-02 00:19:10,878 maskrcnn_benchmark INFO: Namespace(config_file='configs/mmss_v07.yaml', distributed=True, local_rank=0, opts=['OUTPUT_DIR', '/mnt/lustre/lixiangtai/runs/vltrain/121'], skip_test=True)
2021-04-02 00:19:10,878 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2021-04-02 00:20:14,396 maskrcnn_benchmark INFO:
PyTorch version: 1.3.1+cuda90_cudnn7.6.3_lms
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: CentOS Linux 7 (Core)
GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
CMake version: version 2.8.12.2

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration:
GPU 0: Tesla V100-SXM2-32GB
GPU 1: Tesla V100-SXM2-32GB
GPU 2: Tesla V100-SXM2-32GB
GPU 3: Tesla V100-SXM2-32GB
GPU 4: Tesla V100-SXM2-32GB
GPU 5: Tesla V100-SXM2-32GB
GPU 6: Tesla V100-SXM2-32GB
GPU 7: Tesla V100-SXM2-32GB

Nvidia driver version: 418.67
cuDNN version: /usr/local/cuda-9.0/lib64/libcudnn.so.7.0.4

Versions of relevant libraries:
[pip3] numpy==1.17.3
[conda] linklink                  0.3.1+cuda9.0.torch131.mvapich2.pmi2          pypi_0    pypi
[conda] torch                     1.3.1+cuda90.cudnn7.6.3.lms          pypi_0    pypi
[conda] torchvision               0.4.2                    pypi_0    pypi
        Pillow (7.1.2)
2021-04-02 00:20:14,447 maskrcnn_benchmark INFO: Loaded configuration file configs/mmss_v07.yaml
2021-04-02 00:20:14,448 maskrcnn_benchmark INFO:
MODEL:
  # This is what indicates we want image-caption training not object detection
  META_ARCHITECTURE: "MMSS-GCNN"
  # URL to the initial weights, trained for imagenet classification
  WEIGHT: "/mnt/lustreold/lixiangtai/pretrained/R-50.pkl"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
  BACKBONE:
    # a full resnet, including stem and 4 blocks
    CONV_BODY: "R-50-C5"
    # don't freeze any layer, train everything
    FREEZE_CONV_BODY_AT: 0
  LANGUAGE_BACKBONE:
    # make a BERT model to process captions
    TYPE: "BERT-Base"
    # and freeze it (loaded from original pretrained bert of huggingface)
    FREEZE: True
  MMSS_HEAD:
    # We want both a grounding head and a transformer head on top of image and caption,
    # each of which defines its own objective functions.
    TYPES: ("GroundingHead", "TransformerHead")
    DEFAULT_HEAD: "GroundingHead"
    # Share the weights of the vision to language projection between the two heads.
    # Use the one on the grounding head because that is the default (see above)
    TIE_VL_PROJECTION_WEIGHTS: True
    # Randomly keep up to 100 visual regions from each image. This is to save memory.
    SPATIAL_DROPOUT: 100
    GROUNDING:
      # Use dot product for grounding. This could be cosine or euclidean too.
      LOCAL_METRIC: "dot"
      # After aligning words to regions, sum the local distances to compute global distance.
      GLOBAL_METRIC: "aligned_local"
      # Use softmax to softly align each word to regions, and vice versa.
      # This could be for instance hardmax, which aligns to the most similar
      ALIGNMENT: "softmax"
      # Typical good values are 100.0 for euclidean, 10.0 for dot, 0.01 for cosine
      ALIGNMENT_TEMPERATURE: 10.0
      # This loss is to choose the right caption out of all captions in the batch,
      # And similarly choose the right image. Could be triplet loss instead.
      LOSS: "cross_entropy"
      # Whether to find a region for each word
      ALIGN_WORDS_TO_REGIONS: True
      # Whether to find a word for a region
      # At least one of these two should be True
      ALIGN_REGIONS_TO_WORDS: True
    TRANSFORMER:
      # Whether to perform masked language modeling (randomly mask words from captions
      # and have the model reconstruct them)
      MASKED_LANGUAGE_MODELING: True
      # Whether to do that during validation as well. That is not good if you want to
      # measure image-caption matching scores.
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      # For now this is not implemented, so keep it False and ''
      MASKED_VISUAL_MODELING: False
      MVM_LOSS: ''
      # For Multimedia Matching loss, cross-entropy works just like in the grounding head
      MMM_LOSS: 'cross_entropy'
      # Typical BERT configs as in Huggingface
      BERT_CONFIG:
        num_hidden_layers: 6
        num_attention_heads: 8
        intermediate_size: 768
DATASETS:
  TRAIN: ("coco_captions_train",)
  TEST: ("coco_captions_val",)
  DATASET_CLASS: "COCOCaptionsDataset"
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.0001
  STEPS: (20000, 35000)
  MAX_ITER: 40000
  IMS_PER_BATCH: 64
  TEST_PERIOD: 1000
  CHECKPOINT_PERIOD: 1000
  LOG_PERIOD: 100
  CLIP_GRAD_NORM_AT: 5.0
  # A value of more than one means accumulate gradients for several batches before updating
  GRADIENT_ACCUMULATION_STEPS: 1
  # If true, it calls model.train() before computing validation loss. Needed for some models.
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
TEST:
  DO_EVAL: False
  IMS_PER_BATCH: 64

2021-04-02 00:20:14,473 maskrcnn_benchmark INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  DROP_LAST: False
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 0
DATASETS:
  DATASET_ARGS:
    EMB_DIM: 300
    EMB_KEY: GloVE
    LOAD_EMBEDDINGS: False
    MULTI_LABEL_MODE: False
  DATASET_CLASS: COCOCaptionsDataset
  TEST: ('coco_captions_val',)
  TRAIN: ('coco_captions_train',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.0
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-50-C5
    FREEZE_CONV_BODY_AT: 0
  BACKBONE_PREFIX:
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF:
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE:
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  LANGUAGE_BACKBONE:
    ADD_POSITION_EMBEDDING: False
    EMBEDDING_PATH:
    FREEZE: True
    TYPE: BERT-Base
  LOAD_CLASSIFIER: True
  LOAD_EMB_PRED_FROM_MMSS_HEAD: False
  LOAD_TRAINER_STATE: True
  MASK_ON: False
  META_ARCHITECTURE: MMSS-GCNN
  MMSS_HEAD:
    DEFAULT_HEAD: GroundingHead
    GROUNDING:
      ALIGNMENT: softmax
      ALIGNMENT_TEMPERATURE: 10.0
      ALIGN_REGIONS_TO_WORDS: True
      ALIGN_WORDS_TO_REGIONS: True
      GLOBAL_METRIC: aligned_local
      LOCAL_METRIC: dot
      LOSS: cross_entropy
      NEGATIVE_MINING: random
      TRIPLET_MARGIN: 1.0
    SPATIAL_DROPOUT: 100
    TIE_VL_PROJECTION_WEIGHTS: True
    TRANSFORMER:
      BERT_CONFIG:
        attention_probs_dropout_prob: 0.1
        gradient_checkpointing: False
        hidden_act: gelu
        hidden_dropout_prob: 0.1
        hidden_size: 768
        initializer_range: 0.02
        intermediate_size: 768
        layer_norm_eps: 1e-12
        max_position_embeddings: 512
        num_attention_heads: 8
        num_hidden_layers: 6
        pad_token_id: 0
        type_vocab_size: 2
        vocab_size: 30522
      MASKED_LANGUAGE_MODELING: True
      MASKED_LANGUAGE_MODELING_PROB: 0.15
      MASKED_LANGUAGE_MODELING_PROB_MASK: 0.9
      MASKED_LANGUAGE_MODELING_PROB_NOISE: 0.0
      MASKED_LANGUAGE_MODELING_VALIDATION: False
      MASKED_VISUAL_MODELING: False
      MMM_LOSS: cross_entropy
      MVM_LOSS:
      MVM_LOSS_NUM_NEGATIVE: 128
    TYPES: ('GroundingHead', 'TransformerHead')
  RESNETS:
    BACKBONE_OUT_CHANNELS: 2048
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    EMBEDDING_BASED: False
    EMB_DIM: 300
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    FREEZE_EMB_PRED: False
    FREEZE_FEATURE_EXTRACTOR: False
    LOSS_WEIGHT_BACKGROUND: 1.0
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
    WSDDN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    DONT_TRAIN: False
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 12000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  WEIGHT: /mnt/lustreold/lixiangtai/pretrained/R-50.pkl
OUTPUT_DIR: /mnt/lustre/lixiangtai/runs/vltrain/121
PATHS_CATALOG: /mnt/lustre/lixiangtai/project/ovr-cnn/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 1000
  CLIP_GRAD_NORM_AT: 5.0
  GAMMA: 0.1
  GRADIENT_ACCUMULATION_STEPS: 1
  IMS_PER_BATCH: 64
  LOG_PERIOD: 100
  MAX_ITER: 40000
  MOMENTUM: 0.9
  SKIP_VAL_LOSS: False
  STEPS: (20000, 35000)
  TEST_PERIOD: 1000
  USE_TRAIN_MODE_FOR_VALIDATION_LOSS: False
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 100
  DO_EVAL: False
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 64
2021-04-02 00:20:14,475 maskrcnn_benchmark INFO: Saving config into: /mnt/lustre/lixiangtai/runs/vltrain/121/config.yml
2021-04-02 00:20:27,230 maskrcnn_benchmark.make_optimizer INFO: The following parameters will be trained:
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.stem.conv1.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.downsample.0.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv1.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv2.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.0.conv3.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv1.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv2.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.1.conv3.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv1.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv2.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer1.2.conv3.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.downsample.0.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv1.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv2.weight
2021-04-02 00:20:27,231 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.0.conv3.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv1.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv2.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.1.conv3.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv1.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv2.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.2.conv3.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv1.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv2.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer2.3.conv3.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.downsample.0.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv1.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv2.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.0.conv3.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv1.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv2.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.1.conv3.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv1.weight
2021-04-02 00:20:27,232 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv2.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.2.conv3.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv1.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv2.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.3.conv3.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv1.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv2.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.4.conv3.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv1.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv2.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer3.5.conv3.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.downsample.0.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv1.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv2.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.0.conv3.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv1.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv2.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.1.conv3.weight
2021-04-02 00:20:27,233 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv1.weight
2021-04-02 00:20:27,234 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv2.weight
2021-04-02 00:20:27,234 maskrcnn_benchmark.make_optimizer INFO: backbone.body.layer4.2.conv3.weight
2021-04-02 00:20:27,234 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.GroundingHead.v2l_projection.weight
2021-04-02 00:20:27,234 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.GroundingHead.v2l_projection.bias
2021-04-02 00:20:27,234 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_embeddings.weight
2021-04-02 00:20:27,234 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_embeddings.bias
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_location_embeddings.weight
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.image_location_embeddings.bias
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.LayerNorm.weight
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.visual_emb.LayerNorm.bias
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.weight
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.bias
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.weight
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.bias
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.weight
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.bias
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.weight
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.bias
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.weight
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.bias
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.weight
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.bias
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.dense.weight
2021-04-02 00:20:27,235 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.dense.bias
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.weight
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.bias
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.weight
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.bias
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.weight
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.bias
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.weight
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.bias
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.weight
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.bias
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.weight
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.bias
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.weight
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.bias
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.dense.weight
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.dense.bias
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.weight
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.bias
2021-04-02 00:20:27,236 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.weight
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.bias
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.weight
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.bias
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.weight
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.bias
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.weight
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.bias
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.weight
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.bias
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.weight
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.bias
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.dense.weight
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.dense.bias
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.weight
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.bias
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.weight
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.bias
2021-04-02 00:20:27,237 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.weight
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.bias
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.weight
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.bias
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.weight
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.bias
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.weight
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.bias
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.weight
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.bias
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.dense.weight
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.dense.bias
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.weight
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.bias
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.weight
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.bias
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.weight
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.bias
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.weight
2021-04-02 00:20:27,238 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.bias
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.weight
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.bias
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.weight
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.bias
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.weight
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.bias
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.dense.weight
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.dense.bias
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.weight
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.bias
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.weight
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.bias
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.weight
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.bias
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.weight
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.bias
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.weight
2021-04-02 00:20:27,239 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.bias
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.weight
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.bias
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.weight
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.bias
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.dense.weight
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.dense.bias
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.weight
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.bias
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.pooler.dense.weight
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.pooler.dense.bias
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.bias
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.dense.weight
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.dense.bias
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.weight
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.bias
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.bi_seq_relationship.weight
2021-04-02 00:20:27,240 maskrcnn_benchmark.make_optimizer INFO: mmss_heads.TransformerHead.heads.bi_seq_relationship.bias
2021-04-02 00:20:28,109 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /mnt/lustre/lixiangtai/runs/vltrain/121/model_0014000.pth
2021-04-02 00:20:31,050 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn1.bias                                                                   loaded from backbone.body.layer1.0.bn1.bias                                                                   of shape (64,)
2021-04-02 00:20:31,050 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn1.running_mean                                                           loaded from backbone.body.layer1.0.bn1.running_mean                                                           of shape (64,)
2021-04-02 00:20:31,050 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn1.running_var                                                            loaded from backbone.body.layer1.0.bn1.running_var                                                            of shape (64,)
2021-04-02 00:20:31,050 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn1.weight                                                                 loaded from backbone.body.layer1.0.bn1.weight                                                                 of shape (64,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn2.bias                                                                   loaded from backbone.body.layer1.0.bn2.bias                                                                   of shape (64,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn2.running_mean                                                           loaded from backbone.body.layer1.0.bn2.running_mean                                                           of shape (64,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn2.running_var                                                            loaded from backbone.body.layer1.0.bn2.running_var                                                            of shape (64,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn2.weight                                                                 loaded from backbone.body.layer1.0.bn2.weight                                                                 of shape (64,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn3.bias                                                                   loaded from backbone.body.layer1.0.bn3.bias                                                                   of shape (256,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn3.running_mean                                                           loaded from backbone.body.layer1.0.bn3.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn3.running_var                                                            loaded from backbone.body.layer1.0.bn3.running_var                                                            of shape (256,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.bn3.weight                                                                 loaded from backbone.body.layer1.0.bn3.weight                                                                 of shape (256,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv1.weight                                                               loaded from backbone.body.layer1.0.conv1.weight                                                               of shape (64, 64, 1, 1)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv2.weight                                                               loaded from backbone.body.layer1.0.conv2.weight                                                               of shape (64, 64, 3, 3)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.conv3.weight                                                               loaded from backbone.body.layer1.0.conv3.weight                                                               of shape (256, 64, 1, 1)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.0.weight                                                        loaded from backbone.body.layer1.0.downsample.0.weight                                                        of shape (256, 64, 1, 1)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.1.bias                                                          loaded from backbone.body.layer1.0.downsample.1.bias                                                          of shape (256,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.1.running_mean                                                  loaded from backbone.body.layer1.0.downsample.1.running_mean                                                  of shape (256,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.1.running_var                                                   loaded from backbone.body.layer1.0.downsample.1.running_var                                                   of shape (256,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.0.downsample.1.weight                                                        loaded from backbone.body.layer1.0.downsample.1.weight                                                        of shape (256,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn1.bias                                                                   loaded from backbone.body.layer1.1.bn1.bias                                                                   of shape (64,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn1.running_mean                                                           loaded from backbone.body.layer1.1.bn1.running_mean                                                           of shape (64,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn1.running_var                                                            loaded from backbone.body.layer1.1.bn1.running_var                                                            of shape (64,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn1.weight                                                                 loaded from backbone.body.layer1.1.bn1.weight                                                                 of shape (64,)
2021-04-02 00:20:31,051 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn2.bias                                                                   loaded from backbone.body.layer1.1.bn2.bias                                                                   of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn2.running_mean                                                           loaded from backbone.body.layer1.1.bn2.running_mean                                                           of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn2.running_var                                                            loaded from backbone.body.layer1.1.bn2.running_var                                                            of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn2.weight                                                                 loaded from backbone.body.layer1.1.bn2.weight                                                                 of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn3.bias                                                                   loaded from backbone.body.layer1.1.bn3.bias                                                                   of shape (256,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn3.running_mean                                                           loaded from backbone.body.layer1.1.bn3.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn3.running_var                                                            loaded from backbone.body.layer1.1.bn3.running_var                                                            of shape (256,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.bn3.weight                                                                 loaded from backbone.body.layer1.1.bn3.weight                                                                 of shape (256,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv1.weight                                                               loaded from backbone.body.layer1.1.conv1.weight                                                               of shape (64, 256, 1, 1)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv2.weight                                                               loaded from backbone.body.layer1.1.conv2.weight                                                               of shape (64, 64, 3, 3)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.1.conv3.weight                                                               loaded from backbone.body.layer1.1.conv3.weight                                                               of shape (256, 64, 1, 1)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn1.bias                                                                   loaded from backbone.body.layer1.2.bn1.bias                                                                   of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn1.running_mean                                                           loaded from backbone.body.layer1.2.bn1.running_mean                                                           of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn1.running_var                                                            loaded from backbone.body.layer1.2.bn1.running_var                                                            of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn1.weight                                                                 loaded from backbone.body.layer1.2.bn1.weight                                                                 of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn2.bias                                                                   loaded from backbone.body.layer1.2.bn2.bias                                                                   of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn2.running_mean                                                           loaded from backbone.body.layer1.2.bn2.running_mean                                                           of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn2.running_var                                                            loaded from backbone.body.layer1.2.bn2.running_var                                                            of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn2.weight                                                                 loaded from backbone.body.layer1.2.bn2.weight                                                                 of shape (64,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn3.bias                                                                   loaded from backbone.body.layer1.2.bn3.bias                                                                   of shape (256,)
2021-04-02 00:20:31,052 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn3.running_mean                                                           loaded from backbone.body.layer1.2.bn3.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn3.running_var                                                            loaded from backbone.body.layer1.2.bn3.running_var                                                            of shape (256,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.bn3.weight                                                                 loaded from backbone.body.layer1.2.bn3.weight                                                                 of shape (256,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv1.weight                                                               loaded from backbone.body.layer1.2.conv1.weight                                                               of shape (64, 256, 1, 1)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv2.weight                                                               loaded from backbone.body.layer1.2.conv2.weight                                                               of shape (64, 64, 3, 3)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer1.2.conv3.weight                                                               loaded from backbone.body.layer1.2.conv3.weight                                                               of shape (256, 64, 1, 1)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn1.bias                                                                   loaded from backbone.body.layer2.0.bn1.bias                                                                   of shape (128,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn1.running_mean                                                           loaded from backbone.body.layer2.0.bn1.running_mean                                                           of shape (128,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn1.running_var                                                            loaded from backbone.body.layer2.0.bn1.running_var                                                            of shape (128,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn1.weight                                                                 loaded from backbone.body.layer2.0.bn1.weight                                                                 of shape (128,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn2.bias                                                                   loaded from backbone.body.layer2.0.bn2.bias                                                                   of shape (128,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn2.running_mean                                                           loaded from backbone.body.layer2.0.bn2.running_mean                                                           of shape (128,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn2.running_var                                                            loaded from backbone.body.layer2.0.bn2.running_var                                                            of shape (128,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn2.weight                                                                 loaded from backbone.body.layer2.0.bn2.weight                                                                 of shape (128,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn3.bias                                                                   loaded from backbone.body.layer2.0.bn3.bias                                                                   of shape (512,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn3.running_mean                                                           loaded from backbone.body.layer2.0.bn3.running_mean                                                           of shape (512,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn3.running_var                                                            loaded from backbone.body.layer2.0.bn3.running_var                                                            of shape (512,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.bn3.weight                                                                 loaded from backbone.body.layer2.0.bn3.weight                                                                 of shape (512,)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv1.weight                                                               loaded from backbone.body.layer2.0.conv1.weight                                                               of shape (128, 256, 1, 1)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv2.weight                                                               loaded from backbone.body.layer2.0.conv2.weight                                                               of shape (128, 128, 3, 3)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.conv3.weight                                                               loaded from backbone.body.layer2.0.conv3.weight                                                               of shape (512, 128, 1, 1)
2021-04-02 00:20:31,053 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.0.weight                                                        loaded from backbone.body.layer2.0.downsample.0.weight                                                        of shape (512, 256, 1, 1)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.1.bias                                                          loaded from backbone.body.layer2.0.downsample.1.bias                                                          of shape (512,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.1.running_mean                                                  loaded from backbone.body.layer2.0.downsample.1.running_mean                                                  of shape (512,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.1.running_var                                                   loaded from backbone.body.layer2.0.downsample.1.running_var                                                   of shape (512,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.0.downsample.1.weight                                                        loaded from backbone.body.layer2.0.downsample.1.weight                                                        of shape (512,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn1.bias                                                                   loaded from backbone.body.layer2.1.bn1.bias                                                                   of shape (128,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn1.running_mean                                                           loaded from backbone.body.layer2.1.bn1.running_mean                                                           of shape (128,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn1.running_var                                                            loaded from backbone.body.layer2.1.bn1.running_var                                                            of shape (128,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn1.weight                                                                 loaded from backbone.body.layer2.1.bn1.weight                                                                 of shape (128,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn2.bias                                                                   loaded from backbone.body.layer2.1.bn2.bias                                                                   of shape (128,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn2.running_mean                                                           loaded from backbone.body.layer2.1.bn2.running_mean                                                           of shape (128,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn2.running_var                                                            loaded from backbone.body.layer2.1.bn2.running_var                                                            of shape (128,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn2.weight                                                                 loaded from backbone.body.layer2.1.bn2.weight                                                                 of shape (128,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn3.bias                                                                   loaded from backbone.body.layer2.1.bn3.bias                                                                   of shape (512,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn3.running_mean                                                           loaded from backbone.body.layer2.1.bn3.running_mean                                                           of shape (512,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn3.running_var                                                            loaded from backbone.body.layer2.1.bn3.running_var                                                            of shape (512,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.bn3.weight                                                                 loaded from backbone.body.layer2.1.bn3.weight                                                                 of shape (512,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv1.weight                                                               loaded from backbone.body.layer2.1.conv1.weight                                                               of shape (128, 512, 1, 1)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv2.weight                                                               loaded from backbone.body.layer2.1.conv2.weight                                                               of shape (128, 128, 3, 3)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.1.conv3.weight                                                               loaded from backbone.body.layer2.1.conv3.weight                                                               of shape (512, 128, 1, 1)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn1.bias                                                                   loaded from backbone.body.layer2.2.bn1.bias                                                                   of shape (128,)
2021-04-02 00:20:31,054 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn1.running_mean                                                           loaded from backbone.body.layer2.2.bn1.running_mean                                                           of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn1.running_var                                                            loaded from backbone.body.layer2.2.bn1.running_var                                                            of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn1.weight                                                                 loaded from backbone.body.layer2.2.bn1.weight                                                                 of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn2.bias                                                                   loaded from backbone.body.layer2.2.bn2.bias                                                                   of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn2.running_mean                                                           loaded from backbone.body.layer2.2.bn2.running_mean                                                           of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn2.running_var                                                            loaded from backbone.body.layer2.2.bn2.running_var                                                            of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn2.weight                                                                 loaded from backbone.body.layer2.2.bn2.weight                                                                 of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn3.bias                                                                   loaded from backbone.body.layer2.2.bn3.bias                                                                   of shape (512,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn3.running_mean                                                           loaded from backbone.body.layer2.2.bn3.running_mean                                                           of shape (512,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn3.running_var                                                            loaded from backbone.body.layer2.2.bn3.running_var                                                            of shape (512,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.bn3.weight                                                                 loaded from backbone.body.layer2.2.bn3.weight                                                                 of shape (512,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv1.weight                                                               loaded from backbone.body.layer2.2.conv1.weight                                                               of shape (128, 512, 1, 1)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv2.weight                                                               loaded from backbone.body.layer2.2.conv2.weight                                                               of shape (128, 128, 3, 3)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.2.conv3.weight                                                               loaded from backbone.body.layer2.2.conv3.weight                                                               of shape (512, 128, 1, 1)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn1.bias                                                                   loaded from backbone.body.layer2.3.bn1.bias                                                                   of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn1.running_mean                                                           loaded from backbone.body.layer2.3.bn1.running_mean                                                           of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn1.running_var                                                            loaded from backbone.body.layer2.3.bn1.running_var                                                            of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn1.weight                                                                 loaded from backbone.body.layer2.3.bn1.weight                                                                 of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn2.bias                                                                   loaded from backbone.body.layer2.3.bn2.bias                                                                   of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn2.running_mean                                                           loaded from backbone.body.layer2.3.bn2.running_mean                                                           of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn2.running_var                                                            loaded from backbone.body.layer2.3.bn2.running_var                                                            of shape (128,)
2021-04-02 00:20:31,055 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn2.weight                                                                 loaded from backbone.body.layer2.3.bn2.weight                                                                 of shape (128,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn3.bias                                                                   loaded from backbone.body.layer2.3.bn3.bias                                                                   of shape (512,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn3.running_mean                                                           loaded from backbone.body.layer2.3.bn3.running_mean                                                           of shape (512,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn3.running_var                                                            loaded from backbone.body.layer2.3.bn3.running_var                                                            of shape (512,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.bn3.weight                                                                 loaded from backbone.body.layer2.3.bn3.weight                                                                 of shape (512,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv1.weight                                                               loaded from backbone.body.layer2.3.conv1.weight                                                               of shape (128, 512, 1, 1)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv2.weight                                                               loaded from backbone.body.layer2.3.conv2.weight                                                               of shape (128, 128, 3, 3)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer2.3.conv3.weight                                                               loaded from backbone.body.layer2.3.conv3.weight                                                               of shape (512, 128, 1, 1)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn1.bias                                                                   loaded from backbone.body.layer3.0.bn1.bias                                                                   of shape (256,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn1.running_mean                                                           loaded from backbone.body.layer3.0.bn1.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn1.running_var                                                            loaded from backbone.body.layer3.0.bn1.running_var                                                            of shape (256,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn1.weight                                                                 loaded from backbone.body.layer3.0.bn1.weight                                                                 of shape (256,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn2.bias                                                                   loaded from backbone.body.layer3.0.bn2.bias                                                                   of shape (256,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn2.running_mean                                                           loaded from backbone.body.layer3.0.bn2.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn2.running_var                                                            loaded from backbone.body.layer3.0.bn2.running_var                                                            of shape (256,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn2.weight                                                                 loaded from backbone.body.layer3.0.bn2.weight                                                                 of shape (256,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn3.bias                                                                   loaded from backbone.body.layer3.0.bn3.bias                                                                   of shape (1024,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn3.running_mean                                                           loaded from backbone.body.layer3.0.bn3.running_mean                                                           of shape (1024,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn3.running_var                                                            loaded from backbone.body.layer3.0.bn3.running_var                                                            of shape (1024,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.bn3.weight                                                                 loaded from backbone.body.layer3.0.bn3.weight                                                                 of shape (1024,)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv1.weight                                                               loaded from backbone.body.layer3.0.conv1.weight                                                               of shape (256, 512, 1, 1)
2021-04-02 00:20:31,056 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv2.weight                                                               loaded from backbone.body.layer3.0.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.conv3.weight                                                               loaded from backbone.body.layer3.0.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.0.weight                                                        loaded from backbone.body.layer3.0.downsample.0.weight                                                        of shape (1024, 512, 1, 1)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.1.bias                                                          loaded from backbone.body.layer3.0.downsample.1.bias                                                          of shape (1024,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.1.running_mean                                                  loaded from backbone.body.layer3.0.downsample.1.running_mean                                                  of shape (1024,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.1.running_var                                                   loaded from backbone.body.layer3.0.downsample.1.running_var                                                   of shape (1024,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.0.downsample.1.weight                                                        loaded from backbone.body.layer3.0.downsample.1.weight                                                        of shape (1024,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn1.bias                                                                   loaded from backbone.body.layer3.1.bn1.bias                                                                   of shape (256,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn1.running_mean                                                           loaded from backbone.body.layer3.1.bn1.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn1.running_var                                                            loaded from backbone.body.layer3.1.bn1.running_var                                                            of shape (256,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn1.weight                                                                 loaded from backbone.body.layer3.1.bn1.weight                                                                 of shape (256,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn2.bias                                                                   loaded from backbone.body.layer3.1.bn2.bias                                                                   of shape (256,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn2.running_mean                                                           loaded from backbone.body.layer3.1.bn2.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn2.running_var                                                            loaded from backbone.body.layer3.1.bn2.running_var                                                            of shape (256,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn2.weight                                                                 loaded from backbone.body.layer3.1.bn2.weight                                                                 of shape (256,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn3.bias                                                                   loaded from backbone.body.layer3.1.bn3.bias                                                                   of shape (1024,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn3.running_mean                                                           loaded from backbone.body.layer3.1.bn3.running_mean                                                           of shape (1024,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn3.running_var                                                            loaded from backbone.body.layer3.1.bn3.running_var                                                            of shape (1024,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.bn3.weight                                                                 loaded from backbone.body.layer3.1.bn3.weight                                                                 of shape (1024,)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv1.weight                                                               loaded from backbone.body.layer3.1.conv1.weight                                                               of shape (256, 1024, 1, 1)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv2.weight                                                               loaded from backbone.body.layer3.1.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-02 00:20:31,057 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.1.conv3.weight                                                               loaded from backbone.body.layer3.1.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn1.bias                                                                   loaded from backbone.body.layer3.2.bn1.bias                                                                   of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn1.running_mean                                                           loaded from backbone.body.layer3.2.bn1.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn1.running_var                                                            loaded from backbone.body.layer3.2.bn1.running_var                                                            of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn1.weight                                                                 loaded from backbone.body.layer3.2.bn1.weight                                                                 of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn2.bias                                                                   loaded from backbone.body.layer3.2.bn2.bias                                                                   of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn2.running_mean                                                           loaded from backbone.body.layer3.2.bn2.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn2.running_var                                                            loaded from backbone.body.layer3.2.bn2.running_var                                                            of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn2.weight                                                                 loaded from backbone.body.layer3.2.bn2.weight                                                                 of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn3.bias                                                                   loaded from backbone.body.layer3.2.bn3.bias                                                                   of shape (1024,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn3.running_mean                                                           loaded from backbone.body.layer3.2.bn3.running_mean                                                           of shape (1024,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn3.running_var                                                            loaded from backbone.body.layer3.2.bn3.running_var                                                            of shape (1024,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.bn3.weight                                                                 loaded from backbone.body.layer3.2.bn3.weight                                                                 of shape (1024,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv1.weight                                                               loaded from backbone.body.layer3.2.conv1.weight                                                               of shape (256, 1024, 1, 1)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv2.weight                                                               loaded from backbone.body.layer3.2.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.2.conv3.weight                                                               loaded from backbone.body.layer3.2.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn1.bias                                                                   loaded from backbone.body.layer3.3.bn1.bias                                                                   of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn1.running_mean                                                           loaded from backbone.body.layer3.3.bn1.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn1.running_var                                                            loaded from backbone.body.layer3.3.bn1.running_var                                                            of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn1.weight                                                                 loaded from backbone.body.layer3.3.bn1.weight                                                                 of shape (256,)
2021-04-02 00:20:31,058 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn2.bias                                                                   loaded from backbone.body.layer3.3.bn2.bias                                                                   of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn2.running_mean                                                           loaded from backbone.body.layer3.3.bn2.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn2.running_var                                                            loaded from backbone.body.layer3.3.bn2.running_var                                                            of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn2.weight                                                                 loaded from backbone.body.layer3.3.bn2.weight                                                                 of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn3.bias                                                                   loaded from backbone.body.layer3.3.bn3.bias                                                                   of shape (1024,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn3.running_mean                                                           loaded from backbone.body.layer3.3.bn3.running_mean                                                           of shape (1024,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn3.running_var                                                            loaded from backbone.body.layer3.3.bn3.running_var                                                            of shape (1024,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.bn3.weight                                                                 loaded from backbone.body.layer3.3.bn3.weight                                                                 of shape (1024,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv1.weight                                                               loaded from backbone.body.layer3.3.conv1.weight                                                               of shape (256, 1024, 1, 1)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv2.weight                                                               loaded from backbone.body.layer3.3.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.3.conv3.weight                                                               loaded from backbone.body.layer3.3.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn1.bias                                                                   loaded from backbone.body.layer3.4.bn1.bias                                                                   of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn1.running_mean                                                           loaded from backbone.body.layer3.4.bn1.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn1.running_var                                                            loaded from backbone.body.layer3.4.bn1.running_var                                                            of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn1.weight                                                                 loaded from backbone.body.layer3.4.bn1.weight                                                                 of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn2.bias                                                                   loaded from backbone.body.layer3.4.bn2.bias                                                                   of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn2.running_mean                                                           loaded from backbone.body.layer3.4.bn2.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn2.running_var                                                            loaded from backbone.body.layer3.4.bn2.running_var                                                            of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn2.weight                                                                 loaded from backbone.body.layer3.4.bn2.weight                                                                 of shape (256,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn3.bias                                                                   loaded from backbone.body.layer3.4.bn3.bias                                                                   of shape (1024,)
2021-04-02 00:20:31,059 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn3.running_mean                                                           loaded from backbone.body.layer3.4.bn3.running_mean                                                           of shape (1024,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn3.running_var                                                            loaded from backbone.body.layer3.4.bn3.running_var                                                            of shape (1024,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.bn3.weight                                                                 loaded from backbone.body.layer3.4.bn3.weight                                                                 of shape (1024,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv1.weight                                                               loaded from backbone.body.layer3.4.conv1.weight                                                               of shape (256, 1024, 1, 1)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv2.weight                                                               loaded from backbone.body.layer3.4.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.4.conv3.weight                                                               loaded from backbone.body.layer3.4.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn1.bias                                                                   loaded from backbone.body.layer3.5.bn1.bias                                                                   of shape (256,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn1.running_mean                                                           loaded from backbone.body.layer3.5.bn1.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn1.running_var                                                            loaded from backbone.body.layer3.5.bn1.running_var                                                            of shape (256,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn1.weight                                                                 loaded from backbone.body.layer3.5.bn1.weight                                                                 of shape (256,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn2.bias                                                                   loaded from backbone.body.layer3.5.bn2.bias                                                                   of shape (256,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn2.running_mean                                                           loaded from backbone.body.layer3.5.bn2.running_mean                                                           of shape (256,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn2.running_var                                                            loaded from backbone.body.layer3.5.bn2.running_var                                                            of shape (256,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn2.weight                                                                 loaded from backbone.body.layer3.5.bn2.weight                                                                 of shape (256,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn3.bias                                                                   loaded from backbone.body.layer3.5.bn3.bias                                                                   of shape (1024,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn3.running_mean                                                           loaded from backbone.body.layer3.5.bn3.running_mean                                                           of shape (1024,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn3.running_var                                                            loaded from backbone.body.layer3.5.bn3.running_var                                                            of shape (1024,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.bn3.weight                                                                 loaded from backbone.body.layer3.5.bn3.weight                                                                 of shape (1024,)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv1.weight                                                               loaded from backbone.body.layer3.5.conv1.weight                                                               of shape (256, 1024, 1, 1)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv2.weight                                                               loaded from backbone.body.layer3.5.conv2.weight                                                               of shape (256, 256, 3, 3)
2021-04-02 00:20:31,060 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer3.5.conv3.weight                                                               loaded from backbone.body.layer3.5.conv3.weight                                                               of shape (1024, 256, 1, 1)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn1.bias                                                                   loaded from backbone.body.layer4.0.bn1.bias                                                                   of shape (512,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn1.running_mean                                                           loaded from backbone.body.layer4.0.bn1.running_mean                                                           of shape (512,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn1.running_var                                                            loaded from backbone.body.layer4.0.bn1.running_var                                                            of shape (512,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn1.weight                                                                 loaded from backbone.body.layer4.0.bn1.weight                                                                 of shape (512,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn2.bias                                                                   loaded from backbone.body.layer4.0.bn2.bias                                                                   of shape (512,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn2.running_mean                                                           loaded from backbone.body.layer4.0.bn2.running_mean                                                           of shape (512,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn2.running_var                                                            loaded from backbone.body.layer4.0.bn2.running_var                                                            of shape (512,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn2.weight                                                                 loaded from backbone.body.layer4.0.bn2.weight                                                                 of shape (512,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn3.bias                                                                   loaded from backbone.body.layer4.0.bn3.bias                                                                   of shape (2048,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn3.running_mean                                                           loaded from backbone.body.layer4.0.bn3.running_mean                                                           of shape (2048,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn3.running_var                                                            loaded from backbone.body.layer4.0.bn3.running_var                                                            of shape (2048,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.bn3.weight                                                                 loaded from backbone.body.layer4.0.bn3.weight                                                                 of shape (2048,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv1.weight                                                               loaded from backbone.body.layer4.0.conv1.weight                                                               of shape (512, 1024, 1, 1)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv2.weight                                                               loaded from backbone.body.layer4.0.conv2.weight                                                               of shape (512, 512, 3, 3)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.conv3.weight                                                               loaded from backbone.body.layer4.0.conv3.weight                                                               of shape (2048, 512, 1, 1)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.0.weight                                                        loaded from backbone.body.layer4.0.downsample.0.weight                                                        of shape (2048, 1024, 1, 1)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.1.bias                                                          loaded from backbone.body.layer4.0.downsample.1.bias                                                          of shape (2048,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.1.running_mean                                                  loaded from backbone.body.layer4.0.downsample.1.running_mean                                                  of shape (2048,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.1.running_var                                                   loaded from backbone.body.layer4.0.downsample.1.running_var                                                   of shape (2048,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.0.downsample.1.weight                                                        loaded from backbone.body.layer4.0.downsample.1.weight                                                        of shape (2048,)
2021-04-02 00:20:31,061 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn1.bias                                                                   loaded from backbone.body.layer4.1.bn1.bias                                                                   of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn1.running_mean                                                           loaded from backbone.body.layer4.1.bn1.running_mean                                                           of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn1.running_var                                                            loaded from backbone.body.layer4.1.bn1.running_var                                                            of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn1.weight                                                                 loaded from backbone.body.layer4.1.bn1.weight                                                                 of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn2.bias                                                                   loaded from backbone.body.layer4.1.bn2.bias                                                                   of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn2.running_mean                                                           loaded from backbone.body.layer4.1.bn2.running_mean                                                           of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn2.running_var                                                            loaded from backbone.body.layer4.1.bn2.running_var                                                            of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn2.weight                                                                 loaded from backbone.body.layer4.1.bn2.weight                                                                 of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn3.bias                                                                   loaded from backbone.body.layer4.1.bn3.bias                                                                   of shape (2048,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn3.running_mean                                                           loaded from backbone.body.layer4.1.bn3.running_mean                                                           of shape (2048,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn3.running_var                                                            loaded from backbone.body.layer4.1.bn3.running_var                                                            of shape (2048,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.bn3.weight                                                                 loaded from backbone.body.layer4.1.bn3.weight                                                                 of shape (2048,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv1.weight                                                               loaded from backbone.body.layer4.1.conv1.weight                                                               of shape (512, 2048, 1, 1)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv2.weight                                                               loaded from backbone.body.layer4.1.conv2.weight                                                               of shape (512, 512, 3, 3)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.1.conv3.weight                                                               loaded from backbone.body.layer4.1.conv3.weight                                                               of shape (2048, 512, 1, 1)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn1.bias                                                                   loaded from backbone.body.layer4.2.bn1.bias                                                                   of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn1.running_mean                                                           loaded from backbone.body.layer4.2.bn1.running_mean                                                           of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn1.running_var                                                            loaded from backbone.body.layer4.2.bn1.running_var                                                            of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn1.weight                                                                 loaded from backbone.body.layer4.2.bn1.weight                                                                 of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn2.bias                                                                   loaded from backbone.body.layer4.2.bn2.bias                                                                   of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn2.running_mean                                                           loaded from backbone.body.layer4.2.bn2.running_mean                                                           of shape (512,)
2021-04-02 00:20:31,062 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn2.running_var                                                            loaded from backbone.body.layer4.2.bn2.running_var                                                            of shape (512,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn2.weight                                                                 loaded from backbone.body.layer4.2.bn2.weight                                                                 of shape (512,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn3.bias                                                                   loaded from backbone.body.layer4.2.bn3.bias                                                                   of shape (2048,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn3.running_mean                                                           loaded from backbone.body.layer4.2.bn3.running_mean                                                           of shape (2048,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn3.running_var                                                            loaded from backbone.body.layer4.2.bn3.running_var                                                            of shape (2048,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.bn3.weight                                                                 loaded from backbone.body.layer4.2.bn3.weight                                                                 of shape (2048,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv1.weight                                                               loaded from backbone.body.layer4.2.conv1.weight                                                               of shape (512, 2048, 1, 1)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv2.weight                                                               loaded from backbone.body.layer4.2.conv2.weight                                                               of shape (512, 512, 3, 3)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.layer4.2.conv3.weight                                                               loaded from backbone.body.layer4.2.conv3.weight                                                               of shape (2048, 512, 1, 1)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.bn1.bias                                                                       loaded from backbone.body.stem.bn1.bias                                                                       of shape (64,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.bn1.running_mean                                                               loaded from backbone.body.stem.bn1.running_mean                                                               of shape (64,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.bn1.running_var                                                                loaded from backbone.body.stem.bn1.running_var                                                                of shape (64,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.bn1.weight                                                                     loaded from backbone.body.stem.bn1.weight                                                                     of shape (64,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.backbone.body.stem.conv1.weight                                                                   loaded from backbone.body.stem.conv1.weight                                                                   of shape (64, 3, 7, 7)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.embeddings.LayerNorm.bias                                       loaded from language_backbone.body.bert_model.embeddings.LayerNorm.bias                                       of shape (768,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.embeddings.LayerNorm.weight                                     loaded from language_backbone.body.bert_model.embeddings.LayerNorm.weight                                     of shape (768,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.embeddings.position_embeddings.weight                           loaded from language_backbone.body.bert_model.embeddings.position_embeddings.weight                           of shape (512, 768)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.embeddings.token_type_embeddings.weight                         loaded from language_backbone.body.bert_model.embeddings.token_type_embeddings.weight                         of shape (2, 768)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.embeddings.word_embeddings.weight                               loaded from language_backbone.body.bert_model.embeddings.word_embeddings.weight                               of shape (30522, 768)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.0.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.0.attention.output.LayerNorm.weight               of shape (768,)
2021-04-02 00:20:31,063 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.0.attention.output.dense.bias                     of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.0.attention.output.dense.weight                   of shape (768, 768)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.key.bias                         of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.key.weight                       of shape (768, 768)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.query.bias                       of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.query.weight                     of shape (768, 768)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.value.bias                       of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.0.attention.self.value.weight                     of shape (768, 768)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.0.intermediate.dense.bias                         of shape (3072,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.0.intermediate.dense.weight                       of shape (3072, 768)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.0.output.LayerNorm.bias                           of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.0.output.LayerNorm.weight                         of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.0.output.dense.bias                               of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.0.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.0.output.dense.weight                             of shape (768, 3072)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.1.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.1.attention.output.LayerNorm.weight               of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.1.attention.output.dense.bias                     of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.1.attention.output.dense.weight                   of shape (768, 768)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.key.bias                         of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.key.weight                       of shape (768, 768)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.query.bias                       of shape (768,)
2021-04-02 00:20:31,064 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.query.weight                     of shape (768, 768)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.value.bias                       of shape (768,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.1.attention.self.value.weight                     of shape (768, 768)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.1.intermediate.dense.bias                         of shape (3072,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.1.intermediate.dense.weight                       of shape (3072, 768)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.1.output.LayerNorm.bias                           of shape (768,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.1.output.LayerNorm.weight                         of shape (768,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.1.output.dense.bias                               of shape (768,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.1.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.1.output.dense.weight                             of shape (768, 3072)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.output.LayerNorm.bias                loaded from language_backbone.body.bert_model.encoder.layer.10.attention.output.LayerNorm.bias                of shape (768,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.output.LayerNorm.weight              loaded from language_backbone.body.bert_model.encoder.layer.10.attention.output.LayerNorm.weight              of shape (768,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.output.dense.bias                    loaded from language_backbone.body.bert_model.encoder.layer.10.attention.output.dense.bias                    of shape (768,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.output.dense.weight                  loaded from language_backbone.body.bert_model.encoder.layer.10.attention.output.dense.weight                  of shape (768, 768)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.key.bias                        loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.key.bias                        of shape (768,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.key.weight                      loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.key.weight                      of shape (768, 768)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.query.bias                      loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.query.bias                      of shape (768,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.query.weight                    loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.query.weight                    of shape (768, 768)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.value.bias                      loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.value.bias                      of shape (768,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.attention.self.value.weight                    loaded from language_backbone.body.bert_model.encoder.layer.10.attention.self.value.weight                    of shape (768, 768)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.intermediate.dense.bias                        loaded from language_backbone.body.bert_model.encoder.layer.10.intermediate.dense.bias                        of shape (3072,)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.intermediate.dense.weight                      loaded from language_backbone.body.bert_model.encoder.layer.10.intermediate.dense.weight                      of shape (3072, 768)
2021-04-02 00:20:31,065 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.output.LayerNorm.bias                          loaded from language_backbone.body.bert_model.encoder.layer.10.output.LayerNorm.bias                          of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.output.LayerNorm.weight                        loaded from language_backbone.body.bert_model.encoder.layer.10.output.LayerNorm.weight                        of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.output.dense.bias                              loaded from language_backbone.body.bert_model.encoder.layer.10.output.dense.bias                              of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.10.output.dense.weight                            loaded from language_backbone.body.bert_model.encoder.layer.10.output.dense.weight                            of shape (768, 3072)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.output.LayerNorm.bias                loaded from language_backbone.body.bert_model.encoder.layer.11.attention.output.LayerNorm.bias                of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.output.LayerNorm.weight              loaded from language_backbone.body.bert_model.encoder.layer.11.attention.output.LayerNorm.weight              of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.output.dense.bias                    loaded from language_backbone.body.bert_model.encoder.layer.11.attention.output.dense.bias                    of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.output.dense.weight                  loaded from language_backbone.body.bert_model.encoder.layer.11.attention.output.dense.weight                  of shape (768, 768)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.key.bias                        loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.key.bias                        of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.key.weight                      loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.key.weight                      of shape (768, 768)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.query.bias                      loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.query.bias                      of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.query.weight                    loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.query.weight                    of shape (768, 768)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.value.bias                      loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.value.bias                      of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.attention.self.value.weight                    loaded from language_backbone.body.bert_model.encoder.layer.11.attention.self.value.weight                    of shape (768, 768)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.intermediate.dense.bias                        loaded from language_backbone.body.bert_model.encoder.layer.11.intermediate.dense.bias                        of shape (3072,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.intermediate.dense.weight                      loaded from language_backbone.body.bert_model.encoder.layer.11.intermediate.dense.weight                      of shape (3072, 768)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.output.LayerNorm.bias                          loaded from language_backbone.body.bert_model.encoder.layer.11.output.LayerNorm.bias                          of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.output.LayerNorm.weight                        loaded from language_backbone.body.bert_model.encoder.layer.11.output.LayerNorm.weight                        of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.output.dense.bias                              loaded from language_backbone.body.bert_model.encoder.layer.11.output.dense.bias                              of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.11.output.dense.weight                            loaded from language_backbone.body.bert_model.encoder.layer.11.output.dense.weight                            of shape (768, 3072)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.2.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-02 00:20:31,066 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.2.attention.output.LayerNorm.weight               of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.2.attention.output.dense.bias                     of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.2.attention.output.dense.weight                   of shape (768, 768)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.key.bias                         of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.key.weight                       of shape (768, 768)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.query.bias                       of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.query.weight                     of shape (768, 768)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.value.bias                       of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.2.attention.self.value.weight                     of shape (768, 768)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.2.intermediate.dense.bias                         of shape (3072,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.2.intermediate.dense.weight                       of shape (3072, 768)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.2.output.LayerNorm.bias                           of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.2.output.LayerNorm.weight                         of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.2.output.dense.bias                               of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.2.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.2.output.dense.weight                             of shape (768, 3072)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.3.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.3.attention.output.LayerNorm.weight               of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.3.attention.output.dense.bias                     of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.3.attention.output.dense.weight                   of shape (768, 768)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.key.bias                         of shape (768,)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.key.weight                       of shape (768, 768)
2021-04-02 00:20:31,067 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.query.bias                       of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.query.weight                     of shape (768, 768)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.value.bias                       of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.3.attention.self.value.weight                     of shape (768, 768)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.3.intermediate.dense.bias                         of shape (3072,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.3.intermediate.dense.weight                       of shape (3072, 768)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.3.output.LayerNorm.bias                           of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.3.output.LayerNorm.weight                         of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.3.output.dense.bias                               of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.3.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.3.output.dense.weight                             of shape (768, 3072)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.4.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.4.attention.output.LayerNorm.weight               of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.4.attention.output.dense.bias                     of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.4.attention.output.dense.weight                   of shape (768, 768)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.key.bias                         of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.key.weight                       of shape (768, 768)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.query.bias                       of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.query.weight                     of shape (768, 768)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.value.bias                       of shape (768,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.4.attention.self.value.weight                     of shape (768, 768)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.4.intermediate.dense.bias                         of shape (3072,)
2021-04-02 00:20:31,068 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.4.intermediate.dense.weight                       of shape (3072, 768)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.4.output.LayerNorm.bias                           of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.4.output.LayerNorm.weight                         of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.4.output.dense.bias                               of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.4.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.4.output.dense.weight                             of shape (768, 3072)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.5.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.5.attention.output.LayerNorm.weight               of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.5.attention.output.dense.bias                     of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.5.attention.output.dense.weight                   of shape (768, 768)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.key.bias                         of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.key.weight                       of shape (768, 768)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.query.bias                       of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.query.weight                     of shape (768, 768)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.value.bias                       of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.5.attention.self.value.weight                     of shape (768, 768)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.5.intermediate.dense.bias                         of shape (3072,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.5.intermediate.dense.weight                       of shape (3072, 768)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.5.output.LayerNorm.bias                           of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.5.output.LayerNorm.weight                         of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.5.output.dense.bias                               of shape (768,)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.5.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.5.output.dense.weight                             of shape (768, 3072)
2021-04-02 00:20:31,069 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.6.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.6.attention.output.LayerNorm.weight               of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.6.attention.output.dense.bias                     of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.6.attention.output.dense.weight                   of shape (768, 768)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.key.bias                         of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.key.weight                       of shape (768, 768)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.query.bias                       of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.query.weight                     of shape (768, 768)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.value.bias                       of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.6.attention.self.value.weight                     of shape (768, 768)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.6.intermediate.dense.bias                         of shape (3072,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.6.intermediate.dense.weight                       of shape (3072, 768)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.6.output.LayerNorm.bias                           of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.6.output.LayerNorm.weight                         of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.6.output.dense.bias                               of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.6.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.6.output.dense.weight                             of shape (768, 3072)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.7.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.7.attention.output.LayerNorm.weight               of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.7.attention.output.dense.bias                     of shape (768,)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.7.attention.output.dense.weight                   of shape (768, 768)
2021-04-02 00:20:31,070 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.key.bias                         of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.key.weight                       of shape (768, 768)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.query.bias                       of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.query.weight                     of shape (768, 768)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.value.bias                       of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.7.attention.self.value.weight                     of shape (768, 768)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.7.intermediate.dense.bias                         of shape (3072,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.7.intermediate.dense.weight                       of shape (3072, 768)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.7.output.LayerNorm.bias                           of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.7.output.LayerNorm.weight                         of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.7.output.dense.bias                               of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.7.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.7.output.dense.weight                             of shape (768, 3072)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.8.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.8.attention.output.LayerNorm.weight               of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.8.attention.output.dense.bias                     of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.8.attention.output.dense.weight                   of shape (768, 768)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.key.bias                         of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.key.weight                       of shape (768, 768)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.query.bias                       of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.query.weight                     of shape (768, 768)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.value.bias                       of shape (768,)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.8.attention.self.value.weight                     of shape (768, 768)
2021-04-02 00:20:31,071 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.8.intermediate.dense.bias                         of shape (3072,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.8.intermediate.dense.weight                       of shape (3072, 768)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.8.output.LayerNorm.bias                           of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.8.output.LayerNorm.weight                         of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.8.output.dense.bias                               of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.8.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.8.output.dense.weight                             of shape (768, 3072)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.output.LayerNorm.bias                 loaded from language_backbone.body.bert_model.encoder.layer.9.attention.output.LayerNorm.bias                 of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.output.LayerNorm.weight               loaded from language_backbone.body.bert_model.encoder.layer.9.attention.output.LayerNorm.weight               of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.output.dense.bias                     loaded from language_backbone.body.bert_model.encoder.layer.9.attention.output.dense.bias                     of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.output.dense.weight                   loaded from language_backbone.body.bert_model.encoder.layer.9.attention.output.dense.weight                   of shape (768, 768)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.key.bias                         loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.key.bias                         of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.key.weight                       loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.key.weight                       of shape (768, 768)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.query.bias                       loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.query.bias                       of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.query.weight                     loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.query.weight                     of shape (768, 768)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.value.bias                       loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.value.bias                       of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.attention.self.value.weight                     loaded from language_backbone.body.bert_model.encoder.layer.9.attention.self.value.weight                     of shape (768, 768)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.intermediate.dense.bias                         loaded from language_backbone.body.bert_model.encoder.layer.9.intermediate.dense.bias                         of shape (3072,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.intermediate.dense.weight                       loaded from language_backbone.body.bert_model.encoder.layer.9.intermediate.dense.weight                       of shape (3072, 768)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.output.LayerNorm.bias                           loaded from language_backbone.body.bert_model.encoder.layer.9.output.LayerNorm.bias                           of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.output.LayerNorm.weight                         loaded from language_backbone.body.bert_model.encoder.layer.9.output.LayerNorm.weight                         of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.output.dense.bias                               loaded from language_backbone.body.bert_model.encoder.layer.9.output.dense.bias                               of shape (768,)
2021-04-02 00:20:31,072 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.encoder.layer.9.output.dense.weight                             loaded from language_backbone.body.bert_model.encoder.layer.9.output.dense.weight                             of shape (768, 3072)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.pooler.dense.bias                                               loaded from language_backbone.body.bert_model.pooler.dense.bias                                               of shape (768,)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.bert_model.pooler.dense.weight                                             loaded from language_backbone.body.bert_model.pooler.dense.weight                                             of shape (768, 768)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.language_backbone.body.embeddings                                                                 loaded from language_backbone.body.embeddings                                                                 of shape (30522, 768)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.GroundingHead.v2l_projection.bias                                                      loaded from mmss_heads.GroundingHead.v2l_projection.bias                                                      of shape (768,)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.GroundingHead.v2l_projection.weight                                                    loaded from mmss_heads.GroundingHead.v2l_projection.weight                                                    of shape (768, 2048)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.embeddings.LayerNorm.bias                          loaded from mmss_heads.TransformerHead.backbone.bert_model.embeddings.LayerNorm.bias                          of shape (768,)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.embeddings.LayerNorm.weight                        loaded from mmss_heads.TransformerHead.backbone.bert_model.embeddings.LayerNorm.weight                        of shape (768,)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.embeddings.position_embeddings.weight              loaded from mmss_heads.TransformerHead.backbone.bert_model.embeddings.position_embeddings.weight              of shape (512, 768)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.embeddings.token_type_embeddings.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.embeddings.token_type_embeddings.weight            of shape (2, 768)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.embeddings.word_embeddings.weight                  loaded from mmss_heads.TransformerHead.backbone.bert_model.embeddings.word_embeddings.weight                  of shape (30522, 768)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.LayerNorm.bias    of shape (768,)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.LayerNorm.weight  of shape (768,)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.dense.bias        of shape (768,)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.output.dense.weight      of shape (768, 768)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.key.bias            of shape (768,)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.key.weight          of shape (768, 768)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.query.bias          of shape (768,)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.query.weight        of shape (768, 768)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.value.bias          of shape (768,)
2021-04-02 00:20:31,073 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.attention.self.value.weight        of shape (768, 768)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.intermediate.dense.bias            of shape (3072,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.intermediate.dense.weight          of shape (3072, 768)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.LayerNorm.bias              of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.LayerNorm.weight            of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.dense.bias                  of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.0.output.dense.weight                of shape (768, 3072)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.LayerNorm.bias    of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.LayerNorm.weight  of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.dense.bias        of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.output.dense.weight      of shape (768, 768)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.key.bias            of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.key.weight          of shape (768, 768)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.query.bias          of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.query.weight        of shape (768, 768)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.value.bias          of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.attention.self.value.weight        of shape (768, 768)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.intermediate.dense.bias            of shape (3072,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.intermediate.dense.weight          of shape (3072, 768)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.LayerNorm.bias              of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.LayerNorm.weight            of shape (768,)
2021-04-02 00:20:31,074 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.dense.bias                  of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.1.output.dense.weight                of shape (768, 3072)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.LayerNorm.bias   loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.LayerNorm.bias   of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.LayerNorm.weight loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.LayerNorm.weight of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.dense.bias       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.dense.bias       of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.dense.weight     loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.output.dense.weight     of shape (768, 768)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.key.bias           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.key.bias           of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.key.weight         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.key.weight         of shape (768, 768)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.query.bias         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.query.bias         of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.query.weight       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.query.weight       of shape (768, 768)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.value.bias         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.value.bias         of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.value.weight       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.attention.self.value.weight       of shape (768, 768)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.intermediate.dense.bias           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.intermediate.dense.bias           of shape (3072,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.intermediate.dense.weight         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.intermediate.dense.weight         of shape (3072, 768)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.LayerNorm.bias             loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.LayerNorm.bias             of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.LayerNorm.weight           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.LayerNorm.weight           of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.dense.bias                 loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.dense.bias                 of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.dense.weight               loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.10.output.dense.weight               of shape (768, 3072)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.LayerNorm.bias   loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.LayerNorm.bias   of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.LayerNorm.weight loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.LayerNorm.weight of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.dense.bias       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.dense.bias       of shape (768,)
2021-04-02 00:20:31,075 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.dense.weight     loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.output.dense.weight     of shape (768, 768)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.key.bias           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.key.bias           of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.key.weight         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.key.weight         of shape (768, 768)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.query.bias         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.query.bias         of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.query.weight       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.query.weight       of shape (768, 768)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.value.bias         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.value.bias         of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.value.weight       loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.attention.self.value.weight       of shape (768, 768)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.intermediate.dense.bias           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.intermediate.dense.bias           of shape (3072,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.intermediate.dense.weight         loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.intermediate.dense.weight         of shape (3072, 768)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.LayerNorm.bias             loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.LayerNorm.bias             of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.LayerNorm.weight           loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.LayerNorm.weight           of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.dense.bias                 loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.dense.bias                 of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.dense.weight               loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.11.output.dense.weight               of shape (768, 3072)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.LayerNorm.bias    of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.LayerNorm.weight  of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.dense.bias        of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.output.dense.weight      of shape (768, 768)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.key.bias            of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.key.weight          of shape (768, 768)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.query.bias          of shape (768,)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.query.weight        of shape (768, 768)
2021-04-02 00:20:31,076 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.value.bias          of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.attention.self.value.weight        of shape (768, 768)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.intermediate.dense.bias            of shape (3072,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.intermediate.dense.weight          of shape (3072, 768)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.LayerNorm.bias              of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.LayerNorm.weight            of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.dense.bias                  of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.2.output.dense.weight                of shape (768, 3072)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.LayerNorm.bias    of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.LayerNorm.weight  of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.dense.bias        of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.output.dense.weight      of shape (768, 768)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.key.bias            of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.key.weight          of shape (768, 768)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.query.bias          of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.query.weight        of shape (768, 768)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.value.bias          of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.attention.self.value.weight        of shape (768, 768)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.intermediate.dense.bias            of shape (3072,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.intermediate.dense.weight          of shape (3072, 768)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.LayerNorm.bias              of shape (768,)
2021-04-02 00:20:31,077 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.LayerNorm.weight            of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.dense.bias                  of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.3.output.dense.weight                of shape (768, 3072)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.LayerNorm.bias    of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.LayerNorm.weight  of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.dense.bias        of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.output.dense.weight      of shape (768, 768)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.key.bias            of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.key.weight          of shape (768, 768)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.query.bias          of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.query.weight        of shape (768, 768)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.value.bias          of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.attention.self.value.weight        of shape (768, 768)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.intermediate.dense.bias            of shape (3072,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.intermediate.dense.weight          of shape (3072, 768)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.LayerNorm.bias              of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.LayerNorm.weight            of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.dense.bias                  of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.4.output.dense.weight                of shape (768, 3072)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.LayerNorm.bias    of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.LayerNorm.weight  of shape (768,)
2021-04-02 00:20:31,078 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.dense.bias        of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.output.dense.weight      of shape (768, 768)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.key.bias            of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.key.weight          of shape (768, 768)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.query.bias          of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.query.weight        of shape (768, 768)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.value.bias          of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.attention.self.value.weight        of shape (768, 768)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.intermediate.dense.bias            of shape (3072,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.intermediate.dense.weight          of shape (3072, 768)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.LayerNorm.bias              of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.LayerNorm.weight            of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.dense.bias                  of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.5.output.dense.weight                of shape (768, 3072)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.LayerNorm.bias    of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.LayerNorm.weight  of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.dense.bias        of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.output.dense.weight      of shape (768, 768)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.key.bias            of shape (768,)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.key.weight          of shape (768, 768)
2021-04-02 00:20:31,079 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.query.bias          of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.query.weight        of shape (768, 768)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.value.bias          of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.attention.self.value.weight        of shape (768, 768)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.intermediate.dense.bias            of shape (3072,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.intermediate.dense.weight          of shape (3072, 768)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.LayerNorm.bias              of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.LayerNorm.weight            of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.dense.bias                  of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.6.output.dense.weight                of shape (768, 3072)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.LayerNorm.bias    of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.LayerNorm.weight  of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.dense.bias        of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.output.dense.weight      of shape (768, 768)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.key.bias            of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.key.weight          of shape (768, 768)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.query.bias          of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.query.weight        of shape (768, 768)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.value.bias          of shape (768,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.attention.self.value.weight        of shape (768, 768)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.intermediate.dense.bias            of shape (3072,)
2021-04-02 00:20:31,080 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.intermediate.dense.weight          of shape (3072, 768)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.LayerNorm.bias              of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.LayerNorm.weight            of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.dense.bias                  of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.7.output.dense.weight                of shape (768, 3072)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.LayerNorm.bias    of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.LayerNorm.weight  of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.dense.bias        of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.output.dense.weight      of shape (768, 768)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.key.bias            of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.key.weight          of shape (768, 768)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.query.bias          of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.query.weight        of shape (768, 768)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.value.bias          of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.attention.self.value.weight        of shape (768, 768)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.intermediate.dense.bias            of shape (3072,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.intermediate.dense.weight          of shape (3072, 768)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.LayerNorm.bias              of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.LayerNorm.weight            of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.dense.bias                  of shape (768,)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.8.output.dense.weight                of shape (768, 3072)
2021-04-02 00:20:31,081 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.LayerNorm.bias    loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.LayerNorm.bias    of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.LayerNorm.weight  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.LayerNorm.weight  of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.dense.bias        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.dense.bias        of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.dense.weight      loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.output.dense.weight      of shape (768, 768)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.key.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.key.bias            of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.key.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.key.weight          of shape (768, 768)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.query.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.query.bias          of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.query.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.query.weight        of shape (768, 768)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.value.bias          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.value.bias          of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.value.weight        loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.attention.self.value.weight        of shape (768, 768)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.intermediate.dense.bias            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.intermediate.dense.bias            of shape (3072,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.intermediate.dense.weight          loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.intermediate.dense.weight          of shape (3072, 768)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.LayerNorm.bias              loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.LayerNorm.bias              of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.LayerNorm.weight            loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.LayerNorm.weight            of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.dense.bias                  loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.dense.bias                  of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.dense.weight                loaded from mmss_heads.TransformerHead.backbone.bert_model.encoder.layer.9.output.dense.weight                of shape (768, 3072)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.pooler.dense.bias                                  loaded from mmss_heads.TransformerHead.backbone.bert_model.pooler.dense.bias                                  of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.bert_model.pooler.dense.weight                                loaded from mmss_heads.TransformerHead.backbone.bert_model.pooler.dense.weight                                of shape (768, 768)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.backbone.embeddings                                                    loaded from mmss_heads.TransformerHead.backbone.embeddings                                                    of shape (30522, 768)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-02 00:20:31,082 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.bias                            of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.output.dense.weight                          of shape (768, 768)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.bias                                of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.key.weight                              of shape (768, 768)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.bias                              of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.query.weight                            of shape (768, 768)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.bias                              of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.0.attention.self.value.weight                            of shape (768, 768)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.bias                                of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.0.intermediate.dense.weight                              of shape (768, 768)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.bias                                  of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.0.output.LayerNorm.weight                                of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.0.output.dense.bias                                      of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.0.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.0.output.dense.weight                                    of shape (768, 768)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.bias                            of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.output.dense.weight                          of shape (768, 768)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.bias                                of shape (768,)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.key.weight                              of shape (768, 768)
2021-04-02 00:20:31,083 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.bias                              of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.query.weight                            of shape (768, 768)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.bias                              of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.1.attention.self.value.weight                            of shape (768, 768)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.bias                                of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.1.intermediate.dense.weight                              of shape (768, 768)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.bias                                  of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.1.output.LayerNorm.weight                                of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.1.output.dense.bias                                      of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.1.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.1.output.dense.weight                                    of shape (768, 768)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.bias                            of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.output.dense.weight                          of shape (768, 768)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.bias                                of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.key.weight                              of shape (768, 768)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.bias                              of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.query.weight                            of shape (768, 768)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.bias                              of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.2.attention.self.value.weight                            of shape (768, 768)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.bias                                of shape (768,)
2021-04-02 00:20:31,084 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.2.intermediate.dense.weight                              of shape (768, 768)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.bias                                  of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.2.output.LayerNorm.weight                                of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.2.output.dense.bias                                      of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.2.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.2.output.dense.weight                                    of shape (768, 768)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.bias                            of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.output.dense.weight                          of shape (768, 768)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.bias                                of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.key.weight                              of shape (768, 768)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.bias                              of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.query.weight                            of shape (768, 768)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.bias                              of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.3.attention.self.value.weight                            of shape (768, 768)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.bias                                of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.3.intermediate.dense.weight                              of shape (768, 768)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.bias                                  of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.3.output.LayerNorm.weight                                of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.3.output.dense.bias                                      of shape (768,)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.3.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.3.output.dense.weight                                    of shape (768, 768)
2021-04-02 00:20:31,085 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.bias                            of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.output.dense.weight                          of shape (768, 768)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.bias                                of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.key.weight                              of shape (768, 768)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.bias                              of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.query.weight                            of shape (768, 768)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.bias                              of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.4.attention.self.value.weight                            of shape (768, 768)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.bias                                of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.4.intermediate.dense.weight                              of shape (768, 768)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.bias                                  of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.4.output.LayerNorm.weight                                of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.4.output.dense.bias                                      of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.4.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.4.output.dense.weight                                    of shape (768, 768)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.bias                        of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.output.LayerNorm.weight                      of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.bias                            loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.bias                            of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.weight                          loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.output.dense.weight                          of shape (768, 768)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.bias                                of shape (768,)
2021-04-02 00:20:31,086 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.key.weight                              of shape (768, 768)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.bias                              of shape (768,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.query.weight                            of shape (768, 768)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.bias                              loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.bias                              of shape (768,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.weight                            loaded from mmss_heads.TransformerHead.encoder.layer.5.attention.self.value.weight                            of shape (768, 768)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.bias                                loaded from mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.bias                                of shape (768,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.weight                              loaded from mmss_heads.TransformerHead.encoder.layer.5.intermediate.dense.weight                              of shape (768, 768)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.bias                                  loaded from mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.bias                                  of shape (768,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.weight                                loaded from mmss_heads.TransformerHead.encoder.layer.5.output.LayerNorm.weight                                of shape (768,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.output.dense.bias                                      loaded from mmss_heads.TransformerHead.encoder.layer.5.output.dense.bias                                      of shape (768,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.encoder.layer.5.output.dense.weight                                    loaded from mmss_heads.TransformerHead.encoder.layer.5.output.dense.weight                                    of shape (768, 768)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.bi_seq_relationship.bias                                         loaded from mmss_heads.TransformerHead.heads.bi_seq_relationship.bias                                         of shape (2,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.bi_seq_relationship.weight                                       loaded from mmss_heads.TransformerHead.heads.bi_seq_relationship.weight                                       of shape (2, 768)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.decoder.bias                                    loaded from mmss_heads.TransformerHead.heads.imagePredictions.decoder.bias                                    of shape (2048,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.decoder.weight                                  loaded from mmss_heads.TransformerHead.heads.imagePredictions.decoder.weight                                  of shape (2048, 768)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.transform.LayerNorm.bias                        loaded from mmss_heads.TransformerHead.heads.imagePredictions.transform.LayerNorm.bias                        of shape (768,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.transform.LayerNorm.weight                      loaded from mmss_heads.TransformerHead.heads.imagePredictions.transform.LayerNorm.weight                      of shape (768,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.transform.dense.bias                            loaded from mmss_heads.TransformerHead.heads.imagePredictions.transform.dense.bias                            of shape (768,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.imagePredictions.transform.dense.weight                          loaded from mmss_heads.TransformerHead.heads.imagePredictions.transform.dense.weight                          of shape (768, 768)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.bias                                                 loaded from mmss_heads.TransformerHead.heads.predictions.bias                                                 of shape (30522,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.decoder.bias                                         loaded from mmss_heads.TransformerHead.heads.predictions.decoder.bias                                         of shape (30522,)
2021-04-02 00:20:31,087 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.decoder.weight                                       loaded from mmss_heads.TransformerHead.heads.predictions.decoder.weight                                       of shape (30522, 768)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.bias                             loaded from mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.bias                             of shape (768,)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.weight                           loaded from mmss_heads.TransformerHead.heads.predictions.transform.LayerNorm.weight                           of shape (768,)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.transform.dense.bias                                 loaded from mmss_heads.TransformerHead.heads.predictions.transform.dense.bias                                 of shape (768,)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.heads.predictions.transform.dense.weight                               loaded from mmss_heads.TransformerHead.heads.predictions.transform.dense.weight                               of shape (768, 768)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.pooler.dense.bias                                                      loaded from mmss_heads.TransformerHead.pooler.dense.bias                                                      of shape (768,)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.pooler.dense.weight                                                    loaded from mmss_heads.TransformerHead.pooler.dense.weight                                                    of shape (768, 768)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.v2l_projection.bias                                                    loaded from mmss_heads.TransformerHead.v2l_projection.bias                                                    of shape (768,)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.v2l_projection.weight                                                  loaded from mmss_heads.TransformerHead.v2l_projection.weight                                                  of shape (768, 2048)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.LayerNorm.bias                                              loaded from mmss_heads.TransformerHead.visual_emb.LayerNorm.bias                                              of shape (768,)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.LayerNorm.weight                                            loaded from mmss_heads.TransformerHead.visual_emb.LayerNorm.weight                                            of shape (768,)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.image_embeddings.bias                                       loaded from mmss_heads.TransformerHead.visual_emb.image_embeddings.bias                                       of shape (768,)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.image_embeddings.weight                                     loaded from mmss_heads.TransformerHead.visual_emb.image_embeddings.weight                                     of shape (768, 768)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.image_location_embeddings.bias                              loaded from mmss_heads.TransformerHead.visual_emb.image_location_embeddings.bias                              of shape (768,)
2021-04-02 00:20:31,088 maskrcnn_benchmark.utils.model_serialization INFO: module.mmss_heads.TransformerHead.visual_emb.image_location_embeddings.weight                            loaded from mmss_heads.TransformerHead.visual_emb.image_location_embeddings.weight                            of shape (768, 2)
2021-04-02 00:20:31,445 maskrcnn_benchmark.utils.checkpoint INFO: Loading optimizer from /mnt/lustre/lixiangtai/runs/vltrain/121/model_0014000.pth
2021-04-02 00:20:31,549 maskrcnn_benchmark.utils.checkpoint INFO: Loading scheduler from /mnt/lustre/lixiangtai/runs/vltrain/121/model_0014000.pth
2021-04-02 00:20:31,550 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2021-04-02 00:20:38,690 maskrcnn_benchmark.utils.miscellaneous WARNING: Dataset [COCOCaptionsDataset] has no categories attribute, labels.json file won't be created
2021-04-02 00:20:38,908 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2021-04-02 00:20:39,018 maskrcnn_benchmark.trainer INFO: Start training
2021-04-02 00:21:59,705 maskrcnn_benchmark.trainer INFO: eta: 5:47:11  iter: 14100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5085 (0.5607)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5363 (0.5317)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5577 (0.5628)  Cross-Entropy Loss (Align Words, Choose Image): 0.4942 (0.4708)  Image Caption Matching Loss: 0.6918 (0.6374)  Masked Language Modeling Loss: 1.7543 (1.7944)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6594 (4.5577)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8158)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8214)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.8102)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8392)  Batch Accuracy (Choose Caption): 0.8750 (0.8788)  Batch Accuracy (Choose Image): 0.8750 (0.8827)  Masked Language Modeling Accuracy: 0.6368 (0.6437)  time: 0.6797 (0.8043)  data: 0.0203 (0.0691)  lr: 0.010000  max mem: 10756
2021-04-02 00:23:12,452 maskrcnn_benchmark.trainer INFO: eta: 5:29:19  iter: 14200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5443 (0.5388)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4986 (0.5178)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5301 (0.5513)  Cross-Entropy Loss (Align Words, Choose Image): 0.4433 (0.4607)  Image Caption Matching Loss: 0.5919 (0.6140)  Masked Language Modeling Loss: 1.7929 (1.8050)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5171 (4.4876)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8223)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8235)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8120)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8424)  Batch Accuracy (Choose Caption): 0.8750 (0.8822)  Batch Accuracy (Choose Image): 0.8906 (0.8869)  Masked Language Modeling Accuracy: 0.6209 (0.6390)  time: 0.6695 (0.7659)  data: 0.0187 (0.0497)  lr: 0.010000  max mem: 10882
2021-04-02 00:24:26,020 maskrcnn_benchmark.trainer INFO: eta: 5:23:39  iter: 14300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5472 (0.5409)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5515 (0.5221)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5461 (0.5513)  Cross-Entropy Loss (Align Words, Choose Image): 0.4391 (0.4627)  Image Caption Matching Loss: 0.6050 (0.6082)  Masked Language Modeling Loss: 1.6891 (1.8006)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3246 (4.4858)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8208)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8232)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8128)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8401)  Batch Accuracy (Choose Caption): 0.8906 (0.8828)  Batch Accuracy (Choose Image): 0.8906 (0.8888)  Masked Language Modeling Accuracy: 0.6224 (0.6384)  time: 0.6751 (0.7556)  data: 0.0194 (0.0430)  lr: 0.010000  max mem: 10882
2021-04-02 00:25:39,659 maskrcnn_benchmark.trainer INFO: eta: 5:20:27  iter: 14400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4876 (0.5366)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4456 (0.5203)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5757 (0.5487)  Cross-Entropy Loss (Align Words, Choose Image): 0.5052 (0.4629)  Image Caption Matching Loss: 0.6111 (0.6036)  Masked Language Modeling Loss: 1.6913 (1.7918)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2269 (4.4638)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8217)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8241)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8132)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8385)  Batch Accuracy (Choose Caption): 0.8906 (0.8834)  Batch Accuracy (Choose Image): 0.8906 (0.8889)  Masked Language Modeling Accuracy: 0.6413 (0.6394)  time: 0.6714 (0.7511)  data: 0.0184 (0.0400)  lr: 0.010000  max mem: 10882
2021-04-02 00:26:52,213 maskrcnn_benchmark.trainer INFO: eta: 5:17:04  iter: 14500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4738 (0.5364)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4445 (0.5195)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5021 (0.5503)  Cross-Entropy Loss (Align Words, Choose Image): 0.4832 (0.4626)  Image Caption Matching Loss: 0.5555 (0.6052)  Masked Language Modeling Loss: 1.6246 (1.7956)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0788 (4.4695)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8203)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8243)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8123)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8392)  Batch Accuracy (Choose Caption): 0.8906 (0.8831)  Batch Accuracy (Choose Image): 0.8906 (0.8886)  Masked Language Modeling Accuracy: 0.6403 (0.6376)  time: 0.6691 (0.7461)  data: 0.0193 (0.0374)  lr: 0.010000  max mem: 10882
2021-04-02 00:28:05,737 maskrcnn_benchmark.trainer INFO: eta: 5:14:48  iter: 14600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5504 (0.5370)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4956 (0.5177)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5110 (0.5494)  Cross-Entropy Loss (Align Words, Choose Image): 0.4558 (0.4601)  Image Caption Matching Loss: 0.5579 (0.6043)  Masked Language Modeling Loss: 1.7619 (1.7965)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2083 (4.4651)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8202)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8244)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.8129)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8405)  Batch Accuracy (Choose Caption): 0.8750 (0.8825)  Batch Accuracy (Choose Image): 0.8750 (0.8888)  Masked Language Modeling Accuracy: 0.6375 (0.6382)  time: 0.6763 (0.7436)  data: 0.0186 (0.0364)  lr: 0.010000  max mem: 11333
2021-04-02 00:29:21,349 maskrcnn_benchmark.trainer INFO: eta: 5:14:29  iter: 14700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4450 (0.5372)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4568 (0.5181)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4372 (0.5482)  Cross-Entropy Loss (Align Words, Choose Image): 0.4253 (0.4613)  Image Caption Matching Loss: 0.5361 (0.6054)  Masked Language Modeling Loss: 1.6419 (1.7944)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.7533 (4.4647)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8198)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8240)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8132)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8405)  Batch Accuracy (Choose Caption): 0.9062 (0.8820)  Batch Accuracy (Choose Image): 0.8906 (0.8882)  Masked Language Modeling Accuracy: 0.6463 (0.6383)  time: 0.6758 (0.7458)  data: 0.0237 (0.0361)  lr: 0.010000  max mem: 11333
2021-04-02 00:30:31,494 maskrcnn_benchmark.trainer INFO: eta: 5:10:55  iter: 14800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.6048 (0.5372)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5623 (0.5187)  Cross-Entropy Loss (Align Words, Choose Caption): 0.6239 (0.5474)  Cross-Entropy Loss (Align Words, Choose Image): 0.5053 (0.4618)  Image Caption Matching Loss: 0.6259 (0.6051)  Masked Language Modeling Loss: 1.7922 (1.7911)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6450 (4.4613)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8194)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.8239)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.8130)  Batch Accuracy (Align Words, Choose Image): 0.8125 (0.8406)  Batch Accuracy (Choose Caption): 0.8906 (0.8820)  Batch Accuracy (Choose Image): 0.8906 (0.8881)  Masked Language Modeling Accuracy: 0.6187 (0.6383)  time: 0.6715 (0.7403)  data: 0.0210 (0.0353)  lr: 0.010000  max mem: 11333
2021-04-02 00:31:47,884 maskrcnn_benchmark.trainer INFO: eta: 5:10:46  iter: 14900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4610 (0.5361)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4699 (0.5196)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4920 (0.5452)  Cross-Entropy Loss (Align Words, Choose Image): 0.3949 (0.4596)  Image Caption Matching Loss: 0.5229 (0.6012)  Masked Language Modeling Loss: 1.7634 (1.7924)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.9840 (4.4542)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8207)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8239)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8141)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8419)  Batch Accuracy (Choose Caption): 0.9062 (0.8824)  Batch Accuracy (Choose Image): 0.8906 (0.8886)  Masked Language Modeling Accuracy: 0.6299 (0.6382)  time: 0.6855 (0.7429)  data: 0.0224 (0.0347)  lr: 0.010000  max mem: 11333
2021-04-02 00:33:00,337 maskrcnn_benchmark.trainer INFO: eta: 5:08:48  iter: 15000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5327 (0.5358)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4887 (0.5189)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5602 (0.5442)  Cross-Entropy Loss (Align Words, Choose Image): 0.4460 (0.4597)  Image Caption Matching Loss: 0.4893 (0.6027)  Masked Language Modeling Loss: 1.8459 (1.7892)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3527 (4.4505)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8208)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8238)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8141)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8415)  Batch Accuracy (Choose Caption): 0.9062 (0.8826)  Batch Accuracy (Choose Image): 0.9062 (0.8885)  Masked Language Modeling Accuracy: 0.6269 (0.6385)  time: 0.6727 (0.7411)  data: 0.0186 (0.0342)  lr: 0.010000  max mem: 11455
2021-04-02 00:33:00,641 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0015000.pth
2021-04-02 00:34:10,888 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 5:08:48  iter: 15000  loss: 1.9467 (2.0713)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3669 (0.3805)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3854 (0.3915)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4655 (0.4471)  Cross-Entropy Loss (Align Words, Choose Image): 0.3569 (0.3664)  Image Caption Matching Loss: 0.4370 (0.4857)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8794)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8706)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8448)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8717)  Batch Accuracy (Choose Caption): 0.9010 (0.9064)  Batch Accuracy (Choose Image): 0.9062 (0.9097)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11455
2021-04-02 00:35:21,059 maskrcnn_benchmark.trainer INFO: eta: 5:32:41  iter: 15100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4969 (0.5348)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4836 (0.5188)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5064 (0.5418)  Cross-Entropy Loss (Align Words, Choose Image): 0.4144 (0.4580)  Image Caption Matching Loss: 0.5131 (0.6014)  Masked Language Modeling Loss: 1.8396 (1.7900)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0758 (4.4447)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.8213)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8241)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8145)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8423)  Batch Accuracy (Choose Caption): 0.8906 (0.8829)  Batch Accuracy (Choose Image): 0.8906 (0.8884)  Masked Language Modeling Accuracy: 0.6424 (0.6388)  time: 0.6805 (0.8017)  data: 0.0265 (0.0979)  lr: 0.010000  max mem: 11581
2021-04-02 00:36:34,031 maskrcnn_benchmark.trainer INFO: eta: 5:28:50  iter: 15200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5487 (0.5337)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5418 (0.5184)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5436 (0.5415)  Cross-Entropy Loss (Align Words, Choose Image): 0.4841 (0.4578)  Image Caption Matching Loss: 0.5869 (0.5990)  Masked Language Modeling Loss: 1.6803 (1.7866)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.5017 (4.4369)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.8213)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8239)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8148)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8427)  Batch Accuracy (Choose Caption): 0.8906 (0.8835)  Batch Accuracy (Choose Image): 0.8906 (0.8885)  Masked Language Modeling Accuracy: 0.6569 (0.6393)  time: 0.6672 (0.7956)  data: 0.0182 (0.0924)  lr: 0.010000  max mem: 11581
2021-04-02 00:37:43,406 maskrcnn_benchmark.trainer INFO: eta: 5:24:18  iter: 15300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4918 (0.5316)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5054 (0.5180)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4851 (0.5391)  Cross-Entropy Loss (Align Words, Choose Image): 0.4560 (0.4568)  Image Caption Matching Loss: 0.5572 (0.5975)  Masked Language Modeling Loss: 1.6968 (1.7863)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2020 (4.4294)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8218)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8238)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8153)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8429)  Batch Accuracy (Choose Caption): 0.8750 (0.8836)  Batch Accuracy (Choose Image): 0.8906 (0.8887)  Masked Language Modeling Accuracy: 0.6497 (0.6394)  time: 0.6702 (0.7878)  data: 0.0180 (0.0873)  lr: 0.010000  max mem: 11581
2021-04-02 00:38:56,985 maskrcnn_benchmark.trainer INFO: eta: 5:21:28  iter: 15400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5770 (0.5315)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5107 (0.5185)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5279 (0.5389)  Cross-Entropy Loss (Align Words, Choose Image): 0.4429 (0.4569)  Image Caption Matching Loss: 0.5379 (0.5979)  Masked Language Modeling Loss: 1.6470 (1.7842)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3714 (4.4278)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.8220)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.8238)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8157)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8428)  Batch Accuracy (Choose Caption): 0.8750 (0.8836)  Batch Accuracy (Choose Image): 0.8906 (0.8885)  Masked Language Modeling Accuracy: 0.6574 (0.6396)  time: 0.6694 (0.7841)  data: 0.0180 (0.0833)  lr: 0.010000  max mem: 11581
2021-04-02 00:40:05,358 maskrcnn_benchmark.trainer INFO: eta: 5:17:25  iter: 15500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5090 (0.5319)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4911 (0.5190)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4740 (0.5386)  Cross-Entropy Loss (Align Words, Choose Image): 0.3918 (0.4564)  Image Caption Matching Loss: 0.5096 (0.5964)  Masked Language Modeling Loss: 1.8104 (1.7819)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1195 (4.4242)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8219)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8237)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8162)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8431)  Batch Accuracy (Choose Caption): 0.8906 (0.8837)  Batch Accuracy (Choose Image): 0.8906 (0.8889)  Masked Language Modeling Accuracy: 0.6224 (0.6403)  time: 0.6707 (0.7774)  data: 0.0176 (0.0793)  lr: 0.010000  max mem: 11581
2021-04-02 00:41:24,550 maskrcnn_benchmark.trainer INFO: eta: 5:16:30  iter: 15600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5234 (0.5330)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4948 (0.5200)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5468 (0.5378)  Cross-Entropy Loss (Align Words, Choose Image): 0.4506 (0.4561)  Image Caption Matching Loss: 0.6532 (0.5960)  Masked Language Modeling Loss: 1.6694 (1.7805)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.6159 (4.4233)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8218)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8235)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.8163)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8432)  Batch Accuracy (Choose Caption): 0.8750 (0.8838)  Batch Accuracy (Choose Image): 0.8750 (0.8892)  Masked Language Modeling Accuracy: 0.6484 (0.6403)  time: 0.6703 (0.7783)  data: 0.0184 (0.0764)  lr: 0.010000  max mem: 11581
2021-04-02 00:42:33,373 maskrcnn_benchmark.trainer INFO: eta: 5:13:04  iter: 15700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4879 (0.5328)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5055 (0.5197)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4804 (0.5372)  Cross-Entropy Loss (Align Words, Choose Image): 0.4397 (0.4560)  Image Caption Matching Loss: 0.5863 (0.5968)  Masked Language Modeling Loss: 1.7825 (1.7809)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3484 (4.4234)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8218)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8238)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8165)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8433)  Batch Accuracy (Choose Caption): 0.8750 (0.8836)  Batch Accuracy (Choose Image): 0.8906 (0.8891)  Masked Language Modeling Accuracy: 0.6217 (0.6404)  time: 0.6695 (0.7730)  data: 0.0190 (0.0734)  lr: 0.010000  max mem: 11581
2021-04-02 00:43:51,749 maskrcnn_benchmark.trainer INFO: eta: 5:12:01  iter: 15800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4576 (0.5308)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4615 (0.5183)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4913 (0.5354)  Cross-Entropy Loss (Align Words, Choose Image): 0.4539 (0.4551)  Image Caption Matching Loss: 0.5521 (0.5946)  Masked Language Modeling Loss: 1.6593 (1.7785)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1567 (4.4127)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8222)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8246)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8171)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8433)  Batch Accuracy (Choose Caption): 0.8906 (0.8842)  Batch Accuracy (Choose Image): 0.8750 (0.8893)  Masked Language Modeling Accuracy: 0.6680 (0.6408)  time: 0.6687 (0.7736)  data: 0.0189 (0.0710)  lr: 0.010000  max mem: 11581
2021-04-02 00:45:02,217 maskrcnn_benchmark.trainer INFO: eta: 5:09:16  iter: 15900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5332 (0.5301)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5566 (0.5169)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5937 (0.5347)  Cross-Entropy Loss (Align Words, Choose Image): 0.4533 (0.4542)  Image Caption Matching Loss: 0.5959 (0.5944)  Masked Language Modeling Loss: 1.7272 (1.7779)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3854 (4.4083)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8225)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8250)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.8173)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8435)  Batch Accuracy (Choose Caption): 0.8906 (0.8841)  Batch Accuracy (Choose Image): 0.8750 (0.8896)  Masked Language Modeling Accuracy: 0.6437 (0.6408)  time: 0.6641 (0.7700)  data: 0.0182 (0.0686)  lr: 0.010000  max mem: 11938
2021-04-02 00:46:12,506 maskrcnn_benchmark.trainer INFO: eta: 5:06:39  iter: 16000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5376 (0.5302)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4907 (0.5163)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4977 (0.5339)  Cross-Entropy Loss (Align Words, Choose Image): 0.3825 (0.4540)  Image Caption Matching Loss: 0.5458 (0.5933)  Masked Language Modeling Loss: 1.7674 (1.7768)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2561 (4.4046)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.8224)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.8252)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8173)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8437)  Batch Accuracy (Choose Caption): 0.8906 (0.8841)  Batch Accuracy (Choose Image): 0.8906 (0.8898)  Masked Language Modeling Accuracy: 0.6338 (0.6407)  time: 0.6658 (0.7667)  data: 0.0184 (0.0665)  lr: 0.010000  max mem: 11938
2021-04-02 00:46:12,820 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0016000.pth
2021-04-02 00:47:20,424 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 5:06:39  iter: 16000  loss: 1.9960 (2.0103)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3506 (0.3615)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3458 (0.3867)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4250 (0.4317)  Cross-Entropy Loss (Align Words, Choose Image): 0.3879 (0.3680)  Image Caption Matching Loss: 0.4547 (0.4625)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8687)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8682)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8546)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8747)  Batch Accuracy (Choose Caption): 0.9062 (0.9138)  Batch Accuracy (Choose Image): 0.9219 (0.9136)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11938
2021-04-02 00:48:32,297 maskrcnn_benchmark.trainer INFO: eta: 5:17:20  iter: 16100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5044 (0.5297)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4681 (0.5167)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5107 (0.5329)  Cross-Entropy Loss (Align Words, Choose Image): 0.4173 (0.4533)  Image Caption Matching Loss: 0.5025 (0.5920)  Masked Language Modeling Loss: 1.7793 (1.7759)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1589 (4.4005)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8226)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8253)  Batch Accuracy (Align Words, Choose Caption): 0.7969 (0.8178)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8441)  Batch Accuracy (Choose Caption): 0.8906 (0.8843)  Batch Accuracy (Choose Image): 0.8906 (0.8899)  Masked Language Modeling Accuracy: 0.6232 (0.6408)  time: 0.6669 (0.7967)  data: 0.0186 (0.0971)  lr: 0.010000  max mem: 11938
2021-04-02 00:49:43,756 maskrcnn_benchmark.trainer INFO: eta: 5:14:32  iter: 16200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4711 (0.5294)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4307 (0.5159)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4718 (0.5320)  Cross-Entropy Loss (Align Words, Choose Image): 0.3999 (0.4527)  Image Caption Matching Loss: 0.5059 (0.5915)  Masked Language Modeling Loss: 1.6892 (1.7745)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0699 (4.3959)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8227)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8256)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8181)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8444)  Batch Accuracy (Choose Caption): 0.8906 (0.8845)  Batch Accuracy (Choose Image): 0.8906 (0.8900)  Masked Language Modeling Accuracy: 0.6653 (0.6412)  time: 0.6646 (0.7930)  data: 0.0188 (0.0939)  lr: 0.010000  max mem: 11938
2021-04-02 00:50:59,881 maskrcnn_benchmark.trainer INFO: eta: 5:12:40  iter: 16300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4420 (0.5281)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4284 (0.5151)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4263 (0.5310)  Cross-Entropy Loss (Align Words, Choose Image): 0.3597 (0.4516)  Image Caption Matching Loss: 0.4778 (0.5896)  Masked Language Modeling Loss: 1.8148 (1.7723)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.9439 (4.3877)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8232)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8259)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8185)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8447)  Batch Accuracy (Choose Caption): 0.8906 (0.8848)  Batch Accuracy (Choose Image): 0.8906 (0.8903)  Masked Language Modeling Accuracy: 0.6221 (0.6414)  time: 0.6725 (0.7916)  data: 0.0188 (0.0912)  lr: 0.010000  max mem: 11938
2021-04-02 00:52:08,405 maskrcnn_benchmark.trainer INFO: eta: 5:09:36  iter: 16400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5251 (0.5276)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4834 (0.5145)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5084 (0.5300)  Cross-Entropy Loss (Align Words, Choose Image): 0.4598 (0.4513)  Image Caption Matching Loss: 0.5495 (0.5885)  Masked Language Modeling Loss: 1.6835 (1.7730)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2073 (4.3849)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8234)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8261)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8189)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8449)  Batch Accuracy (Choose Caption): 0.9062 (0.8851)  Batch Accuracy (Choose Image): 0.8906 (0.8906)  Masked Language Modeling Accuracy: 0.6547 (0.6412)  time: 0.6796 (0.7871)  data: 0.0194 (0.0884)  lr: 0.010000  max mem: 11938
2021-04-02 00:53:17,075 maskrcnn_benchmark.trainer INFO: eta: 5:06:44  iter: 16500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5473 (0.5273)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4849 (0.5146)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5218 (0.5300)  Cross-Entropy Loss (Align Words, Choose Image): 0.4452 (0.4513)  Image Caption Matching Loss: 0.5876 (0.5897)  Masked Language Modeling Loss: 1.7411 (1.7720)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3594 (4.3849)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8234)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8260)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8188)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8448)  Batch Accuracy (Choose Caption): 0.8750 (0.8847)  Batch Accuracy (Choose Image): 0.8906 (0.8904)  Masked Language Modeling Accuracy: 0.6363 (0.6411)  time: 0.6701 (0.7832)  data: 0.0189 (0.0860)  lr: 0.010000  max mem: 11938
2021-04-02 00:54:33,828 maskrcnn_benchmark.trainer INFO: eta: 5:05:11  iter: 16600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4953 (0.5261)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5195 (0.5143)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4645 (0.5286)  Cross-Entropy Loss (Align Words, Choose Image): 0.4350 (0.4506)  Image Caption Matching Loss: 0.4990 (0.5883)  Masked Language Modeling Loss: 1.8872 (1.7707)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2529 (4.3786)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8236)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8260)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8191)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8451)  Batch Accuracy (Choose Caption): 0.8906 (0.8849)  Batch Accuracy (Choose Image): 0.8906 (0.8909)  Masked Language Modeling Accuracy: 0.6258 (0.6415)  time: 0.6669 (0.7825)  data: 0.0193 (0.0839)  lr: 0.010000  max mem: 11938
2021-04-02 00:55:42,266 maskrcnn_benchmark.trainer INFO: eta: 5:02:28  iter: 16700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5315 (0.5257)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5207 (0.5137)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5145 (0.5282)  Cross-Entropy Loss (Align Words, Choose Image): 0.4257 (0.4503)  Image Caption Matching Loss: 0.5356 (0.5873)  Masked Language Modeling Loss: 1.7004 (1.7693)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2079 (4.3745)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8236)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8262)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8192)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8451)  Batch Accuracy (Choose Caption): 0.8906 (0.8851)  Batch Accuracy (Choose Image): 0.8906 (0.8912)  Masked Language Modeling Accuracy: 0.6490 (0.6417)  time: 0.6716 (0.7789)  data: 0.0189 (0.0818)  lr: 0.010000  max mem: 11938
2021-04-02 00:56:53,503 maskrcnn_benchmark.trainer INFO: eta: 5:00:14  iter: 16800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4959 (0.5249)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4899 (0.5130)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5063 (0.5276)  Cross-Entropy Loss (Align Words, Choose Image): 0.3935 (0.4492)  Image Caption Matching Loss: 0.5446 (0.5859)  Masked Language Modeling Loss: 1.6948 (1.7680)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0721 (4.3687)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8239)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8261)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8194)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8455)  Batch Accuracy (Choose Caption): 0.8906 (0.8854)  Batch Accuracy (Choose Image): 0.8906 (0.8913)  Masked Language Modeling Accuracy: 0.6398 (0.6417)  time: 0.6656 (0.7765)  data: 0.0187 (0.0800)  lr: 0.010000  max mem: 11938
2021-04-02 00:58:08,729 maskrcnn_benchmark.trainer INFO: eta: 4:58:38  iter: 16900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4534 (0.5242)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4255 (0.5122)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4498 (0.5274)  Cross-Entropy Loss (Align Words, Choose Image): 0.4204 (0.4489)  Image Caption Matching Loss: 0.4664 (0.5843)  Masked Language Modeling Loss: 1.7182 (1.7673)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1183 (4.3644)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8239)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8265)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8196)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8455)  Batch Accuracy (Choose Caption): 0.8906 (0.8856)  Batch Accuracy (Choose Image): 0.9062 (0.8916)  Masked Language Modeling Accuracy: 0.6378 (0.6419)  time: 0.6743 (0.7757)  data: 0.0189 (0.0783)  lr: 0.010000  max mem: 11938
2021-04-02 00:59:21,900 maskrcnn_benchmark.trainer INFO: eta: 4:56:47  iter: 17000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5130 (0.5240)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4444 (0.5120)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5618 (0.5273)  Cross-Entropy Loss (Align Words, Choose Image): 0.4309 (0.4487)  Image Caption Matching Loss: 0.5289 (0.5842)  Masked Language Modeling Loss: 1.6689 (1.7663)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1992 (4.3626)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8242)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8265)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8197)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8457)  Batch Accuracy (Choose Caption): 0.9062 (0.8856)  Batch Accuracy (Choose Image): 0.8906 (0.8915)  Masked Language Modeling Accuracy: 0.6440 (0.6421)  time: 0.6716 (0.7742)  data: 0.0191 (0.0766)  lr: 0.010000  max mem: 11938
2021-04-02 00:59:22,205 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0017000.pth
2021-04-02 01:00:30,283 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 4:56:47  iter: 17000  loss: 2.0530 (1.9873)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3741 (0.3709)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3878 (0.3810)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4609 (0.4269)  Cross-Entropy Loss (Align Words, Choose Image): 0.3785 (0.3608)  Image Caption Matching Loss: 0.4539 (0.4477)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8724)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8695)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8498)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8730)  Batch Accuracy (Choose Caption): 0.8906 (0.9138)  Batch Accuracy (Choose Image): 0.9219 (0.9195)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11938
2021-04-02 01:01:44,061 maskrcnn_benchmark.trainer INFO: eta: 5:03:27  iter: 17100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5057 (0.5238)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4771 (0.5118)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4700 (0.5269)  Cross-Entropy Loss (Align Words, Choose Image): 0.4234 (0.4483)  Image Caption Matching Loss: 0.5426 (0.5836)  Masked Language Modeling Loss: 1.7941 (1.7682)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2910 (4.3626)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8242)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8264)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8198)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8458)  Batch Accuracy (Choose Caption): 0.9062 (0.8858)  Batch Accuracy (Choose Image): 0.8906 (0.8916)  Masked Language Modeling Accuracy: 0.6349 (0.6419)  time: 0.6784 (0.7951)  data: 0.0267 (0.0973)  lr: 0.010000  max mem: 11938
2021-04-02 01:02:59,575 maskrcnn_benchmark.trainer INFO: eta: 5:01:38  iter: 17200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4913 (0.5235)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4583 (0.5117)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4825 (0.5264)  Cross-Entropy Loss (Align Words, Choose Image): 0.4152 (0.4479)  Image Caption Matching Loss: 0.5558 (0.5823)  Masked Language Modeling Loss: 1.6995 (1.7683)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0839 (4.3600)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8243)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8265)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8199)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8460)  Batch Accuracy (Choose Caption): 0.9062 (0.8861)  Batch Accuracy (Choose Image): 0.8906 (0.8918)  Masked Language Modeling Accuracy: 0.6650 (0.6420)  time: 0.6611 (0.7938)  data: 0.0189 (0.0952)  lr: 0.010000  max mem: 11938
2021-04-02 01:04:12,944 maskrcnn_benchmark.trainer INFO: eta: 4:59:38  iter: 17300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4759 (0.5233)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4732 (0.5115)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5500 (0.5267)  Cross-Entropy Loss (Align Words, Choose Image): 0.4453 (0.4479)  Image Caption Matching Loss: 0.4473 (0.5822)  Masked Language Modeling Loss: 1.6892 (1.7688)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2675 (4.3605)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8244)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8265)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8197)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8460)  Batch Accuracy (Choose Caption): 0.8906 (0.8860)  Batch Accuracy (Choose Image): 0.8906 (0.8919)  Masked Language Modeling Accuracy: 0.6434 (0.6417)  time: 0.6685 (0.7920)  data: 0.0188 (0.0933)  lr: 0.010000  max mem: 11938
2021-04-02 01:05:28,399 maskrcnn_benchmark.trainer INFO: eta: 4:57:54  iter: 17400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4932 (0.5229)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4689 (0.5109)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4965 (0.5262)  Cross-Entropy Loss (Align Words, Choose Image): 0.4193 (0.4474)  Image Caption Matching Loss: 0.4653 (0.5817)  Masked Language Modeling Loss: 1.7153 (1.7685)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0753 (4.3576)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8246)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8267)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8199)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8462)  Batch Accuracy (Choose Caption): 0.9062 (0.8862)  Batch Accuracy (Choose Image): 0.9062 (0.8920)  Masked Language Modeling Accuracy: 0.6494 (0.6418)  time: 0.6660 (0.7909)  data: 0.0183 (0.0914)  lr: 0.010000  max mem: 11938
2021-04-02 01:06:38,329 maskrcnn_benchmark.trainer INFO: eta: 4:55:36  iter: 17500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4495 (0.5219)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4684 (0.5099)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5285 (0.5258)  Cross-Entropy Loss (Align Words, Choose Image): 0.4393 (0.4471)  Image Caption Matching Loss: 0.5562 (0.5809)  Masked Language Modeling Loss: 1.8225 (1.7669)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.9008 (4.3525)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8249)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8269)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8200)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8463)  Batch Accuracy (Choose Caption): 0.8906 (0.8864)  Batch Accuracy (Choose Image): 0.9062 (0.8922)  Masked Language Modeling Accuracy: 0.6385 (0.6421)  time: 0.6682 (0.7883)  data: 0.0187 (0.0896)  lr: 0.010000  max mem: 11938
2021-04-02 01:07:47,079 maskrcnn_benchmark.trainer INFO: eta: 4:53:15  iter: 17600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4683 (0.5220)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4520 (0.5100)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4383 (0.5254)  Cross-Entropy Loss (Align Words, Choose Image): 0.4175 (0.4469)  Image Caption Matching Loss: 0.5252 (0.5803)  Masked Language Modeling Loss: 1.6839 (1.7654)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.9727 (4.3500)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8250)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8269)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8203)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8465)  Batch Accuracy (Choose Caption): 0.8906 (0.8865)  Batch Accuracy (Choose Image): 0.8906 (0.8923)  Masked Language Modeling Accuracy: 0.6415 (0.6423)  time: 0.6732 (0.7855)  data: 0.0183 (0.0878)  lr: 0.010000  max mem: 11938
2021-04-02 01:09:02,487 maskrcnn_benchmark.trainer INFO: eta: 4:51:37  iter: 17700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4582 (0.5215)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5082 (0.5096)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4981 (0.5249)  Cross-Entropy Loss (Align Words, Choose Image): 0.3922 (0.4463)  Image Caption Matching Loss: 0.5897 (0.5795)  Masked Language Modeling Loss: 1.7425 (1.7651)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2322 (4.3470)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8252)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8272)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8205)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8466)  Batch Accuracy (Choose Caption): 0.8750 (0.8867)  Batch Accuracy (Choose Image): 0.8906 (0.8924)  Masked Language Modeling Accuracy: 0.6396 (0.6425)  time: 0.6789 (0.7847)  data: 0.0188 (0.0863)  lr: 0.010000  max mem: 11938
2021-04-02 01:10:16,518 maskrcnn_benchmark.trainer INFO: eta: 4:49:53  iter: 17800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4967 (0.5207)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4317 (0.5088)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4821 (0.5235)  Cross-Entropy Loss (Align Words, Choose Image): 0.4065 (0.4453)  Image Caption Matching Loss: 0.4936 (0.5779)  Masked Language Modeling Loss: 1.6476 (1.7629)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.9877 (4.3391)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8255)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8276)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8209)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8469)  Batch Accuracy (Choose Caption): 0.8906 (0.8870)  Batch Accuracy (Choose Image): 0.9062 (0.8927)  Masked Language Modeling Accuracy: 0.6359 (0.6427)  time: 0.6781 (0.7835)  data: 0.0189 (0.0848)  lr: 0.010000  max mem: 11938
2021-04-02 01:11:29,008 maskrcnn_benchmark.trainer INFO: eta: 4:48:01  iter: 17900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4412 (0.5199)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4502 (0.5080)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4396 (0.5230)  Cross-Entropy Loss (Align Words, Choose Image): 0.3641 (0.4448)  Image Caption Matching Loss: 0.4795 (0.5766)  Masked Language Modeling Loss: 1.7439 (1.7624)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.8845 (4.3346)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8259)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8277)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8212)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8471)  Batch Accuracy (Choose Caption): 0.9219 (0.8873)  Batch Accuracy (Choose Image): 0.9062 (0.8930)  Masked Language Modeling Accuracy: 0.6405 (0.6428)  time: 0.6705 (0.7820)  data: 0.0188 (0.0834)  lr: 0.010000  max mem: 11938
2021-04-02 01:12:37,659 maskrcnn_benchmark.trainer INFO: eta: 4:45:51  iter: 18000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5247 (0.5194)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5271 (0.5077)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5364 (0.5221)  Cross-Entropy Loss (Align Words, Choose Image): 0.4490 (0.4440)  Image Caption Matching Loss: 0.5498 (0.5752)  Masked Language Modeling Loss: 1.6059 (1.7612)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1539 (4.3297)  Batch Accuracy (Align Regions, Choose Caption): 0.7969 (0.8260)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.8277)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8214)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8473)  Batch Accuracy (Choose Caption): 0.8906 (0.8876)  Batch Accuracy (Choose Image): 0.8906 (0.8932)  Masked Language Modeling Accuracy: 0.6609 (0.6431)  time: 0.6769 (0.7796)  data: 0.0188 (0.0819)  lr: 0.010000  max mem: 11938
2021-04-02 01:12:37,967 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0018000.pth
2021-04-02 01:13:46,682 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 4:45:51  iter: 18000  loss: 2.0893 (2.0466)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3985 (0.3719)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3711 (0.3768)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4555 (0.4254)  Cross-Entropy Loss (Align Words, Choose Image): 0.3272 (0.3496)  Image Caption Matching Loss: 0.5061 (0.5229)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8687)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8715)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8524)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8794)  Batch Accuracy (Choose Caption): 0.9062 (0.9007)  Batch Accuracy (Choose Image): 0.9062 (0.8971)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11938
2021-04-02 01:15:03,115 maskrcnn_benchmark.trainer INFO: eta: 4:50:33  iter: 18100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4749 (0.5185)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4273 (0.5067)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4757 (0.5208)  Cross-Entropy Loss (Align Words, Choose Image): 0.3679 (0.4430)  Image Caption Matching Loss: 0.5420 (0.5741)  Masked Language Modeling Loss: 1.7572 (1.7604)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0175 (4.3236)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8262)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8281)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8220)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8476)  Batch Accuracy (Choose Caption): 0.8906 (0.8878)  Batch Accuracy (Choose Image): 0.9062 (0.8934)  Masked Language Modeling Accuracy: 0.6237 (0.6430)  time: 0.6717 (0.7961)  data: 0.0189 (0.0975)  lr: 0.010000  max mem: 11938
2021-04-02 01:16:14,036 maskrcnn_benchmark.trainer INFO: eta: 4:48:28  iter: 18200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5366 (0.5185)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5248 (0.5067)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4518 (0.5204)  Cross-Entropy Loss (Align Words, Choose Image): 0.4202 (0.4429)  Image Caption Matching Loss: 0.4992 (0.5739)  Masked Language Modeling Loss: 1.8305 (1.7603)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2019 (4.3227)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8264)  Batch Accuracy (Align Regions, Choose Image): 0.7969 (0.8281)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8221)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8478)  Batch Accuracy (Choose Caption): 0.8906 (0.8878)  Batch Accuracy (Choose Image): 0.8906 (0.8934)  Masked Language Modeling Accuracy: 0.6089 (0.6430)  time: 0.6683 (0.7940)  data: 0.0215 (0.0959)  lr: 0.010000  max mem: 11938
2021-04-02 01:17:26,066 maskrcnn_benchmark.trainer INFO: eta: 4:46:32  iter: 18300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5089 (0.5184)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5042 (0.5067)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5165 (0.5198)  Cross-Entropy Loss (Align Words, Choose Image): 0.4347 (0.4424)  Image Caption Matching Loss: 0.5234 (0.5731)  Masked Language Modeling Loss: 1.6291 (1.7594)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0771 (4.3199)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8264)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8281)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8224)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8478)  Batch Accuracy (Choose Caption): 0.8906 (0.8880)  Batch Accuracy (Choose Image): 0.8906 (0.8934)  Masked Language Modeling Accuracy: 0.6656 (0.6431)  time: 0.6668 (0.7923)  data: 0.0186 (0.0944)  lr: 0.010000  max mem: 11938
2021-04-02 01:18:42,923 maskrcnn_benchmark.trainer INFO: eta: 4:45:01  iter: 18400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4975 (0.5182)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4687 (0.5063)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5073 (0.5195)  Cross-Entropy Loss (Align Words, Choose Image): 0.4056 (0.4419)  Image Caption Matching Loss: 0.5365 (0.5719)  Masked Language Modeling Loss: 1.7642 (1.7585)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1621 (4.3164)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8264)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8282)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8224)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8479)  Batch Accuracy (Choose Caption): 0.8906 (0.8882)  Batch Accuracy (Choose Image): 0.8906 (0.8937)  Masked Language Modeling Accuracy: 0.6261 (0.6433)  time: 0.6782 (0.7917)  data: 0.0222 (0.0930)  lr: 0.010000  max mem: 11938
2021-04-02 01:19:53,637 maskrcnn_benchmark.trainer INFO: eta: 4:43:02  iter: 18500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4936 (0.5180)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5156 (0.5063)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5075 (0.5190)  Cross-Entropy Loss (Align Words, Choose Image): 0.4397 (0.4415)  Image Caption Matching Loss: 0.5319 (0.5710)  Masked Language Modeling Loss: 1.5852 (1.7578)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2832 (4.3136)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8265)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8282)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8225)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8481)  Batch Accuracy (Choose Caption): 0.9062 (0.8884)  Batch Accuracy (Choose Image): 0.9219 (0.8938)  Masked Language Modeling Accuracy: 0.6548 (0.6434)  time: 0.6786 (0.7899)  data: 0.0198 (0.0916)  lr: 0.010000  max mem: 11938
2021-04-02 01:21:05,501 maskrcnn_benchmark.trainer INFO: eta: 4:41:09  iter: 18600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5319 (0.5175)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4406 (0.5058)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5160 (0.5186)  Cross-Entropy Loss (Align Words, Choose Image): 0.4252 (0.4411)  Image Caption Matching Loss: 0.4912 (0.5700)  Masked Language Modeling Loss: 1.7013 (1.7571)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3413 (4.3100)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8266)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8284)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8226)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8483)  Batch Accuracy (Choose Caption): 0.8906 (0.8885)  Batch Accuracy (Choose Image): 0.9062 (0.8941)  Masked Language Modeling Accuracy: 0.6390 (0.6435)  time: 0.6714 (0.7883)  data: 0.0194 (0.0902)  lr: 0.010000  max mem: 11938
2021-04-02 01:22:19,147 maskrcnn_benchmark.trainer INFO: eta: 4:39:27  iter: 18700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5138 (0.5172)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5017 (0.5055)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4788 (0.5178)  Cross-Entropy Loss (Align Words, Choose Image): 0.4951 (0.4407)  Image Caption Matching Loss: 0.5494 (0.5697)  Masked Language Modeling Loss: 1.7752 (1.7560)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.4383 (4.3069)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8268)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8285)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8228)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8483)  Batch Accuracy (Choose Caption): 0.8750 (0.8887)  Batch Accuracy (Choose Image): 0.8906 (0.8941)  Masked Language Modeling Accuracy: 0.6122 (0.6435)  time: 0.6641 (0.7872)  data: 0.0192 (0.0889)  lr: 0.010000  max mem: 11938
2021-04-02 01:23:28,635 maskrcnn_benchmark.trainer INFO: eta: 4:37:28  iter: 18800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5233 (0.5169)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4920 (0.5052)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4914 (0.5172)  Cross-Entropy Loss (Align Words, Choose Image): 0.4288 (0.4403)  Image Caption Matching Loss: 0.5329 (0.5690)  Masked Language Modeling Loss: 1.7470 (1.7555)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3292 (4.3040)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8270)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8285)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8231)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8484)  Batch Accuracy (Choose Caption): 0.8906 (0.8888)  Batch Accuracy (Choose Image): 0.8906 (0.8942)  Masked Language Modeling Accuracy: 0.6484 (0.6436)  time: 0.6681 (0.7853)  data: 0.0187 (0.0875)  lr: 0.010000  max mem: 11938
2021-04-02 01:24:42,771 maskrcnn_benchmark.trainer INFO: eta: 4:35:50  iter: 18900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4922 (0.5166)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4862 (0.5045)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4878 (0.5168)  Cross-Entropy Loss (Align Words, Choose Image): 0.4221 (0.4399)  Image Caption Matching Loss: 0.5523 (0.5677)  Masked Language Modeling Loss: 1.7031 (1.7562)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1359 (4.3017)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8272)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8288)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8234)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8487)  Batch Accuracy (Choose Caption): 0.9062 (0.8891)  Batch Accuracy (Choose Image): 0.8906 (0.8944)  Masked Language Modeling Accuracy: 0.6305 (0.6435)  time: 0.6770 (0.7844)  data: 0.0185 (0.0863)  lr: 0.010000  max mem: 11938
2021-04-02 01:25:55,043 maskrcnn_benchmark.trainer INFO: eta: 4:34:06  iter: 19000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5005 (0.5163)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4563 (0.5042)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5070 (0.5170)  Cross-Entropy Loss (Align Words, Choose Image): 0.4047 (0.4397)  Image Caption Matching Loss: 0.4260 (0.5668)  Masked Language Modeling Loss: 1.7329 (1.7560)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0377 (4.3001)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8273)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8289)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8235)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8487)  Batch Accuracy (Choose Caption): 0.9062 (0.8893)  Batch Accuracy (Choose Image): 0.9219 (0.8946)  Masked Language Modeling Accuracy: 0.6503 (0.6434)  time: 0.6697 (0.7832)  data: 0.0185 (0.0852)  lr: 0.010000  max mem: 11938
2021-04-02 01:25:55,340 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0019000.pth
2021-04-02 01:27:03,715 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 4:34:06  iter: 19000  loss: 1.9349 (1.9986)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3466 (0.3614)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3385 (0.3801)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4106 (0.4413)  Cross-Entropy Loss (Align Words, Choose Image): 0.3018 (0.3384)  Image Caption Matching Loss: 0.4246 (0.4774)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8667)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8709)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8554)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8776)  Batch Accuracy (Choose Caption): 0.9062 (0.9072)  Batch Accuracy (Choose Image): 0.9219 (0.9132)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.010000  max mem: 11938
2021-04-02 01:28:12,544 maskrcnn_benchmark.trainer INFO: eta: 4:36:50  iter: 19100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5226 (0.5157)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4928 (0.5039)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4449 (0.5163)  Cross-Entropy Loss (Align Words, Choose Image): 0.3832 (0.4392)  Image Caption Matching Loss: 0.5122 (0.5660)  Masked Language Modeling Loss: 1.7325 (1.7559)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.1050 (4.2970)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8275)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8290)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8236)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8489)  Batch Accuracy (Choose Caption): 0.8906 (0.8895)  Batch Accuracy (Choose Image): 0.8906 (0.8948)  Masked Language Modeling Accuracy: 0.6551 (0.6435)  time: 0.6657 (0.7948)  data: 0.0191 (0.0975)  lr: 0.010000  max mem: 11938
2021-04-02 01:29:25,068 maskrcnn_benchmark.trainer INFO: eta: 4:35:03  iter: 19200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4828 (0.5152)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4308 (0.5034)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4781 (0.5157)  Cross-Entropy Loss (Align Words, Choose Image): 0.4061 (0.4388)  Image Caption Matching Loss: 0.4838 (0.5654)  Masked Language Modeling Loss: 1.6918 (1.7546)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0789 (4.2932)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8276)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8291)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8238)  Batch Accuracy (Align Words, Choose Image): 0.8281 (0.8491)  Batch Accuracy (Choose Caption): 0.9062 (0.8896)  Batch Accuracy (Choose Image): 0.9062 (0.8948)  Masked Language Modeling Accuracy: 0.6444 (0.6436)  time: 0.6640 (0.7934)  data: 0.0196 (0.0961)  lr: 0.010000  max mem: 11938
2021-04-02 01:30:43,462 maskrcnn_benchmark.trainer INFO: eta: 4:33:40  iter: 19300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4867 (0.5148)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4413 (0.5029)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4864 (0.5150)  Cross-Entropy Loss (Align Words, Choose Image): 0.3894 (0.4381)  Image Caption Matching Loss: 0.5388 (0.5644)  Masked Language Modeling Loss: 1.6878 (1.7544)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0162 (4.2897)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8278)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8294)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8241)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8493)  Batch Accuracy (Choose Caption): 0.8906 (0.8898)  Batch Accuracy (Choose Image): 0.8750 (0.8950)  Masked Language Modeling Accuracy: 0.6577 (0.6437)  time: 0.6727 (0.7932)  data: 0.0188 (0.0949)  lr: 0.010000  max mem: 11938
2021-04-02 01:31:52,733 maskrcnn_benchmark.trainer INFO: eta: 4:31:41  iter: 19400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5224 (0.5143)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5027 (0.5028)  Cross-Entropy Loss (Align Words, Choose Caption): 0.5130 (0.5145)  Cross-Entropy Loss (Align Words, Choose Image): 0.4705 (0.4378)  Image Caption Matching Loss: 0.5674 (0.5639)  Masked Language Modeling Loss: 1.6930 (1.7548)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.3077 (4.2881)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8279)  Batch Accuracy (Align Regions, Choose Image): 0.8125 (0.8295)  Batch Accuracy (Align Words, Choose Caption): 0.8125 (0.8243)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8494)  Batch Accuracy (Choose Caption): 0.8906 (0.8900)  Batch Accuracy (Choose Image): 0.8906 (0.8950)  Masked Language Modeling Accuracy: 0.6383 (0.6436)  time: 0.6730 (0.7914)  data: 0.0189 (0.0935)  lr: 0.010000  max mem: 11938
2021-04-02 01:33:05,197 maskrcnn_benchmark.trainer INFO: eta: 4:29:58  iter: 19500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4796 (0.5135)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4534 (0.5021)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4688 (0.5137)  Cross-Entropy Loss (Align Words, Choose Image): 0.3806 (0.4370)  Image Caption Matching Loss: 0.5282 (0.5626)  Masked Language Modeling Loss: 1.6980 (1.7545)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0138 (4.2834)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8281)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8297)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8245)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8496)  Batch Accuracy (Choose Caption): 0.9062 (0.8902)  Batch Accuracy (Choose Image): 0.9062 (0.8953)  Masked Language Modeling Accuracy: 0.6423 (0.6435)  time: 0.6790 (0.7902)  data: 0.0189 (0.0924)  lr: 0.010000  max mem: 11938
2021-04-02 01:34:16,593 maskrcnn_benchmark.trainer INFO: eta: 4:28:11  iter: 19600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5080 (0.5131)  Cross-Entropy Loss (Align Regions, Choose Image): 0.5015 (0.5016)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4744 (0.5131)  Cross-Entropy Loss (Align Words, Choose Image): 0.4034 (0.4364)  Image Caption Matching Loss: 0.4284 (0.5616)  Masked Language Modeling Loss: 1.6707 (1.7538)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0738 (4.2796)  Batch Accuracy (Align Regions, Choose Caption): 0.8281 (0.8283)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8299)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8247)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8498)  Batch Accuracy (Choose Caption): 0.8906 (0.8904)  Batch Accuracy (Choose Image): 0.9062 (0.8955)  Masked Language Modeling Accuracy: 0.6446 (0.6436)  time: 0.6741 (0.7888)  data: 0.0190 (0.0912)  lr: 0.010000  max mem: 11938
2021-04-02 01:35:28,588 maskrcnn_benchmark.trainer INFO: eta: 4:26:28  iter: 19700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4605 (0.5130)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4267 (0.5012)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3953 (0.5126)  Cross-Entropy Loss (Align Words, Choose Image): 0.3773 (0.4361)  Image Caption Matching Loss: 0.5171 (0.5610)  Masked Language Modeling Loss: 1.6613 (1.7539)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.9490 (4.2779)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8284)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8300)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8248)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8499)  Batch Accuracy (Choose Caption): 0.9062 (0.8905)  Batch Accuracy (Choose Image): 0.9062 (0.8957)  Masked Language Modeling Accuracy: 0.6564 (0.6436)  time: 0.6693 (0.7876)  data: 0.0200 (0.0901)  lr: 0.010000  max mem: 11938
2021-04-02 01:36:37,160 maskrcnn_benchmark.trainer INFO: eta: 4:24:34  iter: 19800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5092 (0.5127)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4949 (0.5011)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4773 (0.5123)  Cross-Entropy Loss (Align Words, Choose Image): 0.4325 (0.4360)  Image Caption Matching Loss: 0.4459 (0.5600)  Masked Language Modeling Loss: 1.7831 (1.7537)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.2519 (4.2758)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8285)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8300)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8248)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8500)  Batch Accuracy (Choose Caption): 0.9062 (0.8907)  Batch Accuracy (Choose Image): 0.9062 (0.8958)  Masked Language Modeling Accuracy: 0.6369 (0.6437)  time: 0.6662 (0.7859)  data: 0.0189 (0.0890)  lr: 0.010000  max mem: 11938
2021-04-02 01:37:46,862 maskrcnn_benchmark.trainer INFO: eta: 4:22:45  iter: 19900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.5161 (0.5119)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4155 (0.5003)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4829 (0.5116)  Cross-Entropy Loss (Align Words, Choose Image): 0.3960 (0.4353)  Image Caption Matching Loss: 0.5150 (0.5589)  Masked Language Modeling Loss: 1.7487 (1.7538)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 4.0985 (4.2718)  Batch Accuracy (Align Regions, Choose Caption): 0.8125 (0.8286)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8303)  Batch Accuracy (Align Words, Choose Caption): 0.8281 (0.8252)  Batch Accuracy (Align Words, Choose Image): 0.8594 (0.8502)  Batch Accuracy (Choose Caption): 0.8906 (0.8909)  Batch Accuracy (Choose Image): 0.9062 (0.8961)  Masked Language Modeling Accuracy: 0.6381 (0.6437)  time: 0.6746 (0.7843)  data: 0.0198 (0.0880)  lr: 0.010000  max mem: 11938
2021-04-02 01:39:03,022 maskrcnn_benchmark.trainer INFO: eta: 4:21:19  iter: 20000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4328 (0.5116)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4328 (0.4998)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4286 (0.5112)  Cross-Entropy Loss (Align Words, Choose Image): 0.3775 (0.4349)  Image Caption Matching Loss: 0.4421 (0.5582)  Masked Language Modeling Loss: 1.6850 (1.7538)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.6919 (4.2695)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8287)  Batch Accuracy (Align Regions, Choose Image): 0.8281 (0.8305)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8254)  Batch Accuracy (Align Words, Choose Image): 0.8438 (0.8502)  Batch Accuracy (Choose Caption): 0.9219 (0.8910)  Batch Accuracy (Choose Image): 0.9062 (0.8962)  Masked Language Modeling Accuracy: 0.6492 (0.6436)  time: 0.6712 (0.7840)  data: 0.0191 (0.0870)  lr: 0.001000  max mem: 11938
2021-04-02 01:39:03,332 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0020000.pth
2021-04-02 01:40:11,054 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 4:21:19  iter: 20000  loss: 1.8321 (1.9232)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3199 (0.3493)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3275 (0.3479)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3946 (0.4085)  Cross-Entropy Loss (Align Words, Choose Image): 0.3460 (0.3545)  Image Caption Matching Loss: 0.4091 (0.4631)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8888)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8812)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8553)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8813)  Batch Accuracy (Choose Caption): 0.9062 (0.9092)  Batch Accuracy (Choose Image): 0.9062 (0.9175)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11938
2021-04-02 01:41:20,452 maskrcnn_benchmark.trainer INFO: eta: 4:23:13  iter: 20100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3727 (0.5103)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3291 (0.4982)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3427 (0.5097)  Cross-Entropy Loss (Align Words, Choose Image): 0.3082 (0.4339)  Image Caption Matching Loss: 0.3401 (0.5559)  Masked Language Modeling Loss: 1.5638 (1.7521)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3505 (4.2602)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8291)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8310)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8259)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8505)  Batch Accuracy (Choose Caption): 0.9219 (0.8914)  Batch Accuracy (Choose Image): 0.9219 (0.8966)  Masked Language Modeling Accuracy: 0.6730 (0.6439)  time: 0.6757 (0.7936)  data: 0.0206 (0.0973)  lr: 0.001000  max mem: 11938
2021-04-02 01:42:28,755 maskrcnn_benchmark.trainer INFO: eta: 4:21:18  iter: 20200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3804 (0.5090)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3576 (0.4968)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4240 (0.5082)  Cross-Entropy Loss (Align Words, Choose Image): 0.3062 (0.4325)  Image Caption Matching Loss: 0.4154 (0.5537)  Masked Language Modeling Loss: 1.6626 (1.7513)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.6491 (4.2515)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8296)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8315)  Batch Accuracy (Align Words, Choose Caption): 0.8438 (0.8264)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8510)  Batch Accuracy (Choose Caption): 0.9219 (0.8919)  Batch Accuracy (Choose Image): 0.9219 (0.8970)  Masked Language Modeling Accuracy: 0.6446 (0.6440)  time: 0.6661 (0.7919)  data: 0.0189 (0.0961)  lr: 0.001000  max mem: 11938
2021-04-02 01:43:37,252 maskrcnn_benchmark.trainer INFO: eta: 4:19:26  iter: 20300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3372 (0.5073)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3327 (0.4952)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3685 (0.5063)  Cross-Entropy Loss (Align Words, Choose Image): 0.3156 (0.4310)  Image Caption Matching Loss: 0.3255 (0.5512)  Masked Language Modeling Loss: 1.6066 (1.7504)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4122 (4.2414)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8302)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8321)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8270)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8515)  Batch Accuracy (Choose Caption): 0.9375 (0.8924)  Batch Accuracy (Choose Image): 0.9375 (0.8974)  Masked Language Modeling Accuracy: 0.6507 (0.6441)  time: 0.6695 (0.7902)  data: 0.0193 (0.0950)  lr: 0.001000  max mem: 11938
2021-04-02 01:44:46,732 maskrcnn_benchmark.trainer INFO: eta: 4:17:37  iter: 20400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3877 (0.5056)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3759 (0.4938)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3490 (0.5044)  Cross-Entropy Loss (Align Words, Choose Image): 0.3340 (0.4297)  Image Caption Matching Loss: 0.3630 (0.5489)  Masked Language Modeling Loss: 1.5291 (1.7488)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1822 (4.2312)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8307)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8326)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8276)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8520)  Batch Accuracy (Choose Caption): 0.9219 (0.8929)  Batch Accuracy (Choose Image): 0.9219 (0.8978)  Masked Language Modeling Accuracy: 0.6723 (0.6444)  time: 0.6730 (0.7887)  data: 0.0191 (0.0939)  lr: 0.001000  max mem: 11938
2021-04-02 01:45:57,509 maskrcnn_benchmark.trainer INFO: eta: 4:15:54  iter: 20500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4002 (0.5042)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3936 (0.4921)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3485 (0.5027)  Cross-Entropy Loss (Align Words, Choose Image): 0.3060 (0.4284)  Image Caption Matching Loss: 0.3718 (0.5468)  Masked Language Modeling Loss: 1.6518 (1.7482)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4412 (4.2223)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8312)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8331)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8281)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8523)  Batch Accuracy (Choose Caption): 0.9219 (0.8934)  Batch Accuracy (Choose Image): 0.9219 (0.8982)  Masked Language Modeling Accuracy: 0.6629 (0.6445)  time: 0.6757 (0.7874)  data: 0.0188 (0.0929)  lr: 0.001000  max mem: 11938
2021-04-02 01:47:07,455 maskrcnn_benchmark.trainer INFO: eta: 4:14:10  iter: 20600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3929 (0.5023)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3534 (0.4904)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3761 (0.5006)  Cross-Entropy Loss (Align Words, Choose Image): 0.3220 (0.4268)  Image Caption Matching Loss: 0.3323 (0.5442)  Masked Language Modeling Loss: 1.6919 (1.7475)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4877 (4.2118)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8318)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8336)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8288)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8529)  Batch Accuracy (Choose Caption): 0.9375 (0.8939)  Batch Accuracy (Choose Image): 0.9219 (0.8986)  Masked Language Modeling Accuracy: 0.6565 (0.6446)  time: 0.6686 (0.7861)  data: 0.0190 (0.0918)  lr: 0.001000  max mem: 11938
2021-04-02 01:48:18,839 maskrcnn_benchmark.trainer INFO: eta: 4:12:30  iter: 20700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4076 (0.5008)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4004 (0.4889)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4166 (0.4989)  Cross-Entropy Loss (Align Words, Choose Image): 0.3351 (0.4254)  Image Caption Matching Loss: 0.4018 (0.5419)  Masked Language Modeling Loss: 1.7602 (1.7469)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.7282 (4.2028)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8323)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8341)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8294)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8533)  Batch Accuracy (Choose Caption): 0.9219 (0.8944)  Batch Accuracy (Choose Image): 0.9219 (0.8990)  Masked Language Modeling Accuracy: 0.6415 (0.6447)  time: 0.6703 (0.7850)  data: 0.0190 (0.0909)  lr: 0.001000  max mem: 11938
2021-04-02 01:49:27,795 maskrcnn_benchmark.trainer INFO: eta: 4:10:45  iter: 20800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3684 (0.4991)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3748 (0.4874)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3592 (0.4971)  Cross-Entropy Loss (Align Words, Choose Image): 0.2908 (0.4239)  Image Caption Matching Loss: 0.3710 (0.5396)  Masked Language Modeling Loss: 1.6299 (1.7457)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4303 (4.1927)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8329)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8346)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8300)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8538)  Batch Accuracy (Choose Caption): 0.9219 (0.8948)  Batch Accuracy (Choose Image): 0.9219 (0.8993)  Masked Language Modeling Accuracy: 0.6820 (0.6450)  time: 0.6720 (0.7836)  data: 0.0185 (0.0899)  lr: 0.001000  max mem: 11938
2021-04-02 01:50:36,346 maskrcnn_benchmark.trainer INFO: eta: 4:08:59  iter: 20900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4179 (0.4977)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3976 (0.4858)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3971 (0.4953)  Cross-Entropy Loss (Align Words, Choose Image): 0.3265 (0.4224)  Image Caption Matching Loss: 0.4167 (0.5374)  Masked Language Modeling Loss: 1.7460 (1.7450)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.7131 (4.1836)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8333)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8350)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8306)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8543)  Batch Accuracy (Choose Caption): 0.9062 (0.8953)  Batch Accuracy (Choose Image): 0.9219 (0.8997)  Masked Language Modeling Accuracy: 0.6443 (0.6450)  time: 0.6728 (0.7822)  data: 0.0189 (0.0890)  lr: 0.001000  max mem: 11938
2021-04-02 01:51:47,100 maskrcnn_benchmark.trainer INFO: eta: 4:07:21  iter: 21000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4121 (0.4962)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3935 (0.4846)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3542 (0.4935)  Cross-Entropy Loss (Align Words, Choose Image): 0.3412 (0.4210)  Image Caption Matching Loss: 0.4052 (0.5350)  Masked Language Modeling Loss: 1.7520 (1.7440)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.7086 (4.1743)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8338)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8355)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8312)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8547)  Batch Accuracy (Choose Caption): 0.9375 (0.8958)  Batch Accuracy (Choose Image): 0.9219 (0.9001)  Masked Language Modeling Accuracy: 0.6369 (0.6451)  time: 0.6827 (0.7811)  data: 0.0181 (0.0881)  lr: 0.001000  max mem: 11938
2021-04-02 01:51:47,404 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0021000.pth
2021-04-02 01:52:55,056 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 4:07:21  iter: 21000  loss: 1.4948 (1.4630)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2512 (0.2749)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2745 (0.2892)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3020 (0.3094)  Cross-Entropy Loss (Align Words, Choose Image): 0.2873 (0.2650)  Image Caption Matching Loss: 0.3673 (0.3244)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9098)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9034)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8887)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9073)  Batch Accuracy (Choose Caption): 0.9375 (0.9378)  Batch Accuracy (Choose Image): 0.9531 (0.9431)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11938
2021-04-02 01:54:09,669 maskrcnn_benchmark.trainer INFO: eta: 4:08:54  iter: 21100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3380 (0.4947)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3368 (0.4833)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3125 (0.4919)  Cross-Entropy Loss (Align Words, Choose Image): 0.2843 (0.4197)  Image Caption Matching Loss: 0.3205 (0.5329)  Masked Language Modeling Loss: 1.7473 (1.7427)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2573 (4.1652)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8343)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8359)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8317)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8551)  Batch Accuracy (Choose Caption): 0.9531 (0.8963)  Batch Accuracy (Choose Image): 0.9375 (0.9004)  Masked Language Modeling Accuracy: 0.6319 (0.6453)  time: 0.6706 (0.7902)  data: 0.0186 (0.0968)  lr: 0.001000  max mem: 11938
2021-04-02 01:55:17,974 maskrcnn_benchmark.trainer INFO: eta: 4:07:07  iter: 21200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4088 (0.4933)  Cross-Entropy Loss (Align Regions, Choose Image): 0.4662 (0.4820)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4009 (0.4903)  Cross-Entropy Loss (Align Words, Choose Image): 0.3892 (0.4185)  Image Caption Matching Loss: 0.3952 (0.5306)  Masked Language Modeling Loss: 1.5900 (1.7413)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.6018 (4.1560)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8348)  Batch Accuracy (Align Regions, Choose Image): 0.8438 (0.8363)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8323)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8555)  Batch Accuracy (Choose Caption): 0.9375 (0.8967)  Batch Accuracy (Choose Image): 0.9219 (0.9008)  Masked Language Modeling Accuracy: 0.6599 (0.6454)  time: 0.6761 (0.7887)  data: 0.0190 (0.0958)  lr: 0.001000  max mem: 11938
2021-04-02 01:56:29,273 maskrcnn_benchmark.trainer INFO: eta: 4:05:29  iter: 21300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3430 (0.4917)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3658 (0.4806)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3573 (0.4886)  Cross-Entropy Loss (Align Words, Choose Image): 0.3113 (0.4172)  Image Caption Matching Loss: 0.3872 (0.5284)  Masked Language Modeling Loss: 1.6601 (1.7404)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4257 (4.1468)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8353)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8367)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8328)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8560)  Batch Accuracy (Choose Caption): 0.9062 (0.8972)  Batch Accuracy (Choose Image): 0.9375 (0.9011)  Masked Language Modeling Accuracy: 0.6594 (0.6456)  time: 0.6700 (0.7877)  data: 0.0183 (0.0948)  lr: 0.001000  max mem: 11938
2021-04-02 01:57:37,264 maskrcnn_benchmark.trainer INFO: eta: 4:03:43  iter: 21400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3643 (0.4901)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3564 (0.4790)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3164 (0.4869)  Cross-Entropy Loss (Align Words, Choose Image): 0.2534 (0.4157)  Image Caption Matching Loss: 0.2993 (0.5261)  Masked Language Modeling Loss: 1.5843 (1.7388)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1783 (4.1366)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8358)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8372)  Batch Accuracy (Align Words, Choose Caption): 0.8884 (0.8334)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8564)  Batch Accuracy (Choose Caption): 0.9531 (0.8977)  Batch Accuracy (Choose Image): 0.9438 (0.9014)  Masked Language Modeling Accuracy: 0.6735 (0.6460)  time: 0.6736 (0.7862)  data: 0.0198 (0.0939)  lr: 0.001000  max mem: 11938
2021-04-02 01:58:46,105 maskrcnn_benchmark.trainer INFO: eta: 4:02:01  iter: 21500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3150 (0.4884)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3096 (0.4772)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3317 (0.4849)  Cross-Entropy Loss (Align Words, Choose Image): 0.3070 (0.4142)  Image Caption Matching Loss: 0.3107 (0.5236)  Masked Language Modeling Loss: 1.5657 (1.7371)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2671 (4.1254)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8364)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8377)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8341)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8569)  Batch Accuracy (Choose Caption): 0.9375 (0.8982)  Batch Accuracy (Choose Image): 0.9375 (0.9019)  Masked Language Modeling Accuracy: 0.6525 (0.6462)  time: 0.6714 (0.7849)  data: 0.0187 (0.0930)  lr: 0.001000  max mem: 11938
2021-04-02 01:59:54,951 maskrcnn_benchmark.trainer INFO: eta: 4:00:18  iter: 21600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3793 (0.4868)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3967 (0.4756)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3314 (0.4831)  Cross-Entropy Loss (Align Words, Choose Image): 0.3189 (0.4127)  Image Caption Matching Loss: 0.3379 (0.5213)  Masked Language Modeling Loss: 1.5472 (1.7357)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4948 (4.1151)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8370)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8382)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8347)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8574)  Batch Accuracy (Choose Caption): 0.9219 (0.8987)  Batch Accuracy (Choose Image): 0.9219 (0.9022)  Masked Language Modeling Accuracy: 0.6900 (0.6464)  time: 0.6656 (0.7836)  data: 0.0186 (0.0921)  lr: 0.001000  max mem: 11938
2021-04-02 02:01:10,873 maskrcnn_benchmark.trainer INFO: eta: 3:58:54  iter: 21700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2992 (0.4850)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2936 (0.4741)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3100 (0.4813)  Cross-Entropy Loss (Align Words, Choose Image): 0.2572 (0.4111)  Image Caption Matching Loss: 0.2712 (0.5189)  Masked Language Modeling Loss: 1.6754 (1.7348)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0739 (4.1052)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8376)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8388)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8353)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8579)  Batch Accuracy (Choose Caption): 0.9531 (0.8992)  Batch Accuracy (Choose Image): 0.9531 (0.9026)  Masked Language Modeling Accuracy: 0.6594 (0.6466)  time: 0.6670 (0.7833)  data: 0.0186 (0.0913)  lr: 0.001000  max mem: 11938
2021-04-02 02:02:19,802 maskrcnn_benchmark.trainer INFO: eta: 3:57:14  iter: 21800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3534 (0.4833)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3429 (0.4725)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3566 (0.4796)  Cross-Entropy Loss (Align Words, Choose Image): 0.3043 (0.4098)  Image Caption Matching Loss: 0.3404 (0.5167)  Masked Language Modeling Loss: 1.7248 (1.7346)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4383 (4.0966)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8381)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8393)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8358)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8584)  Batch Accuracy (Choose Caption): 0.9219 (0.8996)  Batch Accuracy (Choose Image): 0.9375 (0.9030)  Masked Language Modeling Accuracy: 0.6432 (0.6466)  time: 0.6686 (0.7821)  data: 0.0197 (0.0905)  lr: 0.001000  max mem: 11938
2021-04-02 02:03:29,330 maskrcnn_benchmark.trainer INFO: eta: 3:55:36  iter: 21900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3166 (0.4821)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3294 (0.4713)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2915 (0.4780)  Cross-Entropy Loss (Align Words, Choose Image): 0.3275 (0.4086)  Image Caption Matching Loss: 0.3590 (0.5149)  Masked Language Modeling Loss: 1.6309 (1.7333)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3838 (4.0882)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8385)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8396)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8363)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8587)  Batch Accuracy (Choose Caption): 0.9375 (0.9000)  Batch Accuracy (Choose Image): 0.9375 (0.9033)  Masked Language Modeling Accuracy: 0.6677 (0.6469)  time: 0.6758 (0.7810)  data: 0.0225 (0.0897)  lr: 0.001000  max mem: 11938
2021-04-02 02:04:38,197 maskrcnn_benchmark.trainer INFO: eta: 3:53:57  iter: 22000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3151 (0.4808)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3130 (0.4701)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3101 (0.4765)  Cross-Entropy Loss (Align Words, Choose Image): 0.2559 (0.4074)  Image Caption Matching Loss: 0.3064 (0.5128)  Masked Language Modeling Loss: 1.6791 (1.7315)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3301 (4.0791)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8390)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8400)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8369)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8592)  Batch Accuracy (Choose Caption): 0.9531 (0.9004)  Batch Accuracy (Choose Image): 0.9375 (0.9036)  Masked Language Modeling Accuracy: 0.6498 (0.6472)  time: 0.6782 (0.7799)  data: 0.0187 (0.0889)  lr: 0.001000  max mem: 11938
2021-04-02 02:04:38,516 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0022000.pth
2021-04-02 02:05:46,865 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 3:53:57  iter: 22000  loss: 1.3887 (1.3582)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2457 (0.2548)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2613 (0.2652)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2980 (0.2912)  Cross-Entropy Loss (Align Words, Choose Image): 0.2421 (0.2460)  Image Caption Matching Loss: 0.3346 (0.3010)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.9098)  Batch Accuracy (Align Regions, Choose Image): 0.9167 (0.9068)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8959)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9129)  Batch Accuracy (Choose Caption): 0.9219 (0.9464)  Batch Accuracy (Choose Image): 0.9375 (0.9454)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11938
2021-04-02 02:06:59,366 maskrcnn_benchmark.trainer INFO: eta: 3:54:59  iter: 22100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3697 (0.4794)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3478 (0.4687)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2712 (0.4748)  Cross-Entropy Loss (Align Words, Choose Image): 0.2680 (0.4061)  Image Caption Matching Loss: 0.3413 (0.5108)  Masked Language Modeling Loss: 1.6045 (1.7306)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1284 (4.0706)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8395)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8404)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8375)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8596)  Batch Accuracy (Choose Caption): 0.9375 (0.9008)  Batch Accuracy (Choose Image): 0.9531 (0.9040)  Masked Language Modeling Accuracy: 0.6448 (0.6473)  time: 0.6698 (0.7877)  data: 0.0187 (0.0967)  lr: 0.001000  max mem: 11938
2021-04-02 02:08:11,675 maskrcnn_benchmark.trainer INFO: eta: 3:53:26  iter: 22200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3324 (0.4782)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3339 (0.4677)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3004 (0.4734)  Cross-Entropy Loss (Align Words, Choose Image): 0.2595 (0.4049)  Image Caption Matching Loss: 0.3132 (0.5087)  Masked Language Modeling Loss: 1.5470 (1.7296)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1285 (4.0625)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8398)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8407)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8379)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8599)  Batch Accuracy (Choose Caption): 0.9375 (0.9012)  Batch Accuracy (Choose Image): 0.9375 (0.9043)  Masked Language Modeling Accuracy: 0.6647 (0.6475)  time: 0.6717 (0.7869)  data: 0.0188 (0.0958)  lr: 0.001000  max mem: 11938
2021-04-02 02:09:21,083 maskrcnn_benchmark.trainer INFO: eta: 3:51:47  iter: 22300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3522 (0.4770)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3758 (0.4665)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3329 (0.4719)  Cross-Entropy Loss (Align Words, Choose Image): 0.2745 (0.4037)  Image Caption Matching Loss: 0.3286 (0.5068)  Masked Language Modeling Loss: 1.6843 (1.7288)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3310 (4.0547)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8403)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8412)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8384)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8603)  Batch Accuracy (Choose Caption): 0.9219 (0.9016)  Batch Accuracy (Choose Image): 0.9219 (0.9046)  Masked Language Modeling Accuracy: 0.6499 (0.6476)  time: 0.6707 (0.7858)  data: 0.0190 (0.0950)  lr: 0.001000  max mem: 11938
2021-04-02 02:10:31,948 maskrcnn_benchmark.trainer INFO: eta: 3:50:13  iter: 22400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3610 (0.4758)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3888 (0.4652)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3321 (0.4703)  Cross-Entropy Loss (Align Words, Choose Image): 0.2814 (0.4024)  Image Caption Matching Loss: 0.3249 (0.5051)  Masked Language Modeling Loss: 1.5317 (1.7273)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3341 (4.0461)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8407)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8416)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8390)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8607)  Batch Accuracy (Choose Caption): 0.9375 (0.9020)  Batch Accuracy (Choose Image): 0.9219 (0.9049)  Masked Language Modeling Accuracy: 0.6805 (0.6478)  time: 0.6690 (0.7848)  data: 0.0196 (0.0942)  lr: 0.001000  max mem: 11938
2021-04-02 02:11:40,808 maskrcnn_benchmark.trainer INFO: eta: 3:48:34  iter: 22500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3938 (0.4746)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3980 (0.4641)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3305 (0.4688)  Cross-Entropy Loss (Align Words, Choose Image): 0.3040 (0.4012)  Image Caption Matching Loss: 0.3743 (0.5034)  Masked Language Modeling Loss: 1.6662 (1.7264)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.5007 (4.0385)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8411)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8420)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8395)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8611)  Batch Accuracy (Choose Caption): 0.9375 (0.9023)  Batch Accuracy (Choose Image): 0.9375 (0.9052)  Masked Language Modeling Accuracy: 0.6685 (0.6479)  time: 0.6667 (0.7837)  data: 0.0187 (0.0934)  lr: 0.001000  max mem: 11938
2021-04-02 02:12:52,954 maskrcnn_benchmark.trainer INFO: eta: 3:47:03  iter: 22600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3328 (0.4735)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3331 (0.4629)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3235 (0.4673)  Cross-Entropy Loss (Align Words, Choose Image): 0.2581 (0.3999)  Image Caption Matching Loss: 0.3220 (0.5017)  Masked Language Modeling Loss: 1.7207 (1.7256)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2219 (4.0308)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8415)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8423)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8400)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8616)  Batch Accuracy (Choose Caption): 0.9219 (0.9026)  Batch Accuracy (Choose Image): 0.9375 (0.9055)  Masked Language Modeling Accuracy: 0.6329 (0.6481)  time: 0.6738 (0.7830)  data: 0.0190 (0.0926)  lr: 0.001000  max mem: 11938
2021-04-02 02:14:01,822 maskrcnn_benchmark.trainer INFO: eta: 3:45:26  iter: 22700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3797 (0.4726)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3598 (0.4620)  Cross-Entropy Loss (Align Words, Choose Caption): 0.4020 (0.4663)  Cross-Entropy Loss (Align Words, Choose Image): 0.3566 (0.3990)  Image Caption Matching Loss: 0.4168 (0.5001)  Masked Language Modeling Loss: 1.6318 (1.7244)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4544 (4.0242)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8419)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8426)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8404)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8618)  Batch Accuracy (Choose Caption): 0.9219 (0.9029)  Batch Accuracy (Choose Image): 0.9219 (0.9057)  Masked Language Modeling Accuracy: 0.6441 (0.6483)  time: 0.6817 (0.7819)  data: 0.0232 (0.0918)  lr: 0.001000  max mem: 11938
2021-04-02 02:15:11,696 maskrcnn_benchmark.trainer INFO: eta: 3:43:52  iter: 22800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3911 (0.4714)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3782 (0.4607)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3364 (0.4650)  Cross-Entropy Loss (Align Words, Choose Image): 0.2789 (0.3979)  Image Caption Matching Loss: 0.3281 (0.4984)  Masked Language Modeling Loss: 1.6581 (1.7236)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3056 (4.0171)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8423)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8431)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8409)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8621)  Batch Accuracy (Choose Caption): 0.9375 (0.9033)  Batch Accuracy (Choose Image): 0.9375 (0.9060)  Masked Language Modeling Accuracy: 0.6553 (0.6484)  time: 0.6786 (0.7810)  data: 0.0188 (0.0911)  lr: 0.001000  max mem: 11938
2021-04-02 02:16:26,543 maskrcnn_benchmark.trainer INFO: eta: 3:42:27  iter: 22900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3249 (0.4702)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3313 (0.4595)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2814 (0.4636)  Cross-Entropy Loss (Align Words, Choose Image): 0.2619 (0.3967)  Image Caption Matching Loss: 0.3352 (0.4967)  Masked Language Modeling Loss: 1.7798 (1.7229)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3163 (4.0096)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8426)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8434)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8413)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8625)  Batch Accuracy (Choose Caption): 0.9375 (0.9036)  Batch Accuracy (Choose Image): 0.9375 (0.9063)  Masked Language Modeling Accuracy: 0.6352 (0.6486)  time: 0.6697 (0.7806)  data: 0.0190 (0.0904)  lr: 0.001000  max mem: 11938
2021-04-02 02:17:35,004 maskrcnn_benchmark.trainer INFO: eta: 3:40:52  iter: 23000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4163 (0.4693)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3835 (0.4586)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3246 (0.4624)  Cross-Entropy Loss (Align Words, Choose Image): 0.3185 (0.3957)  Image Caption Matching Loss: 0.3581 (0.4952)  Masked Language Modeling Loss: 1.7034 (1.7220)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.5366 (4.0032)  Batch Accuracy (Align Regions, Choose Caption): 0.8438 (0.8429)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8437)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8417)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8629)  Batch Accuracy (Choose Caption): 0.9219 (0.9038)  Batch Accuracy (Choose Image): 0.9219 (0.9066)  Masked Language Modeling Accuracy: 0.6605 (0.6488)  time: 0.6728 (0.7795)  data: 0.0197 (0.0897)  lr: 0.001000  max mem: 11938
2021-04-02 02:17:35,281 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0023000.pth
2021-04-02 02:18:45,136 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 3:40:52  iter: 23000  loss: 1.3904 (1.3675)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2368 (0.2498)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2552 (0.2714)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3219 (0.2964)  Cross-Entropy Loss (Align Words, Choose Image): 0.2481 (0.2469)  Image Caption Matching Loss: 0.2979 (0.3031)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9130)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9059)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8944)  Batch Accuracy (Align Words, Choose Image): 0.9115 (0.9162)  Batch Accuracy (Choose Caption): 0.9375 (0.9430)  Batch Accuracy (Choose Image): 0.9531 (0.9435)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 11938
2021-04-02 02:20:01,317 maskrcnn_benchmark.trainer INFO: eta: 3:41:40  iter: 23100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3054 (0.4680)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3487 (0.4573)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3030 (0.4610)  Cross-Entropy Loss (Align Words, Choose Image): 0.2847 (0.3945)  Image Caption Matching Loss: 0.3294 (0.4935)  Masked Language Modeling Loss: 1.6227 (1.7215)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1044 (3.9958)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8433)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8440)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8422)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8633)  Batch Accuracy (Choose Caption): 0.9531 (0.9042)  Batch Accuracy (Choose Image): 0.9219 (0.9068)  Masked Language Modeling Accuracy: 0.6646 (0.6489)  time: 0.6739 (0.7870)  data: 0.0198 (0.0968)  lr: 0.001000  max mem: 11938
2021-04-02 02:21:10,635 maskrcnn_benchmark.trainer INFO: eta: 3:40:05  iter: 23200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3535 (0.4667)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3311 (0.4562)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2553 (0.4596)  Cross-Entropy Loss (Align Words, Choose Image): 0.2552 (0.3933)  Image Caption Matching Loss: 0.3056 (0.4918)  Masked Language Modeling Loss: 1.5329 (1.7205)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0064 (3.9882)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8437)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8444)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8426)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8637)  Batch Accuracy (Choose Caption): 0.9375 (0.9046)  Batch Accuracy (Choose Image): 0.9375 (0.9071)  Masked Language Modeling Accuracy: 0.6806 (0.6491)  time: 0.6637 (0.7860)  data: 0.0186 (0.0960)  lr: 0.001000  max mem: 12203
2021-04-02 02:22:22,808 maskrcnn_benchmark.trainer INFO: eta: 3:38:34  iter: 23300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4064 (0.4656)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3331 (0.4551)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3347 (0.4583)  Cross-Entropy Loss (Align Words, Choose Image): 0.2717 (0.3922)  Image Caption Matching Loss: 0.2985 (0.4902)  Masked Language Modeling Loss: 1.5168 (1.7194)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2423 (3.9808)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8441)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8448)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8431)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8640)  Batch Accuracy (Choose Caption): 0.9375 (0.9049)  Batch Accuracy (Choose Image): 0.9375 (0.9074)  Masked Language Modeling Accuracy: 0.6498 (0.6492)  time: 0.6649 (0.7853)  data: 0.0189 (0.0953)  lr: 0.001000  max mem: 12203
2021-04-02 02:23:33,514 maskrcnn_benchmark.trainer INFO: eta: 3:37:02  iter: 23400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3496 (0.4645)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3584 (0.4541)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3377 (0.4571)  Cross-Entropy Loss (Align Words, Choose Image): 0.2920 (0.3912)  Image Caption Matching Loss: 0.3576 (0.4887)  Masked Language Modeling Loss: 1.5992 (1.7190)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4012 (3.9745)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8444)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8451)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8435)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8644)  Batch Accuracy (Choose Caption): 0.9219 (0.9052)  Batch Accuracy (Choose Image): 0.9219 (0.9076)  Masked Language Modeling Accuracy: 0.6633 (0.6493)  time: 0.6686 (0.7845)  data: 0.0190 (0.0946)  lr: 0.001000  max mem: 12203
2021-04-02 02:24:49,725 maskrcnn_benchmark.trainer INFO: eta: 3:35:40  iter: 23500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3744 (0.4636)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2991 (0.4531)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2806 (0.4557)  Cross-Entropy Loss (Align Words, Choose Image): 0.2319 (0.3901)  Image Caption Matching Loss: 0.3070 (0.4872)  Masked Language Modeling Loss: 1.5990 (1.7184)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1203 (3.9679)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8448)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8454)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8439)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8647)  Batch Accuracy (Choose Caption): 0.9375 (0.9055)  Batch Accuracy (Choose Image): 0.9375 (0.9079)  Masked Language Modeling Accuracy: 0.6671 (0.6495)  time: 0.6744 (0.7843)  data: 0.0194 (0.0940)  lr: 0.001000  max mem: 12203
2021-04-02 02:26:02,672 maskrcnn_benchmark.trainer INFO: eta: 3:34:12  iter: 23600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3442 (0.4625)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3759 (0.4521)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3218 (0.4544)  Cross-Entropy Loss (Align Words, Choose Image): 0.3057 (0.3892)  Image Caption Matching Loss: 0.3104 (0.4856)  Masked Language Modeling Loss: 1.6959 (1.7177)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3252 (3.9614)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8451)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8458)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8443)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8650)  Batch Accuracy (Choose Caption): 0.9375 (0.9058)  Batch Accuracy (Choose Image): 0.9375 (0.9082)  Masked Language Modeling Accuracy: 0.6471 (0.6496)  time: 0.6705 (0.7837)  data: 0.0195 (0.0933)  lr: 0.001000  max mem: 12203
2021-04-02 02:27:14,780 maskrcnn_benchmark.trainer INFO: eta: 3:32:43  iter: 23700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3520 (0.4615)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3867 (0.4513)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3607 (0.4530)  Cross-Entropy Loss (Align Words, Choose Image): 0.2701 (0.3882)  Image Caption Matching Loss: 0.3833 (0.4842)  Masked Language Modeling Loss: 1.7054 (1.7165)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3614 (3.9546)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8454)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8461)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8448)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8653)  Batch Accuracy (Choose Caption): 0.9062 (0.9061)  Batch Accuracy (Choose Image): 0.9219 (0.9084)  Masked Language Modeling Accuracy: 0.6248 (0.6497)  time: 0.6716 (0.7830)  data: 0.0189 (0.0926)  lr: 0.001000  max mem: 12203
2021-04-02 02:28:28,205 maskrcnn_benchmark.trainer INFO: eta: 3:31:16  iter: 23800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3631 (0.4605)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3890 (0.4504)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3523 (0.4518)  Cross-Entropy Loss (Align Words, Choose Image): 0.3019 (0.3872)  Image Caption Matching Loss: 0.3680 (0.4828)  Masked Language Modeling Loss: 1.5103 (1.7157)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3612 (3.9484)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8458)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8465)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8452)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8656)  Batch Accuracy (Choose Caption): 0.9375 (0.9063)  Batch Accuracy (Choose Image): 0.9219 (0.9086)  Masked Language Modeling Accuracy: 0.6735 (0.6499)  time: 0.6728 (0.7825)  data: 0.0192 (0.0920)  lr: 0.001000  max mem: 12203
2021-04-02 02:29:43,157 maskrcnn_benchmark.trainer INFO: eta: 3:29:53  iter: 23900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3513 (0.4594)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3405 (0.4495)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3311 (0.4507)  Cross-Entropy Loss (Align Words, Choose Image): 0.2940 (0.3864)  Image Caption Matching Loss: 0.3507 (0.4814)  Masked Language Modeling Loss: 1.5696 (1.7145)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2144 (3.9419)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8461)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8467)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8456)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8659)  Batch Accuracy (Choose Caption): 0.9375 (0.9066)  Batch Accuracy (Choose Image): 0.9375 (0.9088)  Masked Language Modeling Accuracy: 0.6481 (0.6500)  time: 0.6716 (0.7822)  data: 0.0188 (0.0914)  lr: 0.001000  max mem: 12203
2021-04-02 02:30:52,410 maskrcnn_benchmark.trainer INFO: eta: 3:28:21  iter: 24000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3319 (0.4582)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2818 (0.4483)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3319 (0.4492)  Cross-Entropy Loss (Align Words, Choose Image): 0.2246 (0.3852)  Image Caption Matching Loss: 0.2758 (0.4798)  Masked Language Modeling Loss: 1.5598 (1.7137)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9833 (3.9343)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8466)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8471)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8461)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8663)  Batch Accuracy (Choose Caption): 0.9375 (0.9070)  Batch Accuracy (Choose Image): 0.9375 (0.9092)  Masked Language Modeling Accuracy: 0.6657 (0.6502)  time: 0.6690 (0.7813)  data: 0.0196 (0.0907)  lr: 0.001000  max mem: 12203
2021-04-02 02:30:52,700 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0024000.pth
2021-04-02 02:32:00,500 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 3:28:21  iter: 24000  loss: 1.3648 (1.3125)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2435 (0.2367)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2453 (0.2596)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2748 (0.2834)  Cross-Entropy Loss (Align Words, Choose Image): 0.2172 (0.2310)  Image Caption Matching Loss: 0.3105 (0.3019)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9194)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9067)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8991)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9185)  Batch Accuracy (Choose Caption): 0.9531 (0.9422)  Batch Accuracy (Choose Image): 0.9375 (0.9448)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 02:33:09,719 maskrcnn_benchmark.trainer INFO: eta: 3:28:36  iter: 24100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3380 (0.4573)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3433 (0.4473)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3066 (0.4480)  Cross-Entropy Loss (Align Words, Choose Image): 0.2954 (0.3842)  Image Caption Matching Loss: 0.3840 (0.4784)  Masked Language Modeling Loss: 1.6231 (1.7129)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1881 (3.9281)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8469)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8474)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8465)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8666)  Batch Accuracy (Choose Caption): 0.9219 (0.9072)  Batch Accuracy (Choose Image): 0.9375 (0.9094)  Masked Language Modeling Accuracy: 0.6702 (0.6503)  time: 0.6712 (0.7872)  data: 0.0191 (0.0968)  lr: 0.001000  max mem: 12203
2021-04-02 02:34:22,147 maskrcnn_benchmark.trainer INFO: eta: 3:27:07  iter: 24200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3775 (0.4563)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3650 (0.4464)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3513 (0.4469)  Cross-Entropy Loss (Align Words, Choose Image): 0.2685 (0.3832)  Image Caption Matching Loss: 0.3529 (0.4772)  Masked Language Modeling Loss: 1.5963 (1.7124)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3730 (3.9223)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8472)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8477)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8469)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8670)  Batch Accuracy (Choose Caption): 0.9219 (0.9075)  Batch Accuracy (Choose Image): 0.9375 (0.9096)  Masked Language Modeling Accuracy: 0.6682 (0.6503)  time: 0.6798 (0.7866)  data: 0.0188 (0.0962)  lr: 0.001000  max mem: 12203
2021-04-02 02:35:31,976 maskrcnn_benchmark.trainer INFO: eta: 3:25:35  iter: 24300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3255 (0.4554)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3257 (0.4456)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2840 (0.4458)  Cross-Entropy Loss (Align Words, Choose Image): 0.2606 (0.3824)  Image Caption Matching Loss: 0.2877 (0.4760)  Masked Language Modeling Loss: 1.6902 (1.7122)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0973 (3.9176)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8475)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8480)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8472)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8673)  Batch Accuracy (Choose Caption): 0.9219 (0.9077)  Batch Accuracy (Choose Image): 0.9375 (0.9098)  Masked Language Modeling Accuracy: 0.6590 (0.6503)  time: 0.6625 (0.7857)  data: 0.0190 (0.0955)  lr: 0.001000  max mem: 12203
2021-04-02 02:36:42,063 maskrcnn_benchmark.trainer INFO: eta: 3:24:04  iter: 24400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3523 (0.4545)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3680 (0.4448)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3158 (0.4447)  Cross-Entropy Loss (Align Words, Choose Image): 0.3063 (0.3816)  Image Caption Matching Loss: 0.3306 (0.4747)  Masked Language Modeling Loss: 1.6343 (1.7114)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3122 (3.9117)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8478)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8483)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8476)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8676)  Batch Accuracy (Choose Caption): 0.9375 (0.9080)  Batch Accuracy (Choose Image): 0.9219 (0.9100)  Masked Language Modeling Accuracy: 0.6432 (0.6505)  time: 0.6740 (0.7849)  data: 0.0198 (0.0949)  lr: 0.001000  max mem: 12203
2021-04-02 02:37:55,689 maskrcnn_benchmark.trainer INFO: eta: 3:22:38  iter: 24500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3751 (0.4537)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3594 (0.4440)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3419 (0.4437)  Cross-Entropy Loss (Align Words, Choose Image): 0.2686 (0.3807)  Image Caption Matching Loss: 0.3291 (0.4733)  Masked Language Modeling Loss: 1.6096 (1.7105)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2066 (3.9060)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8481)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8486)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8479)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8678)  Batch Accuracy (Choose Caption): 0.9375 (0.9083)  Batch Accuracy (Choose Image): 0.9375 (0.9102)  Masked Language Modeling Accuracy: 0.6614 (0.6506)  time: 0.6684 (0.7844)  data: 0.0188 (0.0942)  lr: 0.001000  max mem: 12203
2021-04-02 02:39:05,568 maskrcnn_benchmark.trainer INFO: eta: 3:21:07  iter: 24600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3073 (0.4527)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3199 (0.4430)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3336 (0.4426)  Cross-Entropy Loss (Align Words, Choose Image): 0.3027 (0.3799)  Image Caption Matching Loss: 0.2540 (0.4718)  Masked Language Modeling Loss: 1.6114 (1.7094)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3265 (3.8995)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8484)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8488)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8483)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8681)  Batch Accuracy (Choose Caption): 0.9219 (0.9086)  Batch Accuracy (Choose Image): 0.9375 (0.9104)  Masked Language Modeling Accuracy: 0.6426 (0.6508)  time: 0.6666 (0.7836)  data: 0.0189 (0.0936)  lr: 0.001000  max mem: 12203
2021-04-02 02:40:15,346 maskrcnn_benchmark.trainer INFO: eta: 3:19:36  iter: 24700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3680 (0.4518)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2877 (0.4421)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2976 (0.4417)  Cross-Entropy Loss (Align Words, Choose Image): 0.3016 (0.3791)  Image Caption Matching Loss: 0.3020 (0.4705)  Masked Language Modeling Loss: 1.6010 (1.7091)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1744 (3.8944)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8487)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8492)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8486)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8684)  Batch Accuracy (Choose Caption): 0.9375 (0.9088)  Batch Accuracy (Choose Image): 0.9531 (0.9106)  Masked Language Modeling Accuracy: 0.6561 (0.6508)  time: 0.6655 (0.7828)  data: 0.0187 (0.0929)  lr: 0.001000  max mem: 12203
2021-04-02 02:41:30,291 maskrcnn_benchmark.trainer INFO: eta: 3:18:13  iter: 24800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3285 (0.4511)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3034 (0.4413)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3108 (0.4407)  Cross-Entropy Loss (Align Words, Choose Image): 0.3013 (0.3783)  Image Caption Matching Loss: 0.2925 (0.4694)  Masked Language Modeling Loss: 1.5711 (1.7087)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2752 (3.8895)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8490)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8495)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8490)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8686)  Batch Accuracy (Choose Caption): 0.9375 (0.9091)  Batch Accuracy (Choose Image): 0.9219 (0.9108)  Masked Language Modeling Accuracy: 0.6634 (0.6509)  time: 0.6707 (0.7825)  data: 0.0189 (0.0923)  lr: 0.001000  max mem: 12203
2021-04-02 02:42:38,864 maskrcnn_benchmark.trainer INFO: eta: 3:16:42  iter: 24900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3210 (0.4501)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2622 (0.4404)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3362 (0.4396)  Cross-Entropy Loss (Align Words, Choose Image): 0.2826 (0.3775)  Image Caption Matching Loss: 0.3518 (0.4681)  Masked Language Modeling Loss: 1.4311 (1.7077)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0136 (3.8834)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8493)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8497)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8493)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8689)  Batch Accuracy (Choose Caption): 0.9375 (0.9093)  Batch Accuracy (Choose Image): 0.9375 (0.9110)  Masked Language Modeling Accuracy: 0.6808 (0.6511)  time: 0.6662 (0.7816)  data: 0.0190 (0.0917)  lr: 0.001000  max mem: 12203
2021-04-02 02:43:54,985 maskrcnn_benchmark.trainer INFO: eta: 3:15:21  iter: 25000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3060 (0.4492)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2800 (0.4397)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3272 (0.4386)  Cross-Entropy Loss (Align Words, Choose Image): 0.2739 (0.3766)  Image Caption Matching Loss: 0.2828 (0.4670)  Masked Language Modeling Loss: 1.6107 (1.7070)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1941 (3.8780)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8495)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8500)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8496)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8692)  Batch Accuracy (Choose Caption): 0.9531 (0.9096)  Batch Accuracy (Choose Image): 0.9375 (0.9112)  Masked Language Modeling Accuracy: 0.6656 (0.6512)  time: 0.6744 (0.7814)  data: 0.0206 (0.0912)  lr: 0.001000  max mem: 12203
2021-04-02 02:43:55,293 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0025000.pth
2021-04-02 02:45:03,887 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 3:15:21  iter: 25000  loss: 1.2253 (1.2754)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2200 (0.2331)  Cross-Entropy Loss (Align Regions, Choose Image): 0.1983 (0.2467)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2699 (0.2761)  Cross-Entropy Loss (Align Words, Choose Image): 0.2191 (0.2358)  Image Caption Matching Loss: 0.2639 (0.2837)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9375 (0.9168)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9131)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9041)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9174)  Batch Accuracy (Choose Caption): 0.9375 (0.9438)  Batch Accuracy (Choose Image): 0.9531 (0.9486)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 02:46:13,542 maskrcnn_benchmark.trainer INFO: eta: 3:15:24  iter: 25100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3100 (0.4483)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2696 (0.4387)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3039 (0.4374)  Cross-Entropy Loss (Align Words, Choose Image): 0.2044 (0.3758)  Image Caption Matching Loss: 0.2929 (0.4658)  Masked Language Modeling Loss: 1.5664 (1.7065)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8274 (3.8726)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8498)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8504)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8500)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8695)  Batch Accuracy (Choose Caption): 0.9479 (0.9098)  Batch Accuracy (Choose Image): 0.9375 (0.9114)  Masked Language Modeling Accuracy: 0.6771 (0.6513)  time: 0.6631 (0.7869)  data: 0.0185 (0.0968)  lr: 0.001000  max mem: 12203
2021-04-02 02:47:24,606 maskrcnn_benchmark.trainer INFO: eta: 3:13:55  iter: 25200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3437 (0.4474)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3395 (0.4378)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3041 (0.4364)  Cross-Entropy Loss (Align Words, Choose Image): 0.2403 (0.3748)  Image Caption Matching Loss: 0.3469 (0.4646)  Masked Language Modeling Loss: 1.6444 (1.7060)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1910 (3.8671)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8501)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8507)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8504)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8698)  Batch Accuracy (Choose Caption): 0.9375 (0.9101)  Batch Accuracy (Choose Image): 0.9375 (0.9117)  Masked Language Modeling Accuracy: 0.6489 (0.6514)  time: 0.6759 (0.7862)  data: 0.0191 (0.0962)  lr: 0.001000  max mem: 12203
2021-04-02 02:48:39,084 maskrcnn_benchmark.trainer INFO: eta: 3:12:31  iter: 25300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3395 (0.4466)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3901 (0.4371)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3172 (0.4354)  Cross-Entropy Loss (Align Words, Choose Image): 0.3006 (0.3741)  Image Caption Matching Loss: 0.3656 (0.4636)  Masked Language Modeling Loss: 1.5132 (1.7053)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2396 (3.8621)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8504)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8509)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8506)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8701)  Batch Accuracy (Choose Caption): 0.9219 (0.9103)  Batch Accuracy (Choose Image): 0.9219 (0.9119)  Masked Language Modeling Accuracy: 0.6756 (0.6516)  time: 0.6627 (0.7858)  data: 0.0186 (0.0956)  lr: 0.001000  max mem: 12203
2021-04-02 02:49:51,342 maskrcnn_benchmark.trainer INFO: eta: 3:11:04  iter: 25400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3746 (0.4458)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3201 (0.4362)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3336 (0.4344)  Cross-Entropy Loss (Align Words, Choose Image): 0.3071 (0.3732)  Image Caption Matching Loss: 0.2999 (0.4623)  Masked Language Modeling Loss: 1.6379 (1.7048)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2898 (3.8568)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8507)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8512)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8510)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8704)  Batch Accuracy (Choose Caption): 0.9375 (0.9105)  Batch Accuracy (Choose Image): 0.9219 (0.9120)  Masked Language Modeling Accuracy: 0.6449 (0.6516)  time: 0.6722 (0.7853)  data: 0.0201 (0.0950)  lr: 0.001000  max mem: 12203
2021-04-02 02:51:05,087 maskrcnn_benchmark.trainer INFO: eta: 3:09:40  iter: 25500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3415 (0.4452)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3360 (0.4357)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2952 (0.4335)  Cross-Entropy Loss (Align Words, Choose Image): 0.2626 (0.3726)  Image Caption Matching Loss: 0.3299 (0.4614)  Masked Language Modeling Loss: 1.6233 (1.7040)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1883 (3.8524)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8509)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8513)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8513)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8706)  Batch Accuracy (Choose Caption): 0.9375 (0.9107)  Batch Accuracy (Choose Image): 0.9219 (0.9122)  Masked Language Modeling Accuracy: 0.6656 (0.6518)  time: 0.6796 (0.7849)  data: 0.0198 (0.0945)  lr: 0.001000  max mem: 12203
2021-04-02 02:52:20,399 maskrcnn_benchmark.trainer INFO: eta: 3:08:17  iter: 25600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3413 (0.4445)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3456 (0.4349)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3230 (0.4326)  Cross-Entropy Loss (Align Words, Choose Image): 0.3099 (0.3719)  Image Caption Matching Loss: 0.2679 (0.4602)  Masked Language Modeling Loss: 1.7600 (1.7036)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.5101 (3.8476)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8511)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8516)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8516)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8708)  Batch Accuracy (Choose Caption): 0.9531 (0.9110)  Batch Accuracy (Choose Image): 0.9375 (0.9124)  Masked Language Modeling Accuracy: 0.6475 (0.6518)  time: 0.6694 (0.7846)  data: 0.0197 (0.0939)  lr: 0.001000  max mem: 12203
2021-04-02 02:53:32,566 maskrcnn_benchmark.trainer INFO: eta: 3:06:51  iter: 25700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3445 (0.4439)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3840 (0.4343)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2851 (0.4318)  Cross-Entropy Loss (Align Words, Choose Image): 0.2699 (0.3712)  Image Caption Matching Loss: 0.2875 (0.4593)  Masked Language Modeling Loss: 1.6443 (1.7033)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1344 (3.8437)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8513)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8518)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8519)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8710)  Batch Accuracy (Choose Caption): 0.9375 (0.9112)  Batch Accuracy (Choose Image): 0.9375 (0.9126)  Masked Language Modeling Accuracy: 0.6675 (0.6519)  time: 0.6743 (0.7840)  data: 0.0199 (0.0934)  lr: 0.001000  max mem: 12203
2021-04-02 02:54:41,982 maskrcnn_benchmark.trainer INFO: eta: 3:05:22  iter: 25800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2908 (0.4430)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3416 (0.4335)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3111 (0.4308)  Cross-Entropy Loss (Align Words, Choose Image): 0.2702 (0.3705)  Image Caption Matching Loss: 0.2640 (0.4581)  Masked Language Modeling Loss: 1.6348 (1.7026)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1482 (3.8386)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8516)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8521)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8523)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8712)  Batch Accuracy (Choose Caption): 0.9531 (0.9115)  Batch Accuracy (Choose Image): 0.9375 (0.9127)  Masked Language Modeling Accuracy: 0.6408 (0.6520)  time: 0.6792 (0.7833)  data: 0.0193 (0.0929)  lr: 0.001000  max mem: 12203
2021-04-02 02:55:56,840 maskrcnn_benchmark.trainer INFO: eta: 3:04:00  iter: 25900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3115 (0.4424)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3050 (0.4329)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2569 (0.4299)  Cross-Entropy Loss (Align Words, Choose Image): 0.2572 (0.3697)  Image Caption Matching Loss: 0.2690 (0.4571)  Masked Language Modeling Loss: 1.8745 (1.7025)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1864 (3.8345)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8518)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8523)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8525)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8715)  Batch Accuracy (Choose Caption): 0.9375 (0.9117)  Batch Accuracy (Choose Image): 0.9375 (0.9129)  Masked Language Modeling Accuracy: 0.6286 (0.6520)  time: 0.6797 (0.7830)  data: 0.0189 (0.0923)  lr: 0.001000  max mem: 12203
2021-04-02 02:57:08,706 maskrcnn_benchmark.trainer INFO: eta: 3:02:34  iter: 26000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3460 (0.4417)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3341 (0.4321)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3022 (0.4291)  Cross-Entropy Loss (Align Words, Choose Image): 0.2730 (0.3691)  Image Caption Matching Loss: 0.2992 (0.4563)  Masked Language Modeling Loss: 1.6726 (1.7019)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1710 (3.8302)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8520)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8525)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8528)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8717)  Batch Accuracy (Choose Caption): 0.9219 (0.9118)  Batch Accuracy (Choose Image): 0.9375 (0.9130)  Masked Language Modeling Accuracy: 0.6513 (0.6520)  time: 0.6633 (0.7825)  data: 0.0188 (0.0918)  lr: 0.001000  max mem: 12203
2021-04-02 02:57:09,013 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0026000.pth
2021-04-02 02:58:17,579 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 3:02:34  iter: 26000  loss: 1.3079 (1.2770)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2161 (0.2344)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2574 (0.2512)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2740 (0.2845)  Cross-Entropy Loss (Align Words, Choose Image): 0.2041 (0.2276)  Image Caption Matching Loss: 0.3176 (0.2793)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9172)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9135)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.9000)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9224)  Batch Accuracy (Choose Caption): 0.9375 (0.9474)  Batch Accuracy (Choose Image): 0.9531 (0.9498)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 02:59:27,529 maskrcnn_benchmark.trainer INFO: eta: 3:02:25  iter: 26100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3181 (0.4409)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3378 (0.4312)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2973 (0.4282)  Cross-Entropy Loss (Align Words, Choose Image): 0.2613 (0.3683)  Image Caption Matching Loss: 0.3197 (0.4552)  Masked Language Modeling Loss: 1.5137 (1.7013)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0616 (3.8250)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8523)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8528)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8532)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8720)  Batch Accuracy (Choose Caption): 0.9219 (0.9121)  Batch Accuracy (Choose Image): 0.9375 (0.9132)  Masked Language Modeling Accuracy: 0.6550 (0.6521)  time: 0.6753 (0.7875)  data: 0.0189 (0.0969)  lr: 0.001000  max mem: 12203
2021-04-02 03:00:36,221 maskrcnn_benchmark.trainer INFO: eta: 3:00:55  iter: 26200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3945 (0.4402)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3377 (0.4305)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3004 (0.4274)  Cross-Entropy Loss (Align Words, Choose Image): 0.2478 (0.3676)  Image Caption Matching Loss: 0.3111 (0.4541)  Masked Language Modeling Loss: 1.7230 (1.7009)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3707 (3.8208)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8526)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8531)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8534)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8722)  Batch Accuracy (Choose Caption): 0.9375 (0.9123)  Batch Accuracy (Choose Image): 0.9375 (0.9134)  Masked Language Modeling Accuracy: 0.6436 (0.6521)  time: 0.6702 (0.7866)  data: 0.0183 (0.0963)  lr: 0.001000  max mem: 12203
2021-04-02 03:01:48,661 maskrcnn_benchmark.trainer INFO: eta: 2:59:29  iter: 26300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3065 (0.4394)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3205 (0.4297)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2847 (0.4265)  Cross-Entropy Loss (Align Words, Choose Image): 0.2796 (0.3669)  Image Caption Matching Loss: 0.3120 (0.4529)  Masked Language Modeling Loss: 1.5323 (1.7003)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3004 (3.8157)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8529)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8533)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8537)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8724)  Batch Accuracy (Choose Caption): 0.9375 (0.9125)  Batch Accuracy (Choose Image): 0.9375 (0.9136)  Masked Language Modeling Accuracy: 0.6544 (0.6523)  time: 0.6637 (0.7861)  data: 0.0192 (0.0958)  lr: 0.001000  max mem: 12203
2021-04-02 03:03:02,882 maskrcnn_benchmark.trainer INFO: eta: 2:58:06  iter: 26400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3192 (0.4387)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3111 (0.4289)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3068 (0.4257)  Cross-Entropy Loss (Align Words, Choose Image): 0.2707 (0.3661)  Image Caption Matching Loss: 0.2636 (0.4519)  Masked Language Modeling Loss: 1.5759 (1.6997)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1381 (3.8109)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8532)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8536)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8540)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8727)  Batch Accuracy (Choose Caption): 0.9531 (0.9128)  Batch Accuracy (Choose Image): 0.9375 (0.9137)  Masked Language Modeling Accuracy: 0.6647 (0.6523)  time: 0.6804 (0.7858)  data: 0.0196 (0.0953)  lr: 0.001000  max mem: 12203
2021-04-02 03:04:14,355 maskrcnn_benchmark.trainer INFO: eta: 2:56:40  iter: 26500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2615 (0.4379)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2884 (0.4281)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3120 (0.4248)  Cross-Entropy Loss (Align Words, Choose Image): 0.2254 (0.3653)  Image Caption Matching Loss: 0.2332 (0.4508)  Masked Language Modeling Loss: 1.6336 (1.6990)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8593 (3.8057)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8535)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8539)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8543)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8729)  Batch Accuracy (Choose Caption): 0.9531 (0.9130)  Batch Accuracy (Choose Image): 0.9531 (0.9139)  Masked Language Modeling Accuracy: 0.6579 (0.6524)  time: 0.6740 (0.7852)  data: 0.0196 (0.0948)  lr: 0.001000  max mem: 12203
2021-04-02 03:05:25,863 maskrcnn_benchmark.trainer INFO: eta: 2:55:14  iter: 26600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3215 (0.4370)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3082 (0.4273)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3258 (0.4239)  Cross-Entropy Loss (Align Words, Choose Image): 0.2902 (0.3646)  Image Caption Matching Loss: 0.2918 (0.4495)  Masked Language Modeling Loss: 1.5732 (1.6986)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1268 (3.8010)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8537)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8542)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8546)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8732)  Batch Accuracy (Choose Caption): 0.9375 (0.9132)  Batch Accuracy (Choose Image): 0.9375 (0.9141)  Masked Language Modeling Accuracy: 0.6803 (0.6525)  time: 0.6642 (0.7846)  data: 0.0193 (0.0942)  lr: 0.001000  max mem: 12203
2021-04-02 03:06:37,895 maskrcnn_benchmark.trainer INFO: eta: 2:53:49  iter: 26700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3511 (0.4364)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3823 (0.4267)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3508 (0.4231)  Cross-Entropy Loss (Align Words, Choose Image): 0.3066 (0.3640)  Image Caption Matching Loss: 0.2952 (0.4484)  Masked Language Modeling Loss: 1.5804 (1.6981)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2670 (3.7968)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8540)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8544)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8549)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8733)  Batch Accuracy (Choose Caption): 0.9375 (0.9135)  Batch Accuracy (Choose Image): 0.9375 (0.9143)  Masked Language Modeling Accuracy: 0.6742 (0.6525)  time: 0.6665 (0.7841)  data: 0.0192 (0.0937)  lr: 0.001000  max mem: 12203
2021-04-02 03:07:47,019 maskrcnn_benchmark.trainer INFO: eta: 2:52:21  iter: 26800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3403 (0.4358)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3769 (0.4262)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3208 (0.4224)  Cross-Entropy Loss (Align Words, Choose Image): 0.2899 (0.3635)  Image Caption Matching Loss: 0.3029 (0.4476)  Masked Language Modeling Loss: 1.5176 (1.6973)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2151 (3.7929)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8542)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8545)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8551)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8735)  Batch Accuracy (Choose Caption): 0.9219 (0.9137)  Batch Accuracy (Choose Image): 0.9219 (0.9144)  Masked Language Modeling Accuracy: 0.6798 (0.6527)  time: 0.6701 (0.7834)  data: 0.0185 (0.0932)  lr: 0.001000  max mem: 12203
2021-04-02 03:09:00,715 maskrcnn_benchmark.trainer INFO: eta: 2:50:58  iter: 26900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3188 (0.4351)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3332 (0.4254)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3063 (0.4216)  Cross-Entropy Loss (Align Words, Choose Image): 0.2545 (0.3629)  Image Caption Matching Loss: 0.2620 (0.4466)  Masked Language Modeling Loss: 1.6264 (1.6968)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1539 (3.7883)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8544)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8548)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8554)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8738)  Batch Accuracy (Choose Caption): 0.9375 (0.9139)  Batch Accuracy (Choose Image): 0.9375 (0.9146)  Masked Language Modeling Accuracy: 0.6696 (0.6528)  time: 0.6712 (0.7831)  data: 0.0192 (0.0927)  lr: 0.001000  max mem: 12203
2021-04-02 03:10:15,925 maskrcnn_benchmark.trainer INFO: eta: 2:49:36  iter: 27000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3142 (0.4344)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3176 (0.4247)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3363 (0.4208)  Cross-Entropy Loss (Align Words, Choose Image): 0.2774 (0.3622)  Image Caption Matching Loss: 0.3037 (0.4456)  Masked Language Modeling Loss: 1.5657 (1.6959)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1440 (3.7835)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8547)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8550)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8556)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8740)  Batch Accuracy (Choose Caption): 0.9531 (0.9140)  Batch Accuracy (Choose Image): 0.9375 (0.9148)  Masked Language Modeling Accuracy: 0.6564 (0.6529)  time: 0.6751 (0.7828)  data: 0.0196 (0.0922)  lr: 0.001000  max mem: 12203
2021-04-02 03:10:16,242 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0027000.pth
2021-04-02 03:11:25,077 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 2:49:36  iter: 27000  loss: 1.3384 (1.3074)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2579 (0.2442)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2356 (0.2619)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2752 (0.2769)  Cross-Entropy Loss (Align Words, Choose Image): 0.2064 (0.2310)  Image Caption Matching Loss: 0.3164 (0.2935)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9153)  Batch Accuracy (Align Regions, Choose Image): 0.9167 (0.9077)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9022)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9195)  Batch Accuracy (Choose Caption): 0.9271 (0.9433)  Batch Accuracy (Choose Image): 0.9531 (0.9453)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 03:12:37,172 maskrcnn_benchmark.trainer INFO: eta: 2:49:20  iter: 27100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3140 (0.4337)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3069 (0.4241)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2572 (0.4200)  Cross-Entropy Loss (Align Words, Choose Image): 0.2581 (0.3615)  Image Caption Matching Loss: 0.2933 (0.4447)  Masked Language Modeling Loss: 1.7001 (1.6953)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1813 (3.7793)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8549)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8552)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8559)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8742)  Batch Accuracy (Choose Caption): 0.9531 (0.9143)  Batch Accuracy (Choose Image): 0.9375 (0.9149)  Masked Language Modeling Accuracy: 0.6634 (0.6529)  time: 0.6749 (0.7876)  data: 0.0186 (0.0970)  lr: 0.001000  max mem: 12203
2021-04-02 03:13:51,979 maskrcnn_benchmark.trainer INFO: eta: 2:47:57  iter: 27200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3416 (0.4331)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3747 (0.4235)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3160 (0.4191)  Cross-Entropy Loss (Align Words, Choose Image): 0.2794 (0.3608)  Image Caption Matching Loss: 0.3027 (0.4438)  Masked Language Modeling Loss: 1.4852 (1.6946)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1428 (3.7748)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8552)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8554)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8562)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8745)  Batch Accuracy (Choose Caption): 0.9531 (0.9144)  Batch Accuracy (Choose Image): 0.9219 (0.9150)  Masked Language Modeling Accuracy: 0.6555 (0.6530)  time: 0.6654 (0.7873)  data: 0.0190 (0.0964)  lr: 0.001000  max mem: 12203
2021-04-02 03:15:00,963 maskrcnn_benchmark.trainer INFO: eta: 2:46:29  iter: 27300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3474 (0.4326)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3728 (0.4230)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3184 (0.4186)  Cross-Entropy Loss (Align Words, Choose Image): 0.2978 (0.3603)  Image Caption Matching Loss: 0.3037 (0.4430)  Masked Language Modeling Loss: 1.6923 (1.6940)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3994 (3.7714)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8553)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8555)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8564)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8746)  Batch Accuracy (Choose Caption): 0.9375 (0.9146)  Batch Accuracy (Choose Image): 0.9375 (0.9152)  Masked Language Modeling Accuracy: 0.6625 (0.6531)  time: 0.6730 (0.7866)  data: 0.0187 (0.0959)  lr: 0.001000  max mem: 12203
2021-04-02 03:16:14,406 maskrcnn_benchmark.trainer INFO: eta: 2:45:06  iter: 27400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2722 (0.4318)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3383 (0.4223)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2793 (0.4178)  Cross-Entropy Loss (Align Words, Choose Image): 0.2930 (0.3596)  Image Caption Matching Loss: 0.2885 (0.4421)  Masked Language Modeling Loss: 1.6122 (1.6938)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0920 (3.7675)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8556)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8557)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8566)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8749)  Batch Accuracy (Choose Caption): 0.9375 (0.9147)  Batch Accuracy (Choose Image): 0.9375 (0.9153)  Masked Language Modeling Accuracy: 0.6477 (0.6531)  time: 0.6746 (0.7862)  data: 0.0199 (0.0954)  lr: 0.001000  max mem: 12203
2021-04-02 03:17:28,012 maskrcnn_benchmark.trainer INFO: eta: 2:43:42  iter: 27500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2915 (0.4312)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3261 (0.4217)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2975 (0.4169)  Cross-Entropy Loss (Align Words, Choose Image): 0.2652 (0.3590)  Image Caption Matching Loss: 0.2858 (0.4411)  Masked Language Modeling Loss: 1.6729 (1.6933)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2082 (3.7633)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8558)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8559)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8569)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8751)  Batch Accuracy (Choose Caption): 0.9375 (0.9149)  Batch Accuracy (Choose Image): 0.9375 (0.9155)  Masked Language Modeling Accuracy: 0.6707 (0.6531)  time: 0.6705 (0.7858)  data: 0.0193 (0.0950)  lr: 0.001000  max mem: 12203
2021-04-02 03:18:37,627 maskrcnn_benchmark.trainer INFO: eta: 2:42:16  iter: 27600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3052 (0.4306)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2932 (0.4210)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3112 (0.4162)  Cross-Entropy Loss (Align Words, Choose Image): 0.2392 (0.3584)  Image Caption Matching Loss: 0.2412 (0.4401)  Masked Language Modeling Loss: 1.6277 (1.6926)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0679 (3.7589)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8560)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8562)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8571)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8753)  Batch Accuracy (Choose Caption): 0.9531 (0.9151)  Batch Accuracy (Choose Image): 0.9375 (0.9156)  Masked Language Modeling Accuracy: 0.6478 (0.6532)  time: 0.6656 (0.7852)  data: 0.0194 (0.0945)  lr: 0.001000  max mem: 12203
2021-04-02 03:19:46,968 maskrcnn_benchmark.trainer INFO: eta: 2:40:49  iter: 27700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3500 (0.4300)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3178 (0.4205)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3363 (0.4155)  Cross-Entropy Loss (Align Words, Choose Image): 0.2862 (0.3579)  Image Caption Matching Loss: 0.3105 (0.4392)  Masked Language Modeling Loss: 1.6136 (1.6919)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4013 (3.7550)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8562)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8564)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8574)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8755)  Batch Accuracy (Choose Caption): 0.9375 (0.9153)  Batch Accuracy (Choose Image): 0.9375 (0.9158)  Masked Language Modeling Accuracy: 0.6505 (0.6533)  time: 0.6648 (0.7845)  data: 0.0190 (0.0940)  lr: 0.001000  max mem: 12203
2021-04-02 03:20:59,481 maskrcnn_benchmark.trainer INFO: eta: 2:39:25  iter: 27800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3892 (0.4294)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3489 (0.4199)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3135 (0.4147)  Cross-Entropy Loss (Align Words, Choose Image): 0.2770 (0.3572)  Image Caption Matching Loss: 0.3924 (0.4384)  Masked Language Modeling Loss: 1.6562 (1.6915)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4296 (3.7511)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8564)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8565)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8576)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8757)  Batch Accuracy (Choose Caption): 0.9375 (0.9155)  Batch Accuracy (Choose Image): 0.9219 (0.9159)  Masked Language Modeling Accuracy: 0.6350 (0.6534)  time: 0.6724 (0.7841)  data: 0.0190 (0.0935)  lr: 0.001000  max mem: 12203
2021-04-02 03:22:15,439 maskrcnn_benchmark.trainer INFO: eta: 2:38:05  iter: 27900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3474 (0.4287)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3235 (0.4193)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3000 (0.4139)  Cross-Entropy Loss (Align Words, Choose Image): 0.2866 (0.3566)  Image Caption Matching Loss: 0.3610 (0.4374)  Masked Language Modeling Loss: 1.5009 (1.6907)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1363 (3.7467)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8566)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8567)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8578)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8759)  Batch Accuracy (Choose Caption): 0.9375 (0.9157)  Batch Accuracy (Choose Image): 0.9375 (0.9161)  Masked Language Modeling Accuracy: 0.6803 (0.6535)  time: 0.6776 (0.7839)  data: 0.0192 (0.0931)  lr: 0.001000  max mem: 12203
2021-04-02 03:23:26,019 maskrcnn_benchmark.trainer INFO: eta: 2:36:40  iter: 28000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3675 (0.4283)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3743 (0.4187)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2966 (0.4133)  Cross-Entropy Loss (Align Words, Choose Image): 0.2885 (0.3561)  Image Caption Matching Loss: 0.3000 (0.4366)  Masked Language Modeling Loss: 1.4259 (1.6907)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2744 (3.7437)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8568)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8569)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8580)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8761)  Batch Accuracy (Choose Caption): 0.9375 (0.9158)  Batch Accuracy (Choose Image): 0.9375 (0.9163)  Masked Language Modeling Accuracy: 0.6695 (0.6535)  time: 0.6705 (0.7833)  data: 0.0190 (0.0926)  lr: 0.001000  max mem: 12203
2021-04-02 03:23:26,318 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0028000.pth
2021-04-02 03:24:34,379 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 2:36:40  iter: 28000  loss: 1.2800 (1.2711)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.1954 (0.2326)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2455 (0.2569)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2725 (0.2697)  Cross-Entropy Loss (Align Words, Choose Image): 0.2256 (0.2331)  Image Caption Matching Loss: 0.2951 (0.2788)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9191)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9108)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9037)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9140)  Batch Accuracy (Choose Caption): 0.9375 (0.9455)  Batch Accuracy (Choose Image): 0.9375 (0.9466)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 03:25:49,308 maskrcnn_benchmark.trainer INFO: eta: 2:36:16  iter: 28100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3083 (0.4277)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2874 (0.4182)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2894 (0.4127)  Cross-Entropy Loss (Align Words, Choose Image): 0.2537 (0.3556)  Image Caption Matching Loss: 0.3152 (0.4358)  Masked Language Modeling Loss: 1.5143 (1.6903)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2967 (3.7403)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8570)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8571)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8583)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8763)  Batch Accuracy (Choose Caption): 0.9375 (0.9159)  Batch Accuracy (Choose Image): 0.9375 (0.9164)  Masked Language Modeling Accuracy: 0.6714 (0.6536)  time: 0.6734 (0.7879)  data: 0.0193 (0.0970)  lr: 0.001000  max mem: 12203
2021-04-02 03:26:59,235 maskrcnn_benchmark.trainer INFO: eta: 2:34:50  iter: 28200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2957 (0.4270)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3336 (0.4176)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2462 (0.4119)  Cross-Entropy Loss (Align Words, Choose Image): 0.2605 (0.3550)  Image Caption Matching Loss: 0.2964 (0.4350)  Masked Language Modeling Loss: 1.6569 (1.6900)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1773 (3.7364)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8572)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8573)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8585)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8765)  Batch Accuracy (Choose Caption): 0.9375 (0.9161)  Batch Accuracy (Choose Image): 0.9375 (0.9165)  Masked Language Modeling Accuracy: 0.6514 (0.6537)  time: 0.6724 (0.7873)  data: 0.0188 (0.0965)  lr: 0.001000  max mem: 12203
2021-04-02 03:28:10,827 maskrcnn_benchmark.trainer INFO: eta: 2:33:25  iter: 28300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3232 (0.4265)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3358 (0.4170)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3178 (0.4113)  Cross-Entropy Loss (Align Words, Choose Image): 0.2693 (0.3544)  Image Caption Matching Loss: 0.2844 (0.4341)  Masked Language Modeling Loss: 1.5983 (1.6897)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0977 (3.7330)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8574)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8575)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8588)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8767)  Batch Accuracy (Choose Caption): 0.9531 (0.9163)  Batch Accuracy (Choose Image): 0.9375 (0.9167)  Masked Language Modeling Accuracy: 0.6652 (0.6537)  time: 0.6776 (0.7868)  data: 0.0192 (0.0961)  lr: 0.001000  max mem: 12203
2021-04-02 03:29:24,682 maskrcnn_benchmark.trainer INFO: eta: 2:32:03  iter: 28400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2898 (0.4260)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3353 (0.4166)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2965 (0.4107)  Cross-Entropy Loss (Align Words, Choose Image): 0.2783 (0.3540)  Image Caption Matching Loss: 0.3176 (0.4334)  Masked Language Modeling Loss: 1.6424 (1.6892)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1339 (3.7298)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8575)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8576)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8590)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8768)  Batch Accuracy (Choose Caption): 0.9375 (0.9164)  Batch Accuracy (Choose Image): 0.9375 (0.9168)  Masked Language Modeling Accuracy: 0.6427 (0.6538)  time: 0.6776 (0.7865)  data: 0.0196 (0.0956)  lr: 0.001000  max mem: 12203
2021-04-02 03:30:37,261 maskrcnn_benchmark.trainer INFO: eta: 2:30:39  iter: 28500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2788 (0.4254)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3106 (0.4160)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2941 (0.4100)  Cross-Entropy Loss (Align Words, Choose Image): 0.2451 (0.3534)  Image Caption Matching Loss: 0.2759 (0.4325)  Masked Language Modeling Loss: 1.7022 (1.6889)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1861 (3.7263)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8577)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8578)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8592)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8770)  Batch Accuracy (Choose Caption): 0.9531 (0.9166)  Batch Accuracy (Choose Image): 0.9375 (0.9170)  Masked Language Modeling Accuracy: 0.6440 (0.6538)  time: 0.6708 (0.7861)  data: 0.0195 (0.0951)  lr: 0.001000  max mem: 12203
2021-04-02 03:31:49,071 maskrcnn_benchmark.trainer INFO: eta: 2:29:15  iter: 28600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3214 (0.4248)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3301 (0.4155)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3446 (0.4094)  Cross-Entropy Loss (Align Words, Choose Image): 0.2824 (0.3529)  Image Caption Matching Loss: 0.3257 (0.4318)  Masked Language Modeling Loss: 1.6530 (1.6883)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1962 (3.7227)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8580)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8580)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8594)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8772)  Batch Accuracy (Choose Caption): 0.9375 (0.9167)  Batch Accuracy (Choose Image): 0.9375 (0.9171)  Masked Language Modeling Accuracy: 0.6620 (0.6539)  time: 0.6777 (0.7856)  data: 0.0190 (0.0947)  lr: 0.001000  max mem: 12203
2021-04-02 03:33:01,855 maskrcnn_benchmark.trainer INFO: eta: 2:27:52  iter: 28700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3422 (0.4243)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2853 (0.4148)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3413 (0.4088)  Cross-Entropy Loss (Align Words, Choose Image): 0.2438 (0.3523)  Image Caption Matching Loss: 0.3224 (0.4310)  Masked Language Modeling Loss: 1.5009 (1.6878)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1806 (3.7190)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8581)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8582)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8596)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8774)  Batch Accuracy (Choose Caption): 0.9375 (0.9169)  Batch Accuracy (Choose Image): 0.9219 (0.9172)  Masked Language Modeling Accuracy: 0.6535 (0.6540)  time: 0.6722 (0.7852)  data: 0.0198 (0.0942)  lr: 0.001000  max mem: 12203
2021-04-02 03:34:12,784 maskrcnn_benchmark.trainer INFO: eta: 2:26:28  iter: 28800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3069 (0.4238)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2786 (0.4143)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2578 (0.4081)  Cross-Entropy Loss (Align Words, Choose Image): 0.2223 (0.3518)  Image Caption Matching Loss: 0.2573 (0.4301)  Masked Language Modeling Loss: 1.5729 (1.6874)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0077 (3.7155)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8583)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8583)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8598)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8776)  Batch Accuracy (Choose Caption): 0.9531 (0.9171)  Batch Accuracy (Choose Image): 0.9531 (0.9174)  Masked Language Modeling Accuracy: 0.6604 (0.6541)  time: 0.6640 (0.7847)  data: 0.0186 (0.0938)  lr: 0.001000  max mem: 12203
2021-04-02 03:35:22,477 maskrcnn_benchmark.trainer INFO: eta: 2:25:03  iter: 28900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2853 (0.4231)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2834 (0.4137)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2650 (0.4074)  Cross-Entropy Loss (Align Words, Choose Image): 0.2188 (0.3512)  Image Caption Matching Loss: 0.2453 (0.4293)  Masked Language Modeling Loss: 1.4376 (1.6869)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8640 (3.7116)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8585)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8585)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8601)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8778)  Batch Accuracy (Choose Caption): 0.9531 (0.9172)  Batch Accuracy (Choose Image): 0.9531 (0.9175)  Masked Language Modeling Accuracy: 0.6732 (0.6542)  time: 0.6742 (0.7841)  data: 0.0191 (0.0933)  lr: 0.001000  max mem: 12203
2021-04-02 03:36:32,040 maskrcnn_benchmark.trainer INFO: eta: 2:23:38  iter: 29000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2809 (0.4225)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2897 (0.4131)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2549 (0.4067)  Cross-Entropy Loss (Align Words, Choose Image): 0.2515 (0.3507)  Image Caption Matching Loss: 0.2427 (0.4284)  Masked Language Modeling Loss: 1.6702 (1.6867)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0931 (3.7082)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8586)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8587)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8603)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8780)  Batch Accuracy (Choose Caption): 0.9531 (0.9174)  Batch Accuracy (Choose Image): 0.9375 (0.9176)  Masked Language Modeling Accuracy: 0.6652 (0.6542)  time: 0.6628 (0.7835)  data: 0.0188 (0.0929)  lr: 0.001000  max mem: 12203
2021-04-02 03:36:32,342 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0029000.pth
2021-04-02 03:37:41,194 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 2:23:38  iter: 29000  loss: 1.3443 (1.2834)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2716 (0.2441)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2317 (0.2597)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2866 (0.2730)  Cross-Entropy Loss (Align Words, Choose Image): 0.2548 (0.2269)  Image Caption Matching Loss: 0.2979 (0.2797)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9010 (0.9147)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9081)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9055)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.9180)  Batch Accuracy (Choose Caption): 0.9375 (0.9446)  Batch Accuracy (Choose Image): 0.9531 (0.9502)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 03:38:58,012 maskrcnn_benchmark.trainer INFO: eta: 2:23:09  iter: 29100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2841 (0.4220)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2733 (0.4126)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2595 (0.4061)  Cross-Entropy Loss (Align Words, Choose Image): 0.2262 (0.3501)  Image Caption Matching Loss: 0.2884 (0.4278)  Masked Language Modeling Loss: 1.5310 (1.6863)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0674 (3.7050)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8588)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8589)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.8605)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8782)  Batch Accuracy (Choose Caption): 0.9375 (0.9175)  Batch Accuracy (Choose Image): 0.9219 (0.9177)  Masked Language Modeling Accuracy: 0.6651 (0.6543)  time: 0.6751 (0.7880)  data: 0.0191 (0.0970)  lr: 0.001000  max mem: 12203
2021-04-02 03:40:10,886 maskrcnn_benchmark.trainer INFO: eta: 2:21:46  iter: 29200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2971 (0.4215)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3637 (0.4122)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2996 (0.4055)  Cross-Entropy Loss (Align Words, Choose Image): 0.2748 (0.3496)  Image Caption Matching Loss: 0.3185 (0.4271)  Masked Language Modeling Loss: 1.7212 (1.6859)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3437 (3.7018)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8589)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8590)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8607)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8783)  Batch Accuracy (Choose Caption): 0.9219 (0.9176)  Batch Accuracy (Choose Image): 0.9219 (0.9179)  Masked Language Modeling Accuracy: 0.6583 (0.6543)  time: 0.6648 (0.7876)  data: 0.0186 (0.0966)  lr: 0.001000  max mem: 12203
2021-04-02 03:41:27,183 maskrcnn_benchmark.trainer INFO: eta: 2:20:25  iter: 29300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3206 (0.4210)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2660 (0.4117)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2555 (0.4049)  Cross-Entropy Loss (Align Words, Choose Image): 0.2163 (0.3492)  Image Caption Matching Loss: 0.2800 (0.4264)  Masked Language Modeling Loss: 1.6257 (1.6855)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0067 (3.6987)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8591)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8591)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8609)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8785)  Batch Accuracy (Choose Caption): 0.9688 (0.9178)  Batch Accuracy (Choose Image): 0.9531 (0.9180)  Masked Language Modeling Accuracy: 0.6763 (0.6544)  time: 0.6735 (0.7874)  data: 0.0192 (0.0962)  lr: 0.001000  max mem: 12203
2021-04-02 03:42:38,775 maskrcnn_benchmark.trainer INFO: eta: 2:19:01  iter: 29400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3660 (0.4204)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3321 (0.4112)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2767 (0.4041)  Cross-Entropy Loss (Align Words, Choose Image): 0.2728 (0.3486)  Image Caption Matching Loss: 0.3041 (0.4256)  Masked Language Modeling Loss: 1.5394 (1.6851)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9598 (3.6949)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8593)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8593)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8612)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8786)  Batch Accuracy (Choose Caption): 0.9531 (0.9179)  Batch Accuracy (Choose Image): 0.9375 (0.9181)  Masked Language Modeling Accuracy: 0.6647 (0.6544)  time: 0.6755 (0.7870)  data: 0.0189 (0.0957)  lr: 0.001000  max mem: 12203
2021-04-02 03:43:56,223 maskrcnn_benchmark.trainer INFO: eta: 2:17:42  iter: 29500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3026 (0.4200)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3749 (0.4108)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3728 (0.4037)  Cross-Entropy Loss (Align Words, Choose Image): 0.3008 (0.3482)  Image Caption Matching Loss: 0.2762 (0.4250)  Masked Language Modeling Loss: 1.6662 (1.6850)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3966 (3.6928)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8594)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8594)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8613)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8788)  Batch Accuracy (Choose Caption): 0.9375 (0.9181)  Batch Accuracy (Choose Image): 0.9375 (0.9182)  Masked Language Modeling Accuracy: 0.6524 (0.6545)  time: 0.6741 (0.7869)  data: 0.0192 (0.0953)  lr: 0.001000  max mem: 12203
2021-04-02 03:45:09,861 maskrcnn_benchmark.trainer INFO: eta: 2:16:20  iter: 29600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3687 (0.4194)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3062 (0.4102)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3408 (0.4031)  Cross-Entropy Loss (Align Words, Choose Image): 0.2502 (0.3477)  Image Caption Matching Loss: 0.2960 (0.4242)  Masked Language Modeling Loss: 1.6371 (1.6844)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3356 (3.6891)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8596)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8596)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8616)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8789)  Batch Accuracy (Choose Caption): 0.9375 (0.9182)  Batch Accuracy (Choose Image): 0.9375 (0.9183)  Masked Language Modeling Accuracy: 0.6718 (0.6545)  time: 0.6776 (0.7866)  data: 0.0203 (0.0949)  lr: 0.001000  max mem: 12203
2021-04-02 03:46:18,640 maskrcnn_benchmark.trainer INFO: eta: 2:14:55  iter: 29700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3758 (0.4190)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3030 (0.4097)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3108 (0.4026)  Cross-Entropy Loss (Align Words, Choose Image): 0.2641 (0.3472)  Image Caption Matching Loss: 0.3480 (0.4236)  Masked Language Modeling Loss: 1.5734 (1.6839)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2202 (3.6862)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8597)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8598)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8617)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8791)  Batch Accuracy (Choose Caption): 0.9375 (0.9183)  Batch Accuracy (Choose Image): 0.9219 (0.9184)  Masked Language Modeling Accuracy: 0.6559 (0.6546)  time: 0.6710 (0.7859)  data: 0.0187 (0.0944)  lr: 0.001000  max mem: 12203
2021-04-02 03:47:27,543 maskrcnn_benchmark.trainer INFO: eta: 2:13:30  iter: 29800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.4398 (0.4186)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3880 (0.4093)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3449 (0.4020)  Cross-Entropy Loss (Align Words, Choose Image): 0.2949 (0.3468)  Image Caption Matching Loss: 0.3693 (0.4230)  Masked Language Modeling Loss: 1.5960 (1.6835)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3980 (3.6832)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8599)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8600)  Batch Accuracy (Align Words, Choose Caption): 0.8594 (0.8619)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8792)  Batch Accuracy (Choose Caption): 0.9219 (0.9184)  Batch Accuracy (Choose Image): 0.9375 (0.9186)  Masked Language Modeling Accuracy: 0.6515 (0.6546)  time: 0.6657 (0.7853)  data: 0.0206 (0.0940)  lr: 0.001000  max mem: 12203
2021-04-02 03:48:37,538 maskrcnn_benchmark.trainer INFO: eta: 2:12:06  iter: 29900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2981 (0.4181)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3149 (0.4089)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2853 (0.4014)  Cross-Entropy Loss (Align Words, Choose Image): 0.2963 (0.3464)  Image Caption Matching Loss: 0.2804 (0.4221)  Masked Language Modeling Loss: 1.4984 (1.6833)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0461 (3.6802)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8600)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8601)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8621)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8794)  Batch Accuracy (Choose Caption): 0.9531 (0.9186)  Batch Accuracy (Choose Image): 0.9375 (0.9187)  Masked Language Modeling Accuracy: 0.6724 (0.6547)  time: 0.6691 (0.7848)  data: 0.0188 (0.0936)  lr: 0.001000  max mem: 12203
2021-04-02 03:49:47,246 maskrcnn_benchmark.trainer INFO: eta: 2:10:42  iter: 30000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2861 (0.4176)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2976 (0.4084)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2985 (0.4008)  Cross-Entropy Loss (Align Words, Choose Image): 0.2607 (0.3460)  Image Caption Matching Loss: 0.2934 (0.4215)  Masked Language Modeling Loss: 1.5360 (1.6828)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9793 (3.6771)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8602)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8603)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8623)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8795)  Batch Accuracy (Choose Caption): 0.9219 (0.9187)  Batch Accuracy (Choose Image): 0.9375 (0.9188)  Masked Language Modeling Accuracy: 0.6680 (0.6547)  time: 0.6752 (0.7843)  data: 0.0198 (0.0932)  lr: 0.001000  max mem: 12203
2021-04-02 03:49:47,563 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0030000.pth
2021-04-02 03:50:55,866 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 2:10:42  iter: 30000  loss: 1.2892 (1.2560)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2110 (0.2340)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2530 (0.2456)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2909 (0.2698)  Cross-Entropy Loss (Align Words, Choose Image): 0.2708 (0.2280)  Image Caption Matching Loss: 0.2511 (0.2786)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9173)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9176)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.9030)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.9170)  Batch Accuracy (Choose Caption): 0.9375 (0.9492)  Batch Accuracy (Choose Image): 0.9531 (0.9485)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 03:52:08,552 maskrcnn_benchmark.trainer INFO: eta: 2:10:02  iter: 30100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3810 (0.4170)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3064 (0.4079)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3295 (0.4002)  Cross-Entropy Loss (Align Words, Choose Image): 0.3177 (0.3455)  Image Caption Matching Loss: 0.3468 (0.4208)  Masked Language Modeling Loss: 1.5017 (1.6824)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1248 (3.6739)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8604)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8605)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8625)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8797)  Batch Accuracy (Choose Caption): 0.9375 (0.9189)  Batch Accuracy (Choose Image): 0.9062 (0.9189)  Masked Language Modeling Accuracy: 0.6879 (0.6548)  time: 0.6764 (0.7882)  data: 0.0206 (0.0970)  lr: 0.001000  max mem: 12203
2021-04-02 03:53:25,933 maskrcnn_benchmark.trainer INFO: eta: 2:08:42  iter: 30200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3644 (0.4166)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3072 (0.4075)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3125 (0.3997)  Cross-Entropy Loss (Align Words, Choose Image): 0.2724 (0.3450)  Image Caption Matching Loss: 0.3037 (0.4202)  Masked Language Modeling Loss: 1.6125 (1.6819)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2392 (3.6710)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8606)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8606)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8627)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8798)  Batch Accuracy (Choose Caption): 0.9375 (0.9190)  Batch Accuracy (Choose Image): 0.9375 (0.9190)  Masked Language Modeling Accuracy: 0.6622 (0.6549)  time: 0.6757 (0.7881)  data: 0.0194 (0.0966)  lr: 0.001000  max mem: 12203
2021-04-02 03:54:39,103 maskrcnn_benchmark.trainer INFO: eta: 2:07:20  iter: 30300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3083 (0.4161)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3378 (0.4070)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2855 (0.3991)  Cross-Entropy Loss (Align Words, Choose Image): 0.2458 (0.3446)  Image Caption Matching Loss: 0.2677 (0.4195)  Masked Language Modeling Loss: 1.8156 (1.6816)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3678 (3.6679)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8608)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8608)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8629)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8800)  Batch Accuracy (Choose Caption): 0.9531 (0.9191)  Batch Accuracy (Choose Image): 0.9375 (0.9191)  Masked Language Modeling Accuracy: 0.6393 (0.6549)  time: 0.6671 (0.7877)  data: 0.0194 (0.0962)  lr: 0.001000  max mem: 12203
2021-04-02 03:55:48,185 maskrcnn_benchmark.trainer INFO: eta: 2:05:56  iter: 30400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3488 (0.4158)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3475 (0.4068)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2603 (0.3986)  Cross-Entropy Loss (Align Words, Choose Image): 0.2678 (0.3442)  Image Caption Matching Loss: 0.2990 (0.4189)  Masked Language Modeling Loss: 1.6740 (1.6816)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2851 (3.6658)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8609)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8609)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8630)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8801)  Batch Accuracy (Choose Caption): 0.9375 (0.9193)  Batch Accuracy (Choose Image): 0.9375 (0.9192)  Masked Language Modeling Accuracy: 0.6615 (0.6549)  time: 0.6744 (0.7871)  data: 0.0185 (0.0958)  lr: 0.001000  max mem: 12203
2021-04-02 03:56:58,096 maskrcnn_benchmark.trainer INFO: eta: 2:04:32  iter: 30500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3217 (0.4153)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2722 (0.4062)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2696 (0.3980)  Cross-Entropy Loss (Align Words, Choose Image): 0.2415 (0.3437)  Image Caption Matching Loss: 0.2652 (0.4183)  Masked Language Modeling Loss: 1.5582 (1.6814)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0858 (3.6628)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8610)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8611)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8633)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8803)  Batch Accuracy (Choose Caption): 0.9375 (0.9194)  Batch Accuracy (Choose Image): 0.9375 (0.9193)  Masked Language Modeling Accuracy: 0.6689 (0.6549)  time: 0.6771 (0.7866)  data: 0.0194 (0.0954)  lr: 0.001000  max mem: 12203
2021-04-02 03:58:07,009 maskrcnn_benchmark.trainer INFO: eta: 2:03:08  iter: 30600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3106 (0.4148)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2887 (0.4057)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3344 (0.3974)  Cross-Entropy Loss (Align Words, Choose Image): 0.2292 (0.3432)  Image Caption Matching Loss: 0.3389 (0.4176)  Masked Language Modeling Loss: 1.5817 (1.6810)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1357 (3.6596)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8612)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8612)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8635)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8805)  Batch Accuracy (Choose Caption): 0.9219 (0.9195)  Batch Accuracy (Choose Image): 0.9375 (0.9194)  Masked Language Modeling Accuracy: 0.6602 (0.6550)  time: 0.6758 (0.7860)  data: 0.0188 (0.0950)  lr: 0.001000  max mem: 12203
2021-04-02 03:59:16,185 maskrcnn_benchmark.trainer INFO: eta: 2:01:44  iter: 30700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3351 (0.4144)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2782 (0.4053)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2834 (0.3968)  Cross-Entropy Loss (Align Words, Choose Image): 0.2617 (0.3427)  Image Caption Matching Loss: 0.2503 (0.4170)  Masked Language Modeling Loss: 1.5548 (1.6806)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0787 (3.6568)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8613)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8614)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8637)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8806)  Batch Accuracy (Choose Caption): 0.9531 (0.9197)  Batch Accuracy (Choose Image): 0.9531 (0.9196)  Masked Language Modeling Accuracy: 0.6629 (0.6551)  time: 0.6685 (0.7854)  data: 0.0186 (0.0946)  lr: 0.001000  max mem: 12203
2021-04-02 04:00:28,357 maskrcnn_benchmark.trainer INFO: eta: 2:00:22  iter: 30800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3201 (0.4141)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2963 (0.4049)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3128 (0.3963)  Cross-Entropy Loss (Align Words, Choose Image): 0.2737 (0.3423)  Image Caption Matching Loss: 0.2735 (0.4163)  Masked Language Modeling Loss: 1.5328 (1.6802)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0434 (3.6542)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8614)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8615)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8638)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8808)  Batch Accuracy (Choose Caption): 0.9375 (0.9198)  Batch Accuracy (Choose Image): 0.9375 (0.9197)  Masked Language Modeling Accuracy: 0.6629 (0.6552)  time: 0.6673 (0.7851)  data: 0.0187 (0.0942)  lr: 0.001000  max mem: 12203
2021-04-02 04:01:38,373 maskrcnn_benchmark.trainer INFO: eta: 1:58:59  iter: 30900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3074 (0.4136)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3227 (0.4045)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3247 (0.3959)  Cross-Entropy Loss (Align Words, Choose Image): 0.2993 (0.3419)  Image Caption Matching Loss: 0.2628 (0.4156)  Masked Language Modeling Loss: 1.5840 (1.6800)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2178 (3.6516)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8616)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8616)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8640)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8809)  Batch Accuracy (Choose Caption): 0.9531 (0.9199)  Batch Accuracy (Choose Image): 0.9375 (0.9198)  Masked Language Modeling Accuracy: 0.6606 (0.6552)  time: 0.6790 (0.7846)  data: 0.0197 (0.0938)  lr: 0.001000  max mem: 12203
2021-04-02 04:02:53,779 maskrcnn_benchmark.trainer INFO: eta: 1:57:39  iter: 31000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3125 (0.4132)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3341 (0.4042)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2891 (0.3954)  Cross-Entropy Loss (Align Words, Choose Image): 0.2782 (0.3415)  Image Caption Matching Loss: 0.2777 (0.4151)  Masked Language Modeling Loss: 1.4794 (1.6793)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0196 (3.6487)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8618)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8617)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8641)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8810)  Batch Accuracy (Choose Caption): 0.9531 (0.9201)  Batch Accuracy (Choose Image): 0.9375 (0.9199)  Masked Language Modeling Accuracy: 0.6732 (0.6553)  time: 0.6676 (0.7844)  data: 0.0191 (0.0934)  lr: 0.001000  max mem: 12203
2021-04-02 04:02:54,089 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0031000.pth
2021-04-02 04:04:04,988 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 1:57:39  iter: 31000  loss: 1.2109 (1.2800)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2281 (0.2391)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2334 (0.2596)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2689 (0.2694)  Cross-Entropy Loss (Align Words, Choose Image): 0.2379 (0.2274)  Image Caption Matching Loss: 0.2505 (0.2845)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9140)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.9094)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.9004)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9169)  Batch Accuracy (Choose Caption): 0.9375 (0.9424)  Batch Accuracy (Choose Image): 0.9375 (0.9432)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 04:05:21,649 maskrcnn_benchmark.trainer INFO: eta: 1:56:57  iter: 31100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3404 (0.4128)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3702 (0.4037)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2669 (0.3949)  Cross-Entropy Loss (Align Words, Choose Image): 0.2619 (0.3411)  Image Caption Matching Loss: 0.2997 (0.4145)  Masked Language Modeling Loss: 1.5436 (1.6786)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9459 (3.6456)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8619)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8619)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8643)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8812)  Batch Accuracy (Choose Caption): 0.9375 (0.9202)  Batch Accuracy (Choose Image): 0.9531 (0.9200)  Masked Language Modeling Accuracy: 0.6889 (0.6554)  time: 0.6693 (0.7884)  data: 0.0192 (0.0972)  lr: 0.001000  max mem: 12203
2021-04-02 04:06:33,671 maskrcnn_benchmark.trainer INFO: eta: 1:55:34  iter: 31200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3766 (0.4123)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3467 (0.4033)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2991 (0.3943)  Cross-Entropy Loss (Align Words, Choose Image): 0.2537 (0.3406)  Image Caption Matching Loss: 0.3578 (0.4139)  Masked Language Modeling Loss: 1.7115 (1.6783)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.4156 (3.6428)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8621)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8620)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8645)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8813)  Batch Accuracy (Choose Caption): 0.9219 (0.9203)  Batch Accuracy (Choose Image): 0.9219 (0.9201)  Masked Language Modeling Accuracy: 0.6349 (0.6554)  time: 0.6679 (0.7880)  data: 0.0195 (0.0968)  lr: 0.001000  max mem: 12203
2021-04-02 04:07:43,050 maskrcnn_benchmark.trainer INFO: eta: 1:54:11  iter: 31300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2851 (0.4119)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2748 (0.4029)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2514 (0.3938)  Cross-Entropy Loss (Align Words, Choose Image): 0.2271 (0.3403)  Image Caption Matching Loss: 0.2615 (0.4133)  Masked Language Modeling Loss: 1.6114 (1.6782)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8431 (3.6404)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8622)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8621)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8647)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8814)  Batch Accuracy (Choose Caption): 0.9531 (0.9204)  Batch Accuracy (Choose Image): 0.9375 (0.9202)  Masked Language Modeling Accuracy: 0.6836 (0.6555)  time: 0.6735 (0.7875)  data: 0.0198 (0.0964)  lr: 0.001000  max mem: 12203
2021-04-02 04:08:51,382 maskrcnn_benchmark.trainer INFO: eta: 1:52:47  iter: 31400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3139 (0.4115)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3075 (0.4025)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2678 (0.3934)  Cross-Entropy Loss (Align Words, Choose Image): 0.2426 (0.3398)  Image Caption Matching Loss: 0.2854 (0.4128)  Masked Language Modeling Loss: 1.5809 (1.6777)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0649 (3.6376)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8624)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8623)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8648)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8816)  Batch Accuracy (Choose Caption): 0.9375 (0.9205)  Batch Accuracy (Choose Image): 0.9219 (0.9203)  Masked Language Modeling Accuracy: 0.6728 (0.6556)  time: 0.6612 (0.7869)  data: 0.0190 (0.0960)  lr: 0.001000  max mem: 12203
2021-04-02 04:10:03,500 maskrcnn_benchmark.trainer INFO: eta: 1:51:25  iter: 31500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3126 (0.4110)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2781 (0.4021)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3179 (0.3929)  Cross-Entropy Loss (Align Words, Choose Image): 0.2266 (0.3394)  Image Caption Matching Loss: 0.2972 (0.4122)  Masked Language Modeling Loss: 1.6277 (1.6776)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1221 (3.6353)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8625)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8624)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8650)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8817)  Batch Accuracy (Choose Caption): 0.9375 (0.9206)  Batch Accuracy (Choose Image): 0.9375 (0.9204)  Masked Language Modeling Accuracy: 0.6752 (0.6556)  time: 0.6736 (0.7865)  data: 0.0203 (0.0956)  lr: 0.001000  max mem: 12203
2021-04-02 04:11:14,996 maskrcnn_benchmark.trainer INFO: eta: 1:50:03  iter: 31600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2706 (0.4106)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3192 (0.4017)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3071 (0.3924)  Cross-Entropy Loss (Align Words, Choose Image): 0.2359 (0.3390)  Image Caption Matching Loss: 0.2737 (0.4117)  Masked Language Modeling Loss: 1.5966 (1.6773)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1708 (3.6327)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8627)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8625)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8651)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8819)  Batch Accuracy (Choose Caption): 0.9531 (0.9207)  Batch Accuracy (Choose Image): 0.9531 (0.9205)  Masked Language Modeling Accuracy: 0.6520 (0.6556)  time: 0.6840 (0.7861)  data: 0.0192 (0.0953)  lr: 0.001000  max mem: 12203
2021-04-02 04:12:27,006 maskrcnn_benchmark.trainer INFO: eta: 1:48:41  iter: 31700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3567 (0.4103)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3618 (0.4014)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2749 (0.3919)  Cross-Entropy Loss (Align Words, Choose Image): 0.2908 (0.3387)  Image Caption Matching Loss: 0.3494 (0.4113)  Masked Language Modeling Loss: 1.5631 (1.6768)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2118 (3.6306)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8628)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8626)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8653)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8819)  Batch Accuracy (Choose Caption): 0.9219 (0.9208)  Batch Accuracy (Choose Image): 0.9375 (0.9206)  Masked Language Modeling Accuracy: 0.6734 (0.6557)  time: 0.6669 (0.7857)  data: 0.0184 (0.0949)  lr: 0.001000  max mem: 12203
2021-04-02 04:13:35,881 maskrcnn_benchmark.trainer INFO: eta: 1:47:18  iter: 31800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3257 (0.4099)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3447 (0.4011)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3164 (0.3915)  Cross-Entropy Loss (Align Words, Choose Image): 0.2990 (0.3383)  Image Caption Matching Loss: 0.3142 (0.4107)  Masked Language Modeling Loss: 1.5898 (1.6766)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3520 (3.6282)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8629)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8627)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8654)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8820)  Batch Accuracy (Choose Caption): 0.9375 (0.9209)  Batch Accuracy (Choose Image): 0.9375 (0.9207)  Masked Language Modeling Accuracy: 0.6661 (0.6557)  time: 0.6642 (0.7852)  data: 0.0191 (0.0945)  lr: 0.001000  max mem: 12203
2021-04-02 04:14:45,096 maskrcnn_benchmark.trainer INFO: eta: 1:45:55  iter: 31900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3694 (0.4095)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3096 (0.4007)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3012 (0.3910)  Cross-Entropy Loss (Align Words, Choose Image): 0.2704 (0.3379)  Image Caption Matching Loss: 0.3162 (0.4102)  Masked Language Modeling Loss: 1.4599 (1.6765)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0204 (3.6258)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8630)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8628)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8656)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8822)  Batch Accuracy (Choose Caption): 0.9375 (0.9210)  Batch Accuracy (Choose Image): 0.9375 (0.9208)  Masked Language Modeling Accuracy: 0.6908 (0.6558)  time: 0.6689 (0.7847)  data: 0.0194 (0.0941)  lr: 0.001000  max mem: 12203
2021-04-02 04:15:55,784 maskrcnn_benchmark.trainer INFO: eta: 1:44:34  iter: 32000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3508 (0.4091)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3211 (0.4003)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2996 (0.3906)  Cross-Entropy Loss (Align Words, Choose Image): 0.2866 (0.3376)  Image Caption Matching Loss: 0.2854 (0.4096)  Masked Language Modeling Loss: 1.6020 (1.6763)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2194 (3.6234)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8632)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8629)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8657)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8823)  Batch Accuracy (Choose Caption): 0.9531 (0.9212)  Batch Accuracy (Choose Image): 0.9375 (0.9209)  Masked Language Modeling Accuracy: 0.6595 (0.6558)  time: 0.6731 (0.7843)  data: 0.0190 (0.0938)  lr: 0.001000  max mem: 12203
2021-04-02 04:15:56,094 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0032000.pth
2021-04-02 04:17:04,069 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 1:44:34  iter: 32000  loss: 1.2576 (1.2538)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2388 (0.2380)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2397 (0.2511)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3088 (0.2626)  Cross-Entropy Loss (Align Words, Choose Image): 0.2344 (0.2304)  Image Caption Matching Loss: 0.2418 (0.2718)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9167 (0.9206)  Batch Accuracy (Align Regions, Choose Image): 0.9321 (0.9185)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.9063)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9188)  Batch Accuracy (Choose Caption): 0.9531 (0.9501)  Batch Accuracy (Choose Image): 0.9531 (0.9499)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 04:18:16,716 maskrcnn_benchmark.trainer INFO: eta: 1:43:42  iter: 32100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3309 (0.4086)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3302 (0.3997)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3080 (0.3900)  Cross-Entropy Loss (Align Words, Choose Image): 0.2743 (0.3371)  Image Caption Matching Loss: 0.2679 (0.4089)  Masked Language Modeling Loss: 1.5388 (1.6758)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1342 (3.6203)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8633)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8631)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8659)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8825)  Batch Accuracy (Choose Caption): 0.9375 (0.9213)  Batch Accuracy (Choose Image): 0.9375 (0.9210)  Masked Language Modeling Accuracy: 0.6637 (0.6559)  time: 0.6772 (0.7877)  data: 0.0189 (0.0972)  lr: 0.001000  max mem: 12203
2021-04-02 04:19:25,828 maskrcnn_benchmark.trainer INFO: eta: 1:42:19  iter: 32200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3813 (0.4083)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3536 (0.3995)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3370 (0.3896)  Cross-Entropy Loss (Align Words, Choose Image): 0.2755 (0.3368)  Image Caption Matching Loss: 0.3455 (0.4085)  Masked Language Modeling Loss: 1.5162 (1.6753)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3956 (3.6179)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8634)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8632)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8661)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8826)  Batch Accuracy (Choose Caption): 0.9219 (0.9214)  Batch Accuracy (Choose Image): 0.9375 (0.9211)  Masked Language Modeling Accuracy: 0.6661 (0.6560)  time: 0.6707 (0.7872)  data: 0.0190 (0.0968)  lr: 0.001000  max mem: 12203
2021-04-02 04:20:35,561 maskrcnn_benchmark.trainer INFO: eta: 1:40:57  iter: 32300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3828 (0.4081)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3771 (0.3992)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3011 (0.3892)  Cross-Entropy Loss (Align Words, Choose Image): 0.2654 (0.3364)  Image Caption Matching Loss: 0.3493 (0.4079)  Masked Language Modeling Loss: 1.4540 (1.6749)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2173 (3.6159)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8635)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8633)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8662)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8827)  Batch Accuracy (Choose Caption): 0.9219 (0.9215)  Batch Accuracy (Choose Image): 0.9531 (0.9212)  Masked Language Modeling Accuracy: 0.6877 (0.6561)  time: 0.6670 (0.7867)  data: 0.0187 (0.0964)  lr: 0.001000  max mem: 12203
2021-04-02 04:21:44,985 maskrcnn_benchmark.trainer INFO: eta: 1:39:34  iter: 32400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2983 (0.4077)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2839 (0.3988)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3001 (0.3888)  Cross-Entropy Loss (Align Words, Choose Image): 0.2310 (0.3361)  Image Caption Matching Loss: 0.2663 (0.4074)  Masked Language Modeling Loss: 1.6374 (1.6745)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0952 (3.6132)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8637)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8635)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8663)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8828)  Batch Accuracy (Choose Caption): 0.9375 (0.9216)  Batch Accuracy (Choose Image): 0.9375 (0.9213)  Masked Language Modeling Accuracy: 0.6591 (0.6561)  time: 0.6702 (0.7862)  data: 0.0211 (0.0960)  lr: 0.001000  max mem: 12203
2021-04-02 04:22:57,820 maskrcnn_benchmark.trainer INFO: eta: 1:38:13  iter: 32500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2918 (0.4074)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2929 (0.3984)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2995 (0.3884)  Cross-Entropy Loss (Align Words, Choose Image): 0.2738 (0.3358)  Image Caption Matching Loss: 0.2542 (0.4068)  Masked Language Modeling Loss: 1.7172 (1.6742)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2614 (3.6110)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8638)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8636)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8664)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8829)  Batch Accuracy (Choose Caption): 0.9438 (0.9217)  Batch Accuracy (Choose Image): 0.9375 (0.9214)  Masked Language Modeling Accuracy: 0.6535 (0.6562)  time: 0.6787 (0.7859)  data: 0.0184 (0.0957)  lr: 0.001000  max mem: 12203
2021-04-02 04:24:14,729 maskrcnn_benchmark.trainer INFO: eta: 1:36:54  iter: 32600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3213 (0.4070)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3592 (0.3981)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2833 (0.3880)  Cross-Entropy Loss (Align Words, Choose Image): 0.2983 (0.3354)  Image Caption Matching Loss: 0.2777 (0.4063)  Masked Language Modeling Loss: 1.5967 (1.6737)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9859 (3.6084)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8639)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8636)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8666)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8830)  Batch Accuracy (Choose Caption): 0.9219 (0.9218)  Batch Accuracy (Choose Image): 0.9375 (0.9215)  Masked Language Modeling Accuracy: 0.6856 (0.6562)  time: 0.6752 (0.7858)  data: 0.0189 (0.0953)  lr: 0.001000  max mem: 12203
2021-04-02 04:25:27,917 maskrcnn_benchmark.trainer INFO: eta: 1:35:34  iter: 32700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3490 (0.4067)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3422 (0.3978)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2955 (0.3875)  Cross-Entropy Loss (Align Words, Choose Image): 0.2596 (0.3350)  Image Caption Matching Loss: 0.2737 (0.4058)  Masked Language Modeling Loss: 1.5274 (1.6733)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1355 (3.6061)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8640)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8638)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8667)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8831)  Batch Accuracy (Choose Caption): 0.9375 (0.9219)  Batch Accuracy (Choose Image): 0.9375 (0.9215)  Masked Language Modeling Accuracy: 0.6539 (0.6563)  time: 0.6695 (0.7855)  data: 0.0188 (0.0950)  lr: 0.001000  max mem: 12203
2021-04-02 04:26:39,559 maskrcnn_benchmark.trainer INFO: eta: 1:34:12  iter: 32800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3208 (0.4064)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3104 (0.3974)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2782 (0.3871)  Cross-Entropy Loss (Align Words, Choose Image): 0.2493 (0.3347)  Image Caption Matching Loss: 0.2832 (0.4053)  Masked Language Modeling Loss: 1.5836 (1.6729)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9685 (3.6038)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8641)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8639)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8668)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8833)  Batch Accuracy (Choose Caption): 0.9375 (0.9220)  Batch Accuracy (Choose Image): 0.9375 (0.9216)  Masked Language Modeling Accuracy: 0.6704 (0.6563)  time: 0.6719 (0.7851)  data: 0.0189 (0.0946)  lr: 0.001000  max mem: 12203
2021-04-02 04:27:51,516 maskrcnn_benchmark.trainer INFO: eta: 1:32:51  iter: 32900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3155 (0.4061)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3040 (0.3971)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2580 (0.3867)  Cross-Entropy Loss (Align Words, Choose Image): 0.2397 (0.3343)  Image Caption Matching Loss: 0.2388 (0.4048)  Masked Language Modeling Loss: 1.5578 (1.6725)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8942 (3.6014)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8642)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8640)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8670)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8834)  Batch Accuracy (Choose Caption): 0.9531 (0.9221)  Batch Accuracy (Choose Image): 0.9375 (0.9217)  Masked Language Modeling Accuracy: 0.6632 (0.6564)  time: 0.6810 (0.7848)  data: 0.0188 (0.0943)  lr: 0.001000  max mem: 12203
2021-04-02 04:29:04,036 maskrcnn_benchmark.trainer INFO: eta: 1:31:31  iter: 33000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3649 (0.4057)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3253 (0.3968)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3281 (0.3862)  Cross-Entropy Loss (Align Words, Choose Image): 0.2664 (0.3339)  Image Caption Matching Loss: 0.3132 (0.4043)  Masked Language Modeling Loss: 1.5993 (1.6723)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2772 (3.5992)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8644)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8641)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8672)  Batch Accuracy (Align Words, Choose Image): 0.8750 (0.8835)  Batch Accuracy (Choose Caption): 0.9375 (0.9222)  Batch Accuracy (Choose Image): 0.9375 (0.9218)  Masked Language Modeling Accuracy: 0.6556 (0.6565)  time: 0.6748 (0.7845)  data: 0.0188 (0.0940)  lr: 0.001000  max mem: 12203
2021-04-02 04:29:04,323 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0033000.pth
2021-04-02 04:30:13,208 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 1:31:31  iter: 33000  loss: 1.3595 (1.2358)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2351 (0.2386)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2460 (0.2508)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2941 (0.2622)  Cross-Entropy Loss (Align Words, Choose Image): 0.2463 (0.2125)  Image Caption Matching Loss: 0.2558 (0.2717)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9170)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9128)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9077)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9248)  Batch Accuracy (Choose Caption): 0.9375 (0.9495)  Batch Accuracy (Choose Image): 0.9531 (0.9504)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 04:31:30,178 maskrcnn_benchmark.trainer INFO: eta: 1:30:37  iter: 33100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3095 (0.4054)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2992 (0.3965)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2929 (0.3858)  Cross-Entropy Loss (Align Words, Choose Image): 0.2682 (0.3336)  Image Caption Matching Loss: 0.2927 (0.4039)  Masked Language Modeling Loss: 1.4941 (1.6721)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9736 (3.5972)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8644)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8642)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8673)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8836)  Batch Accuracy (Choose Caption): 0.9531 (0.9223)  Batch Accuracy (Choose Image): 0.9375 (0.9218)  Masked Language Modeling Accuracy: 0.6740 (0.6565)  time: 0.6716 (0.7880)  data: 0.0192 (0.0973)  lr: 0.001000  max mem: 12203
2021-04-02 04:32:42,484 maskrcnn_benchmark.trainer INFO: eta: 1:29:16  iter: 33200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3525 (0.4050)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3346 (0.3961)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3074 (0.3854)  Cross-Entropy Loss (Align Words, Choose Image): 0.2905 (0.3332)  Image Caption Matching Loss: 0.3147 (0.4034)  Masked Language Modeling Loss: 1.6039 (1.6719)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1709 (3.5949)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8646)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8643)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8674)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8837)  Batch Accuracy (Choose Caption): 0.9375 (0.9224)  Batch Accuracy (Choose Image): 0.9375 (0.9219)  Masked Language Modeling Accuracy: 0.6595 (0.6565)  time: 0.6831 (0.7877)  data: 0.0196 (0.0969)  lr: 0.001000  max mem: 12203
2021-04-02 04:33:51,857 maskrcnn_benchmark.trainer INFO: eta: 1:27:54  iter: 33300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3084 (0.4048)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2868 (0.3958)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2784 (0.3850)  Cross-Entropy Loss (Align Words, Choose Image): 0.2459 (0.3329)  Image Caption Matching Loss: 0.2898 (0.4029)  Masked Language Modeling Loss: 1.5785 (1.6715)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0276 (3.5929)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8647)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8644)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8675)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8838)  Batch Accuracy (Choose Caption): 0.9375 (0.9225)  Batch Accuracy (Choose Image): 0.9375 (0.9220)  Masked Language Modeling Accuracy: 0.6796 (0.6566)  time: 0.6749 (0.7872)  data: 0.0193 (0.0966)  lr: 0.001000  max mem: 12203
2021-04-02 04:35:07,057 maskrcnn_benchmark.trainer INFO: eta: 1:26:34  iter: 33400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2870 (0.4044)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2954 (0.3954)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2712 (0.3845)  Cross-Entropy Loss (Align Words, Choose Image): 0.2196 (0.3326)  Image Caption Matching Loss: 0.3081 (0.4024)  Masked Language Modeling Loss: 1.6303 (1.6714)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9710 (3.5907)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8648)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8645)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8677)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8839)  Batch Accuracy (Choose Caption): 0.9531 (0.9226)  Batch Accuracy (Choose Image): 0.9375 (0.9221)  Masked Language Modeling Accuracy: 0.6494 (0.6566)  time: 0.6738 (0.7870)  data: 0.0196 (0.0962)  lr: 0.001000  max mem: 12203
2021-04-02 04:36:21,110 maskrcnn_benchmark.trainer INFO: eta: 1:25:13  iter: 33500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3536 (0.4041)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3406 (0.3951)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3270 (0.3842)  Cross-Entropy Loss (Align Words, Choose Image): 0.3051 (0.3323)  Image Caption Matching Loss: 0.3299 (0.4019)  Masked Language Modeling Loss: 1.5275 (1.6711)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9723 (3.5886)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8649)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8646)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8678)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8840)  Batch Accuracy (Choose Caption): 0.9062 (0.9227)  Batch Accuracy (Choose Image): 0.9375 (0.9222)  Masked Language Modeling Accuracy: 0.6941 (0.6567)  time: 0.6810 (0.7868)  data: 0.0197 (0.0959)  lr: 0.001000  max mem: 12203
2021-04-02 04:37:30,899 maskrcnn_benchmark.trainer INFO: eta: 1:23:52  iter: 33600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3453 (0.4037)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3542 (0.3947)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2487 (0.3837)  Cross-Entropy Loss (Align Words, Choose Image): 0.2507 (0.3319)  Image Caption Matching Loss: 0.2729 (0.4014)  Masked Language Modeling Loss: 1.6636 (1.6708)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2963 (3.5862)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8650)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8647)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8679)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8842)  Batch Accuracy (Choose Caption): 0.9531 (0.9228)  Batch Accuracy (Choose Image): 0.9531 (0.9223)  Masked Language Modeling Accuracy: 0.6322 (0.6567)  time: 0.6652 (0.7863)  data: 0.0193 (0.0955)  lr: 0.001000  max mem: 12203
2021-04-02 04:38:39,252 maskrcnn_benchmark.trainer INFO: eta: 1:22:30  iter: 33700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3561 (0.4034)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3514 (0.3944)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2896 (0.3833)  Cross-Entropy Loss (Align Words, Choose Image): 0.2888 (0.3315)  Image Caption Matching Loss: 0.3292 (0.4010)  Masked Language Modeling Loss: 1.4688 (1.6702)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1305 (3.5838)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8651)  Batch Accuracy (Align Regions, Choose Image): 0.8594 (0.8648)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8681)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8843)  Batch Accuracy (Choose Caption): 0.9375 (0.9229)  Batch Accuracy (Choose Image): 0.9219 (0.9223)  Masked Language Modeling Accuracy: 0.6786 (0.6568)  time: 0.6698 (0.7858)  data: 0.0199 (0.0952)  lr: 0.001000  max mem: 12203
2021-04-02 04:39:55,659 maskrcnn_benchmark.trainer INFO: eta: 1:21:11  iter: 33800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2816 (0.4029)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3570 (0.3941)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2669 (0.3828)  Cross-Entropy Loss (Align Words, Choose Image): 0.2405 (0.3312)  Image Caption Matching Loss: 0.2657 (0.4004)  Masked Language Modeling Loss: 1.5701 (1.6699)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0597 (3.5813)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8653)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8649)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8682)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8844)  Batch Accuracy (Choose Caption): 0.9531 (0.9230)  Batch Accuracy (Choose Image): 0.9531 (0.9224)  Masked Language Modeling Accuracy: 0.6611 (0.6568)  time: 0.6758 (0.7857)  data: 0.0185 (0.0949)  lr: 0.001000  max mem: 12203
2021-04-02 04:41:05,529 maskrcnn_benchmark.trainer INFO: eta: 1:19:49  iter: 33900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3441 (0.4026)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3435 (0.3938)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3073 (0.3825)  Cross-Entropy Loss (Align Words, Choose Image): 0.2709 (0.3308)  Image Caption Matching Loss: 0.2828 (0.4000)  Masked Language Modeling Loss: 1.6571 (1.6697)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1890 (3.5794)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8654)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8650)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8683)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8846)  Batch Accuracy (Choose Caption): 0.9531 (0.9231)  Batch Accuracy (Choose Image): 0.9375 (0.9225)  Masked Language Modeling Accuracy: 0.6454 (0.6569)  time: 0.6687 (0.7852)  data: 0.0190 (0.0945)  lr: 0.001000  max mem: 12203
2021-04-02 04:42:16,890 maskrcnn_benchmark.trainer INFO: eta: 1:18:29  iter: 34000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3068 (0.4023)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3462 (0.3934)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2762 (0.3821)  Cross-Entropy Loss (Align Words, Choose Image): 0.2617 (0.3305)  Image Caption Matching Loss: 0.2544 (0.3995)  Masked Language Modeling Loss: 1.5967 (1.6696)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0736 (3.5774)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8655)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8651)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8685)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8847)  Batch Accuracy (Choose Caption): 0.9531 (0.9232)  Batch Accuracy (Choose Image): 0.9375 (0.9226)  Masked Language Modeling Accuracy: 0.6572 (0.6568)  time: 0.6722 (0.7849)  data: 0.0188 (0.0942)  lr: 0.001000  max mem: 12203
2021-04-02 04:42:17,199 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0034000.pth
2021-04-02 04:43:25,926 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 1:18:29  iter: 34000  loss: 1.2352 (1.2361)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2401 (0.2345)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2372 (0.2518)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2862 (0.2577)  Cross-Entropy Loss (Align Words, Choose Image): 0.1843 (0.2175)  Image Caption Matching Loss: 0.2872 (0.2746)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9204)  Batch Accuracy (Align Regions, Choose Image): 0.9155 (0.9142)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9042)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9238)  Batch Accuracy (Choose Caption): 0.9531 (0.9482)  Batch Accuracy (Choose Image): 0.9375 (0.9490)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.001000  max mem: 12203
2021-04-02 04:44:36,471 maskrcnn_benchmark.trainer INFO: eta: 1:17:28  iter: 34100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2994 (0.4019)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2761 (0.3931)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2694 (0.3816)  Cross-Entropy Loss (Align Words, Choose Image): 0.2947 (0.3302)  Image Caption Matching Loss: 0.3088 (0.3990)  Masked Language Modeling Loss: 1.6279 (1.6694)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1117 (3.5753)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8656)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8652)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8686)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8848)  Batch Accuracy (Choose Caption): 0.9531 (0.9233)  Batch Accuracy (Choose Image): 0.9375 (0.9227)  Masked Language Modeling Accuracy: 0.6648 (0.6569)  time: 0.6714 (0.7879)  data: 0.0188 (0.0973)  lr: 0.001000  max mem: 12203
2021-04-02 04:45:45,157 maskrcnn_benchmark.trainer INFO: eta: 1:16:07  iter: 34200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3105 (0.4016)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2872 (0.3928)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2275 (0.3812)  Cross-Entropy Loss (Align Words, Choose Image): 0.2149 (0.3298)  Image Caption Matching Loss: 0.2495 (0.3985)  Masked Language Modeling Loss: 1.5521 (1.6691)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9981 (3.5731)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8657)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8654)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8687)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8849)  Batch Accuracy (Choose Caption): 0.9531 (0.9234)  Batch Accuracy (Choose Image): 0.9531 (0.9227)  Masked Language Modeling Accuracy: 0.6669 (0.6569)  time: 0.6686 (0.7874)  data: 0.0187 (0.0969)  lr: 0.001000  max mem: 12203
2021-04-02 04:46:59,541 maskrcnn_benchmark.trainer INFO: eta: 1:14:47  iter: 34300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3532 (0.4013)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3316 (0.3926)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2947 (0.3808)  Cross-Entropy Loss (Align Words, Choose Image): 0.2694 (0.3295)  Image Caption Matching Loss: 0.2670 (0.3981)  Masked Language Modeling Loss: 1.5454 (1.6689)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1900 (3.5713)  Batch Accuracy (Align Regions, Choose Caption): 0.8594 (0.8659)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8655)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8688)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8850)  Batch Accuracy (Choose Caption): 0.9531 (0.9235)  Batch Accuracy (Choose Image): 0.9531 (0.9228)  Masked Language Modeling Accuracy: 0.6795 (0.6570)  time: 0.6687 (0.7872)  data: 0.0194 (0.0966)  lr: 0.001000  max mem: 12203
2021-04-02 04:48:08,344 maskrcnn_benchmark.trainer INFO: eta: 1:13:25  iter: 34400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2915 (0.4010)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3024 (0.3923)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2869 (0.3804)  Cross-Entropy Loss (Align Words, Choose Image): 0.2757 (0.3292)  Image Caption Matching Loss: 0.2684 (0.3977)  Masked Language Modeling Loss: 1.5698 (1.6684)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9886 (3.5689)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8660)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8656)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8690)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8851)  Batch Accuracy (Choose Caption): 0.9375 (0.9236)  Batch Accuracy (Choose Image): 0.9375 (0.9229)  Masked Language Modeling Accuracy: 0.6747 (0.6571)  time: 0.6694 (0.7867)  data: 0.0188 (0.0962)  lr: 0.001000  max mem: 12203
2021-04-02 04:49:21,202 maskrcnn_benchmark.trainer INFO: eta: 1:12:05  iter: 34500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3219 (0.4007)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3267 (0.3920)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2551 (0.3800)  Cross-Entropy Loss (Align Words, Choose Image): 0.2785 (0.3289)  Image Caption Matching Loss: 0.2666 (0.3973)  Masked Language Modeling Loss: 1.6343 (1.6683)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0791 (3.5672)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8661)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8657)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8691)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8852)  Batch Accuracy (Choose Caption): 0.9375 (0.9236)  Batch Accuracy (Choose Image): 0.9375 (0.9229)  Masked Language Modeling Accuracy: 0.6494 (0.6571)  time: 0.6791 (0.7864)  data: 0.0185 (0.0959)  lr: 0.001000  max mem: 12203
2021-04-02 04:50:29,933 maskrcnn_benchmark.trainer INFO: eta: 1:10:44  iter: 34600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3008 (0.4004)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3042 (0.3917)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2712 (0.3797)  Cross-Entropy Loss (Align Words, Choose Image): 0.2384 (0.3286)  Image Caption Matching Loss: 0.2259 (0.3967)  Masked Language Modeling Loss: 1.5302 (1.6680)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0583 (3.5651)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8662)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8658)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8692)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8853)  Batch Accuracy (Choose Caption): 0.9531 (0.9237)  Batch Accuracy (Choose Image): 0.9531 (0.9230)  Masked Language Modeling Accuracy: 0.6630 (0.6572)  time: 0.6746 (0.7860)  data: 0.0197 (0.0956)  lr: 0.001000  max mem: 12203
2021-04-02 04:51:46,088 maskrcnn_benchmark.trainer INFO: eta: 1:09:24  iter: 34700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3033 (0.4000)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3063 (0.3913)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2594 (0.3792)  Cross-Entropy Loss (Align Words, Choose Image): 0.2260 (0.3283)  Image Caption Matching Loss: 0.2678 (0.3962)  Masked Language Modeling Loss: 1.6029 (1.6676)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9642 (3.5628)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8663)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8659)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8694)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8854)  Batch Accuracy (Choose Caption): 0.9688 (0.9238)  Batch Accuracy (Choose Image): 0.9375 (0.9231)  Masked Language Modeling Accuracy: 0.6619 (0.6572)  time: 0.6720 (0.7858)  data: 0.0191 (0.0952)  lr: 0.001000  max mem: 12203
2021-04-02 04:52:57,284 maskrcnn_benchmark.trainer INFO: eta: 1:08:04  iter: 34800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3244 (0.3998)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2930 (0.3910)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3108 (0.3789)  Cross-Entropy Loss (Align Words, Choose Image): 0.2700 (0.3280)  Image Caption Matching Loss: 0.3037 (0.3958)  Masked Language Modeling Loss: 1.5292 (1.6674)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1892 (3.5609)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8664)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8660)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8695)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8855)  Batch Accuracy (Choose Caption): 0.9375 (0.9239)  Batch Accuracy (Choose Image): 0.9375 (0.9232)  Masked Language Modeling Accuracy: 0.6800 (0.6573)  time: 0.6670 (0.7855)  data: 0.0194 (0.0949)  lr: 0.001000  max mem: 12203
2021-04-02 04:54:09,918 maskrcnn_benchmark.trainer INFO: eta: 1:06:44  iter: 34900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3211 (0.3994)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3629 (0.3907)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3127 (0.3785)  Cross-Entropy Loss (Align Words, Choose Image): 0.2725 (0.3277)  Image Caption Matching Loss: 0.2811 (0.3953)  Masked Language Modeling Loss: 1.6346 (1.6669)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1489 (3.5585)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8666)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8661)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8696)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8856)  Batch Accuracy (Choose Caption): 0.9375 (0.9240)  Batch Accuracy (Choose Image): 0.9375 (0.9233)  Masked Language Modeling Accuracy: 0.6524 (0.6574)  time: 0.6793 (0.7852)  data: 0.0200 (0.0946)  lr: 0.001000  max mem: 12203
2021-04-02 04:55:18,522 maskrcnn_benchmark.trainer INFO: eta: 1:05:23  iter: 35000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3473 (0.3991)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3224 (0.3904)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3024 (0.3781)  Cross-Entropy Loss (Align Words, Choose Image): 0.2378 (0.3273)  Image Caption Matching Loss: 0.2648 (0.3948)  Masked Language Modeling Loss: 1.6249 (1.6668)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0814 (3.5565)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8667)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8662)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8698)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8857)  Batch Accuracy (Choose Caption): 0.9531 (0.9241)  Batch Accuracy (Choose Image): 0.9375 (0.9234)  Masked Language Modeling Accuracy: 0.6793 (0.6574)  time: 0.6687 (0.7847)  data: 0.0198 (0.0943)  lr: 0.000100  max mem: 12203
2021-04-02 04:55:18,827 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0035000.pth
2021-04-02 04:56:29,597 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 1:05:23  iter: 35000  loss: 1.1717 (1.2318)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2340 (0.2389)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2287 (0.2415)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2390 (0.2643)  Cross-Entropy Loss (Align Words, Choose Image): 0.2142 (0.2171)  Image Caption Matching Loss: 0.2601 (0.2700)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9173)  Batch Accuracy (Align Regions, Choose Image): 0.9375 (0.9164)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9097)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9200)  Batch Accuracy (Choose Caption): 0.9375 (0.9472)  Batch Accuracy (Choose Image): 0.9531 (0.9513)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 12203
2021-04-02 04:57:40,043 maskrcnn_benchmark.trainer INFO: eta: 1:04:19  iter: 35100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2976 (0.3988)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3279 (0.3901)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2663 (0.3777)  Cross-Entropy Loss (Align Words, Choose Image): 0.2374 (0.3270)  Image Caption Matching Loss: 0.3271 (0.3945)  Masked Language Modeling Loss: 1.6424 (1.6666)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3353 (3.5547)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8668)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8663)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8699)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8859)  Batch Accuracy (Choose Caption): 0.9375 (0.9242)  Batch Accuracy (Choose Image): 0.9219 (0.9234)  Masked Language Modeling Accuracy: 0.6446 (0.6574)  time: 0.6699 (0.7877)  data: 0.0195 (0.0973)  lr: 0.000100  max mem: 12203
2021-04-02 04:58:49,110 maskrcnn_benchmark.trainer INFO: eta: 1:02:58  iter: 35200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3071 (0.3985)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2774 (0.3898)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2322 (0.3773)  Cross-Entropy Loss (Align Words, Choose Image): 0.2537 (0.3267)  Image Caption Matching Loss: 0.2568 (0.3941)  Masked Language Modeling Loss: 1.5386 (1.6663)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8714 (3.5528)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8669)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8664)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8700)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8859)  Batch Accuracy (Choose Caption): 0.9531 (0.9242)  Batch Accuracy (Choose Image): 0.9531 (0.9235)  Masked Language Modeling Accuracy: 0.6649 (0.6575)  time: 0.6812 (0.7873)  data: 0.0204 (0.0970)  lr: 0.000100  max mem: 12203
2021-04-02 05:00:03,835 maskrcnn_benchmark.trainer INFO: eta: 1:01:39  iter: 35300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3329 (0.3983)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3157 (0.3896)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3008 (0.3770)  Cross-Entropy Loss (Align Words, Choose Image): 0.2326 (0.3264)  Image Caption Matching Loss: 0.2774 (0.3937)  Masked Language Modeling Loss: 1.5804 (1.6662)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0394 (3.5511)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8670)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8665)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8701)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8860)  Batch Accuracy (Choose Caption): 0.9375 (0.9243)  Batch Accuracy (Choose Image): 0.9531 (0.9236)  Masked Language Modeling Accuracy: 0.6550 (0.6575)  time: 0.6778 (0.7871)  data: 0.0200 (0.0967)  lr: 0.000100  max mem: 12203
2021-04-02 05:01:18,839 maskrcnn_benchmark.trainer INFO: eta: 1:00:19  iter: 35400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3103 (0.3980)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2817 (0.3892)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2797 (0.3766)  Cross-Entropy Loss (Align Words, Choose Image): 0.2493 (0.3262)  Image Caption Matching Loss: 0.2214 (0.3932)  Masked Language Modeling Loss: 1.5393 (1.6658)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9348 (3.5490)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8671)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8666)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8703)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8861)  Batch Accuracy (Choose Caption): 0.9531 (0.9244)  Batch Accuracy (Choose Image): 0.9531 (0.9236)  Masked Language Modeling Accuracy: 0.6515 (0.6575)  time: 0.6731 (0.7869)  data: 0.0193 (0.0964)  lr: 0.000100  max mem: 12203
2021-04-02 05:02:27,747 maskrcnn_benchmark.trainer INFO: eta: 0:58:58  iter: 35500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3175 (0.3977)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2870 (0.3889)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2733 (0.3762)  Cross-Entropy Loss (Align Words, Choose Image): 0.2115 (0.3258)  Image Caption Matching Loss: 0.2339 (0.3927)  Masked Language Modeling Loss: 1.6257 (1.6655)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0214 (3.5468)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8672)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8667)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8704)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8863)  Batch Accuracy (Choose Caption): 0.9531 (0.9245)  Batch Accuracy (Choose Image): 0.9531 (0.9237)  Masked Language Modeling Accuracy: 0.6524 (0.6576)  time: 0.6645 (0.7864)  data: 0.0182 (0.0961)  lr: 0.000100  max mem: 12203
2021-04-02 05:03:39,816 maskrcnn_benchmark.trainer INFO: eta: 0:57:38  iter: 35600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3130 (0.3974)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2817 (0.3886)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2437 (0.3758)  Cross-Entropy Loss (Align Words, Choose Image): 0.2454 (0.3255)  Image Caption Matching Loss: 0.2752 (0.3923)  Masked Language Modeling Loss: 1.6048 (1.6653)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0369 (3.5448)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8673)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8668)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8705)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8864)  Batch Accuracy (Choose Caption): 0.9219 (0.9246)  Batch Accuracy (Choose Image): 0.9375 (0.9238)  Masked Language Modeling Accuracy: 0.6645 (0.6576)  time: 0.6741 (0.7861)  data: 0.0188 (0.0957)  lr: 0.000100  max mem: 12203
2021-04-02 05:04:49,147 maskrcnn_benchmark.trainer INFO: eta: 0:56:18  iter: 35700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2857 (0.3970)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2514 (0.3882)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2737 (0.3753)  Cross-Entropy Loss (Align Words, Choose Image): 0.2202 (0.3251)  Image Caption Matching Loss: 0.2283 (0.3917)  Masked Language Modeling Loss: 1.5777 (1.6647)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9142 (3.5421)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8674)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8669)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8707)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8865)  Batch Accuracy (Choose Caption): 0.9375 (0.9247)  Batch Accuracy (Choose Image): 0.9531 (0.9239)  Masked Language Modeling Accuracy: 0.6647 (0.6577)  time: 0.6651 (0.7857)  data: 0.0190 (0.0954)  lr: 0.000100  max mem: 12203
2021-04-02 05:06:07,088 maskrcnn_benchmark.trainer INFO: eta: 0:54:59  iter: 35800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3043 (0.3967)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3336 (0.3879)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2618 (0.3749)  Cross-Entropy Loss (Align Words, Choose Image): 0.2105 (0.3247)  Image Caption Matching Loss: 0.2678 (0.3912)  Masked Language Modeling Loss: 1.5979 (1.6645)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1182 (3.5398)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8675)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8671)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8708)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8866)  Batch Accuracy (Choose Caption): 0.9531 (0.9248)  Batch Accuracy (Choose Image): 0.9531 (0.9240)  Masked Language Modeling Accuracy: 0.6648 (0.6577)  time: 0.6723 (0.7857)  data: 0.0190 (0.0952)  lr: 0.000100  max mem: 12203
2021-04-02 05:07:19,329 maskrcnn_benchmark.trainer INFO: eta: 0:53:40  iter: 35900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3217 (0.3963)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2519 (0.3875)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2788 (0.3744)  Cross-Entropy Loss (Align Words, Choose Image): 0.2500 (0.3244)  Image Caption Matching Loss: 0.2502 (0.3906)  Masked Language Modeling Loss: 1.5770 (1.6642)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0383 (3.5375)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8676)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8672)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8710)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8867)  Batch Accuracy (Choose Caption): 0.9531 (0.9249)  Batch Accuracy (Choose Image): 0.9531 (0.9241)  Masked Language Modeling Accuracy: 0.6565 (0.6578)  time: 0.6663 (0.7854)  data: 0.0191 (0.0949)  lr: 0.000100  max mem: 12203
2021-04-02 05:08:31,832 maskrcnn_benchmark.trainer INFO: eta: 0:52:20  iter: 36000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3769 (0.3961)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2864 (0.3872)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2674 (0.3741)  Cross-Entropy Loss (Align Words, Choose Image): 0.2153 (0.3241)  Image Caption Matching Loss: 0.3043 (0.3903)  Masked Language Modeling Loss: 1.5621 (1.6637)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0428 (3.5354)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8677)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8673)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8711)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8868)  Batch Accuracy (Choose Caption): 0.9375 (0.9250)  Batch Accuracy (Choose Image): 0.9375 (0.9241)  Masked Language Modeling Accuracy: 0.6715 (0.6578)  time: 0.6716 (0.7851)  data: 0.0191 (0.0946)  lr: 0.000100  max mem: 12203
2021-04-02 05:08:32,117 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0036000.pth
2021-04-02 05:09:40,508 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:52:20  iter: 36000  loss: 1.2210 (1.2004)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2228 (0.2288)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2053 (0.2397)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2613 (0.2515)  Cross-Entropy Loss (Align Words, Choose Image): 0.2097 (0.2135)  Image Caption Matching Loss: 0.2816 (0.2669)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9198)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9151)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.9128)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9254)  Batch Accuracy (Choose Caption): 0.9375 (0.9480)  Batch Accuracy (Choose Image): 0.9531 (0.9517)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 12203
2021-04-02 05:10:54,949 maskrcnn_benchmark.trainer INFO: eta: 0:51:13  iter: 36100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2917 (0.3957)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3531 (0.3869)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2851 (0.3736)  Cross-Entropy Loss (Align Words, Choose Image): 0.2477 (0.3237)  Image Caption Matching Loss: 0.2510 (0.3897)  Masked Language Modeling Loss: 1.5210 (1.6634)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0365 (3.5331)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8679)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8674)  Batch Accuracy (Align Words, Choose Caption): 0.8750 (0.8712)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8869)  Batch Accuracy (Choose Caption): 0.9531 (0.9251)  Batch Accuracy (Choose Image): 0.9531 (0.9242)  Masked Language Modeling Accuracy: 0.6719 (0.6579)  time: 0.6722 (0.7880)  data: 0.0193 (0.0974)  lr: 0.000100  max mem: 12203
2021-04-02 05:12:04,561 maskrcnn_benchmark.trainer INFO: eta: 0:49:52  iter: 36200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3334 (0.3954)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2824 (0.3865)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2505 (0.3732)  Cross-Entropy Loss (Align Words, Choose Image): 0.2504 (0.3234)  Image Caption Matching Loss: 0.2661 (0.3893)  Masked Language Modeling Loss: 1.5984 (1.6632)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1252 (3.5309)  Batch Accuracy (Align Regions, Choose Caption): 0.8884 (0.8680)  Batch Accuracy (Align Regions, Choose Image): 0.8854 (0.8675)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8714)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8870)  Batch Accuracy (Choose Caption): 0.9531 (0.9252)  Batch Accuracy (Choose Image): 0.9531 (0.9243)  Masked Language Modeling Accuracy: 0.6419 (0.6579)  time: 0.6722 (0.7876)  data: 0.0186 (0.0971)  lr: 0.000100  max mem: 12203
2021-04-02 05:13:14,019 maskrcnn_benchmark.trainer INFO: eta: 0:48:32  iter: 36300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2810 (0.3951)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2980 (0.3862)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2272 (0.3728)  Cross-Entropy Loss (Align Words, Choose Image): 0.2280 (0.3231)  Image Caption Matching Loss: 0.2669 (0.3888)  Masked Language Modeling Loss: 1.5640 (1.6631)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9680 (3.5291)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8681)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8676)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8715)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8871)  Batch Accuracy (Choose Caption): 0.9531 (0.9253)  Batch Accuracy (Choose Image): 0.9531 (0.9244)  Masked Language Modeling Accuracy: 0.6467 (0.6579)  time: 0.6790 (0.7872)  data: 0.0187 (0.0968)  lr: 0.000100  max mem: 12203
2021-04-02 05:14:25,156 maskrcnn_benchmark.trainer INFO: eta: 0:47:12  iter: 36400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3040 (0.3948)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2970 (0.3859)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2846 (0.3725)  Cross-Entropy Loss (Align Words, Choose Image): 0.2310 (0.3228)  Image Caption Matching Loss: 0.2794 (0.3883)  Masked Language Modeling Loss: 1.5595 (1.6627)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9829 (3.5270)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8682)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8677)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8716)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8872)  Batch Accuracy (Choose Caption): 0.9531 (0.9254)  Batch Accuracy (Choose Image): 0.9375 (0.9245)  Masked Language Modeling Accuracy: 0.6786 (0.6580)  time: 0.6704 (0.7869)  data: 0.0185 (0.0965)  lr: 0.000100  max mem: 12203
2021-04-02 05:15:37,263 maskrcnn_benchmark.trainer INFO: eta: 0:45:53  iter: 36500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3091 (0.3945)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2642 (0.3856)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3025 (0.3722)  Cross-Entropy Loss (Align Words, Choose Image): 0.2215 (0.3225)  Image Caption Matching Loss: 0.2961 (0.3878)  Masked Language Modeling Loss: 1.5320 (1.6624)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9411 (3.5250)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8683)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8678)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8717)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8873)  Batch Accuracy (Choose Caption): 0.9531 (0.9255)  Batch Accuracy (Choose Image): 0.9375 (0.9246)  Masked Language Modeling Accuracy: 0.6688 (0.6580)  time: 0.6659 (0.7866)  data: 0.0190 (0.0962)  lr: 0.000100  max mem: 12203
2021-04-02 05:16:53,017 maskrcnn_benchmark.trainer INFO: eta: 0:44:33  iter: 36600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2866 (0.3942)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2977 (0.3853)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2445 (0.3718)  Cross-Entropy Loss (Align Words, Choose Image): 0.2311 (0.3223)  Image Caption Matching Loss: 0.1947 (0.3875)  Masked Language Modeling Loss: 1.6710 (1.6622)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9314 (3.5233)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8684)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8679)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8719)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8874)  Batch Accuracy (Choose Caption): 0.9531 (0.9256)  Batch Accuracy (Choose Image): 0.9531 (0.9246)  Masked Language Modeling Accuracy: 0.6482 (0.6580)  time: 0.6693 (0.7864)  data: 0.0188 (0.0959)  lr: 0.000100  max mem: 12203
2021-04-02 05:18:05,052 maskrcnn_benchmark.trainer INFO: eta: 0:43:14  iter: 36700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3137 (0.3940)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2540 (0.3851)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2259 (0.3715)  Cross-Entropy Loss (Align Words, Choose Image): 0.2115 (0.3220)  Image Caption Matching Loss: 0.2171 (0.3872)  Masked Language Modeling Loss: 1.6681 (1.6620)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8881 (3.5219)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8684)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.8680)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8720)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8875)  Batch Accuracy (Choose Caption): 0.9531 (0.9256)  Batch Accuracy (Choose Image): 0.9375 (0.9246)  Masked Language Modeling Accuracy: 0.6379 (0.6580)  time: 0.6747 (0.7862)  data: 0.0191 (0.0956)  lr: 0.000100  max mem: 12203
2021-04-02 05:19:17,007 maskrcnn_benchmark.trainer INFO: eta: 0:41:54  iter: 36800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3081 (0.3938)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2972 (0.3848)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2228 (0.3711)  Cross-Entropy Loss (Align Words, Choose Image): 0.2182 (0.3218)  Image Caption Matching Loss: 0.3008 (0.3868)  Masked Language Modeling Loss: 1.5262 (1.6618)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8729 (3.5200)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8685)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8681)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.8721)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8876)  Batch Accuracy (Choose Caption): 0.9375 (0.9257)  Batch Accuracy (Choose Image): 0.9375 (0.9247)  Masked Language Modeling Accuracy: 0.6597 (0.6581)  time: 0.6761 (0.7859)  data: 0.0191 (0.0953)  lr: 0.000100  max mem: 12203
2021-04-02 05:20:29,137 maskrcnn_benchmark.trainer INFO: eta: 0:40:35  iter: 36900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3529 (0.3935)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2677 (0.3845)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2908 (0.3707)  Cross-Entropy Loss (Align Words, Choose Image): 0.2314 (0.3215)  Image Caption Matching Loss: 0.3199 (0.3864)  Masked Language Modeling Loss: 1.4911 (1.6613)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9902 (3.5180)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8686)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8682)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8722)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8876)  Batch Accuracy (Choose Caption): 0.9219 (0.9258)  Batch Accuracy (Choose Image): 0.9531 (0.9248)  Masked Language Modeling Accuracy: 0.6802 (0.6582)  time: 0.6734 (0.7856)  data: 0.0193 (0.0950)  lr: 0.000100  max mem: 12203
2021-04-02 05:21:46,636 maskrcnn_benchmark.trainer INFO: eta: 0:39:16  iter: 37000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3199 (0.3932)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2927 (0.3842)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2916 (0.3704)  Cross-Entropy Loss (Align Words, Choose Image): 0.2428 (0.3212)  Image Caption Matching Loss: 0.2828 (0.3860)  Masked Language Modeling Loss: 1.4341 (1.6610)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0110 (3.5160)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8687)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8683)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8723)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8877)  Batch Accuracy (Choose Caption): 0.9375 (0.9259)  Batch Accuracy (Choose Image): 0.9375 (0.9248)  Masked Language Modeling Accuracy: 0.6738 (0.6582)  time: 0.6675 (0.7855)  data: 0.0191 (0.0947)  lr: 0.000100  max mem: 12203
2021-04-02 05:21:46,947 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0037000.pth
2021-04-02 05:22:55,400 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:39:16  iter: 37000  loss: 1.1647 (1.2079)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2403 (0.2325)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2248 (0.2432)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2607 (0.2597)  Cross-Entropy Loss (Align Words, Choose Image): 0.2043 (0.2098)  Image Caption Matching Loss: 0.3050 (0.2627)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9172)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9125)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.9085)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9268)  Batch Accuracy (Choose Caption): 0.9375 (0.9489)  Batch Accuracy (Choose Image): 0.9531 (0.9525)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 12203
2021-04-02 05:24:05,658 maskrcnn_benchmark.trainer INFO: eta: 0:38:05  iter: 37100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2997 (0.3929)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2929 (0.3839)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2880 (0.3700)  Cross-Entropy Loss (Align Words, Choose Image): 0.2657 (0.3209)  Image Caption Matching Loss: 0.2621 (0.3856)  Masked Language Modeling Loss: 1.5459 (1.6607)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8474 (3.5139)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8688)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8684)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8724)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8878)  Batch Accuracy (Choose Caption): 0.9375 (0.9260)  Batch Accuracy (Choose Image): 0.9531 (0.9249)  Masked Language Modeling Accuracy: 0.6983 (0.6583)  time: 0.6688 (0.7882)  data: 0.0188 (0.0974)  lr: 0.000100  max mem: 12203
2021-04-02 05:25:14,126 maskrcnn_benchmark.trainer INFO: eta: 0:36:45  iter: 37200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3014 (0.3926)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3095 (0.3837)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2770 (0.3696)  Cross-Entropy Loss (Align Words, Choose Image): 0.2308 (0.3206)  Image Caption Matching Loss: 0.2639 (0.3852)  Masked Language Modeling Loss: 1.5732 (1.6604)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0018 (3.5122)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8689)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8685)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8725)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8879)  Batch Accuracy (Choose Caption): 0.9375 (0.9260)  Batch Accuracy (Choose Image): 0.9531 (0.9250)  Masked Language Modeling Accuracy: 0.6613 (0.6583)  time: 0.6682 (0.7877)  data: 0.0186 (0.0971)  lr: 0.000100  max mem: 12203
2021-04-02 05:26:23,298 maskrcnn_benchmark.trainer INFO: eta: 0:35:25  iter: 37300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3267 (0.3923)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3189 (0.3834)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2944 (0.3693)  Cross-Entropy Loss (Align Words, Choose Image): 0.2634 (0.3204)  Image Caption Matching Loss: 0.2554 (0.3848)  Masked Language Modeling Loss: 1.5886 (1.6603)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0702 (3.5105)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8690)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8686)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8727)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8880)  Batch Accuracy (Choose Caption): 0.9375 (0.9261)  Batch Accuracy (Choose Image): 0.9531 (0.9250)  Masked Language Modeling Accuracy: 0.6561 (0.6583)  time: 0.6751 (0.7873)  data: 0.0195 (0.0968)  lr: 0.000100  max mem: 12203
2021-04-02 05:27:40,445 maskrcnn_benchmark.trainer INFO: eta: 0:34:06  iter: 37400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2747 (0.3920)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2899 (0.3831)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2521 (0.3689)  Cross-Entropy Loss (Align Words, Choose Image): 0.2295 (0.3201)  Image Caption Matching Loss: 0.2608 (0.3843)  Masked Language Modeling Loss: 1.6180 (1.6599)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8425 (3.5084)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8691)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8687)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8728)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8881)  Batch Accuracy (Choose Caption): 0.9531 (0.9262)  Batch Accuracy (Choose Image): 0.9375 (0.9251)  Masked Language Modeling Accuracy: 0.6597 (0.6584)  time: 0.6746 (0.7872)  data: 0.0201 (0.0965)  lr: 0.000100  max mem: 12203
2021-04-02 05:28:52,551 maskrcnn_benchmark.trainer INFO: eta: 0:32:47  iter: 37500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2867 (0.3917)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2603 (0.3829)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2600 (0.3686)  Cross-Entropy Loss (Align Words, Choose Image): 0.2153 (0.3199)  Image Caption Matching Loss: 0.1994 (0.3839)  Masked Language Modeling Loss: 1.6298 (1.6596)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9558 (3.5066)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8692)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8687)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8729)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8882)  Batch Accuracy (Choose Caption): 0.9531 (0.9263)  Batch Accuracy (Choose Image): 0.9688 (0.9252)  Masked Language Modeling Accuracy: 0.6584 (0.6584)  time: 0.6693 (0.7869)  data: 0.0192 (0.0962)  lr: 0.000100  max mem: 12203
2021-04-02 05:30:10,243 maskrcnn_benchmark.trainer INFO: eta: 0:31:28  iter: 37600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3053 (0.3914)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3078 (0.3826)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2725 (0.3682)  Cross-Entropy Loss (Align Words, Choose Image): 0.2170 (0.3195)  Image Caption Matching Loss: 0.2446 (0.3835)  Masked Language Modeling Loss: 1.4772 (1.6593)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8202 (3.5046)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8693)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8688)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8730)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8883)  Batch Accuracy (Choose Caption): 0.9531 (0.9264)  Batch Accuracy (Choose Image): 0.9531 (0.9252)  Masked Language Modeling Accuracy: 0.6562 (0.6585)  time: 0.6713 (0.7869)  data: 0.0194 (0.0959)  lr: 0.000100  max mem: 12203
2021-04-02 05:31:22,614 maskrcnn_benchmark.trainer INFO: eta: 0:30:09  iter: 37700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3252 (0.3911)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3617 (0.3823)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2693 (0.3678)  Cross-Entropy Loss (Align Words, Choose Image): 0.2384 (0.3192)  Image Caption Matching Loss: 0.2969 (0.3831)  Masked Language Modeling Loss: 1.5890 (1.6591)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1874 (3.5027)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8694)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8689)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8732)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8884)  Batch Accuracy (Choose Caption): 0.9219 (0.9264)  Batch Accuracy (Choose Image): 0.9375 (0.9253)  Masked Language Modeling Accuracy: 0.6591 (0.6585)  time: 0.6735 (0.7866)  data: 0.0189 (0.0956)  lr: 0.000100  max mem: 12203
2021-04-02 05:32:38,054 maskrcnn_benchmark.trainer INFO: eta: 0:28:50  iter: 37800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3467 (0.3909)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2889 (0.3820)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2835 (0.3676)  Cross-Entropy Loss (Align Words, Choose Image): 0.2415 (0.3190)  Image Caption Matching Loss: 0.2453 (0.3828)  Masked Language Modeling Loss: 1.4792 (1.6589)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9462 (3.5011)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8694)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8690)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8733)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8885)  Batch Accuracy (Choose Caption): 0.9375 (0.9265)  Batch Accuracy (Choose Image): 0.9375 (0.9254)  Masked Language Modeling Accuracy: 0.6823 (0.6585)  time: 0.6759 (0.7865)  data: 0.0192 (0.0953)  lr: 0.000100  max mem: 12203
2021-04-02 05:33:51,062 maskrcnn_benchmark.trainer INFO: eta: 0:27:31  iter: 37900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3528 (0.3906)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3429 (0.3818)  Cross-Entropy Loss (Align Words, Choose Caption): 0.3122 (0.3672)  Cross-Entropy Loss (Align Words, Choose Image): 0.2630 (0.3187)  Image Caption Matching Loss: 0.2708 (0.3823)  Masked Language Modeling Loss: 1.6264 (1.6587)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.3069 (3.4993)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8695)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8691)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8734)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8886)  Batch Accuracy (Choose Caption): 0.9531 (0.9266)  Batch Accuracy (Choose Image): 0.9375 (0.9254)  Masked Language Modeling Accuracy: 0.6578 (0.6586)  time: 0.6755 (0.7863)  data: 0.0193 (0.0950)  lr: 0.000100  max mem: 12203
2021-04-02 05:35:03,374 maskrcnn_benchmark.trainer INFO: eta: 0:26:12  iter: 38000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3283 (0.3904)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3129 (0.3816)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2984 (0.3669)  Cross-Entropy Loss (Align Words, Choose Image): 0.2667 (0.3185)  Image Caption Matching Loss: 0.3025 (0.3820)  Masked Language Modeling Loss: 1.6710 (1.6585)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.2130 (3.4979)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8696)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8692)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8735)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8887)  Batch Accuracy (Choose Caption): 0.9375 (0.9266)  Batch Accuracy (Choose Image): 0.9375 (0.9255)  Masked Language Modeling Accuracy: 0.6663 (0.6586)  time: 0.6720 (0.7860)  data: 0.0193 (0.0948)  lr: 0.000100  max mem: 12203
2021-04-02 05:35:03,650 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0038000.pth
2021-04-02 05:36:11,540 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:26:12  iter: 38000  loss: 1.2479 (1.1580)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2512 (0.2202)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2331 (0.2305)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2085 (0.2380)  Cross-Entropy Loss (Align Words, Choose Image): 0.2066 (0.2082)  Image Caption Matching Loss: 0.2545 (0.2611)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.9245)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9226)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.9150)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9253)  Batch Accuracy (Choose Caption): 0.9531 (0.9509)  Batch Accuracy (Choose Image): 0.9375 (0.9505)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 12203
2021-04-02 05:37:21,874 maskrcnn_benchmark.trainer INFO: eta: 0:24:58  iter: 38100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3173 (0.3902)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3034 (0.3813)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2515 (0.3666)  Cross-Entropy Loss (Align Words, Choose Image): 0.2466 (0.3182)  Image Caption Matching Loss: 0.2911 (0.3817)  Masked Language Modeling Loss: 1.6360 (1.6582)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0326 (3.4962)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8697)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8692)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.8736)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8887)  Batch Accuracy (Choose Caption): 0.9375 (0.9267)  Batch Accuracy (Choose Image): 0.9375 (0.9255)  Masked Language Modeling Accuracy: 0.6498 (0.6586)  time: 0.6774 (0.7885)  data: 0.0190 (0.0973)  lr: 0.000100  max mem: 12203
2021-04-02 05:38:31,508 maskrcnn_benchmark.trainer INFO: eta: 0:23:38  iter: 38200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3449 (0.3899)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3587 (0.3811)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2829 (0.3662)  Cross-Entropy Loss (Align Words, Choose Image): 0.2725 (0.3179)  Image Caption Matching Loss: 0.2639 (0.3813)  Masked Language Modeling Loss: 1.6538 (1.6581)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1740 (3.4944)  Batch Accuracy (Align Regions, Choose Caption): 0.8750 (0.8698)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8693)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8737)  Batch Accuracy (Align Words, Choose Image): 0.8906 (0.8888)  Batch Accuracy (Choose Caption): 0.9531 (0.9268)  Batch Accuracy (Choose Image): 0.9375 (0.9256)  Masked Language Modeling Accuracy: 0.6652 (0.6586)  time: 0.6725 (0.7881)  data: 0.0188 (0.0970)  lr: 0.000100  max mem: 12203
2021-04-02 05:39:43,284 maskrcnn_benchmark.trainer INFO: eta: 0:22:19  iter: 38300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2944 (0.3896)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3281 (0.3808)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2807 (0.3658)  Cross-Entropy Loss (Align Words, Choose Image): 0.2333 (0.3176)  Image Caption Matching Loss: 0.2831 (0.3809)  Masked Language Modeling Loss: 1.5722 (1.6579)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9340 (3.4926)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8699)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8694)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8738)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8889)  Batch Accuracy (Choose Caption): 0.9375 (0.9269)  Batch Accuracy (Choose Image): 0.9375 (0.9256)  Masked Language Modeling Accuracy: 0.6782 (0.6587)  time: 0.6687 (0.7878)  data: 0.0191 (0.0967)  lr: 0.000100  max mem: 12203
2021-04-02 05:40:51,605 maskrcnn_benchmark.trainer INFO: eta: 0:20:59  iter: 38400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3123 (0.3893)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3114 (0.3805)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2680 (0.3655)  Cross-Entropy Loss (Align Words, Choose Image): 0.2576 (0.3173)  Image Caption Matching Loss: 0.2929 (0.3805)  Masked Language Modeling Loss: 1.5493 (1.6576)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0868 (3.4906)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8700)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8695)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8740)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8890)  Batch Accuracy (Choose Caption): 0.9375 (0.9270)  Batch Accuracy (Choose Image): 0.9531 (0.9257)  Masked Language Modeling Accuracy: 0.6588 (0.6587)  time: 0.6721 (0.7874)  data: 0.0191 (0.0964)  lr: 0.000100  max mem: 12203
2021-04-02 05:42:04,912 maskrcnn_benchmark.trainer INFO: eta: 0:19:40  iter: 38500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3014 (0.3891)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2898 (0.3802)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2446 (0.3652)  Cross-Entropy Loss (Align Words, Choose Image): 0.2032 (0.3171)  Image Caption Matching Loss: 0.2614 (0.3801)  Masked Language Modeling Loss: 1.4476 (1.6573)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9110 (3.4890)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8701)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8696)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8741)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8891)  Batch Accuracy (Choose Caption): 0.9531 (0.9270)  Batch Accuracy (Choose Image): 0.9375 (0.9258)  Masked Language Modeling Accuracy: 0.6777 (0.6588)  time: 0.6798 (0.7872)  data: 0.0188 (0.0962)  lr: 0.000100  max mem: 12203
2021-04-02 05:43:14,491 maskrcnn_benchmark.trainer INFO: eta: 0:18:21  iter: 38600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2874 (0.3887)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2748 (0.3799)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2571 (0.3649)  Cross-Entropy Loss (Align Words, Choose Image): 0.1959 (0.3169)  Image Caption Matching Loss: 0.2478 (0.3798)  Masked Language Modeling Loss: 1.5272 (1.6569)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8985 (3.4870)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8702)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8697)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8742)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8891)  Batch Accuracy (Choose Caption): 0.9531 (0.9271)  Batch Accuracy (Choose Image): 0.9375 (0.9258)  Masked Language Modeling Accuracy: 0.6983 (0.6588)  time: 0.6743 (0.7868)  data: 0.0191 (0.0959)  lr: 0.000100  max mem: 12203
2021-04-02 05:44:30,158 maskrcnn_benchmark.trainer INFO: eta: 0:17:02  iter: 38700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2754 (0.3884)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2930 (0.3796)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2321 (0.3645)  Cross-Entropy Loss (Align Words, Choose Image): 0.2361 (0.3166)  Image Caption Matching Loss: 0.2749 (0.3793)  Masked Language Modeling Loss: 1.5484 (1.6565)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9776 (3.4850)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8703)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8698)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8743)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8892)  Batch Accuracy (Choose Caption): 0.9531 (0.9272)  Batch Accuracy (Choose Image): 0.9531 (0.9259)  Masked Language Modeling Accuracy: 0.6649 (0.6589)  time: 0.6723 (0.7867)  data: 0.0187 (0.0956)  lr: 0.000100  max mem: 12203
2021-04-02 05:45:41,618 maskrcnn_benchmark.trainer INFO: eta: 0:15:43  iter: 38800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2700 (0.3881)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2903 (0.3793)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2411 (0.3641)  Cross-Entropy Loss (Align Words, Choose Image): 0.2151 (0.3163)  Image Caption Matching Loss: 0.2843 (0.3789)  Masked Language Modeling Loss: 1.5394 (1.6563)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8239 (3.4832)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8704)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8699)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8744)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8893)  Batch Accuracy (Choose Caption): 0.9531 (0.9273)  Batch Accuracy (Choose Image): 0.9375 (0.9260)  Masked Language Modeling Accuracy: 0.6785 (0.6589)  time: 0.6763 (0.7864)  data: 0.0192 (0.0954)  lr: 0.000100  max mem: 12203
2021-04-02 05:46:49,820 maskrcnn_benchmark.trainer INFO: eta: 0:14:24  iter: 38900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2867 (0.3879)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2925 (0.3790)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2572 (0.3638)  Cross-Entropy Loss (Align Words, Choose Image): 0.2173 (0.3160)  Image Caption Matching Loss: 0.2556 (0.3786)  Masked Language Modeling Loss: 1.6437 (1.6561)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0488 (3.4815)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8705)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8700)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8745)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8894)  Batch Accuracy (Choose Caption): 0.9531 (0.9274)  Batch Accuracy (Choose Image): 0.9531 (0.9260)  Masked Language Modeling Accuracy: 0.6776 (0.6590)  time: 0.6665 (0.7860)  data: 0.0187 (0.0951)  lr: 0.000100  max mem: 12203
2021-04-02 05:47:58,619 maskrcnn_benchmark.trainer INFO: eta: 0:13:05  iter: 39000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3369 (0.3876)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3065 (0.3788)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2754 (0.3634)  Cross-Entropy Loss (Align Words, Choose Image): 0.2415 (0.3158)  Image Caption Matching Loss: 0.2921 (0.3782)  Masked Language Modeling Loss: 1.6643 (1.6560)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1182 (3.4798)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8706)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8701)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8746)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8895)  Batch Accuracy (Choose Caption): 0.9375 (0.9274)  Batch Accuracy (Choose Image): 0.9375 (0.9261)  Masked Language Modeling Accuracy: 0.6608 (0.6590)  time: 0.6763 (0.7856)  data: 0.0193 (0.0948)  lr: 0.000100  max mem: 12203
2021-04-02 05:47:58,925 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0039000.pth
2021-04-02 05:49:07,928 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:13:05  iter: 39000  loss: 1.1249 (1.1767)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2080 (0.2224)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2088 (0.2458)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2451 (0.2467)  Cross-Entropy Loss (Align Words, Choose Image): 0.2012 (0.2049)  Image Caption Matching Loss: 0.2486 (0.2568)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9239)  Batch Accuracy (Align Regions, Choose Image): 0.9375 (0.9157)  Batch Accuracy (Align Words, Choose Caption): 0.9219 (0.9095)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.9288)  Batch Accuracy (Choose Caption): 0.9531 (0.9533)  Batch Accuracy (Choose Image): 0.9688 (0.9547)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 12203
2021-04-02 05:50:17,908 maskrcnn_benchmark.trainer INFO: eta: 0:11:49  iter: 39100  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2831 (0.3873)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2738 (0.3785)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2782 (0.3631)  Cross-Entropy Loss (Align Words, Choose Image): 0.2726 (0.3155)  Image Caption Matching Loss: 0.2804 (0.3779)  Masked Language Modeling Loss: 1.6640 (1.6558)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.1015 (3.4781)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8707)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8702)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8747)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8896)  Batch Accuracy (Choose Caption): 0.9375 (0.9275)  Batch Accuracy (Choose Image): 0.9375 (0.9261)  Masked Language Modeling Accuracy: 0.6428 (0.6590)  time: 0.6821 (0.7880)  data: 0.0194 (0.0973)  lr: 0.000100  max mem: 12203
2021-04-02 05:51:26,785 maskrcnn_benchmark.trainer INFO: eta: 0:10:30  iter: 39200  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2851 (0.3871)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2834 (0.3783)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2558 (0.3628)  Cross-Entropy Loss (Align Words, Choose Image): 0.2239 (0.3152)  Image Caption Matching Loss: 0.2910 (0.3775)  Masked Language Modeling Loss: 1.5243 (1.6555)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8131 (3.4764)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8708)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8702)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8749)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8897)  Batch Accuracy (Choose Caption): 0.9375 (0.9276)  Batch Accuracy (Choose Image): 0.9375 (0.9262)  Masked Language Modeling Accuracy: 0.6869 (0.6591)  time: 0.6774 (0.7876)  data: 0.0187 (0.0970)  lr: 0.000100  max mem: 12203
2021-04-02 05:52:35,324 maskrcnn_benchmark.trainer INFO: eta: 0:09:11  iter: 39300  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2947 (0.3868)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2805 (0.3780)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2829 (0.3625)  Cross-Entropy Loss (Align Words, Choose Image): 0.2106 (0.3150)  Image Caption Matching Loss: 0.2686 (0.3772)  Masked Language Modeling Loss: 1.5561 (1.6554)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8555 (3.4749)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8709)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8703)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8750)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8898)  Batch Accuracy (Choose Caption): 0.9375 (0.9277)  Batch Accuracy (Choose Image): 0.9375 (0.9262)  Masked Language Modeling Accuracy: 0.6679 (0.6591)  time: 0.6700 (0.7872)  data: 0.0189 (0.0967)  lr: 0.000100  max mem: 12203
2021-04-02 05:53:47,450 maskrcnn_benchmark.trainer INFO: eta: 0:07:52  iter: 39400  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2977 (0.3866)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3009 (0.3778)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2631 (0.3622)  Cross-Entropy Loss (Align Words, Choose Image): 0.2250 (0.3148)  Image Caption Matching Loss: 0.2271 (0.3769)  Masked Language Modeling Loss: 1.5492 (1.6553)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9207 (3.4734)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8709)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8704)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8751)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8898)  Batch Accuracy (Choose Caption): 0.9531 (0.9277)  Batch Accuracy (Choose Image): 0.9531 (0.9263)  Masked Language Modeling Accuracy: 0.6712 (0.6591)  time: 0.6758 (0.7869)  data: 0.0193 (0.0964)  lr: 0.000100  max mem: 12203
2021-04-02 05:54:56,719 maskrcnn_benchmark.trainer INFO: eta: 0:06:33  iter: 39500  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3017 (0.3863)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2919 (0.3775)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2455 (0.3618)  Cross-Entropy Loss (Align Words, Choose Image): 0.2447 (0.3145)  Image Caption Matching Loss: 0.2168 (0.3765)  Masked Language Modeling Loss: 1.6179 (1.6552)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0378 (3.4718)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8710)  Batch Accuracy (Align Regions, Choose Image): 0.8750 (0.8705)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8752)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8899)  Batch Accuracy (Choose Caption): 0.9531 (0.9278)  Batch Accuracy (Choose Image): 0.9531 (0.9264)  Masked Language Modeling Accuracy: 0.6615 (0.6591)  time: 0.6683 (0.7866)  data: 0.0189 (0.0962)  lr: 0.000100  max mem: 12203
2021-04-02 05:56:10,837 maskrcnn_benchmark.trainer INFO: eta: 0:05:14  iter: 39600  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3012 (0.3861)  Cross-Entropy Loss (Align Regions, Choose Image): 0.3296 (0.3773)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2575 (0.3615)  Cross-Entropy Loss (Align Words, Choose Image): 0.2234 (0.3143)  Image Caption Matching Loss: 0.2679 (0.3761)  Masked Language Modeling Loss: 1.5381 (1.6550)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9559 (3.4704)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8711)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8706)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8753)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8900)  Batch Accuracy (Choose Caption): 0.9531 (0.9279)  Batch Accuracy (Choose Image): 0.9375 (0.9264)  Masked Language Modeling Accuracy: 0.6704 (0.6592)  time: 0.6798 (0.7864)  data: 0.0189 (0.0959)  lr: 0.000100  max mem: 12203
2021-04-02 05:57:19,633 maskrcnn_benchmark.trainer INFO: eta: 0:03:55  iter: 39700  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3010 (0.3859)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2753 (0.3770)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2629 (0.3612)  Cross-Entropy Loss (Align Words, Choose Image): 0.2513 (0.3140)  Image Caption Matching Loss: 0.2505 (0.3757)  Masked Language Modeling Loss: 1.5897 (1.6548)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9483 (3.4686)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8712)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8706)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8754)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8901)  Batch Accuracy (Choose Caption): 0.9375 (0.9280)  Batch Accuracy (Choose Image): 0.9531 (0.9265)  Masked Language Modeling Accuracy: 0.6542 (0.6592)  time: 0.6642 (0.7860)  data: 0.0195 (0.0956)  lr: 0.000100  max mem: 12203
2021-04-02 05:58:30,256 maskrcnn_benchmark.trainer INFO: eta: 0:02:37  iter: 39800  Cross-Entropy Loss (Align Regions, Choose Caption): 0.3225 (0.3857)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2962 (0.3768)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2622 (0.3609)  Cross-Entropy Loss (Align Words, Choose Image): 0.2315 (0.3138)  Image Caption Matching Loss: 0.2774 (0.3754)  Masked Language Modeling Loss: 1.5568 (1.6546)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 3.0437 (3.4672)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8712)  Batch Accuracy (Align Regions, Choose Image): 0.8906 (0.8707)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.8755)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8902)  Batch Accuracy (Choose Caption): 0.9531 (0.9280)  Batch Accuracy (Choose Image): 0.9375 (0.9265)  Masked Language Modeling Accuracy: 0.6641 (0.6592)  time: 0.6766 (0.7857)  data: 0.0188 (0.0954)  lr: 0.000100  max mem: 12203
2021-04-02 05:59:45,535 maskrcnn_benchmark.trainer INFO: eta: 0:01:18  iter: 39900  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2788 (0.3854)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2446 (0.3765)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2712 (0.3606)  Cross-Entropy Loss (Align Words, Choose Image): 0.1761 (0.3135)  Image Caption Matching Loss: 0.2473 (0.3751)  Masked Language Modeling Loss: 1.4966 (1.6545)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.8091 (3.4655)  Batch Accuracy (Align Regions, Choose Caption): 0.9062 (0.8713)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8708)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8756)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.8902)  Batch Accuracy (Choose Caption): 0.9531 (0.9281)  Batch Accuracy (Choose Image): 0.9531 (0.9266)  Masked Language Modeling Accuracy: 0.6766 (0.6593)  time: 0.6653 (0.7856)  data: 0.0188 (0.0951)  lr: 0.000100  max mem: 12203
2021-04-02 06:01:02,693 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 40000  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2991 (0.3852)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2888 (0.3763)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2758 (0.3603)  Cross-Entropy Loss (Align Words, Choose Image): 0.2584 (0.3133)  Image Caption Matching Loss: 0.2581 (0.3747)  Masked Language Modeling Loss: 1.4967 (1.6541)  Masked Visual Modeling Loss: 0.0000 (0.0000)  loss: 2.9025 (3.4640)  Batch Accuracy (Align Regions, Choose Caption): 0.8906 (0.8714)  Batch Accuracy (Align Regions, Choose Image): 0.9062 (0.8709)  Batch Accuracy (Align Words, Choose Caption): 0.9062 (0.8757)  Batch Accuracy (Align Words, Choose Image): 0.9062 (0.8903)  Batch Accuracy (Choose Caption): 0.9375 (0.9281)  Batch Accuracy (Choose Image): 0.9375 (0.9267)  Masked Language Modeling Accuracy: 0.6701 (0.6593)  time: 0.6767 (0.7855)  data: 0.0190 (0.0949)  lr: 0.000100  max mem: 12203
2021-04-02 06:01:03,018 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_0040000.pth
2021-04-02 06:02:12,644 maskrcnn_benchmark.trainer INFO: [Validation]:   eta: 0:00:00  iter: 40000  loss: 1.1194 (1.1405)  Cross-Entropy Loss (Align Regions, Choose Caption): 0.2286 (0.2192)  Cross-Entropy Loss (Align Regions, Choose Image): 0.2242 (0.2279)  Cross-Entropy Loss (Align Words, Choose Caption): 0.2322 (0.2396)  Cross-Entropy Loss (Align Words, Choose Image): 0.2053 (0.2033)  Image Caption Matching Loss: 0.2519 (0.2504)  Masked Language Modeling Loss: 0.0000 (0.0000)  Masked Visual Modeling Loss: 0.0000 (0.0000)  Batch Accuracy (Align Regions, Choose Caption): 0.9219 (0.9242)  Batch Accuracy (Align Regions, Choose Image): 0.9219 (0.9236)  Batch Accuracy (Align Words, Choose Caption): 0.8906 (0.9127)  Batch Accuracy (Align Words, Choose Image): 0.9219 (0.9299)  Batch Accuracy (Choose Caption): 0.9531 (0.9493)  Batch Accuracy (Choose Image): 0.9688 (0.9559)  Masked Language Modeling Accuracy: 0.0000 (0.0000)  lr: 0.000100  max mem: 12203
2021-04-02 06:02:13,167 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to /mnt/lustre/lixiangtai/runs/vltrain/121/model_final.pth
2021-04-02 06:02:14,447 maskrcnn_benchmark.trainer INFO: Total training time: 5:41:35.427487 (0.5124 s / it)
